{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points:\n",
    "\n",
    "1. **Using VEM/FEM Solutions for Efficient Training**:\n",
    "   - By training the neural network on the displacement field computed using VEM/FEM, you're providing the model with a high-quality reference solution. This allows the model to learn the underlying physical relationships between the parameters (such as Young’s modulus \\(E\\), cross-sectional area \\(A\\), and moment of inertia \\(I\\)) and the displacement field.\n",
    "\n",
    "2. **Generalization with Fewer Data**:\n",
    "   - Since the model is grounded in physically informed solutions, you likely need **fewer training examples** to generalize to new material and geometrical configurations. Unlike traditional machine learning models that require vast amounts of labeled data, your approach can rely on solving a **few instances** of VEM/FEM solutions and using that information to generalize.\n",
    "\n",
    "3. **Parameter Sensitivity and Inference**:\n",
    "   - The network’s sensitivity to material and geometrical parameters (\\(E\\), \\(A\\), \\(I\\)) is key. Once trained, the model will allow for **rapid inference** with new combinations of these parameters without needing to solve the full VEM/FEM system again.\n",
    "   - In an engineering context, this is particularly advantageous, as engineers often need to explore various material or geometric configurations during design optimization. Having a trained neural network that provides **instant predictions** without solving a full VEM/FEM problem would significantly improve efficiency.\n",
    "\n",
    "4. **Efficiency Compared to Traditional VEM/FEM**:\n",
    "   - Solving a full VEM/FEM problem repeatedly for different parameter values can be computationally expensive, especially for large or complex systems. By training a neural network to approximate the displacement field based on these parameters, you essentially create a **surrogate model** that can make predictions more efficiently.\n",
    "\n",
    "### Challenges and Considerations:\n",
    "- **Accuracy vs. Efficiency**: While the neural network may provide fast predictions, the trade-off is the potential for reduced accuracy compared to solving the full VEM/FEM system. This can be mitigated by fine-tuning the network and introducing additional regularization techniques like Sobolev training.\n",
    "  \n",
    "- **Extrapolation Limits**: The network might struggle with extrapolating far beyond the range of material and geometrical parameters it was trained on. Ensuring that the training data includes a representative range of parameters will be crucial for reliable generalization.\n",
    "\n",
    "- **Hybrid Model Validation**: You could validate your hypothesis by comparing the **computational cost** (in terms of time) and **accuracy** between solving multiple VEM/FEM instances and using the trained neural network for inference over a variety of material/geometrical configurations.\n",
    "\n",
    "### Conclusion:\n",
    "The approach of training a neural network using VEM/FEM solutions to enable efficient inference of displacement fields for different material and geometric configurations is a practical and promising solution in engineering contexts. It leverages the strengths of both numerical methods and machine learning to balance accuracy and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import core.vem as vem\n",
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "\n",
    "import utils.mesh as mesh\n",
    "import core.loss as loss_function\n",
    "import core.errors as errors\n",
    "import core.neural_backend as neural\n",
    "\n",
    "import solve_vem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS backend is available!\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS backend is available!\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS backend is not available. Using CPU.\")\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of elements per edge\n",
    "num_elements_per_edge = 128\n",
    "\n",
    "# geometry data\n",
    "L = 2.0\n",
    "I = 1e-4\n",
    "A = 1\n",
    "\n",
    "# material data\n",
    "E = 27e6\n",
    "\n",
    "# Define load parameters\n",
    "q = -400\n",
    "t = 0\n",
    "\n",
    "# Time sampling size\n",
    "time_sampling_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving time [s]: 0.0409\n",
      "######################### Beam ##########################\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "#########################################################\n"
     ]
    }
   ],
   "source": [
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Plot the nodes\n",
    "mesh.plot_nodes(nodes, elements)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Solving and Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring time for solving using VEM\n",
    "solving_time_list = []\n",
    "for _ in range(time_sampling_size):\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t)\n",
    "    solving_time_list.append(solving_time)\n",
    "\n",
    "print(\"Mean solving time: \", np.mean(solving_time_list))\n",
    "print(\"Std Deviation: \", np.std(solving_time_list))\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 800\n",
    "\n",
    "# Layers definition\n",
    "nodes_layers = [128, 256, 512, 512, 512, 512]  # Layers for nodes sub-network\n",
    "material_layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2048, 2048] # Layers for materials sub-network\n",
    "final_layers = [1024, 1024, 1024, 1024]  # Layers for final combination network\n",
    "\n",
    "# Training pipeline\n",
    "(input_vector, \n",
    " model, \n",
    " total_loss_values, \n",
    " loss_values, \n",
    " material_loss_values, \n",
    " sobolev_loss_values, \n",
    " alpha_values_values) = neural.train_material_portic(\n",
    "    epochs=num_epochs,\n",
    "    nodes=nodes,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    E=E,\n",
    "    A=A,\n",
    "    I=I,\n",
    "    uh_vem=uh_vem,\n",
    "    nodes_layers=nodes_layers,\n",
    "    material_layers=material_layers,\n",
    "    final_layers=final_layers,\n",
    "    verbose=True,\n",
    "    noramlize_inputs=True,\n",
    "    network_type=\"material\"\n",
    " )\n",
    "\n",
    "# Setting up material parameters\n",
    "material_params = torch.tensor([E , A , I ], dtype=torch.float32)\n",
    "# nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "\n",
    "# Measuring time spent for inference\n",
    "inference_time_list = []\n",
    "for _ in range(time_sampling_size):\n",
    "    predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    inference_time_list.append(inference_time)\n",
    "\n",
    "print(\"Mean inference time: \", np.mean(inference_time_list))\n",
    "print(\"Std Deviation: \", np.std(inference_time_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model refers to the disaplcement field and the loss function regards to the calculation of the residual taking in consideration the Virtual Element Method's stiffness matrix and load vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence of Deep Layers in the Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing layer 1/10\n",
      "Material params shape: torch.Size([3])\n",
      "Nodes shape: torch.Size([770])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py:131: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  normalized_nodes = torch.tensor(normalized_nodes, dtype=torch.float32, requires_grad=True)\n",
      "/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py:132: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  normalized_material_params = torch.tensor(normalized_material_params, dtype=torch.float32, requires_grad=True)\n",
      "/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py:169: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n",
      "/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 47\u001b[0m\n\u001b[1;32m     38\u001b[0m final_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(layer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Training pipeline\u001b[39;00m\n\u001b[1;32m     41\u001b[0m (input_vector, \n\u001b[1;32m     42\u001b[0m model, \n\u001b[1;32m     43\u001b[0m total_loss_values, \n\u001b[1;32m     44\u001b[0m loss_values, \n\u001b[1;32m     45\u001b[0m material_loss_values, \n\u001b[1;32m     46\u001b[0m sobolev_loss_values, \n\u001b[0;32m---> 47\u001b[0m alpha_values_values) \u001b[38;5;241m=\u001b[39m \u001b[43mneural\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_material_portic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mI\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mI\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43muh_vem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muh_vem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaterial_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaterial_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnoramlize_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaterial\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     62\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Setting up material parameters\u001b[39;00m\n\u001b[1;32m     65\u001b[0m material_params \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([E , A , I ], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/Main/_repos/ai-pinn/core/neural_backend.py:235\u001b[0m, in \u001b[0;36mtrain_material_portic\u001b[0;34m(epochs, nodes, K, f, E, A, I, uh_vem, nodes_layers, material_layers, final_layers, verbose, noramlize_inputs, network_type)\u001b[0m\n\u001b[1;32m    232\u001b[0m alpha \u001b[38;5;241m=\u001b[39m loss_function\u001b[38;5;241m.\u001b[39mnormalize_loss_and_penalty(loss, material_penalty)\n\u001b[1;32m    233\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m+\u001b[39m alpha \u001b[38;5;241m*\u001b[39m material_penalty \u001b[38;5;241m+\u001b[39m sobolev_loss\n\u001b[0;32m--> 235\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 800\n",
    "\n",
    "# Reading the json with respective layers\n",
    "with open(\"data/layers_20240929.json\", \"r\") as data:\n",
    "    layers = json.load(data)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i,layer in enumerate(layers):\n",
    "\n",
    "    # Define the number of elements per edge\n",
    "    num_elements_per_edge = 128\n",
    "\n",
    "    # geometry data\n",
    "    L = 2.0\n",
    "    I = 1e-4\n",
    "    A = 1\n",
    "\n",
    "    # material data\n",
    "    E = 27e6\n",
    "\n",
    "    # Define load parameters\n",
    "    q = -400\n",
    "    t = 0\n",
    "\n",
    "\n",
    "    # Generate the geometry\n",
    "    nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "    # Solve the problem using the VEM\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t, verbose=False)\n",
    "\n",
    "    print(f\"Training and testing layer {i+1}/{len(layers)}\")\n",
    "    # Defining layers\n",
    "    nodes_layers = list(layer[\"node_layers\"])\n",
    "    material_layers = list(layer[\"material_layers\"])\n",
    "    final_layers = list(layer[\"final_layers\"])\n",
    "\n",
    "    # Training pipeline\n",
    "    (input_vector, \n",
    "    model, \n",
    "    total_loss_values, \n",
    "    loss_values, \n",
    "    material_loss_values, \n",
    "    sobolev_loss_values, \n",
    "    alpha_values_values) = neural.train_material_portic(\n",
    "        epochs=num_epochs,\n",
    "        nodes=nodes,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        E=E,\n",
    "        A=A,\n",
    "        I=I,\n",
    "        uh_vem=uh_vem,\n",
    "        nodes_layers=nodes_layers,\n",
    "        material_layers=material_layers,\n",
    "        final_layers=final_layers,\n",
    "        verbose=False,\n",
    "        noramlize_inputs=True,\n",
    "        network_type=\"material\"\n",
    "    )\n",
    "\n",
    "    # Setting up material parameters\n",
    "    material_params = torch.tensor([E , A , I ], dtype=torch.float32)\n",
    "    nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "\n",
    "    # Testing the model with default parameters\n",
    "    predicted_displacements, l2_error_default, energy_error_default, h1_error_default, inference_time_default = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Setting up new material parameters\n",
    "    I_new = 1e-4\n",
    "    A_new = 2\n",
    "    E_new = 110e5\n",
    "\n",
    "    # Generate the geometry\n",
    "    nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "    # Solve the problem using the VEM\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new, A_new, I_new, load, q, t)\n",
    "\n",
    "    # Testing the model with new parameters\n",
    "    material_params = torch.tensor([E_new , A_new , I_new], dtype=torch.float32)\n",
    "    nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "    nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "    predicted_displacements, l2_error_new, energy_error_new, h1_error_new, inference_time_new = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Setting up new material parameters\n",
    "    I_new_2 = 1e-4\n",
    "    A_new_2 = 3\n",
    "    E_new_2 = 80e3\n",
    "\n",
    "    # Generate the geometry\n",
    "    nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "    # Solve the problem using the VEM\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new_2, A_new_2, I_new_2, load, q, t)\n",
    "\n",
    "    # Testing the model with new parameters\n",
    "    material_params = torch.tensor([E_new_2 , A_new_2 , I_new_2], dtype=torch.float32)\n",
    "    nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "    nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "    predicted_displacements, l2_error_new, energy_error_new, h1_error_new, inference_time_new = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"tag\": layer[\"tag\"],\n",
    "        \"l2_error_default\": l2_error_default,\n",
    "        \"energy_error_default\": energy_error_default,\n",
    "        \"h1_error_default\": h1_error_default,\n",
    "        \"inferece_time_default\": inference_time_default,\n",
    "        \"l2_error_new\": l2_error_new,\n",
    "        \"energy_error_new\": energy_error_new,\n",
    "        \"h1_error_new\": h1_error_new,\n",
    "        \"inferece_time_new\": inference_time_new,\n",
    "        \"l2_error_new_2\": l2_error_new,\n",
    "        \"energy_error_new_2\": energy_error_new,\n",
    "        \"h1_error_new_2\": h1_error_new,\n",
    "        \"inferece_time_new_2\": inference_time_new,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in a dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"data/output/results_20240929.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 800\n",
    "\n",
    "# Layers definition\n",
    "nodes_layers = [128, 256, 512, 512, 512, 512]  # Layers for nodes sub-network\n",
    "material_layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2048, 2048] # Layers for materials sub-network\n",
    "final_layers = [1024, 1024, 1024, 1024]  # Layers for final combination network\n",
    "\n",
    "# Training pipeline\n",
    "(input_vector, \n",
    " model, \n",
    " total_loss_values, \n",
    " loss_values, \n",
    " material_loss_values, \n",
    " sobolev_loss_values, \n",
    " alpha_values_values) = neural.train_material_portic(\n",
    "    epochs=num_epochs,\n",
    "    nodes=nodes,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    E=E,\n",
    "    A=A,\n",
    "    I=I,\n",
    "    uh_vem=uh_vem,\n",
    "    nodes_layers=nodes_layers,\n",
    "    material_layers=material_layers,\n",
    "    final_layers=final_layers,\n",
    "    verbose=True,\n",
    "    noramlize_inputs=True,\n",
    "    network_type=\"material\"\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the reference displacement field calculated by the Virtual Element Method, a displacemente field is supposed to be calculated considering the material parameters contributions to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_total_loss = total_loss_values[150:]\n",
    "plt.plot(filtered_total_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_loss = loss_values[150:]\n",
    "plt.plot(filtered_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_material_loss = material_loss_values[150:]\n",
    "plt.plot(filtered_material_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Material Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_sobolev_loss = sobolev_loss_values[150:]\n",
    "plt.plot(filtered_sobolev_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Sobolev Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_alpha_values = alpha_values_values[150:]\n",
    "plt.plot(filtered_alpha_values)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('alpha')\n",
    "plt.title('Alpha Values over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material_params = torch.tensor([E , A , I ], dtype=torch.float32)\n",
    "# nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geometry parameter\n",
    "I = 1e-4\n",
    "A = 2\n",
    "E = 110e5\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t)\n",
    "\n",
    "# Testing the model with new parameters\n",
    "material_params = torch.tensor([E , A , I ], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
