{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points:\n",
    "\n",
    "1. **Using VEM/FEM Solutions for Efficient Training**:\n",
    "   - By training the neural network on the displacement field computed using VEM/FEM, you're providing the model with a high-quality reference solution. This allows the model to learn the underlying physical relationships between the parameters (such as Young’s modulus \\(E\\), cross-sectional area \\(A\\), and moment of inertia \\(I\\)) and the displacement field.\n",
    "\n",
    "2. **Generalization with Fewer Data**:\n",
    "   - Since the model is grounded in physically informed solutions, you likely need **fewer training examples** to generalize to new material and geometrical configurations. Unlike traditional machine learning models that require vast amounts of labeled data, your approach can rely on solving a **few instances** of VEM/FEM solutions and using that information to generalize.\n",
    "\n",
    "3. **Parameter Sensitivity and Inference**:\n",
    "   - The network’s sensitivity to material and geometrical parameters (\\(E\\), \\(A\\), \\(I\\)) is key. Once trained, the model will allow for **rapid inference** with new combinations of these parameters without needing to solve the full VEM/FEM system again.\n",
    "   - In an engineering context, this is particularly advantageous, as engineers often need to explore various material or geometric configurations during design optimization. Having a trained neural network that provides **instant predictions** without solving a full VEM/FEM problem would significantly improve efficiency.\n",
    "\n",
    "4. **Efficiency Compared to Traditional VEM/FEM**:\n",
    "   - Solving a full VEM/FEM problem repeatedly for different parameter values can be computationally expensive, especially for large or complex systems. By training a neural network to approximate the displacement field based on these parameters, you essentially create a **surrogate model** that can make predictions more efficiently.\n",
    "\n",
    "### Challenges and Considerations:\n",
    "- **Accuracy vs. Efficiency**: While the neural network may provide fast predictions, the trade-off is the potential for reduced accuracy compared to solving the full VEM/FEM system. This can be mitigated by fine-tuning the network and introducing additional regularization techniques like Sobolev training.\n",
    "  \n",
    "- **Extrapolation Limits**: The network might struggle with extrapolating far beyond the range of material and geometrical parameters it was trained on. Ensuring that the training data includes a representative range of parameters will be crucial for reliable generalization.\n",
    "\n",
    "- **Hybrid Model Validation**: You could validate your hypothesis by comparing the **computational cost** (in terms of time) and **accuracy** between solving multiple VEM/FEM instances and using the trained neural network for inference over a variety of material/geometrical configurations.\n",
    "\n",
    "### Conclusion:\n",
    "The approach of training a neural network using VEM/FEM solutions to enable efficient inference of displacement fields for different material and geometric configurations is a practical and promising solution in engineering contexts. It leverages the strengths of both numerical methods and machine learning to balance accuracy and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import core.vem as vem\n",
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "\n",
    "import utils.mesh as mesh\n",
    "import core.loss as loss_function\n",
    "import core.errors as errors\n",
    "import core.neural_backend as neural\n",
    "\n",
    "import solve_vem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS backend is available!\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS backend is available!\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS backend is not available. Using CPU.\")\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of elements per edge\n",
    "num_elements_per_edge = 32\n",
    "\n",
    "# geometry data\n",
    "L = 2.0\n",
    "I = 1e-4\n",
    "A = 1\n",
    "\n",
    "# material data\n",
    "E = 27e6\n",
    "\n",
    "# Define load parameters\n",
    "q = -400\n",
    "t = 0\n",
    "\n",
    "# Time sampling size\n",
    "time_sampling_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving time [s]: 0.0011\n",
      "######################### Beam ##########################\n",
      "[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -6.11294039e-19\n",
      " -1.94881114e-06  2.00665681e-18 -1.07225777e-18 -3.89762227e-06\n",
      " -4.81056994e-18 -1.20533083e-18 -5.84643341e-06 -8.48584458e-18\n",
      " -1.20465840e-18 -7.79524455e-06 -9.09042567e-18 -1.17311919e-18\n",
      " -9.74405568e-06 -9.47358127e-18 -1.20009988e-18 -1.16928668e-05\n",
      " -7.21778913e-18 -1.06211412e-18 -1.36416780e-05 -1.47525077e-17\n",
      " -1.56704915e-18 -1.55904891e-05  1.33556765e-17  2.95131067e-19\n",
      " -1.75393002e-05 -9.05001960e-17 -6.58894322e-18 -1.94881114e-05\n",
      "  2.93235821e-16  1.88480147e-17 -2.14369225e-05 -1.12477323e-15\n",
      " -7.51477879e-17 -2.33857336e-05  4.11508416e-15  2.72187318e-16\n",
      " -2.53345448e-05 -1.52473623e-14 -1.01129425e-15 -2.72833559e-05\n",
      "  5.63012177e-14  3.73145723e-15 -2.92321670e-05 -2.08086820e-13\n",
      " -1.37940730e-14 -3.11809782e-05  7.68886231e-13  5.09666882e-14\n",
      " -3.31297893e-05 -2.84124814e-12 -1.88338838e-13 -3.50786005e-05\n",
      "  1.04990074e-11  6.95948712e-13 -3.70274116e-05 -3.87962266e-11\n",
      " -2.57169197e-12 -3.89762227e-05  1.43360711e-10  9.50297265e-12\n",
      " -4.09250339e-05 -5.29749996e-10 -3.51156192e-11 -4.28738450e-05\n",
      "  1.95754492e-09  1.29760077e-10 -4.48226561e-05 -7.23356722e-09\n",
      " -4.79492571e-10 -4.67714673e-05  2.67296519e-08  1.77183250e-09\n",
      " -4.87202784e-05 -9.87720544e-08 -6.54731819e-09 -5.06690896e-05\n",
      "  3.64984877e-07  2.41938080e-08 -5.26179007e-05 -1.34870092e-06\n",
      " -8.94015428e-08 -5.45667118e-05  4.98375214e-06  3.30358736e-07\n",
      " -5.65155230e-05 -1.84160811e-05 -1.22074957e-06 -5.84643341e-05\n",
      "  6.80515468e-05  4.51094324e-06 -6.04131452e-05 -2.51465717e-04\n",
      " -1.66689462e-05 -6.23619564e-05  9.29222179e-04 -1.66689462e-05\n",
      " -2.49403084e-05  4.68257634e-04 -1.66689462e-05 -1.14713779e-05\n",
      "  1.56707057e-04 -1.66689462e-05 -1.02158223e-05  7.14014743e-05\n",
      " -1.66689462e-05 -1.13480773e-05  7.42689527e-05 -1.66689462e-05\n",
      " -1.18228193e-05  8.64137252e-05 -1.66689462e-05 -1.16199620e-05\n",
      "  8.99239695e-05 -1.66689462e-05 -1.11843858e-05  8.78325676e-05\n",
      " -1.66689462e-05 -1.07363370e-05  8.42949259e-05 -1.66689462e-05\n",
      " -1.03169442e-05  8.08874125e-05 -1.66689462e-05 -9.91340720e-06\n",
      "  7.77593785e-05 -1.66689462e-05 -9.51333441e-06  7.47483930e-05\n",
      " -1.66689462e-05 -9.11258594e-06  7.17528371e-05 -1.66689462e-05\n",
      " -8.71099027e-06  6.87473397e-05 -1.66689462e-05 -8.30908177e-06\n",
      "  6.57346839e-05 -1.66689462e-05 -7.90714701e-06  6.27200166e-05\n",
      " -1.66689462e-05 -7.50524612e-06  5.97054363e-05 -1.66689462e-05\n",
      " -7.10336572e-06  5.66911975e-05 -1.66689462e-05 -6.70149018e-06\n",
      "  5.36771172e-05 -1.66689462e-05 -6.29961428e-06  5.06630455e-05\n",
      " -1.66689462e-05 -5.89773628e-06  4.76490206e-05 -1.66689462e-05\n",
      " -5.49586171e-06  4.46347723e-05 -1.66689462e-05 -5.09397289e-06\n",
      "  4.16213132e-05 -1.66689462e-05 -4.69213661e-06  3.86049272e-05\n",
      " -1.66689462e-05 -4.29010633e-06  3.55993577e-05 -1.66689462e-05\n",
      " -3.88879303e-06  3.25538202e-05 -1.66689462e-05 -3.48483035e-06\n",
      "  2.96559744e-05 -1.66689462e-05 -3.09065773e-06  2.62123746e-05\n",
      " -1.66689462e-05 -2.66030863e-06  2.47854582e-05 -1.66689462e-05\n",
      " -2.36363974e-06  1.59064445e-05 -1.66689462e-05 -1.57299253e-06\n",
      "  3.45646005e-05 -1.66689462e-05 -2.60770588e-06 -4.85332570e-05\n",
      " -1.66689462e-05  3.10269711e-06  2.44380160e-04 -4.90681721e-06\n",
      "  3.00573783e-06  1.32007968e-04  9.26621974e-08  2.90877854e-06\n",
      "  2.79753734e-05  7.77873404e-07  2.81181926e-06 -6.04861474e-06\n",
      "  3.66021873e-07  2.71485997e-06 -7.13063427e-06  6.25963471e-08\n",
      "  2.61790069e-06 -2.57898256e-06 -2.40822363e-08  2.52094140e-06\n",
      " -1.94732114e-07 -2.11061147e-08  2.42398212e-06  2.89968006e-07\n",
      " -6.71104246e-09  2.32702283e-06  1.70674305e-07 -1.25888822e-10\n",
      "  2.23006355e-06  4.00506109e-08  9.40533016e-10  2.13310426e-06\n",
      " -5.92511206e-09  4.78084318e-10  2.03614498e-06 -8.87324628e-09\n",
      "  9.30332502e-11  1.93918569e-06 -3.44838788e-09 -2.59508058e-11\n",
      "  1.84222641e-06 -3.59101896e-10 -2.65630429e-11  1.74526713e-06\n",
      "  3.39510326e-10 -9.09682050e-12  1.64830784e-06  2.19408809e-10\n",
      " -4.76171238e-13  1.55134856e-06  5.64519850e-11  1.12569390e-12\n",
      "  1.45438927e-06 -5.19228312e-12  6.20802451e-13  1.35742999e-06\n",
      " -1.09642257e-11  1.35079797e-13  1.26047070e-06 -4.57888174e-12\n",
      " -2.67279550e-14  1.16351142e-06 -5.98948824e-13 -3.32211745e-14\n",
      "  1.06655213e-06  3.91183282e-13 -1.22329051e-14  9.69592847e-07\n",
      "  2.80458819e-13 -1.01426933e-15  8.72633563e-07  7.85550065e-14\n",
      "  1.33039671e-15  7.75674278e-07 -3.50821239e-15  8.00336905e-16\n",
      "  6.78714993e-07 -1.34362207e-14  1.91418290e-16  5.81755708e-07\n",
      " -6.03169426e-15 -2.67919063e-17  4.84796424e-07 -9.33551324e-16\n",
      " -4.24328640e-17  3.87837139e-07  4.50521385e-16 -1.74943124e-17\n",
      "  2.90877854e-07  3.64992977e-16 -2.96629836e-18  1.93918569e-07\n",
      "  1.17384181e-16  3.50978645e-19  9.69592847e-08  6.24939266e-18\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "#########################################################\n"
     ]
    }
   ],
   "source": [
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Plot the nodes\n",
    "mesh.plot_nodes(nodes, elements)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Solving and Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring time for solving using VEM\n",
    "solving_time_list = []\n",
    "for _ in range(time_sampling_size):\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t)\n",
    "    solving_time_list.append(solving_time)\n",
    "\n",
    "print(\"Mean solving time: \", np.mean(solving_time_list))\n",
    "print(\"Std Deviation: \", np.std(solving_time_list))\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 800\n",
    "\n",
    "# Layers definition\n",
    "nodes_layers = [128, 256, 512, 512, 512, 512]  # Layers for nodes sub-network\n",
    "material_layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2048, 2048] # Layers for materials sub-network\n",
    "final_layers = [1024, 1024, 1024, 1024]  # Layers for final combination network\n",
    "\n",
    "# Training pipeline\n",
    "(input_vector, \n",
    " model, \n",
    " total_loss_values, \n",
    " loss_values, \n",
    " material_loss_values, \n",
    " sobolev_loss_values, \n",
    " alpha_values_values) = neural.train_material_portic(\n",
    "    epochs=num_epochs,\n",
    "    nodes=nodes,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    E=E,\n",
    "    A=A,\n",
    "    I=I,\n",
    "    uh_vem=uh_vem,\n",
    "    nodes_layers=nodes_layers,\n",
    "    material_layers=material_layers,\n",
    "    final_layers=final_layers,\n",
    "    verbose=True,\n",
    "    noramlize_inputs=True,\n",
    "    network_type=\"material\"\n",
    " )\n",
    "\n",
    "# Setting up material parameters\n",
    "material_params = torch.tensor([E , A , I ], dtype=torch.float32)\n",
    "# nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "\n",
    "# Measuring time spent for inference\n",
    "inference_time_list = []\n",
    "for _ in range(time_sampling_size):\n",
    "    predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    inference_time_list.append(inference_time)\n",
    "\n",
    "print(\"Mean inference time: \", np.mean(inference_time_list))\n",
    "print(\"Std Deviation: \", np.std(inference_time_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model refers to the disaplcement field and the loss function regards to the calculation of the residual taking in consideration the Virtual Element Method's stiffness matrix and load vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence of Deep Layers in the Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 800\n",
    "\n",
    "# Reading the json with respective layers\n",
    "with open(\"data/layers_20240929.json\", \"r\") as data:\n",
    "    layers = json.load(data)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i,layer in enumerate(layers):\n",
    "\n",
    "    # Define the number of elements per edge\n",
    "    num_elements_per_edge = 128\n",
    "\n",
    "    # geometry data\n",
    "    L = 2.0\n",
    "    I = 1e-4\n",
    "    A = 1\n",
    "\n",
    "    # material data\n",
    "    E = 27e6\n",
    "\n",
    "    # Define load parameters\n",
    "    q = -400\n",
    "    t = 0\n",
    "\n",
    "\n",
    "    # Generate the geometry\n",
    "    nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "    # Solve the problem using the VEM\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t, verbose=False)\n",
    "\n",
    "    print(f\"Training and testing layer {i+1}/{len(layers)}\")\n",
    "    # Defining layers\n",
    "    nodes_layers = list(layer[\"node_layers\"])\n",
    "    material_layers = list(layer[\"material_layers\"])\n",
    "    final_layers = list(layer[\"final_layers\"])\n",
    "\n",
    "    # Training pipeline\n",
    "    (input_vector, \n",
    "    model, \n",
    "    total_loss_values, \n",
    "    loss_values, \n",
    "    material_loss_values, \n",
    "    sobolev_loss_values, \n",
    "    alpha_values_values) = neural.train_material_portic(\n",
    "        epochs=num_epochs,\n",
    "        nodes=nodes,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        E=E,\n",
    "        A=A,\n",
    "        I=I,\n",
    "        uh_vem=uh_vem,\n",
    "        nodes_layers=nodes_layers,\n",
    "        material_layers=material_layers,\n",
    "        final_layers=final_layers,\n",
    "        verbose=False,\n",
    "        noramlize_inputs=True,\n",
    "        network_type=\"material\"\n",
    "    )\n",
    "\n",
    "    # Setting up material parameters\n",
    "    material_params = torch.tensor([E , A , I ], dtype=torch.float32)\n",
    "    nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "\n",
    "    # Testing the model with default parameters\n",
    "    predicted_displacements, l2_error_default, energy_error_default, h1_error_default, inference_time_default = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Setting up new material parameters\n",
    "    I_new = 1e-4\n",
    "    A_new = 2\n",
    "    E_new = 110e5\n",
    "\n",
    "    # Generate the geometry\n",
    "    nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "    # Solve the problem using the VEM\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new, A_new, I_new, load, q, t)\n",
    "\n",
    "    # Testing the model with new parameters\n",
    "    material_params = torch.tensor([E_new , A_new , I_new], dtype=torch.float32)\n",
    "    nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "    nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "    predicted_displacements, l2_error_new, energy_error_new, h1_error_new, inference_time_new = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Setting up new material parameters\n",
    "    I_new_2 = 1e-4\n",
    "    A_new_2 = 3\n",
    "    E_new_2 = 80e3\n",
    "\n",
    "    # Generate the geometry\n",
    "    nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "    # Solve the problem using the VEM\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new_2, A_new_2, I_new_2, load, q, t)\n",
    "\n",
    "    # Testing the model with new parameters\n",
    "    material_params = torch.tensor([E_new_2 , A_new_2 , I_new_2], dtype=torch.float32)\n",
    "    nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "    nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "    predicted_displacements, l2_error_new, energy_error_new, h1_error_new, inference_time_new = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"tag\": layer[\"tag\"],\n",
    "        \"l2_error_default\": l2_error_default,\n",
    "        \"energy_error_default\": energy_error_default,\n",
    "        \"h1_error_default\": h1_error_default,\n",
    "        \"inferece_time_default\": inference_time_default,\n",
    "        \"l2_error_new\": l2_error_new,\n",
    "        \"energy_error_new\": energy_error_new,\n",
    "        \"h1_error_new\": h1_error_new,\n",
    "        \"inferece_time_new\": inference_time_new,\n",
    "        \"l2_error_new_2\": l2_error_new,\n",
    "        \"energy_error_new_2\": energy_error_new,\n",
    "        \"h1_error_new_2\": h1_error_new,\n",
    "        \"inferece_time_new_2\": inference_time_new,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in a dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"data/output/results_20240929.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 800\n",
    "\n",
    "# Layers definition\n",
    "nodes_layers = [128, 256, 512, 512, 512, 512]  # Layers for nodes sub-network\n",
    "material_layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2048, 2048] # Layers for materials sub-network\n",
    "final_layers = [1024, 1024, 1024, 1024]  # Layers for final combination network\n",
    "\n",
    "# Training pipeline\n",
    "(input_vector, \n",
    " model, \n",
    " total_loss_values, \n",
    " loss_values, \n",
    " material_loss_values, \n",
    " sobolev_loss_values, \n",
    " alpha_values_values) = neural.train_material_portic(\n",
    "    epochs=num_epochs,\n",
    "    nodes=nodes,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    E=E,\n",
    "    A=A,\n",
    "    I=I,\n",
    "    uh_vem=uh_vem,\n",
    "    nodes_layers=nodes_layers,\n",
    "    material_layers=material_layers,\n",
    "    final_layers=final_layers,\n",
    "    verbose=True,\n",
    "    noramlize_inputs=True,\n",
    "    network_type=\"material\",\n",
    "    batch_norm=False\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the reference displacement field calculated by the Virtual Element Method, a displacemente field is supposed to be calculated considering the material parameters contributions to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_total_loss = total_loss_values[150:]\n",
    "plt.plot(filtered_total_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_loss = loss_values[150:]\n",
    "plt.plot(filtered_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_material_loss = material_loss_values[150:]\n",
    "plt.plot(filtered_material_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Material Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_sobolev_loss = sobolev_loss_values[150:]\n",
    "plt.plot(filtered_sobolev_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Sobolev Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_alpha_values = alpha_values_values[150:]\n",
    "plt.plot(filtered_alpha_values)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('alpha')\n",
    "plt.title('Alpha Values over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material_params = torch.tensor([E , A , I ], dtype=torch.float32)\n",
    "# nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geometry parameter\n",
    "I_new = 1e-4\n",
    "A_new = 2\n",
    "E_new = 110e5\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new, A_new, I_new, load, q, t)\n",
    "\n",
    "# Testing the model with new parameters\n",
    "material_params = torch.tensor([E_new , A_new , I_new ], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geometry parameter\n",
    "I_new_2 = 1e-4\n",
    "A_new_2 = 3\n",
    "E_new_2 = 80e3\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new_2, A_new_2, I_new_2, load, q, t)\n",
    "\n",
    "# Testing the model with new parameters\n",
    "material_params = torch.tensor([E_new_2 , A_new_2 , I_new_2 ], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import core.grad_norm as gn\n",
    "import core.neural_backend as neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py:199: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  normalized_nodes = torch.tensor(normalized_nodes, dtype=torch.float32, requires_grad=True)\n",
      "/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py:200: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  normalized_material_params = torch.tensor(normalized_material_params, dtype=torch.float32, requires_grad=True)\n",
      "/var/folders/r8/9jdwwqz11dq7_2m0n6cds_k40000gn/T/ipykernel_50936/2093153052.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "ndof = 3 * len(nodes)\n",
    "input_dim = 2*len(nodes) + 3\n",
    "\n",
    "input_dim_nodes = 2*len(nodes)\n",
    "input_dim_materials = 3\n",
    "\n",
    "# Original material parameters\n",
    "material_params_1 = torch.tensor([E, A, I], dtype=torch.float32)\n",
    "\n",
    "# Perturbed material parameters (slightly changed)\n",
    "material_params_2 = torch.tensor([E *1.1, A * 1.1, I * 0.9], dtype=torch.float32)\n",
    "\n",
    "nodes, material_params_1 = neural.normalize_inputs(nodes, material_params_1)\n",
    "_, material_params_2 = neural.normalize_inputs(nodes, material_params_2)\n",
    "\n",
    "nodes = nodes.flatten()\n",
    "nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "input_vector = torch.cat([nodes, material_params_1])\n",
    "\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers definition\n",
    "nodes_layers = [128, 256, 512, 512, 512, 512]  # Layers for nodes sub-network\n",
    "material_layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2048, 2048] # Layers for materials sub-network\n",
    "final_layers = [1024, 1024, 1024, 1024]  # Layers for final combination network\n",
    "\n",
    "model = neural.BeamApproximatorWithMaterials(\n",
    "                input_dim_nodes=input_dim_nodes, \n",
    "                input_dim_materials=input_dim_materials, \n",
    "                nodes_layers=nodes_layers, \n",
    "                material_layers=material_layers, \n",
    "                final_layers=final_layers, \n",
    "                ndof=ndof)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "K = torch.tensor(K, dtype=torch.float32, requires_grad=True)\n",
    "f = torch.tensor(f, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "total_loss_values = []\n",
    "loss_values = []\n",
    "material_loss_values = []\n",
    "sobolev_loss_values = []\n",
    "alpha_values_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loss weights\n",
    "loss_weights = torch.ones(3, requires_grad=True)  # We have 3 tasks: loss, sobolev_loss, and material_penalty\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 5\n",
    "concatanate = False\n",
    "\n",
    "# Initialize optimizer (including the loss_weights as parameters)\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + [loss_weights], lr=1e-3)\n",
    "\n",
    "# Initialize lists to store loss values\n",
    "total_loss_values, loss_values, material_loss_values, sobolev_loss_values, alpha_values_values = [], [], [], [], []\n",
    "\n",
    "\n",
    "\n",
    "# Loop through epochs\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    uh = model(nodes, material_params_1)\n",
    "    \n",
    "    # Compute individual losses\n",
    "    loss = loss_function.compute_loss_with_uh(uh_vem, uh)\n",
    "    sobolev_loss = loss_function.compute_sobolev_loss(model, nodes, material_params_1, loss, concatanate)\n",
    "    material_penalty = loss_function.compute_material_penalty(model, nodes, material_params_1, material_params_2, concatanate)\n",
    "    \n",
    "    # Weighted sum of losses (with GradNorm weights)\n",
    "    weighted_losses = [loss_weights[0] * loss, loss_weights[1] * sobolev_loss, loss_weights[2] * material_penalty]\n",
    "\n",
    "    # Store the initial loss weights\n",
    "    if epoch == 0:\n",
    "        initial_loss_weights = [loss_weights[0] * loss, loss_weights[1] * sobolev_loss, loss_weights[2] * material_penalty]\n",
    "\n",
    "    # Calculate the gradient norms for each task\n",
    "    grad_norms = gn.calculate_gradient_norm(model, weighted_losses)\n",
    "    tilde_losses = [gn.compute_loss_ratio(weighted_losses[i].item(), initial_loss_weights[i].item()) for i in range(len(weighted_losses))]\n",
    "\n",
    "    # Compute the grad norm loss\n",
    "    loss_grad = gn.compute_grad_norm_loss(grad_norms, tilde_losses)\n",
    "\n",
    "    # Compute total loss\n",
    "    total_loss = sum(weighted_losses)\n",
    "\n",
    "    # Backpropagation\n",
    "    total_loss.backward()\n",
    "    \n",
    "    # Perform optimization step\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Store losses for analysis\n",
    "    if epoch > 0:\n",
    "        total_loss_values.append(total_loss.item())\n",
    "        loss_values.append(loss.item())\n",
    "        material_loss_values.append(material_penalty.item())\n",
    "        sobolev_loss_values.append(sobolev_loss.item())\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Epoch: {epoch + 1}, Total Loss: {total_loss.item()}')\n",
    "\n",
    "    # Optional: Adjust loss weights using GradNorm logic here based on the computed `grad_norms`\n",
    "    # You need to implement the logic to update loss_weights based on the gradient norms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
