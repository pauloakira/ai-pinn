{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points:\n",
    "\n",
    "1. **Using VEM/FEM Solutions for Efficient Training**:\n",
    "   - By training the neural network on the displacement field computed using VEM/FEM, you're providing the model with a high-quality reference solution. This allows the model to learn the underlying physical relationships between the parameters (such as Young’s modulus \\(E\\), cross-sectional area \\(A\\), and moment of inertia \\(I\\)) and the displacement field.\n",
    "\n",
    "2. **Generalization with Fewer Data**:\n",
    "   - Since the model is grounded in physically informed solutions, you likely need **fewer training examples** to generalize to new material and geometrical configurations. Unlike traditional machine learning models that require vast amounts of labeled data, your approach can rely on solving a **few instances** of VEM/FEM solutions and using that information to generalize.\n",
    "\n",
    "3. **Parameter Sensitivity and Inference**:\n",
    "   - The network’s sensitivity to material and geometrical parameters (\\(E\\), \\(A\\), \\(I\\)) is key. Once trained, the model will allow for **rapid inference** with new combinations of these parameters without needing to solve the full VEM/FEM system again.\n",
    "   - In an engineering context, this is particularly advantageous, as engineers often need to explore various material or geometric configurations during design optimization. Having a trained neural network that provides **instant predictions** without solving a full VEM/FEM problem would significantly improve efficiency.\n",
    "\n",
    "4. **Efficiency Compared to Traditional VEM/FEM**:\n",
    "   - Solving a full VEM/FEM problem repeatedly for different parameter values can be computationally expensive, especially for large or complex systems. By training a neural network to approximate the displacement field based on these parameters, you essentially create a **surrogate model** that can make predictions more efficiently.\n",
    "\n",
    "### Challenges and Considerations:\n",
    "- **Accuracy vs. Efficiency**: While the neural network may provide fast predictions, the trade-off is the potential for reduced accuracy compared to solving the full VEM/FEM system. This can be mitigated by fine-tuning the network and introducing additional regularization techniques like Sobolev training.\n",
    "  \n",
    "- **Extrapolation Limits**: The network might struggle with extrapolating far beyond the range of material and geometrical parameters it was trained on. Ensuring that the training data includes a representative range of parameters will be crucial for reliable generalization.\n",
    "\n",
    "- **Hybrid Model Validation**: You could validate your hypothesis by comparing the **computational cost** (in terms of time) and **accuracy** between solving multiple VEM/FEM instances and using the trained neural network for inference over a variety of material/geometrical configurations.\n",
    "\n",
    "### Conclusion:\n",
    "The approach of training a neural network using VEM/FEM solutions to enable efficient inference of displacement fields for different material and geometric configurations is a practical and promising solution in engineering contexts. It leverages the strengths of both numerical methods and machine learning to balance accuracy and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import core.vem as vem\n",
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "\n",
    "import utils.mesh as mesh\n",
    "import core.loss as loss_function\n",
    "import core.errors as errors\n",
    "import core.neural_backend as neural\n",
    "\n",
    "import solve_vem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS backend is available!\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS backend is available!\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS backend is not available. Using CPU.\")\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of elements per edge\n",
    "num_elements_per_edge = 64\n",
    "\n",
    "# geometry data\n",
    "L = 2.0\n",
    "I = 1e-4\n",
    "A = 1\n",
    "\n",
    "# material data\n",
    "E = 27e6\n",
    "\n",
    "# Define load parameters\n",
    "q = -400\n",
    "t = 0\n",
    "\n",
    "# Time sampling size\n",
    "time_sampling_size = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving time [s]: 0.0049\n",
      "######################### Beam ##########################\n",
      "[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.98147011e-21\n",
      " -9.92911555e-07  2.16004753e-20 -6.93215545e-21 -1.98582311e-06\n",
      " -6.59702248e-20 -7.80737837e-21 -2.97873466e-06 -1.11229119e-19\n",
      " -7.83606854e-21 -3.97164622e-06 -1.20148322e-19 -7.76206055e-21\n",
      " -4.96455777e-06 -1.17801801e-19 -7.76276734e-21 -5.95746933e-06\n",
      " -1.15366576e-19 -7.81444027e-21 -6.95038088e-06 -1.14539968e-19\n",
      " -7.87966006e-21 -7.94329244e-06 -1.14499578e-19 -7.94392117e-21\n",
      " -8.93620399e-06 -1.14601322e-19 -8.00573588e-21 -9.92911555e-06\n",
      " -1.14656148e-19 -8.06651519e-21 -1.09220271e-05 -1.14667588e-19\n",
      " -8.12715538e-21 -1.19149387e-05 -1.14665051e-19 -8.18788046e-21\n",
      " -1.29078502e-05 -1.14662155e-19 -8.24866674e-21 -1.39007618e-05\n",
      " -1.14661135e-19 -8.30946999e-21 -1.48936733e-05 -1.14661069e-19\n",
      " -8.37027243e-21 -1.58865849e-05 -1.14661187e-19 -8.43107200e-21\n",
      " -1.68794964e-05 -1.14661253e-19 -8.49187030e-21 -1.78724080e-05\n",
      " -1.14661267e-19 -8.55266841e-21 -1.88653195e-05 -1.14661265e-19\n",
      " -8.61346662e-21 -1.98582311e-05 -1.14661260e-19 -8.67426487e-21\n",
      " -2.08511427e-05 -1.14661263e-19 -8.73506330e-21 -2.18440542e-05\n",
      " -1.14661249e-19 -8.79586117e-21 -2.28369658e-05 -1.14661298e-19\n",
      " -8.85666100e-21 -2.38298773e-05 -1.14661125e-19 -8.91745384e-21\n",
      " -2.48227889e-05 -1.14661744e-19 -8.97827165e-21 -2.58157004e-05\n",
      " -1.14659528e-19 -9.03900013e-21 -2.68086120e-05 -1.14667461e-19\n",
      " -9.10004831e-21 -2.78015235e-05 -1.14639066e-19 -9.15995225e-21\n",
      " -2.87944351e-05 -1.14740694e-19 -9.22395151e-21 -2.97873466e-05\n",
      " -1.14376965e-19 -9.27329345e-21 -3.07802582e-05 -1.15678762e-19\n",
      " -9.37509441e-21 -3.17731698e-05 -1.11019588e-19 -9.28914282e-21\n",
      " -3.27660813e-05 -1.27694925e-19 -9.87516387e-21 -3.37589929e-05\n",
      " -6.80133394e-20 -8.05617242e-21 -3.47519044e-05 -2.81615725e-19\n",
      " -1.48448009e-20 -3.57448160e-05  4.82874337e-19  9.17352950e-21\n",
      " -3.67377275e-05 -2.25326110e-18 -7.70672737e-20 -3.77306391e-05\n",
      "  7.53945889e-18  2.31313040e-19 -3.87235506e-05 -2.75090126e-17\n",
      " -8.72668788e-19 -3.97164622e-05  9.79306360e-17  3.07824060e-18\n",
      " -4.07093738e-05 -3.51022051e-16 -1.10624743e-17 -4.17022853e-05\n",
      "  1.25579459e-15  3.95473376e-17 -4.26951969e-05 -4.49505577e-15\n",
      " -1.41587146e-16 -4.36881084e-05  1.60874295e-14  5.06698934e-16\n",
      " -4.46810200e-05 -5.75779719e-14 -1.81353885e-15 -4.56739315e-05\n",
      "  2.06072957e-13  6.49066930e-15 -4.66668431e-05 -7.37542512e-13\n",
      " -2.32303690e-14 -4.76597546e-05  2.63968873e-12  8.31422181e-14\n",
      " -4.86526662e-05 -9.44753453e-12 -2.97568820e-13 -4.96455777e-05\n",
      "  3.38130407e-11  1.06500868e-12 -5.06384893e-05 -1.21018001e-10\n",
      " -3.81170165e-12 -5.16314009e-05  4.33127463e-10  1.36422073e-11\n",
      " -5.26243124e-05 -1.55017764e-09 -4.88259151e-11 -5.36172240e-05\n",
      "  5.54813747e-09  1.74749579e-10 -5.46101355e-05 -1.98569691e-08\n",
      " -6.25434572e-10 -5.56030471e-05  7.10687547e-08  2.23845120e-09\n",
      " -5.65959586e-05 -2.54357444e-07 -8.01149150e-09 -5.75888702e-05\n",
      "  9.10353776e-07  2.86733953e-08 -5.85817817e-05 -3.25818653e-06\n",
      " -1.02623038e-07 -5.95746933e-05  1.16611583e-05  3.67291277e-07\n",
      " -6.05676049e-05 -4.17356745e-05 -1.31454773e-06 -6.15605164e-05\n",
      "  1.49373371e-04  4.70481019e-06 -6.25534280e-05 -5.34612278e-04\n",
      " -1.68386726e-05 -6.35463395e-05  1.91339518e-03 -1.68386726e-05\n",
      " -1.89416689e-05  9.92641125e-04 -1.68386726e-05 -8.80666094e-07\n",
      "  2.13846918e-04 -1.68386726e-05  1.27910433e-06 -2.57912684e-05\n",
      " -1.68386726e-05 -3.13824796e-07 -2.70793738e-05 -1.68386726e-05\n",
      " -1.37988056e-06  7.17510615e-06 -1.68386726e-05 -1.64263773e-06\n",
      "  2.35782164e-05 -1.68386726e-05 -1.59649666e-06  2.61910722e-05\n",
      " -1.68386726e-05 -1.51961865e-06  2.47918605e-05 -1.68386726e-05\n",
      " -1.47324242e-06  2.34854383e-05 -1.68386726e-05 -1.44603276e-06\n",
      "  2.28116789e-05 -1.68386726e-05 -1.42356522e-06  2.24284227e-05\n",
      " -1.68386726e-05 -1.40056777e-06  2.20920722e-05 -1.68386726e-05\n",
      " -1.37662055e-06  2.17356879e-05 -1.68386726e-05 -1.35229447e-06\n",
      "  2.13627989e-05 -1.68386726e-05 -1.32792549e-06  2.09849129e-05\n",
      " -1.68386726e-05 -1.30359142e-06  2.06070441e-05 -1.68386726e-05\n",
      " -1.27928042e-06  2.02299160e-05 -1.68386726e-05 -1.25497539e-06\n",
      "  1.98531415e-05 -1.68386726e-05 -1.23066985e-06  1.94764283e-05\n",
      " -1.68386726e-05 -1.20636318e-06  1.90996928e-05 -1.68386726e-05\n",
      " -1.18205606e-06  1.87229375e-05 -1.68386726e-05 -1.15774887e-06\n",
      "  1.83461761e-05 -1.68386726e-05 -1.13344173e-06  1.79694145e-05\n",
      " -1.68386726e-05 -1.10913461e-06  1.75926539e-05 -1.68386726e-05\n",
      " -1.08482751e-06  1.72158936e-05 -1.68386726e-05 -1.06052040e-06\n",
      "  1.68391335e-05 -1.68386726e-05 -1.03621329e-06  1.64623733e-05\n",
      " -1.68386726e-05 -1.01190617e-06  1.60856130e-05 -1.68386726e-05\n",
      " -9.87599063e-07  1.57088528e-05 -1.68386726e-05 -9.63291952e-07\n",
      "  1.53320926e-05 -1.68386726e-05 -9.38984841e-07  1.49553324e-05\n",
      " -1.68386726e-05 -9.14677730e-07  1.45785721e-05 -1.68386726e-05\n",
      " -8.90370618e-07  1.42018119e-05 -1.68386726e-05 -8.66063507e-07\n",
      "  1.38250517e-05 -1.68386726e-05 -8.41756396e-07  1.34482915e-05\n",
      " -1.68386726e-05 -8.17449285e-07  1.30715312e-05 -1.68386726e-05\n",
      " -7.93142173e-07  1.26947710e-05 -1.68386726e-05 -7.68835062e-07\n",
      "  1.23180108e-05 -1.68386726e-05 -7.44527951e-07  1.19412506e-05\n",
      " -1.68386726e-05 -7.20220840e-07  1.15644904e-05 -1.68386726e-05\n",
      " -6.95913729e-07  1.11877301e-05 -1.68386726e-05 -6.71606617e-07\n",
      "  1.08109699e-05 -1.68386726e-05 -6.47299506e-07  1.04342097e-05\n",
      " -1.68386726e-05 -6.22992395e-07  1.00574495e-05 -1.68386726e-05\n",
      " -5.98685284e-07  9.68068922e-06 -1.68386726e-05 -5.74378172e-07\n",
      "  9.30392906e-06 -1.68386726e-05 -5.50071063e-07  8.92716859e-06\n",
      " -1.68386726e-05 -5.25763944e-07  8.55040926e-06 -1.68386726e-05\n",
      " -5.01456861e-07  8.17364586e-06 -1.68386726e-05 -4.77149650e-07\n",
      "  7.79689700e-06 -1.68386726e-05 -4.52842896e-07  7.42009610e-06\n",
      " -1.68386726e-05 -4.28534504e-07  7.04348146e-06 -1.68386726e-05\n",
      " -4.04231978e-07  6.66620017e-06 -1.68386726e-05 -3.79908455e-07\n",
      "  6.29130485e-06 -1.68386726e-05 -3.55660083e-07  5.90787009e-06\n",
      " -1.68386726e-05 -3.31142744e-07  5.55499827e-06 -1.68386726e-05\n",
      " -3.07588045e-07  5.09274064e-06 -1.68386726e-05 -2.80588024e-07\n",
      "  5.02197849e-06 -1.68386726e-05 -2.65918928e-07  3.55004095e-06\n",
      " -1.68386726e-05 -2.07117038e-07  7.09295688e-06 -1.68386726e-05\n",
      " -3.06267891e-07 -7.31245506e-06 -1.68386726e-05  1.59899393e-07\n",
      "  4.25197972e-05 -1.68386726e-05 -1.39722579e-06 -1.37556693e-04\n",
      " -1.68386726e-05  4.28708026e-06  5.05217876e-04 -4.80946967e-06\n",
      "  4.22009463e-06  2.64651112e-04  1.56316370e-07  4.15310900e-06\n",
      "  5.31591939e-05  7.80076091e-07  4.08612337e-06 -1.32385717e-05\n",
      "  3.52049501e-07  4.01913774e-06 -1.41551301e-05  5.48823812e-08\n",
      "  3.95215211e-06 -4.86356558e-06 -2.52205390e-08  3.88516648e-06\n",
      " -2.63021315e-07 -2.01671077e-08  3.81818086e-06  5.86440921e-07\n",
      " -5.99712449e-09  3.75119523e-06  3.20438002e-07  7.33023017e-11\n",
      "  3.68420960e-06  6.80693121e-08  9.14251793e-10  3.61722397e-06\n",
      " -1.42485446e-08  4.28711731e-10  3.55023834e-06 -1.68260194e-08\n",
      "  7.20652682e-11  3.48325271e-06 -5.99935424e-09 -2.81978182e-11\n",
      "  3.41626708e-06 -4.17483287e-10 -2.41167542e-11  3.34928145e-06\n",
      "  6.78671380e-10 -7.45922261e-12  3.28229582e-06  3.87410643e-10\n",
      " -5.05762467e-14  3.21531019e-06  8.67427240e-11  1.06901107e-12\n",
      "  3.14832457e-06 -1.50891356e-11  5.21257559e-13  3.08133894e-06\n",
      " -1.99670892e-11  9.38659678e-14  3.01435331e-06 -7.38597268e-12\n",
      " -3.12835500e-14  2.94736768e-06 -6.23596452e-13 -2.87953784e-14\n",
      "  2.88038205e-06  7.82839431e-13 -9.25582424e-15  2.81339642e-06\n",
      "  4.67692035e-13 -2.28393072e-16  2.74641079e-06  1.10063559e-13\n",
      "  1.24687282e-15  2.67942516e-06 -1.56465427e-14  6.32813913e-16\n",
      "  2.61243953e-06 -2.36532276e-14  1.21418206e-16  2.54545390e-06\n",
      " -9.07609795e-15 -3.43912046e-17  2.47846827e-06 -8.95704667e-16\n",
      " -3.43276566e-17  2.41148265e-06  8.99771378e-16 -1.14596333e-17\n",
      "  2.34449702e-06  5.63781754e-16 -4.76910425e-19  2.27751139e-06\n",
      "  1.39112149e-16  1.45034935e-18  2.21052576e-06 -1.57678828e-17\n",
      "  7.66961048e-19  2.14354013e-06 -2.79693278e-17  1.55993158e-19\n",
      "  2.07655450e-06 -1.11329765e-17 -3.75133264e-20  2.00956887e-06\n",
      " -1.25179791e-18 -4.09723966e-20  1.94258324e-06  1.03005800e-18\n",
      " -1.42694926e-20  1.87559761e-06  6.78568450e-19 -9.24397412e-22\n",
      "  1.80861198e-06  1.75158229e-19  1.57902830e-21  1.74162636e-06\n",
      " -1.52983948e-20  8.29055494e-22  1.67464073e-06 -3.30592769e-20\n",
      "  1.04360380e-22  1.60765510e-06 -1.36806224e-20 -1.31323592e-22\n",
      "  1.54066947e-06 -1.76256384e-21 -1.35658289e-22  1.47368384e-06\n",
      "  1.12573126e-21 -1.00465604e-22  1.40669821e-06  7.67188592e-22\n",
      " -8.01827758e-23  1.33971258e-06  1.71500430e-22 -7.28603614e-23\n",
      "  1.27272695e-06 -6.22778814e-23 -6.95822794e-23  1.20574132e-06\n",
      " -8.73368519e-23 -6.63485491e-23  1.13875569e-06 -6.51163820e-23\n",
      " -6.25433472e-23  1.07177006e-06 -5.07626770e-23 -5.84569523e-23\n",
      "  1.00478444e-06 -4.71200225e-23 -5.43191637e-23  9.37798807e-07\n",
      " -4.74734824e-23 -5.01978661e-23  8.70813178e-07 -4.81754465e-23\n",
      " -4.60921027e-23  8.03827549e-07 -4.84676740e-23 -4.19911223e-23\n",
      "  7.36841920e-07 -4.84815566e-23 -3.78911188e-23  6.69856290e-07\n",
      " -4.85301990e-23 -3.37874666e-23  6.02870661e-07 -4.82480358e-23\n",
      " -2.96941480e-23  5.35885032e-07 -4.91915482e-23 -2.55625574e-23\n",
      "  4.68899403e-07 -4.57986293e-23 -2.15677239e-23  4.01913774e-07\n",
      " -5.79440076e-23 -1.70835152e-23  3.34928145e-07 -1.44786125e-23\n",
      " -1.43508691e-23  2.67942516e-07 -1.70044012e-22 -5.34934462e-24\n",
      "  2.00956887e-07  3.86729604e-22 -1.87843452e-23  1.33971258e-07\n",
      " -1.60598162e-21 -2.19389040e-23  6.69856290e-08  1.04467788e-21\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "#########################################################\n"
     ]
    }
   ],
   "source": [
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Plot the nodes\n",
    "mesh.plot_nodes(nodes, elements)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Solving and Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring time for solving using VEM\n",
    "solving_time_list = []\n",
    "for _ in range(time_sampling_size):\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t)\n",
    "    solving_time_list.append(solving_time)\n",
    "\n",
    "print(\"Mean solving time: \", np.mean(solving_time_list))\n",
    "print(\"Std Deviation: \", np.std(solving_time_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 800\n",
    "\n",
    "# Layers definition\n",
    "nodes_layers = [128, 256, 512, 512, 512, 512]  # Layers for nodes sub-network\n",
    "material_layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2048, 2048] # Layers for materials sub-network\n",
    "final_layers = [1024, 1024, 1024, 1024]  # Layers for final combination network\n",
    "\n",
    "# Training pipeline\n",
    "(input_vector, \n",
    " model, \n",
    " total_loss_values, \n",
    " loss_values, \n",
    " material_loss_values, \n",
    " sobolev_loss_values, \n",
    " alpha_values_values) = neural.train_material_portic(\n",
    "    epochs=num_epochs,\n",
    "    nodes=nodes,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    E=E,\n",
    "    A=A,\n",
    "    I=I,\n",
    "    uh_vem=uh_vem,\n",
    "    nodes_layers=nodes_layers,\n",
    "    material_layers=material_layers,\n",
    "    final_layers=final_layers,\n",
    "    verbose=True,\n",
    "    noramlize_inputs=True,\n",
    "    network_type=\"material\"\n",
    " )\n",
    "\n",
    "# Setting up material parameters\n",
    "material_params = torch.tensor([E , A , I ], dtype=torch.float32)\n",
    "# nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "\n",
    "# Measuring time spent for inference\n",
    "inference_time_list = []\n",
    "for _ in range(time_sampling_size):\n",
    "    predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    inference_time_list.append(inference_time)\n",
    "\n",
    "print(\"Mean inference time: \", np.mean(inference_time_list))\n",
    "print(\"Std Deviation: \", np.std(inference_time_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model refers to the disaplcement field and the loss function regards to the calculation of the residual taking in consideration the Virtual Element Method's stiffness matrix and load vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence of Deep Layers in the Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 800\n",
    "\n",
    "# Reading the json with respective layers\n",
    "with open(\"data/layers_20240929.json\", \"r\") as data:\n",
    "    layers = json.load(data)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i,layer in enumerate(layers):\n",
    "\n",
    "    # Define the number of elements per edge\n",
    "    num_elements_per_edge = 128\n",
    "\n",
    "    # geometry data\n",
    "    L = 2.0\n",
    "    I = 1e-4\n",
    "    A = 1\n",
    "\n",
    "    # material data\n",
    "    E = 27e6\n",
    "\n",
    "    # Define load parameters\n",
    "    q = -400\n",
    "    t = 0\n",
    "\n",
    "\n",
    "    # Generate the geometry\n",
    "    nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "    # Solve the problem using the VEM\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t, verbose=False)\n",
    "\n",
    "    print(f\"Training and testing layer {i+1}/{len(layers)}\")\n",
    "    # Defining layers\n",
    "    nodes_layers = list(layer[\"node_layers\"])\n",
    "    material_layers = list(layer[\"material_layers\"])\n",
    "    final_layers = list(layer[\"final_layers\"])\n",
    "\n",
    "    # Training pipeline\n",
    "    (input_vector, \n",
    "    model, \n",
    "    total_loss_values, \n",
    "    loss_values, \n",
    "    material_loss_values, \n",
    "    sobolev_loss_values, \n",
    "    alpha_values_values) = neural.train_material_portic(\n",
    "        epochs=num_epochs,\n",
    "        nodes=nodes,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        E=E,\n",
    "        A=A,\n",
    "        I=I,\n",
    "        uh_vem=uh_vem,\n",
    "        nodes_layers=nodes_layers,\n",
    "        material_layers=material_layers,\n",
    "        final_layers=final_layers,\n",
    "        verbose=False,\n",
    "        noramlize_inputs=True,\n",
    "        network_type=\"material\"\n",
    "    )\n",
    "\n",
    "    # Setting up material parameters\n",
    "    material_params = torch.tensor([E , A , I ], dtype=torch.float32)\n",
    "    nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "\n",
    "    # Testing the model with default parameters\n",
    "    predicted_displacements, l2_error_default, energy_error_default, h1_error_default, inference_time_default = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Setting up new material parameters\n",
    "    I_new = 1e-4\n",
    "    A_new = 2\n",
    "    E_new = 110e5\n",
    "\n",
    "    # Generate the geometry\n",
    "    nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "    # Solve the problem using the VEM\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new, A_new, I_new, load, q, t)\n",
    "\n",
    "    # Testing the model with new parameters\n",
    "    material_params = torch.tensor([E_new , A_new , I_new], dtype=torch.float32)\n",
    "    nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "    nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "    predicted_displacements, l2_error_new, energy_error_new, h1_error_new, inference_time_new = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Setting up new material parameters\n",
    "    I_new_2 = 1e-4\n",
    "    A_new_2 = 3\n",
    "    E_new_2 = 80e3\n",
    "\n",
    "    # Generate the geometry\n",
    "    nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "    # Solve the problem using the VEM\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new_2, A_new_2, I_new_2, load, q, t)\n",
    "\n",
    "    # Testing the model with new parameters\n",
    "    material_params = torch.tensor([E_new_2 , A_new_2 , I_new_2], dtype=torch.float32)\n",
    "    nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "    nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "    predicted_displacements, l2_error_new, energy_error_new, h1_error_new, inference_time_new = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"tag\": layer[\"tag\"],\n",
    "        \"l2_error_default\": l2_error_default,\n",
    "        \"energy_error_default\": energy_error_default,\n",
    "        \"h1_error_default\": h1_error_default,\n",
    "        \"inferece_time_default\": inference_time_default,\n",
    "        \"l2_error_new\": l2_error_new,\n",
    "        \"energy_error_new\": energy_error_new,\n",
    "        \"h1_error_new\": h1_error_new,\n",
    "        \"inferece_time_new\": inference_time_new,\n",
    "        \"l2_error_new_2\": l2_error_new,\n",
    "        \"energy_error_new_2\": energy_error_new,\n",
    "        \"h1_error_new_2\": h1_error_new,\n",
    "        \"inferece_time_new_2\": inference_time_new,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in a dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"data/output/results_20240929.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 800\n",
    "\n",
    "# Layers definition\n",
    "nodes_layers = [128, 256, 512, 512, 512, 512]  # Layers for nodes sub-network\n",
    "material_layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2048, 2048] # Layers for materials sub-network\n",
    "final_layers = [1024, 1024, 1024, 1024]  # Layers for final combination network\n",
    "\n",
    "# Training pipeline\n",
    "(input_vector, \n",
    " model, \n",
    " total_loss_values, \n",
    " loss_values, \n",
    " material_loss_values, \n",
    " sobolev_loss_values, \n",
    " alpha_values_values) = neural.train_material_portic(\n",
    "    epochs=num_epochs,\n",
    "    nodes=nodes,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    E=E,\n",
    "    A=A,\n",
    "    I=I,\n",
    "    uh_vem=uh_vem,\n",
    "    nodes_layers=nodes_layers,\n",
    "    material_layers=material_layers,\n",
    "    final_layers=final_layers,\n",
    "    verbose=True,\n",
    "    noramlize_inputs=True,\n",
    "    network_type=\"material\",\n",
    "    batch_norm=False\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the reference displacement field calculated by the Virtual Element Method, a displacemente field is supposed to be calculated considering the material parameters contributions to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_total_loss = total_loss_values[150:]\n",
    "plt.plot(filtered_total_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_loss = loss_values[150:]\n",
    "plt.plot(filtered_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_material_loss = material_loss_values[150:]\n",
    "plt.plot(filtered_material_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Material Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_sobolev_loss = sobolev_loss_values[150:]\n",
    "plt.plot(filtered_sobolev_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Sobolev Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_alpha_values = alpha_values_values[150:]\n",
    "plt.plot(filtered_alpha_values)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('alpha')\n",
    "plt.title('Alpha Values over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material_params = torch.tensor([E , A , I ], dtype=torch.float32)\n",
    "# nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geometry parameter\n",
    "I_new = 1e-4\n",
    "A_new = 2\n",
    "E_new = 110e5\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new, A_new, I_new, load, q, t)\n",
    "\n",
    "# Testing the model with new parameters\n",
    "material_params = torch.tensor([E_new , A_new , I_new ], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geometry parameter\n",
    "I_new_2 = 1e-4\n",
    "A_new_2 = 3\n",
    "E_new_2 = 80e3\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new_2, A_new_2, I_new_2, load, q, t)\n",
    "\n",
    "# Testing the model with new parameters\n",
    "material_params = torch.tensor([E_new_2 , A_new_2 , I_new_2 ], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import core.grad_norm as gn\n",
    "import core.neural_backend as neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndof = 3 * len(nodes)\n",
    "input_dim = 2*len(nodes) + 3\n",
    "\n",
    "input_dim_nodes = 2*len(nodes)\n",
    "input_dim_materials = 3\n",
    "\n",
    "# Original material parameters\n",
    "material_params_1 = torch.tensor([E, A, I], dtype=torch.float32)\n",
    "\n",
    "# Perturbed material parameters (slightly changed)\n",
    "material_params_2 = torch.tensor([E *1.1, A * 1.1, I * 0.9], dtype=torch.float32)\n",
    "\n",
    "nodes, material_params_1 = neural.normalize_inputs(nodes, material_params_1)\n",
    "_, material_params_2 = neural.normalize_inputs(nodes, material_params_2)\n",
    "\n",
    "nodes = nodes.flatten()\n",
    "nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "input_vector = torch.cat([nodes, material_params_1])\n",
    "\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers definition\n",
    "nodes_layers = [128, 256, 512, 512, 512, 512]  # Layers for nodes sub-network\n",
    "material_layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2048, 2048] # Layers for materials sub-network\n",
    "final_layers = [1024, 1024, 1024, 1024]  # Layers for final combination network\n",
    "\n",
    "model = neural.BeamApproximatorWithMaterials(\n",
    "                input_dim_nodes=input_dim_nodes, \n",
    "                input_dim_materials=input_dim_materials, \n",
    "                nodes_layers=nodes_layers, \n",
    "                material_layers=material_layers, \n",
    "                final_layers=final_layers, \n",
    "                ndof=ndof)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "K = torch.tensor(K, dtype=torch.float32, requires_grad=True)\n",
    "f = torch.tensor(f, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "total_loss_values = []\n",
    "loss_values = []\n",
    "material_loss_values = []\n",
    "sobolev_loss_values = []\n",
    "alpha_values_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loss weights\n",
    "loss_weights = torch.ones(3, requires_grad=True)  # We have 3 tasks: loss, sobolev_loss, and material_penalty\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 200\n",
    "concatanate = False\n",
    "\n",
    "# Initialize optimizers (including the loss_weights as parameters)\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + [loss_weights], lr=1e-3)\n",
    "optimizer_w = torch.optim.SGD([loss_weights], lr=1e-3)\n",
    "\n",
    "# Initialize lists to store loss values\n",
    "total_loss_values, loss_values, material_loss_values, sobolev_loss_values, alpha_values_values = [], [], [], [], []\n",
    "\n",
    "# Enable anomaly detection for debugging\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Loop through epochs\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    uh = model(nodes, material_params_1)\n",
    "    \n",
    "    # Compute individual losses\n",
    "    loss = loss_function.compute_loss_with_uh(uh_vem, uh)\n",
    "    sobolev_loss = loss_function.compute_sobolev_loss(model, nodes, material_params_1, loss, concatanate)\n",
    "    material_penalty = loss_function.compute_material_penalty(model, nodes, material_params_1, material_params_2, concatanate) * 1e10\n",
    "\n",
    "    # Weighted sum of losses (with GradNorm weights)\n",
    "    weighted_losses = [\n",
    "        loss_weights[0] * loss, \n",
    "        loss_weights[1] * sobolev_loss, \n",
    "        loss_weights[2] * material_penalty\n",
    "    ]\n",
    "\n",
    "    # Store the initial loss weights\n",
    "    if epoch == 0:\n",
    "        initial_loss_weights = [\n",
    "            loss_weights[0] * loss, \n",
    "            loss_weights[1] * sobolev_loss, \n",
    "            loss_weights[2] * material_penalty\n",
    "        ]\n",
    "\n",
    "    # Calculate the gradient norms for each task\n",
    "    grad_norms = gn.calculate_gradient_norm(model, weighted_losses)\n",
    "    tilde_losses = [gn.compute_loss_ratio(weighted_losses[i].item(), initial_loss_weights[i].item()) for i in range(len(weighted_losses))]\n",
    "\n",
    "    # Compute the grad norm loss\n",
    "    loss_grad = gn.compute_grad_norm_loss(grad_norms, tilde_losses, 100)\n",
    "\n",
    "    # Backpropagation of the gradient loss (update the grad_loss weights)\n",
    "    loss_grad.backward(retain_graph=True)\n",
    "\n",
    "    # Step 1: Perform the optimizer step to update the task weights using the gradient loss\n",
    "    optimizer_w.step()\n",
    "\n",
    "    # Step 2: Compute the total loss (sum of the weighted loss)\n",
    "    total_loss = loss_weights[0] * loss + loss_weights[1] * sobolev_loss + loss_weights[2] * material_penalty\n",
    "\n",
    "    # Backpropagation for the model weights using total loss\n",
    "    total_loss.backward()\n",
    "\n",
    "    # Step 3: Perform the optimizer step to update the model weights using the total loss\n",
    "    optimizer.step()\n",
    "\n",
    "    # Step 4: Renormalize the loss weights (no in-place operation)\n",
    "    T = len(weighted_losses)\n",
    "    sum_w = torch.sum(loss_weights).item()\n",
    "\n",
    "    # Instead of modifying in-place, re-assign to a new tensor\n",
    "    with torch.no_grad():\n",
    "        loss_weights.copy_((loss_weights / sum_w) * T)  # Use .copy_ to avoid creating new tensors and keep gradients\n",
    "\n",
    "    # Store losses for analysis\n",
    "    if epoch > 0:\n",
    "        total_loss_values.append(total_loss.item())\n",
    "        loss_values.append(loss_weights[0].item()*loss.item())\n",
    "        material_loss_values.append(loss_weights[2].item()*material_penalty.item())\n",
    "        sobolev_loss_values.append(loss_weights[1].item()*sobolev_loss.item())\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Epoch: {epoch + 1}, Total Loss: {total_loss.item()}, Loss Weights: {loss_weights.detach().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_total_loss = total_loss_values[150:]\n",
    "plt.plot(filtered_total_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_loss = loss_values[150:]\n",
    "plt.plot(filtered_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_material_loss = material_loss_values[150:]\n",
    "plt.plot(filtered_material_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Material Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_sobolev_loss = sobolev_loss_values[150:]\n",
    "plt.plot(filtered_sobolev_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Sobolev Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_alpha_values = alpha_values_values[150:]\n",
    "plt.plot(filtered_alpha_values)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('alpha')\n",
    "plt.title('Alpha Values over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geometry parameter\n",
    "I_new = 1e-4\n",
    "A_new = 2\n",
    "E_new = 110e5\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new, A_new, I_new, load, q, t)\n",
    "\n",
    "# Testing the model with new parameters\n",
    "material_params = torch.tensor([E_new , A_new , I_new ], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geometry parameter\n",
    "I_new_2 = 1e-4\n",
    "A_new_2 = 3\n",
    "E_new_2 = 80e2\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new_2, A_new_2, I_new_2, load, q, t)\n",
    "\n",
    "# Testing the model with new parameters\n",
    "material_params = torch.tensor([E_new_2 , A_new_2 , I_new_2 ], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using few material data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import core.grad_norm as gn\n",
    "import core.neural_backend as neural\n",
    "from utils.helpers import generate_beam_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  normalized_nodes = torch.tensor(normalized_nodes, dtype=torch.float32, requires_grad=True)\n",
      "/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py:204: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  normalized_material_params = torch.tensor(normalized_material_params, dtype=torch.float32, requires_grad=True)\n",
      "/var/folders/r8/9jdwwqz11dq7_2m0n6cds_k40000gn/T/ipykernel_45938/2093153052.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "ndof = 3 * len(nodes)\n",
    "input_dim = 2*len(nodes) + 3\n",
    "\n",
    "input_dim_nodes = 2*len(nodes)\n",
    "input_dim_materials = 3\n",
    "\n",
    "# Original material parameters\n",
    "material_params_1 = torch.tensor([E, A, I], dtype=torch.float32)\n",
    "\n",
    "# Perturbed material parameters (slightly changed)\n",
    "material_params_2 = torch.tensor([E *1.1, A * 1.1, I * 0.9], dtype=torch.float32)\n",
    "\n",
    "nodes, material_params_1 = neural.normalize_inputs(nodes, material_params_1)\n",
    "_, material_params_2 = neural.normalize_inputs(nodes, material_params_2)\n",
    "\n",
    "nodes = nodes.flatten()\n",
    "nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "input_vector = torch.cat([nodes, material_params_1])\n",
    "\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Layers definition\n",
    "nodes_layers = [128, 256, 512, 512, 512, 512]  # Layers for nodes sub-network\n",
    "material_layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2048, 2048, 4096, 4096, 2048, 2048, 1024, 1024, 1024, 1024, 512, 512] # Layers for materials sub-network\n",
    "final_layers = [1024, 1024, 1024, 1024, 1024, 1024] # Layers for final combination network\n",
    "\n",
    "model = neural.BeamApproximatorWithMaterials(\n",
    "                input_dim_nodes=input_dim_nodes, \n",
    "                input_dim_materials=input_dim_materials, \n",
    "                nodes_layers=nodes_layers, \n",
    "                material_layers=material_layers, \n",
    "                final_layers=final_layers, \n",
    "                ndof=ndof).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "K = torch.tensor(K, dtype=torch.float32, requires_grad=True).to(device)\n",
    "f = torch.tensor(f, dtype=torch.float32, requires_grad=True).to(device)\n",
    "\n",
    "total_loss_values = []\n",
    "loss_values = []\n",
    "material_loss_values = []\n",
    "sobolev_loss_values = []\n",
    "alpha_values_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalize(value, mean_val, std_val):\n",
    "    \"\"\"Z-score normalization.\"\"\"\n",
    "    return (value - mean_val) / std_val\n",
    "\n",
    "def generate_beam_dataset(elastic_module_range: list, inertia_moment_range: list, area_range: list, num_samples: int):\n",
    "    \"\"\"\n",
    "    Function to generate a dataset of beam parameters with z-score normalized material properties.\n",
    "    \"\"\"\n",
    "    # Initialize lists to store the dataset\n",
    "    dataset = []\n",
    "\n",
    "    # Generate the material parameters\n",
    "    params = generate_beam_parameters(elastic_module_range, inertia_moment_range, area_range, num_samples)\n",
    "\n",
    "    # Extract E, I, and A values for normalization\n",
    "    E_values = [param['E'] for param in params]\n",
    "    I_values = [param['I'] for param in params]\n",
    "    A_values = [param['A'] for param in params]\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    E_mean, E_std = torch.mean(torch.tensor(E_values)), torch.std(torch.tensor(E_values))\n",
    "    I_mean, I_std = torch.mean(torch.tensor(I_values)), torch.std(torch.tensor(I_values))\n",
    "    A_mean, A_std = torch.mean(torch.tensor(A_values)), torch.std(torch.tensor(A_values))\n",
    "\n",
    "    # Normalize each parameter using z-score normalization\n",
    "    for i in range(num_samples):\n",
    "        E, I, A = params[i]['E'], params[i]['I'], params[i]['A']\n",
    "\n",
    "        # Z-score normalization\n",
    "        E_norm = z_score_normalize(E, E_mean, E_std)\n",
    "        I_norm = z_score_normalize(I, I_mean, I_std)\n",
    "        A_norm = z_score_normalize(A, A_mean, A_std)\n",
    "\n",
    "        # Generate the geometry\n",
    "        nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "        # Solve the problem using the VEM\n",
    "        uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t, verbose=False)\n",
    "\n",
    "        # Convert nodes to tensor\n",
    "        nodes = nodes.flatten()\n",
    "        nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "        # Store the dataset\n",
    "        dataset.append({\n",
    "            \"nodes\": nodes,\n",
    "            \"elements\": elements,\n",
    "            \"supp\": supp,\n",
    "            \"load\": load,\n",
    "            \"uh_vem\": uh_vem,\n",
    "            \"K\": K,\n",
    "            \"f\": f,\n",
    "            \"material_params\": torch.tensor([E_norm, A_norm, I_norm], dtype=torch.float32),\n",
    "            \"distorted_material_params\": torch.tensor([z_score_normalize(E * 1.3, E_mean, E_std), \n",
    "                                                      z_score_normalize(A * 1.1, A_mean, A_std), \n",
    "                                                      z_score_normalize(I * 0.3, I_mean, I_std)], dtype=torch.float32)\n",
    "        })\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loss weights\n",
    "loss_weights = torch.ones(3, requires_grad=True, device=device)  # We have 3 tasks: loss, sobolev_loss, and material_penalty \n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 80\n",
    "concatenate = False\n",
    "\n",
    "# Initialize optimizers (including the loss_weights as parameters)\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + [loss_weights], lr=1e-3)\n",
    "optimizer_w = torch.optim.SGD([loss_weights], lr=1e-3)\n",
    "\n",
    "# Initialize lists to store loss values\n",
    "total_loss_values, loss_values, material_loss_values, sobolev_loss_values, alpha_values_values = [], [], [], [], []\n",
    "\n",
    "# Enable anomaly detection for debugging\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Different material property configurations (for example, different E, I, A values)\n",
    "dataset = generate_beam_dataset([1e6, 210e9], [1e-6, 1e-3], [1, 10], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each material in the dataset\n",
    "for i,data in enumerate(dataset):\n",
    "    \n",
    "    material_params_1 = data['material_params']\n",
    "    material_params_2 = data['distorted_material_params']\n",
    "    nodes = data['nodes']\n",
    "    uh_vem = data['uh_vem']\n",
    "\n",
    "    nodes, material_params_1 = neural.normalize_inputs(nodes, material_params_1)\n",
    "    _, material_params_2 = neural.normalize_inputs(nodes, material_params_2)\n",
    "\n",
    "    nodes = nodes.flatten()\n",
    "    nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n",
    "    \n",
    "    # Loop through epochs for the same material\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass using the current material parameters\n",
    "        uh = model(nodes, material_params_1)  # Adjust input to include material params\n",
    "\n",
    "        # Compute individual losses\n",
    "        loss = loss_function.compute_loss_with_uh(uh_vem, uh)\n",
    "        sobolev_loss = loss_function.compute_sobolev_loss(model, nodes, material_params_1, loss, concatenate)\n",
    "        material_penalty = loss_function.compute_material_penalty(model, nodes, material_params_1, material_params_2, concatenate) \n",
    "\n",
    "        # Weighted sum of losses (with GradNorm weights)\n",
    "        weighted_losses = [\n",
    "            loss_weights[0] * loss, \n",
    "            loss_weights[1] * sobolev_loss, \n",
    "            loss_weights[2] * material_penalty\n",
    "        ]\n",
    "\n",
    "        # Store the initial loss weights\n",
    "        if epoch == 0:\n",
    "            initial_loss_weights = [\n",
    "                loss_weights[0] * loss, \n",
    "                loss_weights[1] * sobolev_loss, \n",
    "                loss_weights[2] * material_penalty\n",
    "            ]\n",
    "\n",
    "        # Calculate the gradient norms for each task\n",
    "        grad_norms = gn.calculate_gradient_norm(model, weighted_losses)\n",
    "        tilde_losses = [gn.compute_loss_ratio(weighted_losses[i].item(), initial_loss_weights[i].item()) for i in range(len(weighted_losses))]\n",
    "\n",
    "        # Compute the grad norm loss\n",
    "        loss_grad = gn.compute_grad_norm_loss(grad_norms, tilde_losses, alpha=100)\n",
    "\n",
    "        # Backpropagation of the gradient loss (update the grad_loss weights)\n",
    "        loss_grad.backward(retain_graph=True)\n",
    "\n",
    "        # Step 1: Perform the optimizer step to update the task weights using the gradient loss\n",
    "        optimizer_w.step()\n",
    "\n",
    "        # Step 2: Compute the total loss (sum of the weighted loss)\n",
    "        total_loss = loss_weights[0] * loss + loss_weights[1] * sobolev_loss + loss_weights[2] * material_penalty\n",
    "\n",
    "        # Perform gradient clipping and check for NaN/Inf before backpropagation\n",
    "        if torch.isnan(total_loss).any() or torch.isinf(total_loss).any():\n",
    "            print(f\"NaN or Inf detected in total_loss at epoch {epoch}\")\n",
    "            continue\n",
    "        \n",
    "        # Break if the total loss is too high\n",
    "        if abs(total_loss.item()) > 100.0 and epoch > 0:\n",
    "            break\n",
    "\n",
    "        # Backpropagation for the model weights using total loss\n",
    "        total_loss.backward()\n",
    "\n",
    "        # Step 3: Perform the optimizer step to update the model weights using the total loss\n",
    "        optimizer.step()\n",
    "\n",
    "        # Step 4: Renormalize the loss weights (no in-place operation)\n",
    "        T = len(weighted_losses)\n",
    "        sum_w = torch.sum(loss_weights).item()\n",
    "\n",
    "        # Instead of modifying in-place, re-assign to a new tensor\n",
    "        with torch.no_grad():\n",
    "            loss_weights.copy_((loss_weights / sum_w) * T)  # Use .copy_ to avoid creating new tensors and keep gradients\n",
    "\n",
    "        # Store losses for analysis\n",
    "        if epoch > 1:\n",
    "            total_loss_values.append(total_loss.item())\n",
    "            loss_values.append(loss_weights[0].item()*loss.item())\n",
    "            material_loss_values.append(loss_weights[2].item()*material_penalty.item())\n",
    "            sobolev_loss_values.append(loss_weights[1].item()*sobolev_loss.item())\n",
    "\n",
    "        # Print progress\n",
    "        print(f'Material {i+1}: {material_params_1}, Epoch: {epoch + 1}, Total Loss: {total_loss.item()}, Loss Weights: {loss_weights.detach().numpy()}')\n",
    "        \n",
    "    # Break if the total loss is too high\n",
    "    if abs(total_loss.item()) > 1.0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLASSICAL APPROACH ##\n",
    "\n",
    "print(nodes.shape)\n",
    "print(type(nodes))\n",
    "\n",
    "# Loop through epochs (train across all materials in each epoch)\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    print(f\"--> Epoch {epoch + 1}\")\n",
    "    \n",
    "    # Loop through each material in the dataset\n",
    "    for i, data in enumerate(dataset):\n",
    "        \n",
    "        # Move material parameters and nodes to the correct device\n",
    "        material_params_1 = data['material_params']\n",
    "        material_params_2 = data['distorted_material_params']\n",
    "        nodes = data['nodes']\n",
    "        uh_vem = data['uh_vem']\n",
    "\n",
    "        # Normalize inputs\n",
    "        nodes, material_params_1 = neural.normalize_inputs(nodes, material_params_1)\n",
    "        _, material_params_2 = neural.normalize_inputs(nodes, material_params_2)\n",
    "\n",
    "        material_params_1 = material_params_1.to(device)\n",
    "        material_params_2 = material_params_2.to(device)\n",
    "\n",
    "        nodes = nodes.flatten()\n",
    "        nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True).to(device)\n",
    "        \n",
    "        # Forward pass using the current material parameters\n",
    "        uh = model(nodes, material_params_1.to(device))  # Adjust input to include material params\n",
    "        uh_vem = torch.tensor(uh_vem, dtype=torch.float32, requires_grad=True).to(device)\n",
    "        # Compute individual losses\n",
    "        loss = loss_function.compute_loss_with_uh(uh_vem, uh).to(device)\n",
    "        sobolev_loss = loss_function.compute_sobolev_loss(model, nodes, material_params_1, loss, concatenate).to(device)\n",
    "        material_penalty = loss_function.compute_material_penalty(model, nodes, material_params_1, material_params_2, concatenate).to(device) * 1e10\n",
    "\n",
    "        # Weighted sum of losses (with GradNorm weights)\n",
    "        weighted_losses = [\n",
    "            loss_weights[0] * loss, \n",
    "            loss_weights[1] * sobolev_loss, \n",
    "            loss_weights[2] * material_penalty\n",
    "        ]\n",
    "\n",
    "        # Store the initial loss weights\n",
    "        if epoch == 0 and i == 0:\n",
    "            initial_loss_weights = [\n",
    "                loss_weights[0] * loss, \n",
    "                loss_weights[1] * sobolev_loss, \n",
    "                loss_weights[2] * material_penalty\n",
    "            ]\n",
    "\n",
    "        # Calculate the gradient norms for each task\n",
    "        grad_norms = gn.calculate_gradient_norm(model, weighted_losses)\n",
    "        tilde_losses = [gn.compute_loss_ratio(weighted_losses[i].item(), initial_loss_weights[i].item()) for i in range(len(weighted_losses))]\n",
    "\n",
    "        # Compute the grad norm loss\n",
    "        loss_grad = gn.compute_grad_norm_loss(grad_norms, tilde_losses, alpha=100)\n",
    "\n",
    "        # Backpropagation of the gradient loss (update the grad_loss weights)\n",
    "        loss_grad.backward(retain_graph=True)\n",
    "\n",
    "        # Step 1: Perform the optimizer step to update the task weights using the gradient loss\n",
    "        optimizer_w.step()\n",
    "\n",
    "        # Step 2: Compute the total loss (sum of the weighted loss)\n",
    "        total_loss = loss_weights[0] * loss + loss_weights[1] * sobolev_loss + loss_weights[2] * material_penalty\n",
    "\n",
    "        # Backpropagation for the model weights using total loss\n",
    "        total_loss.backward()\n",
    "\n",
    "        # Step 3: Perform the optimizer step to update the model weights using the total loss\n",
    "        optimizer.step()\n",
    "\n",
    "        # Step 4: Renormalize the loss weights (no in-place operation)\n",
    "        T = len(weighted_losses)\n",
    "        sum_w = torch.sum(loss_weights).item()\n",
    "\n",
    "        # Instead of modifying in-place, re-assign to a new tensor\n",
    "        with torch.no_grad():\n",
    "            loss_weights.copy_((loss_weights / sum_w) * T)\n",
    "\n",
    "        # Store losses for analysis\n",
    "        if epoch > 0:\n",
    "            total_loss_values.append(total_loss.item())\n",
    "            loss_values.append(loss_weights[0].item() * loss.item())\n",
    "            material_loss_values.append(loss_weights[2].item() * material_penalty.item())\n",
    "            sobolev_loss_values.append(loss_weights[1].item() * sobolev_loss.item())\n",
    "\n",
    "        # Print progress\n",
    "        print(f'Material {i+1}: {material_params_1}, Epoch: {epoch + 1}, Total Loss: {total_loss.item()}, Loss Weights: {loss_weights.detach().cpu().numpy()}')\n",
    "\n",
    "    print(\"Finished epoch\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geometry parameter\n",
    "I_new = 1e-4\n",
    "A_new = 1\n",
    "E_new = 110e6\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new, A_new, I_new, load, q, t)\n",
    "\n",
    "# Testing the model with new parameters\n",
    "material_params = torch.tensor([E_new , A_new , I_new ], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"data/models/neural_vem_64.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BeamApproximatorWithMaterials(\n",
       "  (nodes_in): Linear(in_features=386, out_features=128, bias=True)\n",
       "  (nodes_hidden): ModuleList(\n",
       "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (2-4): 3 x Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (nodes_out): Linear(in_features=512, out_features=579, bias=True)\n",
       "  (materials_in): Linear(in_features=3, out_features=128, bias=True)\n",
       "  (materials_hidden): ModuleList(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (4-5): 2 x Linear(in_features=512, out_features=512, bias=True)\n",
       "    (6): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (7-15): 9 x Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (16): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    (17): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (18): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "    (19): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (20): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (21): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (22): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (23-25): 3 x Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (26): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (27): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (materials_out): Linear(in_features=512, out_features=579, bias=True)\n",
       "  (final_in): Linear(in_features=1158, out_features=1024, bias=True)\n",
       "  (final_hidden): ModuleList(\n",
       "    (0-4): 5 x Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (final_out): Linear(in_features=1024, out_features=579, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_layers = [128, 256, 512, 512, 512, 512]  # Layers for nodes sub-network\n",
    "material_layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2048, 2048, 4096, 4096, 2048, 2048, 1024, 1024, 1024, 1024, 512, 512] # Layers for materials sub-network\n",
    "final_layers = [1024, 1024, 1024, 1024, 1024, 1024] # Layers for final combination network\n",
    "\n",
    "# Create a new instance of the model (with the same architecture)\n",
    "loaded_model = neural.BeamApproximatorWithMaterials(\n",
    "    input_dim_nodes=input_dim_nodes, \n",
    "    input_dim_materials=input_dim_materials, \n",
    "    nodes_layers=nodes_layers, \n",
    "    material_layers=material_layers, \n",
    "    final_layers=final_layers, \n",
    "    ndof=ndof\n",
    ")\n",
    "\n",
    "# Load the saved model state\n",
    "loaded_model.load_state_dict(torch.load(\"data/models/neural_vem_64.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode (important for inference)\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving time [s]: 0.0132\n",
      "######################### Beam ##########################\n",
      "[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  5.22081181e-22\n",
      " -2.43714654e-07 -2.95856192e-21  9.02978408e-22 -4.87429309e-07\n",
      "  9.03577313e-21  9.99604850e-22 -7.31143963e-07  1.52347683e-20\n",
      "  9.80283862e-22 -9.74858618e-07  1.64564087e-20  9.46896571e-22\n",
      " -1.21857327e-06  1.61350116e-20  9.23742772e-22 -1.46228793e-06\n",
      "  1.58014652e-20  9.07569675e-22 -1.70600258e-06  1.56882467e-20\n",
      "  8.93252056e-22 -1.94971724e-06  1.56827146e-20  8.78803132e-22\n",
      " -2.19343189e-06  1.56966503e-20  8.64019128e-22 -2.43714654e-06\n",
      "  1.57041596e-20  8.49093308e-22 -2.68086120e-06  1.57057266e-20\n",
      "  8.34148434e-22 -2.92457585e-06  1.57053791e-20  8.19215187e-22\n",
      " -3.16829051e-06  1.57049824e-20  8.04290323e-22 -3.41200516e-06\n",
      "  1.57048426e-20  7.89367783e-22 -3.65571982e-06  1.57048336e-20\n",
      "  7.74445132e-22 -3.89943447e-06  1.57048498e-20  7.59522086e-22\n",
      " -4.14314912e-06  1.57048588e-20  7.44598868e-22 -4.38686378e-06\n",
      "  1.57048609e-20  7.29675624e-22 -4.63057843e-06  1.57048604e-20\n",
      "  7.14752391e-22 -4.87429309e-06  1.57048602e-20  6.99829179e-22\n",
      " -5.11800774e-06  1.57048591e-20  6.84905932e-22 -5.36172240e-06\n",
      "  1.57048624e-20  6.69982818e-22 -5.60543705e-06  1.57048506e-20\n",
      "  6.55059226e-22 -5.84915171e-06  1.57048930e-20  6.40137346e-22\n",
      " -6.09286636e-06  1.57047410e-20  6.25209339e-22 -6.33658101e-06\n",
      "  1.57052851e-20  6.10303258e-22 -6.58029567e-06  1.57033377e-20\n",
      "  5.95318703e-22 -6.82401032e-06  1.57103075e-20  5.80615010e-22\n",
      " -7.06772498e-06  1.56853625e-20  5.64906101e-22 -7.31143963e-06\n",
      "  1.57746414e-20  5.52794895e-22 -7.55515429e-06  1.54551095e-20\n",
      "  5.27807387e-22 -7.79886894e-06  1.65987247e-20  5.48904596e-22\n",
      " -8.04258360e-06  1.25056876e-20  4.05063066e-22 -8.28629825e-06\n",
      "  2.71548040e-20  8.51542785e-22 -8.53001290e-06 -2.52748723e-20\n",
      " -8.14756938e-22 -8.77372756e-06  1.62372688e-19  5.08065144e-21\n",
      " -9.01744221e-06 -5.09224191e-19 -1.60875457e-20 -9.26115687e-06\n",
      "  1.89444344e-18  5.96058041e-20 -9.50487152e-06 -6.70836320e-18\n",
      " -2.11371554e-19 -9.74858618e-06  2.40813687e-17  7.58397115e-19\n",
      " -9.99230083e-06 -8.61161089e-17 -2.71250563e-18 -1.02360155e-05\n",
      "  3.08284339e-16  9.70990275e-18 -1.04797301e-05 -1.10328802e-15\n",
      " -3.47503796e-17 -1.07234448e-05  3.94877654e-15  1.24374386e-16\n",
      " -1.09671594e-05 -1.41327311e-14 -4.45138525e-16 -1.12108741e-05\n",
      "  5.05815878e-14  1.59316711e-15 -1.14545888e-05 -1.81033118e-13\n",
      " -5.70199682e-15 -1.16983034e-05  6.47923641e-13  2.04076382e-14\n",
      " -1.19420181e-05 -2.31894025e-12 -7.30396165e-14 -1.21857327e-05\n",
      "  8.29956458e-12  2.61411225e-13 -1.24294474e-05 -2.97044184e-11\n",
      " -9.35599494e-13 -1.26731620e-05  1.06313104e-10  3.34854180e-12\n",
      " -1.29168767e-05 -3.80498147e-10 -1.19845428e-11 -1.31605913e-05\n",
      "  1.36181556e-09  4.28930784e-11 -1.34043060e-05 -4.87398332e-09\n",
      " -1.53515759e-10 -1.36480206e-05  1.74441489e-08  5.49438021e-10\n",
      " -1.38917353e-05 -6.24331908e-08 -1.96645700e-09 -1.41354500e-05\n",
      "  2.23450472e-07  7.03801521e-09 -1.43791646e-05 -7.99736694e-07\n",
      " -2.51892912e-08 -1.46228793e-05  2.86228431e-06  9.01533135e-08\n",
      " -1.48665939e-05 -1.02442110e-05 -3.22661716e-07 -1.51103086e-05\n",
      "  3.66643729e-05  1.15481705e-06 -1.53540232e-05 -1.31223014e-04\n",
      " -4.13312873e-06 -1.55977379e-05  4.69651543e-04 -4.13312873e-06\n",
      " -4.64931873e-06  2.43648276e-04 -4.13312873e-06 -2.16163496e-07\n",
      "  5.24896980e-05 -4.13312873e-06  3.13961972e-07 -6.33058405e-06\n",
      " -4.13312873e-06 -7.70297227e-08 -6.64675539e-06 -4.13312873e-06\n",
      " -3.38697956e-07  1.76116242e-06 -4.13312873e-06 -4.03192897e-07\n",
      "  5.78738040e-06 -4.13312873e-06 -3.91867363e-07  6.42871773e-06\n",
      " -4.13312873e-06 -3.72997306e-07  6.08527484e-06 -4.13312873e-06\n",
      " -3.61614048e-07  5.76460758e-06 -4.13312873e-06 -3.54935315e-07\n",
      "  5.59923027e-06 -4.13312873e-06 -3.49420554e-07  5.50515831e-06\n",
      " -4.13312873e-06 -3.43775726e-07  5.42259954e-06 -4.13312873e-06\n",
      " -3.37897772e-07  5.33512340e-06 -4.13312873e-06 -3.31926824e-07\n",
      "  5.24359609e-06 -4.13312873e-06 -3.25945346e-07  5.15084225e-06\n",
      " -4.13312873e-06 -3.19972439e-07  5.05809265e-06 -4.13312873e-06\n",
      " -3.14005193e-07  4.96552485e-06 -4.13312873e-06 -3.08039413e-07\n",
      "  4.87304382e-06 -4.13312873e-06 -3.02073508e-07  4.78057786e-06\n",
      " -4.13312873e-06 -2.96107327e-07  4.68810641e-06 -4.13312873e-06\n",
      " -2.90141033e-07  4.59563012e-06 -4.13312873e-06 -2.84174724e-07\n",
      "  4.50315231e-06 -4.13312873e-06 -2.78208425e-07  4.41067448e-06\n",
      " -4.13312873e-06 -2.72242133e-07  4.31819686e-06 -4.13312873e-06\n",
      " -2.66275842e-07  4.22571934e-06 -4.13312873e-06 -2.60309552e-07\n",
      "  4.13324185e-06 -4.13312873e-06 -2.54343261e-07  4.04076435e-06\n",
      " -4.13312873e-06 -2.48376970e-07  3.94828684e-06 -4.13312873e-06\n",
      " -2.42410679e-07  3.85580933e-06 -4.13312873e-06 -2.36444388e-07\n",
      "  3.76333182e-06 -4.13312873e-06 -2.30478097e-07  3.67085431e-06\n",
      " -4.13312873e-06 -2.24511806e-07  3.57837680e-06 -4.13312873e-06\n",
      " -2.18545515e-07  3.48589929e-06 -4.13312873e-06 -2.12579224e-07\n",
      "  3.39342178e-06 -4.13312873e-06 -2.06612934e-07  3.30094427e-06\n",
      " -4.13312873e-06 -2.00646643e-07  3.20846676e-06 -4.13312873e-06\n",
      " -1.94680352e-07  3.11598925e-06 -4.13312873e-06 -1.88714061e-07\n",
      "  3.02351174e-06 -4.13312873e-06 -1.82747770e-07  2.93103423e-06\n",
      " -4.13312873e-06 -1.76781479e-07  2.83855672e-06 -4.13312873e-06\n",
      " -1.70815188e-07  2.74607921e-06 -4.13312873e-06 -1.64848897e-07\n",
      "  2.65360170e-06 -4.13312873e-06 -1.58882606e-07  2.56112419e-06\n",
      " -4.13312873e-06 -1.52916315e-07  2.46864669e-06 -4.13312873e-06\n",
      " -1.46950024e-07  2.37616917e-06 -4.13312873e-06 -1.40983733e-07\n",
      "  2.28369168e-06 -4.13312873e-06 -1.35017443e-07  2.19121411e-06\n",
      " -4.13312873e-06 -1.29051150e-07  2.09873682e-06 -4.13312873e-06\n",
      " -1.23084866e-07  2.00625853e-06 -4.13312873e-06 -1.17118550e-07\n",
      "  1.91378381e-06 -4.13312873e-06 -1.11152347e-07  1.82129631e-06\n",
      " -4.13312873e-06 -1.05185742e-07  1.72885454e-06 -4.13312873e-06\n",
      " -9.92205765e-08  1.63624913e-06 -4.13312873e-06 -9.32502572e-08\n",
      "  1.54422937e-06 -4.13312873e-06 -8.72983839e-08  1.45011357e-06\n",
      " -4.13312873e-06 -8.12804916e-08  1.36349958e-06 -4.13312873e-06\n",
      " -7.54988838e-08  1.25003634e-06 -4.13312873e-06 -6.88716058e-08\n",
      "  1.23266745e-06 -4.13312873e-06 -6.52710096e-08  8.71373687e-07\n",
      " -4.13312873e-06 -5.08378184e-08  1.74099851e-06 -4.13312873e-06\n",
      " -7.51748459e-08 -1.79487533e-06 -4.13312873e-06  3.92480327e-08\n",
      "  1.04366775e-05 -4.13312873e-06 -3.42955422e-07 -3.37639157e-05\n",
      " -4.13312873e-06  1.05228334e-06  1.24008024e-04 -1.18050619e-06\n",
      "  1.03584141e-06  6.49598185e-05  3.83685636e-08  1.01939948e-06\n",
      "  1.30481658e-05  1.91473222e-07  1.00295755e-06 -3.24946760e-06\n",
      "  8.64121502e-08  9.86515628e-07 -3.47444102e-06  1.34711299e-08\n",
      "  9.70073701e-07 -1.19378428e-06 -6.19049593e-09  9.53631774e-07\n",
      " -6.45597774e-08 -4.95010824e-09  9.37189846e-07  1.43944590e-07\n",
      " -1.47202146e-09  9.20747919e-07  7.86529642e-08  1.79923832e-11\n",
      "  9.04305992e-07  1.67079221e-08  2.24407258e-10  8.87864065e-07\n",
      " -3.49737004e-09  1.05229243e-10  8.71422138e-07 -4.13002294e-09\n",
      "  1.76887476e-11  8.54980211e-07 -1.47256877e-09 -6.92128264e-12\n",
      "  8.38538284e-07 -1.02473171e-10 -5.91956694e-12  8.22096356e-07\n",
      "  1.66582975e-10 -1.83090009e-12  8.05654429e-07  9.50917033e-11\n",
      " -1.24141696e-14  7.89212502e-07  2.12913959e-11  2.62393627e-13\n",
      "  7.72770575e-07 -3.70369693e-12  1.27945037e-13  7.56328648e-07\n",
      " -4.90101280e-12  2.30398285e-14  7.39886721e-07 -1.81292057e-12\n",
      " -7.67868954e-15  7.23444794e-07 -1.53064584e-13 -7.06795652e-15\n",
      "  7.07002867e-07  1.92151497e-13 -2.27188414e-15  6.90560939e-07\n",
      "  1.14797136e-13 -5.60601238e-17  6.74119012e-07  2.70156010e-14\n",
      "  3.06050595e-16  6.57677085e-07 -3.84051492e-15  1.55327045e-16\n",
      "  6.41235158e-07 -5.80579215e-15  2.98026444e-17  6.24793231e-07\n",
      " -2.22776940e-15 -8.44148358e-18  6.08351304e-07 -2.19854687e-16\n",
      " -8.42588544e-18  5.91909377e-07  2.20853069e-16 -2.81282518e-18\n",
      "  5.75467450e-07  1.38382889e-16 -1.17065930e-19  5.59025522e-07\n",
      "  3.41458038e-17  3.55988741e-19  5.42583595e-07 -3.87020398e-18\n",
      "  1.88247976e-19  5.26141668e-07 -6.86510412e-18  3.82831308e-20\n",
      "  5.09699741e-07 -2.73254516e-18 -9.21391538e-21  4.93257814e-07\n",
      " -3.07164954e-19 -1.00629599e-20  4.76815887e-07  2.52926951e-19\n",
      " -3.50861072e-21  4.60373960e-07  1.66652243e-19 -2.32996459e-22\n",
      "  4.43932033e-07  4.30879165e-20  3.81480762e-22  4.27490105e-07\n",
      " -3.66052742e-21  1.97396527e-22  4.11048178e-07 -8.02001664e-21\n",
      "  1.95168178e-23  3.94606251e-07 -3.26343781e-21 -3.83328845e-23\n",
      "  3.78164324e-07 -3.38096172e-22 -3.93968556e-23  3.61722397e-07\n",
      "  3.70848990e-22 -3.07586511e-23  3.45280470e-07  2.82843062e-22\n",
      " -2.57801388e-23  3.28838543e-07  1.36628696e-22 -2.39828188e-23\n",
      "  3.12396615e-07  7.92467460e-23 -2.31781987e-23  2.95954688e-07\n",
      "  7.30959095e-23 -2.23844650e-23  2.79512761e-07  7.85500187e-23\n",
      " -2.14504607e-23  2.63070834e-07  8.20732229e-23 -2.04474372e-23\n",
      "  2.46628907e-07  8.29672500e-23 -1.94317956e-23  2.30186980e-07\n",
      "  8.28807745e-23 -1.84202133e-23  2.13745053e-07  8.27074618e-23\n",
      " -1.74124032e-23  1.97303126e-07  8.26393568e-23 -1.64059130e-23\n",
      "  1.80861198e-07  8.26229801e-23 -1.53991400e-23  1.64419271e-07\n",
      "  8.26574578e-23 -1.43933419e-23  1.47977344e-07  8.25605874e-23\n",
      " -1.33833857e-23  1.31535417e-07  8.29235780e-23 -1.23879955e-23\n",
      "  1.15093490e-07  8.16283637e-23 -1.13404192e-23  9.86515628e-08\n",
      "  8.62634858e-23 -1.04796390e-23  8.22096356e-08  6.96734147e-23\n",
      " -8.95032715e-24  6.57677085e-08  1.29049513e-22 -9.81371796e-24\n",
      "  4.93257814e-08 -8.34595578e-23 -2.11354608e-24  3.28838543e-08\n",
      "  6.77117526e-22  4.23320763e-24  1.64419271e-08 -1.70078321e-22\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "#########################################################\n",
      "Predicted displacements: tensor([-2.0303e-06, -1.4706e-06, -1.9688e-06, -1.5432e-06, -2.1365e-06,\n",
      "        -1.7304e-06, -1.6857e-06, -1.5322e-06, -1.6759e-06, -1.8738e-06,\n",
      "        -1.8473e-06, -1.6767e-06, -1.6079e-06, -1.7080e-06, -2.1174e-06,\n",
      "        -1.9539e-06, -1.9809e-06, -1.6540e-06, -2.1141e-06, -1.8210e-06,\n",
      "        -1.5646e-06, -1.9884e-06, -1.4640e-06, -2.2240e-06, -1.8682e-06,\n",
      "        -1.5281e-06, -1.4901e-06, -1.7048e-06, -2.1468e-06, -1.6321e-06,\n",
      "        -1.6503e-06, -1.6270e-06, -1.9763e-06, -1.7285e-06, -2.0899e-06,\n",
      "        -1.6522e-06, -1.7378e-06, -1.6252e-06, -2.1029e-06, -1.9938e-06,\n",
      "        -1.6484e-06, -1.4622e-06, -1.6242e-06, -1.6280e-06, -1.8743e-06,\n",
      "        -1.5311e-06, -2.1234e-06, -1.8757e-06, -2.0699e-06, -2.1104e-06,\n",
      "        -2.1029e-06, -1.7174e-06, -2.1104e-06, -1.5274e-06, -1.4082e-06,\n",
      "        -1.8012e-06, -1.4929e-06, -2.1607e-06, -2.2370e-06, -1.6284e-06,\n",
      "        -1.8990e-06, -1.6656e-06, -2.1700e-06, -1.4694e-06, -1.7043e-06,\n",
      "        -1.5683e-06, -1.6754e-06, -2.0005e-06, -2.0061e-06, -2.1495e-06,\n",
      "        -2.3022e-06, -1.7341e-06, -1.9576e-06, -2.1458e-06, -1.9427e-06,\n",
      "        -1.6857e-06, -2.0228e-06, -1.5828e-06, -1.5832e-06, -1.8533e-06,\n",
      "        -2.2352e-06, -1.5572e-06, -1.9457e-06, -1.5106e-06, -1.9709e-06,\n",
      "        -2.0880e-06, -1.9232e-06, -2.0489e-06, -1.4603e-06, -1.5497e-06,\n",
      "        -1.9153e-06, -2.0540e-06, -1.6522e-06, -1.4533e-06, -2.0023e-06,\n",
      "        -1.5870e-06, -1.8217e-06, -1.6182e-06, -1.9642e-06, -2.2203e-06,\n",
      "        -2.1430e-06, -1.6579e-06, -1.7593e-06, -1.6168e-06, -1.5860e-06,\n",
      "        -2.2163e-06, -1.6876e-06, -1.4752e-06, -2.0582e-06, -2.0424e-06,\n",
      "        -1.7324e-06, -2.1295e-06, -1.9502e-06, -1.8657e-06, -1.6292e-06,\n",
      "        -1.9474e-06, -1.7602e-06, -1.6950e-06, -1.5032e-06, -1.4324e-06,\n",
      "        -1.9744e-06, -1.7574e-06, -1.5087e-06, -1.4617e-06, -1.6827e-06,\n",
      "        -1.9716e-06, -1.6429e-06, -1.5893e-06, -1.9632e-06, -1.8636e-06,\n",
      "        -2.1011e-06, -1.9290e-06, -1.5767e-06, -1.9129e-06, -2.1011e-06,\n",
      "        -1.5963e-06, -1.6987e-06, -2.0899e-06, -1.8566e-06, -1.9958e-06,\n",
      "        -1.6605e-06, -1.6857e-06, -1.8519e-06, -1.3281e-06, -2.0573e-06,\n",
      "        -1.8736e-06, -1.6596e-06, -1.7751e-06, -1.6957e-06, -2.1011e-06,\n",
      "        -1.6121e-06, -1.7527e-06, -1.7972e-06, -1.6131e-06, -2.0899e-06,\n",
      "        -1.5525e-06, -1.8002e-06, -1.8952e-06, -1.6158e-06, -2.0843e-06,\n",
      "        -1.7541e-06, -1.7062e-06, -2.0238e-06, -1.9654e-06, -1.7285e-06,\n",
      "        -2.2277e-06, -2.1188e-06, -1.8897e-06, -1.9404e-06, -1.8529e-06,\n",
      "        -1.7574e-06, -2.1411e-06, -1.8571e-06, -2.1067e-06, -1.6307e-06,\n",
      "        -1.6536e-06, -1.4920e-06, -1.6708e-06, -1.6410e-06, -1.6317e-06,\n",
      "        -1.6764e-06, -1.4696e-06, -1.6326e-06, -1.6214e-06, -1.7032e-06,\n",
      "        -2.0303e-06, -1.5562e-06, -1.8734e-06, -1.9926e-06, -1.4396e-06,\n",
      "        -2.2622e-06, -1.6261e-06, -2.1271e-06, -2.1998e-06, -1.3523e-06,\n",
      "        -2.0172e-06, -2.1346e-06, -1.4286e-06, -1.4082e-06, -1.6300e-06,\n",
      "        -2.3413e-06, -2.0629e-06, -1.6619e-06, -1.6894e-06, -1.5898e-06,\n",
      "        -1.7742e-06, -1.8831e-06, -1.8661e-06, -1.4920e-06, -1.6447e-06,\n",
      "        -1.6326e-06, -2.1523e-06, -2.0112e-06, -1.7243e-06, -1.7402e-06,\n",
      "        -2.1625e-06, -2.1588e-06, -1.6186e-06, -1.6234e-06, -1.6820e-06,\n",
      "        -2.1048e-06, -1.7341e-06, -2.0992e-06, -1.4771e-06, -1.4352e-06,\n",
      "        -2.1569e-06, -1.8980e-06, -1.7730e-06, -1.5292e-06, -2.2787e-06,\n",
      "        -2.0321e-06, -1.6242e-06, -2.2883e-06, -1.5199e-06, -1.5926e-06,\n",
      "        -1.7919e-06, -1.4957e-06, -1.8142e-06, -1.5311e-06, -1.6578e-06,\n",
      "        -2.0945e-06, -1.9036e-06, -1.6068e-06, -2.1439e-06, -1.4212e-06,\n",
      "        -1.8971e-06, -1.7062e-06, -2.0890e-06, -2.0047e-06, -1.4664e-06,\n",
      "        -1.7425e-06, -2.3542e-06, -1.8291e-06, -1.6615e-06, -1.4370e-06,\n",
      "        -1.6335e-06, -1.7718e-06, -1.7472e-06, -1.7639e-06, -2.2855e-06,\n",
      "        -2.0713e-06, -1.6652e-06, -2.1700e-06, -1.6969e-06, -1.5367e-06,\n",
      "        -2.1750e-06, -2.1681e-06, -2.0686e-06, -1.4566e-06, -2.0051e-06,\n",
      "        -1.7481e-06, -2.1579e-06, -1.6876e-06, -1.9595e-06, -1.6000e-06,\n",
      "        -2.1327e-06, -2.0154e-06, -1.9094e-06, -1.9218e-06, -2.1290e-06,\n",
      "        -2.1986e-06, -1.6545e-06, -1.7110e-06, -2.0098e-06, -2.1020e-06,\n",
      "        -1.6838e-06, -1.6051e-06, -1.7080e-06, -1.5716e-06, -1.4789e-06,\n",
      "        -2.2892e-06, -1.6754e-06, -1.5115e-06, -1.4808e-06, -1.7048e-06,\n",
      "        -1.6084e-06, -1.8816e-06, -2.1830e-06, -2.0657e-06, -2.1029e-06,\n",
      "        -2.1551e-06, -1.9197e-06, -1.5930e-06, -1.7183e-06, -1.7155e-06,\n",
      "        -1.9129e-06, -2.2026e-06, -1.8105e-06, -1.4976e-06, -1.3858e-06,\n",
      "        -1.8869e-06, -1.4994e-06, -1.5292e-06, -2.1253e-06, -1.5222e-06,\n",
      "        -1.6009e-06, -1.7248e-06, -1.7267e-06, -2.1402e-06, -2.1625e-06,\n",
      "        -1.9637e-06, -1.9576e-06, -1.9072e-06, -1.7155e-06, -1.9241e-06,\n",
      "        -1.8906e-06, -2.1914e-06, -2.2724e-06, -2.1857e-06, -1.7192e-06,\n",
      "        -2.0973e-06, -1.5739e-06, -2.0349e-06, -1.6158e-06, -1.6470e-06,\n",
      "        -1.5898e-06, -1.5544e-06, -1.7490e-06, -1.5115e-06, -2.0554e-06,\n",
      "        -1.5385e-06, -1.9744e-06, -1.2759e-06, -2.0731e-06, -2.1048e-06,\n",
      "        -1.7025e-06, -1.9292e-06, -1.6519e-06, -2.1048e-06, -1.7304e-06,\n",
      "        -1.6801e-06, -1.6897e-06, -2.0340e-06, -2.0927e-06, -1.4827e-06,\n",
      "        -2.1346e-06, -1.6874e-06, -1.8794e-06, -1.2973e-06, -2.2184e-06,\n",
      "        -2.1681e-06, -1.9930e-06, -2.1830e-06, -1.7761e-06, -1.8454e-06,\n",
      "        -2.0671e-06, -1.4519e-06, -1.9660e-06, -2.2277e-06, -1.9274e-06,\n",
      "        -1.9660e-06, -1.6280e-06, -1.9874e-06, -2.1271e-06, -1.6950e-06,\n",
      "        -2.0284e-06, -1.5739e-06, -1.6829e-06, -1.6624e-06, -2.1057e-06,\n",
      "        -1.8743e-06, -2.0694e-06, -2.1756e-06, -2.2133e-06, -1.9455e-06,\n",
      "        -1.7346e-06, -1.5730e-06, -1.7677e-06, -2.0084e-06, -1.9842e-06,\n",
      "        -1.7853e-06, -2.0405e-06, -2.1458e-06, -2.2799e-06, -1.5560e-06,\n",
      "        -1.7099e-06, -1.8626e-06, -2.1262e-06, -1.9185e-06, -1.9930e-06,\n",
      "        -1.4704e-06, -1.6165e-06, -1.7248e-06, -1.5429e-06, -1.8626e-06,\n",
      "        -1.6503e-06, -2.2221e-06, -1.5637e-06, -1.8328e-06, -1.8389e-06,\n",
      "        -2.0708e-06, -1.8384e-06, -2.0433e-06, -1.5516e-06, -2.1290e-06,\n",
      "        -2.1141e-06, -1.4398e-06, -2.0619e-06, -1.8822e-06, -1.7962e-06,\n",
      "        -1.9385e-06, -2.0294e-06, -2.0619e-06, -1.5143e-06, -2.1105e-06,\n",
      "        -1.5812e-06, -1.8654e-06, -2.0170e-06, -2.0345e-06, -1.8366e-06,\n",
      "        -2.0694e-06, -2.1504e-06, -1.6177e-06, -1.3708e-06, -1.9860e-06,\n",
      "        -1.5569e-06, -2.1588e-06, -1.6863e-06, -2.1267e-06, -2.0657e-06,\n",
      "        -1.8002e-06, -1.9744e-06, -1.7334e-06, -1.9129e-06, -2.2072e-06,\n",
      "        -1.6475e-06, -1.6345e-06, -1.8608e-06, -1.6298e-06, -1.5777e-06,\n",
      "        -1.5441e-06, -2.0610e-06, -1.9949e-06, -1.8952e-06, -2.1858e-06,\n",
      "        -2.0880e-06, -1.5455e-06, -1.5483e-06, -1.5567e-06, -1.8291e-06,\n",
      "        -2.0918e-06, -1.7770e-06, -2.1132e-06, -2.0573e-06, -1.6786e-06,\n",
      "        -2.0564e-06, -1.9763e-06, -1.9418e-06, -1.8515e-06, -2.1476e-06,\n",
      "        -1.5236e-06, -1.7141e-06, -1.9716e-06, -1.6405e-06, -2.0359e-06,\n",
      "        -1.6647e-06, -1.7993e-06, -1.7344e-06, -1.6745e-06, -2.1011e-06,\n",
      "        -1.5018e-06, -1.8692e-06, -1.6540e-06, -2.0899e-06, -1.6335e-06,\n",
      "        -1.8179e-06, -1.6047e-06, -1.8012e-06, -1.6219e-06, -1.5148e-06,\n",
      "        -1.8962e-06, -2.0787e-06, -1.5665e-06, -1.7611e-06, -1.6019e-06,\n",
      "        -1.5218e-06, -1.6838e-06, -2.0303e-06, -1.9195e-06, -2.0918e-06,\n",
      "        -1.7956e-06, -2.1420e-06, -2.0694e-06, -1.7276e-06, -2.2054e-06,\n",
      "        -1.9278e-06, -2.0694e-06, -2.1756e-06, -1.7276e-06, -2.1029e-06,\n",
      "        -2.1691e-06, -1.6214e-06, -2.0210e-06, -1.8672e-06, -2.0470e-06,\n",
      "        -1.6112e-06, -1.5926e-06, -1.4653e-06, -2.0508e-06, -1.6270e-06,\n",
      "        -1.6838e-06, -1.6605e-06, -1.9390e-06, -1.4892e-06, -1.6671e-06,\n",
      "        -1.6391e-06, -1.9856e-06, -2.1402e-06, -1.4938e-06, -1.6475e-06,\n",
      "        -1.5870e-06, -2.1309e-06, -1.6140e-06, -2.0207e-06, -1.5823e-06,\n",
      "        -2.0713e-06, -2.2538e-06, -1.7164e-06, -1.5246e-06, -1.5665e-06,\n",
      "        -1.6403e-06, -1.3653e-06, -1.5441e-06, -1.9930e-06, -1.9483e-06,\n",
      "        -1.7149e-06, -1.5935e-06, -1.5497e-06, -2.1923e-06, -1.7746e-06,\n",
      "        -1.7937e-06, -1.5483e-06, -1.4901e-06, -1.7462e-06, -1.5898e-06,\n",
      "        -2.1234e-06, -1.6987e-06, -2.0079e-06, -2.2482e-06, -1.8738e-06,\n",
      "        -1.8477e-06, -1.6822e-06, -2.0731e-06, -1.9914e-06, -2.2836e-06,\n",
      "        -2.0722e-06, -2.0191e-06, -1.6298e-06, -2.0210e-06, -1.5106e-06,\n",
      "        -2.0368e-06, -1.9746e-06, -2.1756e-06, -2.2054e-06, -2.0228e-06,\n",
      "        -2.0512e-06, -1.6354e-06, -1.9921e-06, -1.6540e-06],\n",
      "       requires_grad=True)\n",
      "Inference time [s]: 0.003278970718383789\n",
      "L2 error: 1.0034536123275757\n",
      "Energy error: 0\n",
      "H1 error: 0.0005762420478276908\n"
     ]
    }
   ],
   "source": [
    "# New geometry parameters for inference\n",
    "I_new = 1e-4\n",
    "A_new = 1\n",
    "E_new = 110e6\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new, A_new, I_new, load, q, t)\n",
    "\n",
    "# Prepare the input for the model\n",
    "material_params = torch.tensor([E_new, A_new, I_new], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "\n",
    "# Normalize inputs before passing to the model\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "\n",
    "# Test the model using the new material parameters\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=loaded_model,  # Use the loaded model for inference\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_time_list = []\n",
    "for _ in range(time_sampling_size):\n",
    "    # Test the model using the new material parameters\n",
    "    predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=loaded_model,  # Use the loaded model for inference\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=True\n",
    "    )\n",
    "    inference_time_list.append(inference_time)\n",
    "\n",
    "print(\"Mean inference time: \", np.mean(inference_time_list))\n",
    "print(\"Std Deviation: \", np.std(inference_time_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helpers import read_disp_json, consolidate_json_in_dataset\n",
    "import numpy as np\n",
    "filename = \"data/displacements_64_1.json_1731459229.json\"\n",
    "\n",
    "# Read the displacement data from the JSON file\n",
    "u, E, I, A = read_disp_json(filename)\n",
    "\n",
    "print(type(u))\n",
    "print(type(u[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path_name = \"data/datasets/portic/\"\n",
    "consolidate_json_in_dataset(directory_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datasets import generate_beam_dataset_from_json\n",
    "\n",
    "result_filename = \"data/consolidated_portic_data.json\"\n",
    "geometry_filename = \"data/geometries/portic_64.json\"\n",
    "dataset = generate_beam_dataset_from_json(result_filename=result_filename, geometry_filename=geometry_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved in data/consolidated_beam_data.json\n"
     ]
    }
   ],
   "source": [
    "from utils.helpers import read_disp_json, consolidate_json_in_dataset\n",
    "directory_path_name = \"data/datasets/beam/\"\n",
    "consolidate_json_in_dataset(directory_path_name, \"consolidated_beam_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datasets import generate_beam_dataset_from_json\n",
    "\n",
    "result_filename = \"data/consolidated_beam_data.json\"\n",
    "geometry_filename = \"data/geometries/beam_64.json\"\n",
    "dataset = generate_beam_dataset_from_json(result_filename=result_filename, geometry_filename=geometry_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
