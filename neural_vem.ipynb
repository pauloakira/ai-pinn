{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points:\n",
    "\n",
    "1. **Using VEM/FEM Solutions for Efficient Training**:\n",
    "   - By training the neural network on the displacement field computed using VEM/FEM, you're providing the model with a high-quality reference solution. This allows the model to learn the underlying physical relationships between the parameters (such as Young’s modulus \\(E\\), cross-sectional area \\(A\\), and moment of inertia \\(I\\)) and the displacement field.\n",
    "\n",
    "2. **Generalization with Fewer Data**:\n",
    "   - Since the model is grounded in physically informed solutions, you likely need **fewer training examples** to generalize to new material and geometrical configurations. Unlike traditional machine learning models that require vast amounts of labeled data, your approach can rely on solving a **few instances** of VEM/FEM solutions and using that information to generalize.\n",
    "\n",
    "3. **Parameter Sensitivity and Inference**:\n",
    "   - The network’s sensitivity to material and geometrical parameters (\\(E\\), \\(A\\), \\(I\\)) is key. Once trained, the model will allow for **rapid inference** with new combinations of these parameters without needing to solve the full VEM/FEM system again.\n",
    "   - In an engineering context, this is particularly advantageous, as engineers often need to explore various material or geometric configurations during design optimization. Having a trained neural network that provides **instant predictions** without solving a full VEM/FEM problem would significantly improve efficiency.\n",
    "\n",
    "4. **Efficiency Compared to Traditional VEM/FEM**:\n",
    "   - Solving a full VEM/FEM problem repeatedly for different parameter values can be computationally expensive, especially for large or complex systems. By training a neural network to approximate the displacement field based on these parameters, you essentially create a **surrogate model** that can make predictions more efficiently.\n",
    "\n",
    "### Challenges and Considerations:\n",
    "- **Accuracy vs. Efficiency**: While the neural network may provide fast predictions, the trade-off is the potential for reduced accuracy compared to solving the full VEM/FEM system. This can be mitigated by fine-tuning the network and introducing additional regularization techniques like Sobolev training.\n",
    "  \n",
    "- **Extrapolation Limits**: The network might struggle with extrapolating far beyond the range of material and geometrical parameters it was trained on. Ensuring that the training data includes a representative range of parameters will be crucial for reliable generalization.\n",
    "\n",
    "- **Hybrid Model Validation**: You could validate your hypothesis by comparing the **computational cost** (in terms of time) and **accuracy** between solving multiple VEM/FEM instances and using the trained neural network for inference over a variety of material/geometrical configurations.\n",
    "\n",
    "### Conclusion:\n",
    "The approach of training a neural network using VEM/FEM solutions to enable efficient inference of displacement fields for different material and geometric configurations is a practical and promising solution in engineering contexts. It leverages the strengths of both numerical methods and machine learning to balance accuracy and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import core.vem as vem\n",
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "\n",
    "import utils.mesh as mesh\n",
    "import core.loss as loss_function\n",
    "import core.errors as errors\n",
    "import core.neural_backend as neural\n",
    "\n",
    "import solve_vem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS backend is available!\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS backend is available!\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS backend is not available. Using CPU.\")\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of elements per edge\n",
    "num_elements_per_edge = 32\n",
    "\n",
    "# geometry data\n",
    "L = 2.0\n",
    "I = 1e-4\n",
    "A = 1\n",
    "\n",
    "# material data\n",
    "E = 27e6\n",
    "\n",
    "# Define load parameters\n",
    "q = -400\n",
    "t = 0\n",
    "\n",
    "# Time sampling size\n",
    "time_sampling_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving time [s]: 0.0011\n",
      "######################### Beam ##########################\n",
      "[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -6.11294039e-19\n",
      " -1.94881114e-06  2.00665681e-18 -1.07225777e-18 -3.89762227e-06\n",
      " -4.81056994e-18 -1.20533083e-18 -5.84643341e-06 -8.48584458e-18\n",
      " -1.20465840e-18 -7.79524455e-06 -9.09042567e-18 -1.17311919e-18\n",
      " -9.74405568e-06 -9.47358127e-18 -1.20009988e-18 -1.16928668e-05\n",
      " -7.21778913e-18 -1.06211412e-18 -1.36416780e-05 -1.47525077e-17\n",
      " -1.56704915e-18 -1.55904891e-05  1.33556765e-17  2.95131067e-19\n",
      " -1.75393002e-05 -9.05001960e-17 -6.58894322e-18 -1.94881114e-05\n",
      "  2.93235821e-16  1.88480147e-17 -2.14369225e-05 -1.12477323e-15\n",
      " -7.51477879e-17 -2.33857336e-05  4.11508416e-15  2.72187318e-16\n",
      " -2.53345448e-05 -1.52473623e-14 -1.01129425e-15 -2.72833559e-05\n",
      "  5.63012177e-14  3.73145723e-15 -2.92321670e-05 -2.08086820e-13\n",
      " -1.37940730e-14 -3.11809782e-05  7.68886231e-13  5.09666882e-14\n",
      " -3.31297893e-05 -2.84124814e-12 -1.88338838e-13 -3.50786005e-05\n",
      "  1.04990074e-11  6.95948712e-13 -3.70274116e-05 -3.87962266e-11\n",
      " -2.57169197e-12 -3.89762227e-05  1.43360711e-10  9.50297265e-12\n",
      " -4.09250339e-05 -5.29749996e-10 -3.51156192e-11 -4.28738450e-05\n",
      "  1.95754492e-09  1.29760077e-10 -4.48226561e-05 -7.23356722e-09\n",
      " -4.79492571e-10 -4.67714673e-05  2.67296519e-08  1.77183250e-09\n",
      " -4.87202784e-05 -9.87720544e-08 -6.54731819e-09 -5.06690896e-05\n",
      "  3.64984877e-07  2.41938080e-08 -5.26179007e-05 -1.34870092e-06\n",
      " -8.94015428e-08 -5.45667118e-05  4.98375214e-06  3.30358736e-07\n",
      " -5.65155230e-05 -1.84160811e-05 -1.22074957e-06 -5.84643341e-05\n",
      "  6.80515468e-05  4.51094324e-06 -6.04131452e-05 -2.51465717e-04\n",
      " -1.66689462e-05 -6.23619564e-05  9.29222179e-04 -1.66689462e-05\n",
      " -2.49403084e-05  4.68257634e-04 -1.66689462e-05 -1.14713779e-05\n",
      "  1.56707057e-04 -1.66689462e-05 -1.02158223e-05  7.14014743e-05\n",
      " -1.66689462e-05 -1.13480773e-05  7.42689527e-05 -1.66689462e-05\n",
      " -1.18228193e-05  8.64137252e-05 -1.66689462e-05 -1.16199620e-05\n",
      "  8.99239695e-05 -1.66689462e-05 -1.11843858e-05  8.78325676e-05\n",
      " -1.66689462e-05 -1.07363370e-05  8.42949259e-05 -1.66689462e-05\n",
      " -1.03169442e-05  8.08874125e-05 -1.66689462e-05 -9.91340720e-06\n",
      "  7.77593785e-05 -1.66689462e-05 -9.51333441e-06  7.47483930e-05\n",
      " -1.66689462e-05 -9.11258594e-06  7.17528371e-05 -1.66689462e-05\n",
      " -8.71099027e-06  6.87473397e-05 -1.66689462e-05 -8.30908177e-06\n",
      "  6.57346839e-05 -1.66689462e-05 -7.90714701e-06  6.27200166e-05\n",
      " -1.66689462e-05 -7.50524612e-06  5.97054363e-05 -1.66689462e-05\n",
      " -7.10336572e-06  5.66911975e-05 -1.66689462e-05 -6.70149018e-06\n",
      "  5.36771172e-05 -1.66689462e-05 -6.29961428e-06  5.06630455e-05\n",
      " -1.66689462e-05 -5.89773628e-06  4.76490206e-05 -1.66689462e-05\n",
      " -5.49586171e-06  4.46347723e-05 -1.66689462e-05 -5.09397289e-06\n",
      "  4.16213132e-05 -1.66689462e-05 -4.69213661e-06  3.86049272e-05\n",
      " -1.66689462e-05 -4.29010633e-06  3.55993577e-05 -1.66689462e-05\n",
      " -3.88879303e-06  3.25538202e-05 -1.66689462e-05 -3.48483035e-06\n",
      "  2.96559744e-05 -1.66689462e-05 -3.09065773e-06  2.62123746e-05\n",
      " -1.66689462e-05 -2.66030863e-06  2.47854582e-05 -1.66689462e-05\n",
      " -2.36363974e-06  1.59064445e-05 -1.66689462e-05 -1.57299253e-06\n",
      "  3.45646005e-05 -1.66689462e-05 -2.60770588e-06 -4.85332570e-05\n",
      " -1.66689462e-05  3.10269711e-06  2.44380160e-04 -4.90681721e-06\n",
      "  3.00573783e-06  1.32007968e-04  9.26621974e-08  2.90877854e-06\n",
      "  2.79753734e-05  7.77873404e-07  2.81181926e-06 -6.04861474e-06\n",
      "  3.66021873e-07  2.71485997e-06 -7.13063427e-06  6.25963471e-08\n",
      "  2.61790069e-06 -2.57898256e-06 -2.40822363e-08  2.52094140e-06\n",
      " -1.94732114e-07 -2.11061147e-08  2.42398212e-06  2.89968006e-07\n",
      " -6.71104246e-09  2.32702283e-06  1.70674305e-07 -1.25888822e-10\n",
      "  2.23006355e-06  4.00506109e-08  9.40533016e-10  2.13310426e-06\n",
      " -5.92511206e-09  4.78084318e-10  2.03614498e-06 -8.87324628e-09\n",
      "  9.30332502e-11  1.93918569e-06 -3.44838788e-09 -2.59508058e-11\n",
      "  1.84222641e-06 -3.59101896e-10 -2.65630429e-11  1.74526713e-06\n",
      "  3.39510326e-10 -9.09682050e-12  1.64830784e-06  2.19408809e-10\n",
      " -4.76171238e-13  1.55134856e-06  5.64519850e-11  1.12569390e-12\n",
      "  1.45438927e-06 -5.19228312e-12  6.20802451e-13  1.35742999e-06\n",
      " -1.09642257e-11  1.35079797e-13  1.26047070e-06 -4.57888174e-12\n",
      " -2.67279550e-14  1.16351142e-06 -5.98948824e-13 -3.32211745e-14\n",
      "  1.06655213e-06  3.91183282e-13 -1.22329051e-14  9.69592847e-07\n",
      "  2.80458819e-13 -1.01426933e-15  8.72633563e-07  7.85550065e-14\n",
      "  1.33039671e-15  7.75674278e-07 -3.50821239e-15  8.00336905e-16\n",
      "  6.78714993e-07 -1.34362207e-14  1.91418290e-16  5.81755708e-07\n",
      " -6.03169426e-15 -2.67919063e-17  4.84796424e-07 -9.33551324e-16\n",
      " -4.24328640e-17  3.87837139e-07  4.50521385e-16 -1.74943124e-17\n",
      "  2.90877854e-07  3.64992977e-16 -2.96629836e-18  1.93918569e-07\n",
      "  1.17384181e-16  3.50978645e-19  9.69592847e-08  6.24939266e-18\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "#########################################################\n"
     ]
    }
   ],
   "source": [
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Plot the nodes\n",
    "mesh.plot_nodes(nodes, elements)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Solving and Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring time for solving using VEM\n",
    "solving_time_list = []\n",
    "for _ in range(time_sampling_size):\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t)\n",
    "    solving_time_list.append(solving_time)\n",
    "\n",
    "print(\"Mean solving time: \", np.mean(solving_time_list))\n",
    "print(\"Std Deviation: \", np.std(solving_time_list))\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 800\n",
    "\n",
    "# Layers definition\n",
    "nodes_layers = [128, 256, 512, 512, 512, 512]  # Layers for nodes sub-network\n",
    "material_layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2048, 2048] # Layers for materials sub-network\n",
    "final_layers = [1024, 1024, 1024, 1024]  # Layers for final combination network\n",
    "\n",
    "# Training pipeline\n",
    "(input_vector, \n",
    " model, \n",
    " total_loss_values, \n",
    " loss_values, \n",
    " material_loss_values, \n",
    " sobolev_loss_values, \n",
    " alpha_values_values) = neural.train_material_portic(\n",
    "    epochs=num_epochs,\n",
    "    nodes=nodes,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    E=E,\n",
    "    A=A,\n",
    "    I=I,\n",
    "    uh_vem=uh_vem,\n",
    "    nodes_layers=nodes_layers,\n",
    "    material_layers=material_layers,\n",
    "    final_layers=final_layers,\n",
    "    verbose=True,\n",
    "    noramlize_inputs=True,\n",
    "    network_type=\"material\"\n",
    " )\n",
    "\n",
    "# Setting up material parameters\n",
    "material_params = torch.tensor([E , A , I ], dtype=torch.float32)\n",
    "# nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "\n",
    "# Measuring time spent for inference\n",
    "inference_time_list = []\n",
    "for _ in range(time_sampling_size):\n",
    "    predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    inference_time_list.append(inference_time)\n",
    "\n",
    "print(\"Mean inference time: \", np.mean(inference_time_list))\n",
    "print(\"Std Deviation: \", np.std(inference_time_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model refers to the disaplcement field and the loss function regards to the calculation of the residual taking in consideration the Virtual Element Method's stiffness matrix and load vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence of Deep Layers in the Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 800\n",
    "\n",
    "# Reading the json with respective layers\n",
    "with open(\"data/layers_20240929.json\", \"r\") as data:\n",
    "    layers = json.load(data)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i,layer in enumerate(layers):\n",
    "\n",
    "    # Define the number of elements per edge\n",
    "    num_elements_per_edge = 128\n",
    "\n",
    "    # geometry data\n",
    "    L = 2.0\n",
    "    I = 1e-4\n",
    "    A = 1\n",
    "\n",
    "    # material data\n",
    "    E = 27e6\n",
    "\n",
    "    # Define load parameters\n",
    "    q = -400\n",
    "    t = 0\n",
    "\n",
    "\n",
    "    # Generate the geometry\n",
    "    nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "    # Solve the problem using the VEM\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t, verbose=False)\n",
    "\n",
    "    print(f\"Training and testing layer {i+1}/{len(layers)}\")\n",
    "    # Defining layers\n",
    "    nodes_layers = list(layer[\"node_layers\"])\n",
    "    material_layers = list(layer[\"material_layers\"])\n",
    "    final_layers = list(layer[\"final_layers\"])\n",
    "\n",
    "    # Training pipeline\n",
    "    (input_vector, \n",
    "    model, \n",
    "    total_loss_values, \n",
    "    loss_values, \n",
    "    material_loss_values, \n",
    "    sobolev_loss_values, \n",
    "    alpha_values_values) = neural.train_material_portic(\n",
    "        epochs=num_epochs,\n",
    "        nodes=nodes,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        E=E,\n",
    "        A=A,\n",
    "        I=I,\n",
    "        uh_vem=uh_vem,\n",
    "        nodes_layers=nodes_layers,\n",
    "        material_layers=material_layers,\n",
    "        final_layers=final_layers,\n",
    "        verbose=False,\n",
    "        noramlize_inputs=True,\n",
    "        network_type=\"material\"\n",
    "    )\n",
    "\n",
    "    # Setting up material parameters\n",
    "    material_params = torch.tensor([E , A , I ], dtype=torch.float32)\n",
    "    nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "\n",
    "    # Testing the model with default parameters\n",
    "    predicted_displacements, l2_error_default, energy_error_default, h1_error_default, inference_time_default = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Setting up new material parameters\n",
    "    I_new = 1e-4\n",
    "    A_new = 2\n",
    "    E_new = 110e5\n",
    "\n",
    "    # Generate the geometry\n",
    "    nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "    # Solve the problem using the VEM\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new, A_new, I_new, load, q, t)\n",
    "\n",
    "    # Testing the model with new parameters\n",
    "    material_params = torch.tensor([E_new , A_new , I_new], dtype=torch.float32)\n",
    "    nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "    nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "    predicted_displacements, l2_error_new, energy_error_new, h1_error_new, inference_time_new = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Setting up new material parameters\n",
    "    I_new_2 = 1e-4\n",
    "    A_new_2 = 3\n",
    "    E_new_2 = 80e3\n",
    "\n",
    "    # Generate the geometry\n",
    "    nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "    # Solve the problem using the VEM\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new_2, A_new_2, I_new_2, load, q, t)\n",
    "\n",
    "    # Testing the model with new parameters\n",
    "    material_params = torch.tensor([E_new_2 , A_new_2 , I_new_2], dtype=torch.float32)\n",
    "    nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "    nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "    predicted_displacements, l2_error_new, energy_error_new, h1_error_new, inference_time_new = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"tag\": layer[\"tag\"],\n",
    "        \"l2_error_default\": l2_error_default,\n",
    "        \"energy_error_default\": energy_error_default,\n",
    "        \"h1_error_default\": h1_error_default,\n",
    "        \"inferece_time_default\": inference_time_default,\n",
    "        \"l2_error_new\": l2_error_new,\n",
    "        \"energy_error_new\": energy_error_new,\n",
    "        \"h1_error_new\": h1_error_new,\n",
    "        \"inferece_time_new\": inference_time_new,\n",
    "        \"l2_error_new_2\": l2_error_new,\n",
    "        \"energy_error_new_2\": energy_error_new,\n",
    "        \"h1_error_new_2\": h1_error_new,\n",
    "        \"inferece_time_new_2\": inference_time_new,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in a dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"data/output/results_20240929.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 800\n",
    "\n",
    "# Layers definition\n",
    "nodes_layers = [128, 256, 512, 512, 512, 512]  # Layers for nodes sub-network\n",
    "material_layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2048, 2048] # Layers for materials sub-network\n",
    "final_layers = [1024, 1024, 1024, 1024]  # Layers for final combination network\n",
    "\n",
    "# Training pipeline\n",
    "(input_vector, \n",
    " model, \n",
    " total_loss_values, \n",
    " loss_values, \n",
    " material_loss_values, \n",
    " sobolev_loss_values, \n",
    " alpha_values_values) = neural.train_material_portic(\n",
    "    epochs=num_epochs,\n",
    "    nodes=nodes,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    E=E,\n",
    "    A=A,\n",
    "    I=I,\n",
    "    uh_vem=uh_vem,\n",
    "    nodes_layers=nodes_layers,\n",
    "    material_layers=material_layers,\n",
    "    final_layers=final_layers,\n",
    "    verbose=True,\n",
    "    noramlize_inputs=True,\n",
    "    network_type=\"material\",\n",
    "    batch_norm=False\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the reference displacement field calculated by the Virtual Element Method, a displacemente field is supposed to be calculated considering the material parameters contributions to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_total_loss = total_loss_values[150:]\n",
    "plt.plot(filtered_total_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_loss = loss_values[150:]\n",
    "plt.plot(filtered_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_material_loss = material_loss_values[150:]\n",
    "plt.plot(filtered_material_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Material Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_sobolev_loss = sobolev_loss_values[150:]\n",
    "plt.plot(filtered_sobolev_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Sobolev Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_alpha_values = alpha_values_values[150:]\n",
    "plt.plot(filtered_alpha_values)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('alpha')\n",
    "plt.title('Alpha Values over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material_params = torch.tensor([E , A , I ], dtype=torch.float32)\n",
    "# nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geometry parameter\n",
    "I_new = 1e-4\n",
    "A_new = 2\n",
    "E_new = 110e5\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new, A_new, I_new, load, q, t)\n",
    "\n",
    "# Testing the model with new parameters\n",
    "material_params = torch.tensor([E_new , A_new , I_new ], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geometry parameter\n",
    "I_new_2 = 1e-4\n",
    "A_new_2 = 3\n",
    "E_new_2 = 80e3\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new_2, A_new_2, I_new_2, load, q, t)\n",
    "\n",
    "# Testing the model with new parameters\n",
    "material_params = torch.tensor([E_new_2 , A_new_2 , I_new_2 ], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import core.grad_norm as gn\n",
    "import core.neural_backend as neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndof = 3 * len(nodes)\n",
    "input_dim = 2*len(nodes) + 3\n",
    "\n",
    "input_dim_nodes = 2*len(nodes)\n",
    "input_dim_materials = 3\n",
    "\n",
    "# Original material parameters\n",
    "material_params_1 = torch.tensor([E, A, I], dtype=torch.float32)\n",
    "\n",
    "# Perturbed material parameters (slightly changed)\n",
    "material_params_2 = torch.tensor([E *1.1, A * 1.1, I * 0.9], dtype=torch.float32)\n",
    "\n",
    "nodes, material_params_1 = neural.normalize_inputs(nodes, material_params_1)\n",
    "_, material_params_2 = neural.normalize_inputs(nodes, material_params_2)\n",
    "\n",
    "nodes = nodes.flatten()\n",
    "nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "input_vector = torch.cat([nodes, material_params_1])\n",
    "\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers definition\n",
    "nodes_layers = [128, 256, 512, 512, 512, 512]  # Layers for nodes sub-network\n",
    "material_layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2048, 2048] # Layers for materials sub-network\n",
    "final_layers = [1024, 1024, 1024, 1024]  # Layers for final combination network\n",
    "\n",
    "model = neural.BeamApproximatorWithMaterials(\n",
    "                input_dim_nodes=input_dim_nodes, \n",
    "                input_dim_materials=input_dim_materials, \n",
    "                nodes_layers=nodes_layers, \n",
    "                material_layers=material_layers, \n",
    "                final_layers=final_layers, \n",
    "                ndof=ndof)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "K = torch.tensor(K, dtype=torch.float32, requires_grad=True)\n",
    "f = torch.tensor(f, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "total_loss_values = []\n",
    "loss_values = []\n",
    "material_loss_values = []\n",
    "sobolev_loss_values = []\n",
    "alpha_values_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loss weights\n",
    "loss_weights = torch.ones(3, requires_grad=True)  # We have 3 tasks: loss, sobolev_loss, and material_penalty\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 200\n",
    "concatanate = False\n",
    "\n",
    "# Initialize optimizers (including the loss_weights as parameters)\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + [loss_weights], lr=1e-3)\n",
    "optimizer_w = torch.optim.SGD([loss_weights], lr=1e-3)\n",
    "\n",
    "# Initialize lists to store loss values\n",
    "total_loss_values, loss_values, material_loss_values, sobolev_loss_values, alpha_values_values = [], [], [], [], []\n",
    "\n",
    "# Enable anomaly detection for debugging\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Loop through epochs\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    uh = model(nodes, material_params_1)\n",
    "    \n",
    "    # Compute individual losses\n",
    "    loss = loss_function.compute_loss_with_uh(uh_vem, uh)\n",
    "    sobolev_loss = loss_function.compute_sobolev_loss(model, nodes, material_params_1, loss, concatanate)\n",
    "    material_penalty = loss_function.compute_material_penalty(model, nodes, material_params_1, material_params_2, concatanate) * 1e10\n",
    "\n",
    "    # Weighted sum of losses (with GradNorm weights)\n",
    "    weighted_losses = [\n",
    "        loss_weights[0] * loss, \n",
    "        loss_weights[1] * sobolev_loss, \n",
    "        loss_weights[2] * material_penalty\n",
    "    ]\n",
    "\n",
    "    # Store the initial loss weights\n",
    "    if epoch == 0:\n",
    "        initial_loss_weights = [\n",
    "            loss_weights[0] * loss, \n",
    "            loss_weights[1] * sobolev_loss, \n",
    "            loss_weights[2] * material_penalty\n",
    "        ]\n",
    "\n",
    "    # Calculate the gradient norms for each task\n",
    "    grad_norms = gn.calculate_gradient_norm(model, weighted_losses)\n",
    "    tilde_losses = [gn.compute_loss_ratio(weighted_losses[i].item(), initial_loss_weights[i].item()) for i in range(len(weighted_losses))]\n",
    "\n",
    "    # Compute the grad norm loss\n",
    "    loss_grad = gn.compute_grad_norm_loss(grad_norms, tilde_losses, 100)\n",
    "\n",
    "    # Backpropagation of the gradient loss (update the grad_loss weights)\n",
    "    loss_grad.backward(retain_graph=True)\n",
    "\n",
    "    # Step 1: Perform the optimizer step to update the task weights using the gradient loss\n",
    "    optimizer_w.step()\n",
    "\n",
    "    # Step 2: Compute the total loss (sum of the weighted loss)\n",
    "    total_loss = loss_weights[0] * loss + loss_weights[1] * sobolev_loss + loss_weights[2] * material_penalty\n",
    "\n",
    "    # Backpropagation for the model weights using total loss\n",
    "    total_loss.backward()\n",
    "\n",
    "    # Step 3: Perform the optimizer step to update the model weights using the total loss\n",
    "    optimizer.step()\n",
    "\n",
    "    # Step 4: Renormalize the loss weights (no in-place operation)\n",
    "    T = len(weighted_losses)\n",
    "    sum_w = torch.sum(loss_weights).item()\n",
    "\n",
    "    # Instead of modifying in-place, re-assign to a new tensor\n",
    "    with torch.no_grad():\n",
    "        loss_weights.copy_((loss_weights / sum_w) * T)  # Use .copy_ to avoid creating new tensors and keep gradients\n",
    "\n",
    "    # Store losses for analysis\n",
    "    if epoch > 0:\n",
    "        total_loss_values.append(total_loss.item())\n",
    "        loss_values.append(loss_weights[0].item()*loss.item())\n",
    "        material_loss_values.append(loss_weights[2].item()*material_penalty.item())\n",
    "        sobolev_loss_values.append(loss_weights[1].item()*sobolev_loss.item())\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Epoch: {epoch + 1}, Total Loss: {total_loss.item()}, Loss Weights: {loss_weights.detach().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_total_loss = total_loss_values[150:]\n",
    "plt.plot(filtered_total_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_loss = loss_values[150:]\n",
    "plt.plot(filtered_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_material_loss = material_loss_values[150:]\n",
    "plt.plot(filtered_material_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Material Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_sobolev_loss = sobolev_loss_values[150:]\n",
    "plt.plot(filtered_sobolev_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Sobolev Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_alpha_values = alpha_values_values[150:]\n",
    "plt.plot(filtered_alpha_values)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('alpha')\n",
    "plt.title('Alpha Values over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geometry parameter\n",
    "I_new = 1e-4\n",
    "A_new = 2\n",
    "E_new = 110e5\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new, A_new, I_new, load, q, t)\n",
    "\n",
    "# Testing the model with new parameters\n",
    "material_params = torch.tensor([E_new , A_new , I_new ], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geometry parameter\n",
    "I_new_2 = 1e-4\n",
    "A_new_2 = 3\n",
    "E_new_2 = 80e2\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new_2, A_new_2, I_new_2, load, q, t)\n",
    "\n",
    "# Testing the model with new parameters\n",
    "material_params = torch.tensor([E_new_2 , A_new_2 , I_new_2 ], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using few material data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import core.grad_norm as gn\n",
    "import core.neural_backend as neural\n",
    "from utils.helpers import generate_beam_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py:199: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  normalized_nodes = torch.tensor(normalized_nodes, dtype=torch.float32, requires_grad=True)\n",
      "/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py:200: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  normalized_material_params = torch.tensor(normalized_material_params, dtype=torch.float32, requires_grad=True)\n",
      "/var/folders/r8/9jdwwqz11dq7_2m0n6cds_k40000gn/T/ipykernel_1338/2093153052.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "ndof = 3 * len(nodes)\n",
    "input_dim = 2*len(nodes) + 3\n",
    "\n",
    "input_dim_nodes = 2*len(nodes)\n",
    "input_dim_materials = 3\n",
    "\n",
    "# Original material parameters\n",
    "material_params_1 = torch.tensor([E, A, I], dtype=torch.float32)\n",
    "\n",
    "# Perturbed material parameters (slightly changed)\n",
    "material_params_2 = torch.tensor([E *1.1, A * 1.1, I * 0.9], dtype=torch.float32)\n",
    "\n",
    "nodes, material_params_1 = neural.normalize_inputs(nodes, material_params_1)\n",
    "_, material_params_2 = neural.normalize_inputs(nodes, material_params_2)\n",
    "\n",
    "nodes = nodes.flatten()\n",
    "nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "input_vector = torch.cat([nodes, material_params_1])\n",
    "\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Layers definition\n",
    "nodes_layers = [128, 256, 512, 512, 512, 512]  # Layers for nodes sub-network\n",
    "material_layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2048, 2048, 4096, 4096, 2048, 2048, 1024, 1024, 1024, 1024, 512, 512] # Layers for materials sub-network\n",
    "final_layers = [1024, 1024, 1024, 1024, 1024, 1024] # Layers for final combination network\n",
    "\n",
    "model = neural.BeamApproximatorWithMaterials(\n",
    "                input_dim_nodes=input_dim_nodes, \n",
    "                input_dim_materials=input_dim_materials, \n",
    "                nodes_layers=nodes_layers, \n",
    "                material_layers=material_layers, \n",
    "                final_layers=final_layers, \n",
    "                ndof=ndof).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "K = torch.tensor(K, dtype=torch.float32, requires_grad=True).to(device)\n",
    "f = torch.tensor(f, dtype=torch.float32, requires_grad=True).to(device)\n",
    "\n",
    "total_loss_values = []\n",
    "loss_values = []\n",
    "material_loss_values = []\n",
    "sobolev_loss_values = []\n",
    "alpha_values_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalize(value, mean_val, std_val):\n",
    "    \"\"\"Z-score normalization.\"\"\"\n",
    "    return (value - mean_val) / std_val\n",
    "\n",
    "def generate_beam_dataset(elastic_module_range: list, inertia_moment_range: list, area_range: list, num_samples: int):\n",
    "    \"\"\"\n",
    "    Function to generate a dataset of beam parameters with z-score normalized material properties.\n",
    "    \"\"\"\n",
    "    # Initialize lists to store the dataset\n",
    "    dataset = []\n",
    "\n",
    "    # Generate the material parameters\n",
    "    params = generate_beam_parameters(elastic_module_range, inertia_moment_range, area_range, num_samples)\n",
    "\n",
    "    # Extract E, I, and A values for normalization\n",
    "    E_values = [param['E'] for param in params]\n",
    "    I_values = [param['I'] for param in params]\n",
    "    A_values = [param['A'] for param in params]\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    E_mean, E_std = torch.mean(torch.tensor(E_values)), torch.std(torch.tensor(E_values))\n",
    "    I_mean, I_std = torch.mean(torch.tensor(I_values)), torch.std(torch.tensor(I_values))\n",
    "    A_mean, A_std = torch.mean(torch.tensor(A_values)), torch.std(torch.tensor(A_values))\n",
    "\n",
    "    # Normalize each parameter using z-score normalization\n",
    "    for i in range(num_samples):\n",
    "        E, I, A = params[i]['E'], params[i]['I'], params[i]['A']\n",
    "\n",
    "        # Z-score normalization\n",
    "        E_norm = z_score_normalize(E, E_mean, E_std)\n",
    "        I_norm = z_score_normalize(I, I_mean, I_std)\n",
    "        A_norm = z_score_normalize(A, A_mean, A_std)\n",
    "\n",
    "        # Generate the geometry\n",
    "        nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "        # Solve the problem using the VEM\n",
    "        uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t, verbose=False)\n",
    "\n",
    "        # Convert nodes to tensor\n",
    "        nodes = nodes.flatten()\n",
    "        nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "        # Store the dataset\n",
    "        dataset.append({\n",
    "            \"nodes\": nodes,\n",
    "            \"elements\": elements,\n",
    "            \"supp\": supp,\n",
    "            \"load\": load,\n",
    "            \"uh_vem\": uh_vem,\n",
    "            \"K\": K,\n",
    "            \"f\": f,\n",
    "            \"material_params\": torch.tensor([E_norm, A_norm, I_norm], dtype=torch.float32),\n",
    "            \"distorted_material_params\": torch.tensor([z_score_normalize(E * 1.3, E_mean, E_std), \n",
    "                                                      z_score_normalize(A * 1.1, A_mean, A_std), \n",
    "                                                      z_score_normalize(I * 0.3, I_mean, I_std)], dtype=torch.float32)\n",
    "        })\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loss weights\n",
    "loss_weights = torch.ones(3, requires_grad=True, device=device)  # We have 3 tasks: loss, sobolev_loss, and material_penalty \n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 80\n",
    "concatenate = False\n",
    "\n",
    "# Initialize optimizers (including the loss_weights as parameters)\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + [loss_weights], lr=1e-3)\n",
    "optimizer_w = torch.optim.SGD([loss_weights], lr=1e-3)\n",
    "\n",
    "# Initialize lists to store loss values\n",
    "total_loss_values, loss_values, material_loss_values, sobolev_loss_values, alpha_values_values = [], [], [], [], []\n",
    "\n",
    "# Enable anomaly detection for debugging\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Different material property configurations (for example, different E, I, A values)\n",
    "dataset = generate_beam_dataset([1e6, 210e9], [1e-6, 1e-3], [1, 10], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each material in the dataset\n",
    "for i,data in enumerate(dataset):\n",
    "    \n",
    "    material_params_1 = data['material_params']\n",
    "    material_params_2 = data['distorted_material_params']\n",
    "    nodes = data['nodes']\n",
    "    uh_vem = data['uh_vem']\n",
    "\n",
    "    nodes, material_params_1 = neural.normalize_inputs(nodes, material_params_1).to(device)\n",
    "    _, material_params_2 = neural.normalize_inputs(nodes, material_params_2).to(device)\n",
    "\n",
    "    nodes = nodes.flatten()\n",
    "    nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True).to(device)\n",
    "    \n",
    "    # Loop through epochs for the same material\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass using the current material parameters\n",
    "        uh = model(nodes, material_params_1)  # Adjust input to include material params\n",
    "\n",
    "        # Compute individual losses\n",
    "        loss = loss_function.compute_loss_with_uh(uh_vem, uh)\n",
    "        sobolev_loss = loss_function.compute_sobolev_loss(model, nodes, material_params_1, loss, concatenate)\n",
    "        material_penalty = loss_function.compute_material_penalty(model, nodes, material_params_1, material_params_2, concatenate) \n",
    "\n",
    "        # Weighted sum of losses (with GradNorm weights)\n",
    "        weighted_losses = [\n",
    "            loss_weights[0] * loss, \n",
    "            loss_weights[1] * sobolev_loss, \n",
    "            loss_weights[2] * material_penalty\n",
    "        ]\n",
    "\n",
    "        # Store the initial loss weights\n",
    "        if epoch == 0:\n",
    "            initial_loss_weights = [\n",
    "                loss_weights[0] * loss, \n",
    "                loss_weights[1] * sobolev_loss, \n",
    "                loss_weights[2] * material_penalty\n",
    "            ]\n",
    "\n",
    "        # Calculate the gradient norms for each task\n",
    "        grad_norms = gn.calculate_gradient_norm(model, weighted_losses)\n",
    "        tilde_losses = [gn.compute_loss_ratio(weighted_losses[i].item(), initial_loss_weights[i].item()) for i in range(len(weighted_losses))]\n",
    "\n",
    "        # Compute the grad norm loss\n",
    "        loss_grad = gn.compute_grad_norm_loss(grad_norms, tilde_losses, alpha=100)\n",
    "\n",
    "        # Backpropagation of the gradient loss (update the grad_loss weights)\n",
    "        loss_grad.backward(retain_graph=True)\n",
    "\n",
    "        # Step 1: Perform the optimizer step to update the task weights using the gradient loss\n",
    "        optimizer_w.step()\n",
    "\n",
    "        # Step 2: Compute the total loss (sum of the weighted loss)\n",
    "        total_loss = loss_weights[0] * loss + loss_weights[1] * sobolev_loss + loss_weights[2] * material_penalty\n",
    "\n",
    "        # Perform gradient clipping and check for NaN/Inf before backpropagation\n",
    "        if torch.isnan(total_loss).any() or torch.isinf(total_loss).any():\n",
    "            print(f\"NaN or Inf detected in total_loss at epoch {epoch}\")\n",
    "            continue\n",
    "        \n",
    "        # Break if the total loss is too high\n",
    "        if abs(total_loss.item()) > 100.0 and epoch > 0:\n",
    "            break\n",
    "\n",
    "        # Backpropagation for the model weights using total loss\n",
    "        total_loss.backward()\n",
    "\n",
    "        # Step 3: Perform the optimizer step to update the model weights using the total loss\n",
    "        optimizer.step()\n",
    "\n",
    "        # Step 4: Renormalize the loss weights (no in-place operation)\n",
    "        T = len(weighted_losses)\n",
    "        sum_w = torch.sum(loss_weights).item()\n",
    "\n",
    "        # Instead of modifying in-place, re-assign to a new tensor\n",
    "        with torch.no_grad():\n",
    "            loss_weights.copy_((loss_weights / sum_w) * T)  # Use .copy_ to avoid creating new tensors and keep gradients\n",
    "\n",
    "        # Store losses for analysis\n",
    "        if epoch > 1:\n",
    "            total_loss_values.append(total_loss.item())\n",
    "            loss_values.append(loss_weights[0].item()*loss.item())\n",
    "            material_loss_values.append(loss_weights[2].item()*material_penalty.item())\n",
    "            sobolev_loss_values.append(loss_weights[1].item()*sobolev_loss.item())\n",
    "\n",
    "        # Print progress\n",
    "        print(f'Material {i+1}: {material_params_1}, Epoch: {epoch + 1}, Total Loss: {total_loss.item()}, Loss Weights: {loss_weights.detach().numpy()}')\n",
    "        \n",
    "    # Break if the total loss is too high\n",
    "    if abs(total_loss.item()) > 1.0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py:199: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  normalized_nodes = torch.tensor(normalized_nodes, dtype=torch.float32, requires_grad=True)\n",
      "/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py:200: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  normalized_material_params = torch.tensor(normalized_material_params, dtype=torch.float32, requires_grad=True)\n",
      "/var/folders/r8/9jdwwqz11dq7_2m0n6cds_k40000gn/T/ipykernel_1338/1313515995.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.21293501555919647, Loss Weights: [0.99996364 0.99996364 1.0000727 ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.11489386856555939, Loss Weights: [0.9999057 0.9999057 1.0001887]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.05982651188969612, Loss Weights: [0.9998249 0.9998249 1.0003505]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.02178216353058815, Loss Weights: [0.9997267 0.9997267 1.0005465]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.16781048476696014, Loss Weights: [0.9995901 0.9995901 1.0008199]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.7122839093208313, Loss Weights: [0.99933225 0.99933225 1.0013356 ]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 1.970165729522705, Loss Weights: [0.99877685 0.99877685 1.0024462 ]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 3.7480533123016357, Loss Weights: [0.9975927 0.9975927 1.0048147]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 4.357455730438232, Loss Weights: [0.99566555 0.99566555 1.0086689 ]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 3.263272762298584, Loss Weights: [0.99316645 0.99316645 1.0136671 ]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 1.8191150426864624, Loss Weights: [0.99033505 0.99033505 1.01933   ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.8847890496253967, Loss Weights: [0.9873288 0.9873288 1.0253423]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.3406611979007721, Loss Weights: [0.9842408 0.9842408 1.0315185]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.08928816020488739, Loss Weights: [0.9811145 0.9811145 1.0377709]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.1177704855799675, Loss Weights: [0.9779445 0.9779444 1.0441113]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.13265377283096313, Loss Weights: [0.9747273  0.97472703 1.0505457 ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.07219560444355011, Loss Weights: [0.9714734  0.97147304 1.0570537 ]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.07811954617500305, Loss Weights: [0.96818125 0.96818066 1.0636383 ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.1476980745792389, Loss Weights: [0.96483725 0.9648362  1.0703268 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.22699645161628723, Loss Weights: [0.9614254  0.96142364 1.0771511 ]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.19306156039237976, Loss Weights: [0.9579511  0.95794857 1.0841004 ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.08071509003639221, Loss Weights: [0.9544351  0.95443135 1.0911336 ]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.04817887395620346, Loss Weights: [0.95088303 0.95087796 1.0982391 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.06743036955595016, Loss Weights: [0.94729066 0.94728416 1.1054249 ]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.07946589589118958, Loss Weights: [0.9436554  0.94364744 1.1126971 ]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.055565498769283295, Loss Weights: [0.9399814 0.9399719 1.1200466]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.03763280436396599, Loss Weights: [0.9362721 0.9362608 1.127467 ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.045883193612098694, Loss Weights: [0.9325253  0.93251204 1.1349626 ]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.06456993520259857, Loss Weights: [0.9287367 0.9287213 1.1425421]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.06150098517537117, Loss Weights: [0.92490613 0.9248886  1.1502051 ]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.03511330485343933, Loss Weights: [0.9210391  0.92101926 1.1579417 ]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.017607450485229492, Loss Weights: [0.9171387  0.91711646 1.1657448 ]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.027204759418964386, Loss Weights: [0.91320276 0.91317797 1.1736192 ]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.03393511101603508, Loss Weights: [0.9092295 0.9092021 1.1815684]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.014838595874607563, Loss Weights: [0.90522283 0.9051928  1.1895843 ]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.013321335427463055, Loss Weights: [0.90118307 0.90115017 1.1976669 ]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.03295418992638588, Loss Weights: [0.89710504 0.8970693  1.2058256 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.031776729971170425, Loss Weights: [0.8929888 0.8929501 1.2140609]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.009581999853253365, Loss Weights: [0.88883924 0.88879764 1.2223632 ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.005533363204449415, Loss Weights: [0.8846568 0.8846122 1.230731 ]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.01780548505485058, Loss Weights: [0.8804385 0.8803909 1.2391706]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.012425784021615982, Loss Weights: [0.8761854  0.87613475 1.2476798 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0015096144052222371, Loss Weights: [0.87189984 0.8718461  1.256254  ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0066008130088448524, Loss Weights: [0.8675804 0.8675235 1.2648959]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.012482045218348503, Loss Weights: [0.86322534 0.86316526 1.2736094 ]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.010327734053134918, Loss Weights: [0.85883474 0.8587713  1.2823939 ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.003216966288164258, Loss Weights: [0.85441005 0.8543434  1.2912467 ]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0013208884047344327, Loss Weights: [0.84995145 0.8498814  1.3001671 ]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0052170529961586, Loss Weights: [0.8454578  0.84538436 1.3091578 ]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.00771727180108428, Loss Weights: [0.84092796 0.8408512  1.3182209 ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.005231532733887434, Loss Weights: [0.83636236 0.8362822  1.3273555 ]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0018243908416479826, Loss Weights: [0.8317614 0.8316779 1.3365605]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0016919727204367518, Loss Weights: [0.8271253 0.8270383 1.3458364]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.003336132736876607, Loss Weights: [0.822453   0.82236254 1.3551844 ]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.003239923622459173, Loss Weights: [0.81774426 0.81765044 1.3646053 ]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0019135217880830169, Loss Weights: [0.81299925 0.8129019  1.3740989 ]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0008648792281746864, Loss Weights: [0.8082179  0.80811703 1.3836651 ]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.001221235143020749, Loss Weights: [0.8033999 0.8032954 1.3933048]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0018637467874214053, Loss Weights: [0.79854465 0.7984365  1.4030187 ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.001671767677180469, Loss Weights: [0.79365206 0.79354024 1.4128076 ]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0008739016484469175, Loss Weights: [0.7887219 0.7886064 1.4226717]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0005514019285328686, Loss Weights: [0.7837541 0.7836347 1.4326112]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0008735309238545597, Loss Weights: [0.77874804 0.7786249  1.4426273 ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0012615583837032318, Loss Weights: [0.77370334 0.77357626 1.4527204 ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0010523564415052533, Loss Weights: [0.7686197 0.7684888 1.4628913]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.00046805950114503503, Loss Weights: [0.7634971 0.7633623 1.4731406]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.00028373071108944714, Loss Weights: [0.75833523 0.7581965  1.4834685 ]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0004820421745534986, Loss Weights: [0.75313365 0.75299084 1.4938755 ]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0006323305424302816, Loss Weights: [0.7478921 0.7477453 1.5043627]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0004286106559447944, Loss Weights: [0.7426102  0.74245936 1.5149305 ]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.00015841814456507564, Loss Weights: [0.73728776 0.73713285 1.5255792 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.00014477003423962742, Loss Weights: [0.73192453 0.7317655  1.53631   ]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0002920342667493969, Loss Weights: [0.7265202 0.7263569 1.547123 ]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.00026791568961925805, Loss Weights: [0.7210743  0.72090673 1.5580189 ]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.00015167909441515803, Loss Weights: [0.71558654 0.71541476 1.5689988 ]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 7.78974499553442e-05, Loss Weights: [0.7100566  0.70988053 1.5800629 ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.00010556237248238176, Loss Weights: [0.7044843 0.7043039 1.5912119]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.00015518933651037514, Loss Weights: [0.69886893 0.6986842  1.6024466 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.00016169235459528863, Loss Weights: [0.69321054 0.6930214  1.6137682 ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 0.0001126471470342949, Loss Weights: [0.68750834 0.68731487 1.6251767 ]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 5.1081195124424994e-05, Loss Weights: [0.68176246 0.6815645  1.6366732 ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 4.336173151386902e-05, Loss Weights: [0.67597216 0.67576975 1.6482582 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 7.425185322063044e-05, Loss Weights: [0.6701373 0.6699303 1.6599326]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 9.766764560481533e-05, Loss Weights: [0.6642574 0.6640457 1.6716968]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 6.702991231577471e-05, Loss Weights: [0.6583322  0.65811586 1.6835518 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 3.827847831416875e-05, Loss Weights: [0.65236145 0.6521404  1.6954982 ]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 3.892573658959009e-05, Loss Weights: [0.6463446 0.6461188 1.7075367]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 7.286343316081911e-05, Loss Weights: [0.6402814 0.6400508 1.7196677]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 6.302946712821722e-05, Loss Weights: [0.6341714  0.63393605 1.7318926 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 4.403879211167805e-05, Loss Weights: [0.6280144 0.6277741 1.7442117]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 3.180975909344852e-05, Loss Weights: [0.62180984 0.6215646  1.7566254 ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 3.268228465458378e-05, Loss Weights: [0.6155575 0.6153074 1.769135 ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 4.8392921598860994e-05, Loss Weights: [0.60925686 0.60900176 1.7817411 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 5.0129394367104396e-05, Loss Weights: [0.6029078  0.60264754 1.7944448 ]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 2.487460369593464e-05, Loss Weights: [0.59650964 0.5962443  1.8072463 ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 2.1354833734221756e-05, Loss Weights: [0.5900621  0.58979154 1.8201466 ]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 3.404431481612846e-05, Loss Weights: [0.5835647 0.583289  1.8331465]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 3.474145341897383e-05, Loss Weights: [0.57701707 0.5767362  1.8462467 ]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 3.00973879348021e-05, Loss Weights: [0.5704189 0.5701328 1.8594484]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 1, Total Loss: 2.3946397050167434e-05, Loss Weights: [0.5637698  0.56347835 1.872752  ]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 2\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 2.1162981283850968e-05, Loss Weights: [0.56338257 0.56309074 1.8735266 ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 2.541273715905845e-05, Loss Weights: [0.56303227 0.5627401  1.8742278 ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 2.707648673094809e-05, Loss Weights: [0.56271523 0.5624229  1.874862  ]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 2.6258945581503212e-05, Loss Weights: [0.5624287 0.5621362 1.8754352]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.5993860870366916e-05, Loss Weights: [0.56216997 0.56187713 1.875953  ]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.9205941498512402e-05, Loss Weights: [0.5619365 0.5616434 1.8764201]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 2.0237916032783687e-05, Loss Weights: [0.561726   0.56143266 1.8768414 ]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 2.1158077288419008e-05, Loss Weights: [0.5615364 0.5612428 1.8772209]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 2.0986666640965268e-05, Loss Weights: [0.56136584 0.5610721  1.877562  ]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.5435547538800165e-05, Loss Weights: [0.5612128 0.5609188 1.8778685]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.717699706205167e-05, Loss Weights: [0.56107557 0.5607814  1.8781431 ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 2.592430064396467e-05, Loss Weights: [0.560953  0.5606587 1.8783885]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 2.0903557015117258e-05, Loss Weights: [0.5608439  0.56054926 1.878607  ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.549548869661521e-05, Loss Weights: [0.56074697 0.5604521  1.8788011 ]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.4205480511009227e-05, Loss Weights: [0.5606612  0.56036615 1.8789728 ]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.6109854186652228e-05, Loss Weights: [0.56058574 0.5602904  1.8791238 ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.535673436592333e-05, Loss Weights: [0.5605196  0.56022406 1.8792562 ]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.7009995644912124e-05, Loss Weights: [0.560462   0.56016636 1.8793716 ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.321611853200011e-05, Loss Weights: [0.56041235 0.5601166  1.8794711 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.457181315345224e-05, Loss Weights: [0.56036997 0.5600741  1.879556  ]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.3929877241025679e-05, Loss Weights: [0.5603343  0.56003827 1.8796275 ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.6203779523493722e-05, Loss Weights: [0.56030476 0.5600086  1.8796866 ]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.609402897884138e-05, Loss Weights: [0.56028104 0.5599847  1.8797343 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.1324364095344208e-05, Loss Weights: [0.56026256 0.5599661  1.8797712 ]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.185431938210968e-05, Loss Weights: [0.56024903 0.55995244 1.8797987 ]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 2.1813939383719116e-05, Loss Weights: [0.5602401 0.5599434 1.8798165]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.3209863027441315e-05, Loss Weights: [0.5602355  0.55993867 1.8798258 ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.1971962521784008e-05, Loss Weights: [0.56023496 0.55993795 1.879827  ]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.5114173038455192e-05, Loss Weights: [0.5602382 0.559941  1.8798208]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 2.223458795924671e-05, Loss Weights: [0.56024504 0.55994767 1.8798072 ]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.2932530808029696e-05, Loss Weights: [0.56025535 0.5599578  1.8797868 ]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.0884283256018534e-05, Loss Weights: [0.5602689 0.5599711 1.8797598]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.816208168747835e-05, Loss Weights: [0.56028557 0.55998755 1.8797268 ]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.3665758160641417e-05, Loss Weights: [0.56030524 0.5600069  1.8796878 ]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.1621428711805493e-05, Loss Weights: [0.56032765 0.5600291  1.8796432 ]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.2302751201787032e-05, Loss Weights: [0.5603527 0.5600539 1.8795931]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.2744600098812953e-05, Loss Weights: [0.56038034 0.5600813  1.8795385 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.3375218259170651e-05, Loss Weights: [0.56041026 0.56011105 1.8794786 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.2277418136363849e-05, Loss Weights: [0.5604427 0.5601432 1.8794142]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.531883935967926e-05, Loss Weights: [0.5604773  0.56017756 1.8793449 ]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.9019804312847555e-05, Loss Weights: [0.5605143 0.5602142 1.8792713]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.1339542652422097e-05, Loss Weights: [0.5605534 0.5602531 1.8791933]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.4627397831645794e-05, Loss Weights: [0.5605947 0.5602941 1.8791113]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.273644193133805e-05, Loss Weights: [0.560638  0.5603372 1.8790247]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.521550802863203e-05, Loss Weights: [0.5606834  0.56038237 1.8789343 ]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.8028429622063413e-05, Loss Weights: [0.5607309  0.56042945 1.8788395 ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.5137597074499354e-05, Loss Weights: [0.56078047 0.5604788  1.878741  ]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.1225289199501276e-05, Loss Weights: [0.5608319  0.56052995 1.8786381 ]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.1064764294133056e-05, Loss Weights: [0.56088537 0.56058306 1.8785315 ]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.7941350961336866e-05, Loss Weights: [0.5609408 0.5606381 1.8784208]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.0663439752534032e-05, Loss Weights: [0.5609982 0.5606952 1.8783069]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.3885191947338171e-05, Loss Weights: [0.5610574 0.560754  1.8781886]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.268948290089611e-05, Loss Weights: [0.5611184  0.56081474 1.8780668 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.274187980015995e-05, Loss Weights: [0.5611813 0.5608772 1.8779415]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.245983276021434e-05, Loss Weights: [0.5612459 0.5609415 1.8778126]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.290162981604226e-05, Loss Weights: [0.5613123 0.5610075 1.8776801]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.1587646440602839e-05, Loss Weights: [0.5613805 0.5610753 1.8775439]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.3618683624372352e-05, Loss Weights: [0.5614505 0.5611449 1.8774045]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.4991220268711913e-05, Loss Weights: [0.5615222  0.56121624 1.8772616 ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.2729295121971518e-05, Loss Weights: [0.5615957 0.5612893 1.8771152]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.8285094483871944e-05, Loss Weights: [0.5616709 0.5613641 1.876965 ]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.1333066140650772e-05, Loss Weights: [0.56174785 0.56144077 1.8768113 ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.3860700164514128e-05, Loss Weights: [0.56182665 0.5615192  1.8766541 ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.2776252333424054e-05, Loss Weights: [0.5619072 0.5615994 1.8764937]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.1468302545836195e-05, Loss Weights: [0.5619894 0.5616812 1.8763294]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.232535214512609e-05, Loss Weights: [0.5620734 0.5617648 1.8761618]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 2.3246386263053864e-05, Loss Weights: [0.5621593 0.5618502 1.8759906]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 2.8548067348310724e-05, Loss Weights: [0.5622472  0.56193763 1.875815  ]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.1448748409748077e-05, Loss Weights: [0.5623371 0.5620271 1.8756356]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.171438088931609e-05, Loss Weights: [0.56242895 0.56211853 1.8754524 ]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.567408071423415e-05, Loss Weights: [0.56252277 0.56221193 1.8752654 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.9620198145275936e-05, Loss Weights: [0.5626186 0.5623073 1.875074 ]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.2195563613204286e-05, Loss Weights: [0.5627165  0.56240463 1.8748788 ]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.3112263332004659e-05, Loss Weights: [0.5628163 0.562504  1.8746798]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.3427631529339124e-05, Loss Weights: [0.562918   0.56260526 1.8744767 ]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.2055152183165774e-05, Loss Weights: [0.56302166 0.56270844 1.87427   ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.2727060493489262e-05, Loss Weights: [0.56312716 0.5628135  1.8740592 ]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.386210169584956e-05, Loss Weights: [0.56323457 0.56292045 1.8738451 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.3565169865614735e-05, Loss Weights: [0.56334376 0.5630291  1.873627  ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.0024361472460441e-05, Loss Weights: [0.56345487 0.56313974 1.8734055 ]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.7081943951779976e-05, Loss Weights: [0.56356776 0.5632521  1.87318   ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.998479274334386e-05, Loss Weights: [0.5636826 0.5633664 1.872951 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 9.793188837647904e-06, Loss Weights: [0.5637994  0.56348264 1.872718  ]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.961872294486966e-05, Loss Weights: [0.56391805 0.5636008  1.8724811 ]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.2034879546263255e-05, Loss Weights: [0.5640387 0.5637209 1.8722405]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.1634532711468637e-05, Loss Weights: [0.5641611 0.5638428 1.8719962]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.2027150660287589e-05, Loss Weights: [0.56428546 0.5639665  1.8717481 ]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 9.32418606680585e-06, Loss Weights: [0.5644115  0.56409204 1.8714963 ]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.7525244402349927e-05, Loss Weights: [0.5645395 0.5642195 1.8712411]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.2654883903451264e-05, Loss Weights: [0.56466925 0.5643487  1.870982  ]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.1241547326790169e-05, Loss Weights: [0.56480074 0.56447965 1.8707196 ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.5050100046209991e-05, Loss Weights: [0.56493413 0.56461245 1.8704536 ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.2170832633273676e-05, Loss Weights: [0.5650692  0.56474686 1.8701838 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.1233500117668882e-05, Loss Weights: [0.56520605 0.5648831  1.8699107 ]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.4510194887407124e-05, Loss Weights: [0.56534475 0.56502116 1.8696342 ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.0708608897402883e-05, Loss Weights: [0.56548506 0.5651609  1.8693538 ]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.1648673535091802e-05, Loss Weights: [0.5656272 0.5653024 1.8690705]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.3435997971100733e-05, Loss Weights: [0.565771   0.56544554 1.8687835 ]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.692028126853984e-05, Loss Weights: [0.56591654 0.56559044 1.8684931 ]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 2, Total Loss: 1.382840309815947e-05, Loss Weights: [0.5660638 0.5657371 1.8681991]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 3\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1007628017978277e-05, Loss Weights: [0.5661967  0.56586987 1.8679333 ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.543993676023092e-05, Loss Weights: [0.566317  0.5659901 1.8676927]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.2448384040908422e-05, Loss Weights: [0.56642616 0.56609905 1.8674748 ]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 2.4739945729379542e-05, Loss Weights: [0.5665254 0.5661983 1.8672764]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1639880540315062e-05, Loss Weights: [0.5666158 0.5662887 1.8670952]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.3827133443555795e-05, Loss Weights: [0.5666987 0.5663715 1.8669298]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1200587323401123e-05, Loss Weights: [0.56677467 0.56644744 1.8667778 ]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1712523701135069e-05, Loss Weights: [0.5668447  0.56651735 1.866638  ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.2272927051526494e-05, Loss Weights: [0.56690943 0.56658185 1.8665085 ]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.227331995323766e-05, Loss Weights: [0.56696963 0.5666419  1.8663886 ]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.0613296581141185e-05, Loss Weights: [0.5670257 0.5666979 1.8662764]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.0467687388882041e-05, Loss Weights: [0.5670783 0.5667503 1.8661712]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1472765436337795e-05, Loss Weights: [0.5671279 0.5667997 1.8660722]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.218006309500197e-05, Loss Weights: [0.567175  0.5668466 1.8659785]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.133430123445578e-05, Loss Weights: [0.5672198  0.56689125 1.8658888 ]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1360963981132954e-05, Loss Weights: [0.56726277 0.5669341  1.8658029 ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.52628927025944e-05, Loss Weights: [0.5673043 0.5669756 1.8657199]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1896989235538058e-05, Loss Weights: [0.5673447  0.56701595 1.8656392 ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.10222090370371e-05, Loss Weights: [0.56738424 0.5670554  1.8655604 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.09420279841288e-05, Loss Weights: [0.5674231 0.5670942 1.865483 ]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.3520108041120693e-05, Loss Weights: [0.5674615 0.5671325 1.865406 ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.0428107998450287e-05, Loss Weights: [0.56749964 0.5671705  1.8653295 ]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.3288944501255173e-05, Loss Weights: [0.56753784 0.5672086  1.8652534 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 9.434295861865394e-06, Loss Weights: [0.56757605 0.5672467  1.865177  ]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.2335198334767483e-05, Loss Weights: [0.56761456 0.56728506 1.8651004 ]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.0069262316392269e-05, Loss Weights: [0.56765336 0.56732374 1.8650227 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.728329516481608e-05, Loss Weights: [0.5676928 0.567363  1.864944 ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.2021393558825366e-05, Loss Weights: [0.56773293 0.56740296 1.8648639 ]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.0248654689348768e-05, Loss Weights: [0.5677738 0.5674437 1.8647826]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1134115084132645e-05, Loss Weights: [0.5678155 0.5674852 1.8646994]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 2.1456133254105225e-05, Loss Weights: [0.56785816 0.5675278  1.8646141 ]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1256269317527767e-05, Loss Weights: [0.5679019 0.5675714 1.8645265]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1489040844026022e-05, Loss Weights: [0.5679469  0.56761634 1.8644367 ]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.3038556062383577e-05, Loss Weights: [0.5679931 0.5676624 1.8643445]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.0868130630115047e-05, Loss Weights: [0.5680406  0.56770974 1.8642497 ]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.7796814063331112e-05, Loss Weights: [0.5680895  0.56775844 1.8641521 ]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.2044814866385423e-05, Loss Weights: [0.56813985 0.56780857 1.8640516 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.2300421985855792e-05, Loss Weights: [0.56819165 0.5678602  1.8639482 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.6444126231363043e-05, Loss Weights: [0.56824505 0.56791335 1.8638417 ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.3026926353632007e-05, Loss Weights: [0.56830007 0.5679682  1.8637321 ]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 9.267721907235682e-06, Loss Weights: [0.5683565  0.56802446 1.8636189 ]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.3013202078582253e-05, Loss Weights: [0.5684147  0.56808245 1.8635027 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1317161806800868e-05, Loss Weights: [0.5684745  0.56814206 1.8633833 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.168002654594602e-05, Loss Weights: [0.5685359 0.5682033 1.8632609]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1197531421203166e-05, Loss Weights: [0.568599   0.56826615 1.8631351 ]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.313192660745699e-05, Loss Weights: [0.5686637  0.56833065 1.8630059 ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.18527914310107e-05, Loss Weights: [0.56873006 0.5683968  1.8628731 ]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.259684177057352e-05, Loss Weights: [0.5687982 0.5684647 1.8627372]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.8515100236982107e-05, Loss Weights: [0.56886816 0.56853443 1.8625977 ]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.192134186567273e-05, Loss Weights: [0.56893986 0.5686059  1.8624542 ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.239265202457318e-05, Loss Weights: [0.5690134 0.5686792 1.8623073]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.247271939064376e-05, Loss Weights: [0.5690888 0.5687543 1.8621569]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.3741460861638188e-05, Loss Weights: [0.5691661  0.56883126 1.8620027 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 9.47567150433315e-06, Loss Weights: [0.5692452 0.56891   1.8618447]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.3613313058158383e-05, Loss Weights: [0.5693262  0.56899065 1.8616831 ]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1816842743428424e-05, Loss Weights: [0.569409  0.5690731 1.8615179]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 2.146786209777929e-05, Loss Weights: [0.56949383 0.56915754 1.8613486 ]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.047907517204294e-05, Loss Weights: [0.56958055 0.5692439  1.8611753 ]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.4203968021320179e-05, Loss Weights: [0.5696693  0.56933236 1.8609984 ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.6806292478577234e-05, Loss Weights: [0.5697601 0.5694228 1.8608172]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.5219857232295908e-05, Loss Weights: [0.56985295 0.56951535 1.8606317 ]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.5166428056545556e-05, Loss Weights: [0.56994796 0.56961006 1.860442  ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.6711652278900146e-05, Loss Weights: [0.5700452 0.5697069 1.8602482]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.343598614766961e-05, Loss Weights: [0.5701444  0.56980586 1.8600495 ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.2953460100106895e-05, Loss Weights: [0.570246   0.56990707 1.859847  ]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.0979207218042575e-05, Loss Weights: [0.57034963 0.5700103  1.8596401 ]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1323073522362392e-05, Loss Weights: [0.5704553 0.5701157 1.8594291]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1079770047217607e-05, Loss Weights: [0.570563   0.57022303 1.859214  ]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1247407201153692e-05, Loss Weights: [0.5706728 0.5703324 1.858995 ]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.3649864740727935e-05, Loss Weights: [0.57078457 0.57044375 1.8587718 ]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1488287782412954e-05, Loss Weights: [0.5708983 0.5705571 1.8585445]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.2043357855873182e-05, Loss Weights: [0.5710141 0.5706725 1.8583134]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.3453793144435622e-05, Loss Weights: [0.5711318 0.5707898 1.8580781]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1359390555298887e-05, Loss Weights: [0.5712517 0.5709092 1.8578391]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.9265895389253274e-05, Loss Weights: [0.5713736 0.5710307 1.8575959]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.3223025234765373e-05, Loss Weights: [0.5714975 0.5711542 1.8573482]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1412846106395591e-05, Loss Weights: [0.57162356 0.5712798  1.8570964 ]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1813493074441794e-05, Loss Weights: [0.5717517  0.57140756 1.8568408 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1251373507548124e-05, Loss Weights: [0.5718818 0.5715372 1.856581 ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.113879079639446e-05, Loss Weights: [0.5720139 0.5716689 1.8563173]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 9.865788342722226e-06, Loss Weights: [0.5721479 0.5718025 1.8560495]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.990761847991962e-05, Loss Weights: [0.57228404 0.5719382  1.8557779 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.5867213733145036e-05, Loss Weights: [0.57242227 0.57207596 1.8555018 ]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.168625385616906e-05, Loss Weights: [0.5725625 0.5722158 1.8552215]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.229254121426493e-05, Loss Weights: [0.5727049 0.5723577 1.8549374]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.620346483832691e-05, Loss Weights: [0.5728494  0.57250166 1.8546488 ]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.3251657946966588e-05, Loss Weights: [0.572996  0.5726478 1.854356 ]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.2101875654479954e-05, Loss Weights: [0.57314473 0.572796   1.8540591 ]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.0982925232383423e-05, Loss Weights: [0.57329553 0.57294625 1.8537581 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1557993275346234e-05, Loss Weights: [0.5734483  0.57309854 1.8534532 ]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.165417143056402e-05, Loss Weights: [0.5736031  0.57325286 1.8531442 ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.3481022506312001e-05, Loss Weights: [0.57375985 0.57340914 1.852831  ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.0075184945890214e-05, Loss Weights: [0.5739186  0.57356733 1.852514  ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.408246680512093e-05, Loss Weights: [0.5740794 0.5737276 1.852193 ]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.2370338481559884e-05, Loss Weights: [0.5742421  0.57388985 1.8518679 ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.0417375960969366e-05, Loss Weights: [0.57440674 0.574054   1.8515391 ]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.2010846148768906e-05, Loss Weights: [0.5745734  0.57422006 1.8512065 ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.9523971786838956e-05, Loss Weights: [0.5747421  0.57438815 1.8508698 ]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.2308865734667052e-05, Loss Weights: [0.5749127  0.57455826 1.850529  ]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 3, Total Loss: 1.1789707059506327e-05, Loss Weights: [0.57508546 0.57473046 1.8501842 ]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 4\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1725032891263254e-05, Loss Weights: [0.5752412 0.574886  1.8498727]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.2386014532239642e-05, Loss Weights: [0.57538205 0.57502675 1.849591  ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.3540868167183362e-05, Loss Weights: [0.57550967 0.5751542  1.8493361 ]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1057330993935466e-05, Loss Weights: [0.5756255 0.5752699 1.8491046]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.6026639059418812e-05, Loss Weights: [0.5757309 0.5753752 1.8488936]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.2356238585198298e-05, Loss Weights: [0.5758273  0.57547146 1.8487015 ]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.4897113032930065e-05, Loss Weights: [0.5759155  0.57555956 1.8485248 ]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 9.11114057089435e-06, Loss Weights: [0.57599676 0.5756406  1.8483628 ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.2917002095491625e-05, Loss Weights: [0.5760717 0.5757155 1.848213 ]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0968643437081482e-05, Loss Weights: [0.5761412 0.5757849 1.8480742]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1839196304208599e-05, Loss Weights: [0.5762059 0.5758496 1.8479445]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.195973891299218e-05, Loss Weights: [0.57626665 0.5759102  1.8478231 ]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.6218600649153814e-05, Loss Weights: [0.576324   0.57596743 1.8477085 ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1515861842781305e-05, Loss Weights: [0.5763785  0.57602185 1.8475997 ]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1144456038891803e-05, Loss Weights: [0.57643056 0.5760738  1.8474958 ]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1991439350822475e-05, Loss Weights: [0.57648057 0.5761237  1.8473959 ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.065457945514936e-05, Loss Weights: [0.5765289 0.576172  1.8472991]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.2854104170401115e-05, Loss Weights: [0.576576  0.576219  1.8472049]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 9.325117389380466e-06, Loss Weights: [0.5766221  0.57626504 1.8471127 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 9.007540029415395e-06, Loss Weights: [0.57666755 0.57631034 1.847022  ]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.2787524610757828e-05, Loss Weights: [0.5767124  0.57635516 1.8469323 ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1887902473972645e-05, Loss Weights: [0.5767571 0.5763997 1.846843 ]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0295724678144325e-05, Loss Weights: [0.5768018 0.5764443 1.8467542]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1591138900257647e-05, Loss Weights: [0.5768465 0.576489  1.8466648]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0329900760552846e-05, Loss Weights: [0.5768915 0.5765339 1.8465747]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.615064866200555e-05, Loss Weights: [0.57693714 0.57657945 1.8464837 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.4535394257109147e-05, Loss Weights: [0.57698345 0.5766257  1.846391  ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.7874985132948495e-05, Loss Weights: [0.5770307  0.57667285 1.8462963 ]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0395776371296961e-05, Loss Weights: [0.5770791 0.5767211 1.8461998]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.064689513441408e-05, Loss Weights: [0.57712865 0.5767705  1.846101  ]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 9.941868484020233e-06, Loss Weights: [0.5771793  0.57682097 1.8459996 ]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.2540831448859535e-05, Loss Weights: [0.5772313 0.5768728 1.8458959]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 9.660361683927476e-06, Loss Weights: [0.5772845 0.5769259 1.8457893]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1456956599431578e-05, Loss Weights: [0.5773392 0.5769804 1.8456802]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1625688784988597e-05, Loss Weights: [0.5773953 0.5770364 1.8455684]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1814874596893787e-05, Loss Weights: [0.5774529 0.5770938 1.8454535]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1787454241130035e-05, Loss Weights: [0.57751197 0.57715267 1.8453355 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0307549018762074e-05, Loss Weights: [0.5775726  0.57721317 1.8452144 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.2520448763098102e-05, Loss Weights: [0.57763475 0.5772752  1.8450898 ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 9.813107681111433e-06, Loss Weights: [0.5776987 0.577339  1.8449625]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.05235312730656e-05, Loss Weights: [0.57776415 0.5774043  1.8448315 ]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.123267793445848e-05, Loss Weights: [0.5778313 0.5774713 1.8446972]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0167965228902176e-05, Loss Weights: [0.57790023 0.57754004 1.8445598 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0513564120628871e-05, Loss Weights: [0.5779708  0.57761043 1.8444189 ]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0644405847415328e-05, Loss Weights: [0.57804304 0.5776825  1.8442745 ]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1241946594964247e-05, Loss Weights: [0.578117  0.5777563 1.8441267]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.2230240827193484e-05, Loss Weights: [0.57819283 0.5778318  1.8439753 ]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.3109860447002575e-05, Loss Weights: [0.57827044 0.5779092  1.8438202 ]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0219834621238988e-05, Loss Weights: [0.5783499 0.5779884 1.8436615]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 9.73360329226125e-06, Loss Weights: [0.5784311  0.57806945 1.8434994 ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.255673123523593e-05, Loss Weights: [0.5785143  0.57815236 1.8433337 ]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.152409731730586e-05, Loss Weights: [0.57859915 0.57823694 1.8431637 ]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1655437447188888e-05, Loss Weights: [0.57868606 0.57832354 1.8429905 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.3496405699697789e-05, Loss Weights: [0.5787748  0.57841206 1.8428131 ]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.4458602890954353e-05, Loss Weights: [0.57886565 0.57850254 1.8426318 ]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0254825610900298e-05, Loss Weights: [0.5789585 0.5785951 1.8424466]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.2993336895306129e-05, Loss Weights: [0.57905334 0.57868963 1.842257  ]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.2499736840254627e-05, Loss Weights: [0.57915026 0.57878625 1.8420635 ]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1552095202205237e-05, Loss Weights: [0.57924926 0.57888496 1.841866  ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.4520674085360952e-05, Loss Weights: [0.57935023 0.5789857  1.8416638 ]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0523082892177626e-05, Loss Weights: [0.57945347 0.57908857 1.8414578 ]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 9.056324415723793e-06, Loss Weights: [0.5795587 0.5791935 1.8412478]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 9.98554787656758e-06, Loss Weights: [0.5796659 0.5793004 1.8410337]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.116909334086813e-05, Loss Weights: [0.5797751  0.57940936 1.8408155 ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1460976566013414e-05, Loss Weights: [0.5798863  0.57952034 1.8405933 ]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1527064998517744e-05, Loss Weights: [0.5799996 0.5796333 1.8403671]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.7068308807210997e-05, Loss Weights: [0.5801151  0.57974833 1.8401366 ]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1083045137638692e-05, Loss Weights: [0.58023256 0.57986546 1.8399017 ]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.14875929284608e-05, Loss Weights: [0.5803523  0.57998484 1.839663  ]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0661085070751142e-05, Loss Weights: [0.580474   0.58010614 1.8394198 ]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0947571354336105e-05, Loss Weights: [0.5805979  0.58022964 1.8391725 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 9.744328963279258e-06, Loss Weights: [0.58072376 0.58035517 1.8389211 ]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 9.921903256326914e-06, Loss Weights: [0.5808517 0.5804827 1.8386655]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0629020835040137e-05, Loss Weights: [0.5809816 0.5806123 1.8384058]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0540330549702048e-05, Loss Weights: [0.5811136 0.5807439 1.8381425]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.2241125659784302e-05, Loss Weights: [0.58124757 0.58087754 1.837875  ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0029920304077677e-05, Loss Weights: [0.5813835 0.5810131 1.8376033]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 9.837081051955465e-06, Loss Weights: [0.58152145 0.58115065 1.8373278 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 9.911278539220802e-06, Loss Weights: [0.5816614 0.5812902 1.8370483]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1407020792830735e-05, Loss Weights: [0.58180326 0.5814316  1.8367649 ]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1388134225853719e-05, Loss Weights: [0.58194715 0.5815751  1.8364778 ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1599446224863641e-05, Loss Weights: [0.58209294 0.58172053 1.8361863 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 9.743911505211145e-06, Loss Weights: [0.5822408 0.581868  1.8358912]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0852348168555181e-05, Loss Weights: [0.5823906  0.58201736 1.835592  ]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 9.726250937092118e-06, Loss Weights: [0.5825423  0.58216864 1.835289  ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.2372530363791157e-05, Loss Weights: [0.582696  0.5823219 1.8349822]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1706828445312567e-05, Loss Weights: [0.58285165 0.58247703 1.8346713 ]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 9.456892257730942e-06, Loss Weights: [0.5830093 0.5826342 1.8343567]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.7632195522310212e-05, Loss Weights: [0.5831689  0.58279335 1.8340375 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.2493036592786666e-05, Loss Weights: [0.58333075 0.58295476 1.8337145 ]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1699646165652666e-05, Loss Weights: [0.58349466 0.5831182  1.8333871 ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0396926882094704e-05, Loss Weights: [0.5836606 0.5832837 1.8330556]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 9.722994946059771e-06, Loss Weights: [0.5838286 0.5834513 1.83272  ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.3610841961053666e-05, Loss Weights: [0.5839987 0.5836209 1.8323803]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.0145977284992114e-05, Loss Weights: [0.5841708  0.58379257 1.8320365 ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.7002512322505936e-05, Loss Weights: [0.58434516 0.58396643 1.8316886 ]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1479675777081866e-05, Loss Weights: [0.58452153 0.5841423  1.8313361 ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.1155942047480494e-05, Loss Weights: [0.5847001 0.5843204 1.8309796]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 1.3542677152145188e-05, Loss Weights: [0.5848808 0.5845007 1.8306186]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 4, Total Loss: 9.96994276647456e-06, Loss Weights: [0.58506364 0.58468306 1.8302534 ]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 5\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.1108850230812095e-05, Loss Weights: [0.58522856 0.5848478  1.8299236 ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.3916290299675893e-05, Loss Weights: [0.5853777  0.58499676 1.8296256 ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.3348607353691477e-05, Loss Weights: [0.5855128  0.58513176 1.8293555 ]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 9.754506208992098e-06, Loss Weights: [0.5856355 0.5852543 1.8291103]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.1036150681320578e-05, Loss Weights: [0.5857471 0.5853659 1.8288871]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0057094186777249e-05, Loss Weights: [0.585849   0.58546764 1.8286833 ]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0453361028339714e-05, Loss Weights: [0.5859423 0.5855608 1.8284969]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.1313824870740063e-05, Loss Weights: [0.58602804 0.5856464  1.8283256 ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 8.742102181713562e-06, Loss Weights: [0.5861071 0.5857253 1.8281676]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 9.989407772081904e-06, Loss Weights: [0.5861802  0.58579844 1.8280213 ]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.170286486740224e-05, Loss Weights: [0.5862484 0.5858666 1.8278852]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.2583335774252191e-05, Loss Weights: [0.58631223 0.5859303  1.8277576 ]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 8.530095328751486e-06, Loss Weights: [0.5863723 0.5859903 1.8276376]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 9.933213732438162e-06, Loss Weights: [0.58642924 0.5860471  1.8275238 ]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.267783864022931e-05, Loss Weights: [0.5864835 0.5861013 1.8274152]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.115932082029758e-05, Loss Weights: [0.5865356  0.58615327 1.827311  ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.232180238730507e-05, Loss Weights: [0.586586  0.5862036 1.8272105]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.6219752069446258e-05, Loss Weights: [0.58663505 0.5862525  1.8271122 ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0745868166850414e-05, Loss Weights: [0.5866833 0.5863006 1.827016 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.2953661098435987e-05, Loss Weights: [0.5867309 0.5863482 1.8269209]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.8251914298161864e-05, Loss Weights: [0.5867784  0.58639556 1.8268263 ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0638736966939177e-05, Loss Weights: [0.58682585 0.58644295 1.8267313 ]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 8.637345672468655e-06, Loss Weights: [0.58687353 0.5864905  1.8266361 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0908511285379063e-05, Loss Weights: [0.5869216  0.58653843 1.82654   ]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.3190958270570263e-05, Loss Weights: [0.58697027 0.5865871  1.826443  ]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0004679097619373e-05, Loss Weights: [0.5870196  0.58663636 1.8263443 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0209280844719615e-05, Loss Weights: [0.58706987 0.5866865  1.8262436 ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.519930265203584e-05, Loss Weights: [0.5871212  0.58673775 1.8261411 ]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.332075316895498e-05, Loss Weights: [0.5871737 0.5867902 1.8260361]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.292015440412797e-05, Loss Weights: [0.58722764 0.586844   1.8259284 ]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.054012591339415e-05, Loss Weights: [0.58728296 0.5868993  1.8258178 ]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0747979104053229e-05, Loss Weights: [0.58733976 0.58695596 1.8257042 ]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.510278343630489e-05, Loss Weights: [0.5873983  0.58701444 1.8255875 ]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0004681826103479e-05, Loss Weights: [0.5874584 0.5870744 1.8254671]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0185815881413873e-05, Loss Weights: [0.58752024 0.58713615 1.8253436 ]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 8.199200237868354e-06, Loss Weights: [0.58758384 0.58719957 1.8252165 ]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0377828402852174e-05, Loss Weights: [0.5876492 0.5872648 1.8250861]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.1384256140445359e-05, Loss Weights: [0.5877163  0.58733165 1.8249519 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.214148142025806e-05, Loss Weights: [0.58778524 0.58740044 1.8248143 ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0500922144274227e-05, Loss Weights: [0.58785605 0.5874711  1.8246728 ]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.1906724466825835e-05, Loss Weights: [0.58792883 0.5875437  1.8245275 ]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.1031444046238903e-05, Loss Weights: [0.5880035  0.58761823 1.8243781 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.7073652998078614e-05, Loss Weights: [0.58808035 0.5876949  1.8242247 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 8.797112968750298e-06, Loss Weights: [0.58815926 0.5877736  1.824067  ]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0081304935738444e-05, Loss Weights: [0.5882402  0.58785444 1.8239052 ]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 2.3872615201980807e-05, Loss Weights: [0.5883236 0.5879376 1.8237388]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.2892282029497437e-05, Loss Weights: [0.5884093 0.5880232 1.8235677]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.194013293570606e-05, Loss Weights: [0.5884973  0.58811104 1.8233914 ]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0538024980633054e-05, Loss Weights: [0.5885878 0.5882014 1.8232108]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.294800949835917e-05, Loss Weights: [0.5886807 0.5882941 1.8230252]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.4203975297277793e-05, Loss Weights: [0.58877605 0.5883893  1.8228346 ]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 9.260612387151923e-06, Loss Weights: [0.5888738  0.58848685 1.8226393 ]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.1143411029479466e-05, Loss Weights: [0.588974   0.58858687 1.8224392 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.2801574484910816e-05, Loss Weights: [0.5890765 0.5886892 1.8222342]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.2132049050705973e-05, Loss Weights: [0.58918154 0.588794   1.8220243 ]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.1065001672250219e-05, Loss Weights: [0.58928895 0.58890116 1.8218098 ]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0072579243569635e-05, Loss Weights: [0.58939874 0.5890107  1.8215904 ]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0970773473673034e-05, Loss Weights: [0.589511   0.58912265 1.8213665 ]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.3009668691665865e-05, Loss Weights: [0.5896255  0.58923686 1.8211377 ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.2623348993656691e-05, Loss Weights: [0.5897425 0.5893535 1.820904 ]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.1872568393300753e-05, Loss Weights: [0.58986187 0.58947253 1.8206656 ]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.9337880075909197e-05, Loss Weights: [0.5899839 0.5895942 1.820422 ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.3142885109118652e-05, Loss Weights: [0.5901084  0.58971846 1.8201731 ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 9.710596714285202e-06, Loss Weights: [0.59023553 0.58984524 1.8199191 ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 9.559469617670402e-06, Loss Weights: [0.5903652 0.5899745 1.8196603]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 9.253873940906487e-06, Loss Weights: [0.5904972  0.59010625 1.8193965 ]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0890241355809849e-05, Loss Weights: [0.59063166 0.59024036 1.819128  ]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 9.516909813100938e-06, Loss Weights: [0.59076846 0.59037685 1.8188548 ]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 8.712732778803911e-06, Loss Weights: [0.5909075 0.5905156 1.8185768]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 9.588054126652423e-06, Loss Weights: [0.5910489  0.59065664 1.8182945 ]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.6577698261244223e-05, Loss Weights: [0.59119266 0.59080005 1.8180073 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 9.492881872574799e-06, Loss Weights: [0.59133875 0.59094584 1.8177155 ]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.4678354091302026e-05, Loss Weights: [0.5914872  0.59109396 1.8174187 ]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 8.561250069760717e-06, Loss Weights: [0.59163815 0.5912445  1.8171175 ]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.3595927157439291e-05, Loss Weights: [0.5917914  0.59139746 1.8168113 ]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0306240255886223e-05, Loss Weights: [0.591947   0.59155273 1.8165003 ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0458090400788933e-05, Loss Weights: [0.592105  0.5917104 1.8161845]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.98482048290316e-05, Loss Weights: [0.5922655 0.5918706 1.8158638]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.101653015211923e-05, Loss Weights: [0.59242857 0.5920333  1.8155383 ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 9.884476639854256e-06, Loss Weights: [0.592594  0.5921984 1.8152075]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 9.006300388136879e-06, Loss Weights: [0.59276193 0.5923659  1.8148723 ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 9.512783435638994e-06, Loss Weights: [0.5929321  0.59253573 1.814532  ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0678942089725751e-05, Loss Weights: [0.59310466 0.59270793 1.8141873 ]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.54043755173916e-05, Loss Weights: [0.59327966 0.5928825  1.8138378 ]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.1640847333183046e-05, Loss Weights: [0.59345704 0.5930595  1.8134835 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0378991646575741e-05, Loss Weights: [0.59363675 0.59323883 1.8131244 ]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.1257462574576493e-05, Loss Weights: [0.59381884 0.5934205  1.8127606 ]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0505005775485188e-05, Loss Weights: [0.59400326 0.5936045  1.812392  ]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.2195871022413485e-05, Loss Weights: [0.59419006 0.5937909  1.8120189 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.281701224797871e-05, Loss Weights: [0.5943793 0.5939797 1.8116412]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0584593837847933e-05, Loss Weights: [0.59457076 0.59417075 1.8112583 ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0554757864156272e-05, Loss Weights: [0.59476465 0.59436417 1.8108711 ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.3115371075400617e-05, Loss Weights: [0.59496087 0.59455997 1.8104792 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.04973169072764e-05, Loss Weights: [0.5951594 0.5947581 1.8100824]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.0265357559546828e-05, Loss Weights: [0.5953603  0.59495854 1.8096812 ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 8.410413101955783e-06, Loss Weights: [0.59556335 0.5951612  1.8092754 ]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.039479138853494e-05, Loss Weights: [0.59576863 0.59536606 1.8088651 ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.043311658577295e-05, Loss Weights: [0.5959762 0.5955732 1.8084507]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.4574354281648993e-05, Loss Weights: [0.5961859 0.5957825 1.8080316]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 5, Total Loss: 1.056499604601413e-05, Loss Weights: [0.59639794 0.5959941  1.8076079 ]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 6\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.522219443169888e-06, Loss Weights: [0.5965891 0.5961851 1.8072257]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0082881999551319e-05, Loss Weights: [0.5967619 0.5963577 1.8068807]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 8.636005077278242e-06, Loss Weights: [0.59691805 0.59651375 1.8065683 ]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 8.721535778022371e-06, Loss Weights: [0.5970596  0.59665513 1.8062851 ]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.716134627524298e-06, Loss Weights: [0.5971882 0.5967835 1.8060282]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.745204806677066e-06, Loss Weights: [0.5973052 0.5969004 1.8057945]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0155928976018913e-05, Loss Weights: [0.5974119  0.59700704 1.8055811 ]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 8.977088327810634e-06, Loss Weights: [0.59750956 0.59710467 1.8053858 ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.523530934529845e-06, Loss Weights: [0.5975993 0.5971944 1.8052063]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0193849448114634e-05, Loss Weights: [0.5976822  0.59727716 1.8050406 ]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0479846423550043e-05, Loss Weights: [0.597759   0.59735394 1.804887  ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0646078408171888e-05, Loss Weights: [0.59783053 0.59742546 1.8047438 ]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0896934327320196e-05, Loss Weights: [0.59789777 0.5974926  1.8046098 ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0383737389929593e-05, Loss Weights: [0.59796107 0.5975559  1.8044833 ]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.490624163125176e-05, Loss Weights: [0.5980212 0.5976159 1.8043628]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0560876035015099e-05, Loss Weights: [0.59807885 0.5976734  1.8042479 ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.6540261640329845e-05, Loss Weights: [0.59813446 0.59772897 1.8041365 ]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.153520295512863e-06, Loss Weights: [0.5981885  0.59778297 1.8040285 ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.2712688658211846e-05, Loss Weights: [0.59824145 0.5978358  1.8039229 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.1035446732421406e-05, Loss Weights: [0.5982935  0.59788775 1.8038187 ]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.4437626305152662e-05, Loss Weights: [0.59834516 0.5979394  1.8037155 ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.4700807696499396e-05, Loss Weights: [0.59839684 0.597991   1.8036122 ]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.4894311789248604e-05, Loss Weights: [0.59844875 0.59804285 1.8035084 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.130735927290516e-05, Loss Weights: [0.5985012 0.5980952 1.8034036]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.2311261343711521e-05, Loss Weights: [0.5985544 0.5981482 1.8032973]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.406244316778611e-06, Loss Weights: [0.5986085 0.5982022 1.8031895]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.384923032484949e-06, Loss Weights: [0.59866345 0.59825706 1.8030794 ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.3358839169086423e-05, Loss Weights: [0.59871966 0.59831315 1.8029671 ]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0558610483712982e-05, Loss Weights: [0.5987772  0.59837055 1.8028524 ]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 8.541330316802487e-06, Loss Weights: [0.598836   0.59842926 1.8027349 ]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.148110621026717e-06, Loss Weights: [0.59889627 0.5984894  1.8026143 ]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.3567328096542042e-05, Loss Weights: [0.59895813 0.59855115 1.8024907 ]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0738034688984044e-05, Loss Weights: [0.5990216 0.5986146 1.8023639]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.055048323905794e-05, Loss Weights: [0.5990869  0.59867966 1.8022337 ]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.840394341154024e-06, Loss Weights: [0.5991538  0.59874654 1.8020995 ]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 8.564292329538148e-06, Loss Weights: [0.5992226 0.5988152 1.8019621]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0738049240899272e-05, Loss Weights: [0.59929323 0.5988857  1.8018211 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.7523303540656343e-05, Loss Weights: [0.59936595 0.59895825 1.8016758 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 8.94381901161978e-06, Loss Weights: [0.5994407 0.5990329 1.8015264]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.1990347957180347e-05, Loss Weights: [0.5995176  0.59910965 1.8013728 ]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.558566145831719e-05, Loss Weights: [0.59959674 0.5991887  1.8012146 ]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.02777576103108e-05, Loss Weights: [0.59967816 0.59927    1.8010519 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0819677299878094e-05, Loss Weights: [0.5997619 0.5993536 1.8008845]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0804538760567084e-05, Loss Weights: [0.599848   0.59943956 1.8007126 ]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.1582531442400068e-05, Loss Weights: [0.59993637 0.59952784 1.8005359 ]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.842421988840215e-05, Loss Weights: [0.6000272  0.59961855 1.800354  ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.023112145048799e-05, Loss Weights: [0.6001207 0.5997119 1.8001674]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.2557225090858992e-05, Loss Weights: [0.60021675 0.5998078  1.7999756 ]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.357284397992771e-06, Loss Weights: [0.6003152 0.5999061 1.7997785]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0969213690259494e-05, Loss Weights: [0.6004163  0.60000706 1.7995766 ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.347910236101598e-06, Loss Weights: [0.6005199 0.6001104 1.7993698]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 8.496655027556699e-06, Loss Weights: [0.6006258  0.60021615 1.7991579 ]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.662629054218996e-06, Loss Weights: [0.6007342  0.60032433 1.7989414 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0288589692208916e-05, Loss Weights: [0.600845   0.60043496 1.7987199 ]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0229970030195545e-05, Loss Weights: [0.6009583 0.600548  1.7984939]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.016274018184049e-05, Loss Weights: [0.60107386 0.6006634  1.7982628 ]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.2827531463699415e-05, Loss Weights: [0.6011919  0.60078126 1.7980268 ]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0481786375748925e-05, Loss Weights: [0.6013124  0.60090154 1.797786  ]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.1332323992974125e-05, Loss Weights: [0.6014354 0.6010243 1.7975403]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.1375505891919602e-05, Loss Weights: [0.6015609  0.60114956 1.7972896 ]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.272519239137182e-05, Loss Weights: [0.60168886 0.60127735 1.7970338 ]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0860393558687065e-05, Loss Weights: [0.60181934 0.60140765 1.7967728 ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 8.918917046685237e-06, Loss Weights: [0.6019524 0.6015404 1.7965071]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.287666327698389e-05, Loss Weights: [0.602088   0.60167575 1.7962364 ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0352655408496503e-05, Loss Weights: [0.602226  0.6018135 1.7959604]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0493658919585869e-05, Loss Weights: [0.60236657 0.60195374 1.7956796 ]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 3.768917667912319e-05, Loss Weights: [0.60251033 0.6020972  1.7953924 ]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.464230970479548e-06, Loss Weights: [0.6026572 0.6022438 1.7950991]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.4171918337524403e-05, Loss Weights: [0.6028071 0.6023934 1.7947996]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.56244912231341e-06, Loss Weights: [0.60296  0.602546 1.794494]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0084494533657562e-05, Loss Weights: [0.60311586 0.60270154 1.7941828 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.38646826398326e-06, Loss Weights: [0.60327446 0.6028599  1.7938654 ]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.946174031938426e-06, Loss Weights: [0.60343605 0.6030212  1.7935429 ]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.242583473678678e-06, Loss Weights: [0.60360026 0.6031852  1.7932146 ]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.227668670064304e-06, Loss Weights: [0.6037672  0.60335183 1.7928811 ]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.262434105039574e-06, Loss Weights: [0.60393673 0.6035211  1.7925422 ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.1203063877474051e-05, Loss Weights: [0.60410887 0.60369295 1.7921982 ]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0368189578002784e-05, Loss Weights: [0.6042836  0.60386735 1.791849  ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.82346864475403e-06, Loss Weights: [0.60446084 0.6040443  1.7914948 ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.72882207861403e-06, Loss Weights: [0.6046406 0.6042238 1.7911355]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.160468835034408e-06, Loss Weights: [0.60482293 0.60440576 1.7907715 ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0400784049124923e-05, Loss Weights: [0.60500765 0.6045901  1.7904024 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0243793440167792e-05, Loss Weights: [0.6051948  0.60477686 1.7900283 ]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.709276127978228e-06, Loss Weights: [0.6053844 0.6049661 1.7896495]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.1098079085058998e-05, Loss Weights: [0.60557646 0.60515773 1.7892659 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 8.878610060492065e-06, Loss Weights: [0.6057709 0.6053518 1.7888772]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0599977940728422e-05, Loss Weights: [0.60596764 0.6055482  1.7884839 ]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.3597016732092015e-05, Loss Weights: [0.60616696 0.60574716 1.7880859 ]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.818897524382919e-06, Loss Weights: [0.60636866 0.60594845 1.7876828 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.65134040598059e-06, Loss Weights: [0.6065728  0.60615224 1.7872751 ]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0488413863640744e-05, Loss Weights: [0.6067793  0.60635835 1.7868624 ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.4355157873069402e-05, Loss Weights: [0.6069883 0.606567  1.7864449]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.329262866231147e-06, Loss Weights: [0.60719967 0.606778   1.7860222 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.0927884432021528e-05, Loss Weights: [0.60741365 0.6069916  1.7855949 ]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.769159078132361e-06, Loss Weights: [0.6076299 0.6072075 1.7851627]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.129646969086025e-06, Loss Weights: [0.6078485 0.6074257 1.7847257]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.3832566764904186e-05, Loss Weights: [0.6080697  0.60764647 1.7842839 ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.978426533052698e-06, Loss Weights: [0.6082933 0.6078696 1.7838371]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 1.386320946039632e-05, Loss Weights: [0.6085194 0.6080953 1.7833854]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 6, Total Loss: 9.593160939402878e-06, Loss Weights: [0.60874784 0.60832334 1.7829287 ]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 7\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.883946404443122e-06, Loss Weights: [0.60895383 0.60852915 1.782517  ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.1153897503390908e-05, Loss Weights: [0.60914004 0.6087151  1.7821448 ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 7.766879207338206e-06, Loss Weights: [0.6093084 0.6088834 1.7818081]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.2747586677433e-06, Loss Weights: [0.60946107 0.60903585 1.781503  ]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 2.0810402929782867e-05, Loss Weights: [0.60960007 0.60917467 1.7812253 ]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.2222689292684663e-05, Loss Weights: [0.6097269  0.60930145 1.7809718 ]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 7.315377388295019e-06, Loss Weights: [0.609843  0.6094175 1.7807395]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0995336197083816e-05, Loss Weights: [0.60994977 0.6095242  1.7805262 ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.020494892145507e-05, Loss Weights: [0.61004823 0.6096226  1.7803291 ]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.5894534953986295e-05, Loss Weights: [0.6101397 0.609714  1.7801461]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.7496078726253472e-05, Loss Weights: [0.6102253 0.6097995 1.779975 ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0923725312750321e-05, Loss Weights: [0.6103058 0.60988   1.7798141]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0394264791102614e-05, Loss Weights: [0.61038196 0.609956   1.7796618 ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.172083466371987e-05, Loss Weights: [0.61045456 0.6100286  1.7795169 ]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0141651728190482e-05, Loss Weights: [0.61052406 0.61009806 1.7793778 ]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 8.235657332988922e-06, Loss Weights: [0.61059105 0.61016506 1.779244  ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 7.602475307066925e-06, Loss Weights: [0.6106559  0.61022985 1.779114  ]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 8.395147233386524e-06, Loss Weights: [0.6107191 0.610293  1.7789876]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.344768841401674e-06, Loss Weights: [0.610781   0.61035484 1.7788641 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.17504894459853e-06, Loss Weights: [0.610842  0.6104157 1.7787426]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.4191638001648244e-05, Loss Weights: [0.6109023  0.61047596 1.7786217 ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.2150703696534038e-05, Loss Weights: [0.6109625 0.6105361 1.778501 ]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.979199603549205e-06, Loss Weights: [0.6110229 0.6105964 1.7783808]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0103629392688163e-05, Loss Weights: [0.6110835 0.6106569 1.7782595]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0083757842949126e-05, Loss Weights: [0.6111447 0.610718  1.7781372]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0414270036562812e-05, Loss Weights: [0.61120665 0.6107799  1.7780135 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0895594641624484e-05, Loss Weights: [0.61126953 0.61084265 1.777888  ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 7.789197297825012e-06, Loss Weights: [0.6113334  0.61090636 1.7777603 ]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.2128483831475023e-05, Loss Weights: [0.6113984  0.61097133 1.7776301 ]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0285689313604962e-05, Loss Weights: [0.6114649  0.61103773 1.7774974 ]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.384406439494342e-06, Loss Weights: [0.6115328 0.6111055 1.7773616]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0826315701706335e-05, Loss Weights: [0.6116023 0.6111749 1.7772228]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 8.268238161690533e-06, Loss Weights: [0.6116734 0.6112459 1.7770805]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0054158337879926e-05, Loss Weights: [0.6117463 0.6113186 1.7769351]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.368184166494757e-05, Loss Weights: [0.611821  0.6113932 1.7767857]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 2.0711559045594186e-05, Loss Weights: [0.61189795 0.61147004 1.776632  ]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.757892096065916e-05, Loss Weights: [0.61197734 0.6115493  1.7764733 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.038854841492139e-06, Loss Weights: [0.6120592  0.61163104 1.7763097 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0490613931324333e-05, Loss Weights: [0.6121435 0.6117152 1.7761414]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0306664989911951e-05, Loss Weights: [0.61223024 0.6118018  1.7759681 ]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.43667964747874e-06, Loss Weights: [0.6123194 0.6118908 1.7757895]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 7.971088962221984e-06, Loss Weights: [0.612411   0.61198235 1.7756064 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.7380407169112e-06, Loss Weights: [0.6125051 0.6120763 1.7754185]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 7.47858575778082e-06, Loss Weights: [0.61260146 0.61217254 1.7752258 ]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.7326707165921107e-05, Loss Weights: [0.61270046 0.6122715  1.7750282 ]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0138154721062165e-05, Loss Weights: [0.61280197 0.6123729  1.7748251 ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 8.696202712599188e-06, Loss Weights: [0.61290604 0.6124768  1.7746171 ]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0197170922765508e-05, Loss Weights: [0.6130127  0.61258334 1.7744039 ]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 7.771533091727179e-06, Loss Weights: [0.6131218  0.61269236 1.7741859 ]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.7647977074375376e-05, Loss Weights: [0.61323357 0.612804   1.7739625 ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0477642717887647e-05, Loss Weights: [0.613348   0.61291826 1.7737336 ]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 8.616450031695422e-06, Loss Weights: [0.61346513 0.61303526 1.7734997 ]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.038476491696201e-06, Loss Weights: [0.6135849 0.6131548 1.7732602]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0785218364617322e-05, Loss Weights: [0.6137073  0.61327714 1.7730157 ]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.432874341844581e-05, Loss Weights: [0.61383235 0.61340207 1.7727654 ]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 7.918620212876704e-06, Loss Weights: [0.6139602  0.61352974 1.7725103 ]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.5212329344649334e-05, Loss Weights: [0.61409074 0.6136601  1.7722492 ]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.092598176910542e-05, Loss Weights: [0.614224   0.61379325 1.7719827 ]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.295728887082078e-06, Loss Weights: [0.61436015 0.6139292  1.7717109 ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.2698241334874183e-05, Loss Weights: [0.614499   0.61406785 1.7714331 ]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.027286978380289e-06, Loss Weights: [0.6146406  0.61420935 1.7711501 ]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.257643796445336e-06, Loss Weights: [0.61478496 0.61435354 1.7708616 ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.1466710930108093e-05, Loss Weights: [0.614932  0.6145004 1.7705674]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 8.888593583833426e-06, Loss Weights: [0.61508185 0.61465    1.7702682 ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.432686056243256e-06, Loss Weights: [0.61523426 0.61480224 1.7699635 ]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.4005304365127813e-05, Loss Weights: [0.61538947 0.6149572  1.7696532 ]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0405097782495432e-05, Loss Weights: [0.6155474 0.6151149 1.7693377]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.1492858902784064e-05, Loss Weights: [0.6157081 0.6152754 1.7690165]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 7.918563824205194e-06, Loss Weights: [0.6158715 0.6154385 1.7686899]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.671329280536156e-06, Loss Weights: [0.61603755 0.61560434 1.768358  ]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0560190276009962e-05, Loss Weights: [0.61620635 0.6157729  1.7680209 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 8.619400432507973e-06, Loss Weights: [0.6163777 0.615944  1.7676783]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0707385627028998e-05, Loss Weights: [0.6165517 0.6161178 1.7673306]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.676260560809169e-06, Loss Weights: [0.6167283  0.61629415 1.7669775 ]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0687956091715023e-05, Loss Weights: [0.6169076  0.61647314 1.7666192 ]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.42640417633811e-06, Loss Weights: [0.6170895  0.61665475 1.7662557 ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0452814422023948e-05, Loss Weights: [0.61727405 0.61683893 1.765887  ]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 8.280916517833248e-06, Loss Weights: [0.6174611 0.6170257 1.7655133]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.455035069549922e-06, Loss Weights: [0.6176506 0.6172149 1.7651343]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0233874490950257e-05, Loss Weights: [0.6178428 0.6174068 1.7647507]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.414962732989807e-06, Loss Weights: [0.6180374  0.61760104 1.7643616 ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0630324140947778e-05, Loss Weights: [0.6182346 0.6177979 1.7639675]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.4666522474726662e-05, Loss Weights: [0.6184344 0.6179974 1.7635682]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.91649449133547e-06, Loss Weights: [0.61863697 0.6181996  1.7631636 ]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 2.0935243810527027e-05, Loss Weights: [0.61884236 0.6184046  1.762753  ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.2966719623364042e-05, Loss Weights: [0.61905074 0.6186127  1.7623367 ]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 8.750028428039514e-06, Loss Weights: [0.619262   0.61882365 1.7619145 ]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.2745712410833221e-05, Loss Weights: [0.61947614 0.6190375  1.7614864 ]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.136712762672687e-05, Loss Weights: [0.61969316 0.61925423 1.7610524 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.1031466783606447e-05, Loss Weights: [0.61991316 0.61947393 1.760613  ]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.058599061972927e-06, Loss Weights: [0.6201359 0.6196964 1.7601676]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 8.66114623931935e-06, Loss Weights: [0.62036145 0.61992157 1.759717  ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.5575953511870466e-05, Loss Weights: [0.62058985 0.6201496  1.7592605 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.583259270584676e-06, Loss Weights: [0.62082106 0.62038046 1.7587985 ]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.000495467451401e-05, Loss Weights: [0.621055   0.62061405 1.7583307 ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.0846998520719353e-05, Loss Weights: [0.6212918 0.6208505 1.7578578]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 8.359483217645902e-06, Loss Weights: [0.62153125 0.6210896  1.7573793 ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 9.011064321384765e-06, Loss Weights: [0.6217733 0.6213313 1.7568953]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 8.296684427477885e-06, Loss Weights: [0.6220179  0.62157553 1.7564065 ]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 7, Total Loss: 1.2593000974447932e-05, Loss Weights: [0.6222651 0.6218224 1.7559124]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 8\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.807729500404093e-06, Loss Weights: [0.622488   0.62204516 1.7554669 ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.5809440810699016e-05, Loss Weights: [0.62268955 0.6222465  1.7550641 ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.432641491002869e-06, Loss Weights: [0.622872  0.6224287 1.7546993]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.3926118299423251e-05, Loss Weights: [0.62303764 0.62259424 1.7543681 ]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.028750926314387e-06, Loss Weights: [0.6231884  0.62274486 1.754067  ]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.0762468264147174e-05, Loss Weights: [0.6233258  0.62288225 1.7537918 ]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.0982172170770355e-05, Loss Weights: [0.62345177 0.6230081  1.7535403 ]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.761997378314845e-06, Loss Weights: [0.6235674  0.62312365 1.7533089 ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.214782039634883e-06, Loss Weights: [0.62367415 0.6232303  1.7530957 ]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.8635682863532566e-05, Loss Weights: [0.6237732  0.62332934 1.7528975 ]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.0708363333833404e-05, Loss Weights: [0.6238658  0.62342185 1.7527124 ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.2596541637321934e-05, Loss Weights: [0.62395275 0.62350875 1.7525386 ]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.632461114961188e-06, Loss Weights: [0.62403494 0.6235909  1.7523742 ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.017818229040131e-06, Loss Weights: [0.6241131 0.6236689 1.752218 ]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.443015187571291e-06, Loss Weights: [0.62418777 0.62374353 1.7520686 ]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.72053203440737e-06, Loss Weights: [0.62425965 0.6238154  1.7519249 ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.1571255527087487e-05, Loss Weights: [0.6243293  0.62388504 1.7517858 ]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.0224937796010636e-05, Loss Weights: [0.6243972  0.62395287 1.7516501 ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.0204259524471126e-05, Loss Weights: [0.6244638 0.6240194 1.751517 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.0042349458672106e-05, Loss Weights: [0.6245295 0.624085  1.7513856]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.4742025996383745e-05, Loss Weights: [0.6245947  0.62415016 1.751255  ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.0960391591652296e-05, Loss Weights: [0.6246599  0.62421536 1.7511249 ]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 2.0545303414110094e-05, Loss Weights: [0.6247256 0.624281  1.7509935]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.1714271749951877e-05, Loss Weights: [0.62479204 0.6243473  1.7508607 ]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.395992153964471e-06, Loss Weights: [0.6248594 0.6244146 1.7507261]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.298637107538525e-05, Loss Weights: [0.6249278  0.62448305 1.7505889 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.25104905036278e-06, Loss Weights: [0.6249977  0.62455285 1.7504494 ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.867043445410673e-06, Loss Weights: [0.62506896 0.624624   1.7503071 ]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.021576261147857e-06, Loss Weights: [0.62514174 0.6246967  1.7501616 ]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.9939716164954e-06, Loss Weights: [0.6252162 0.624771  1.7500126]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 7.357444246736122e-06, Loss Weights: [0.6252924 0.6248471 1.7498606]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.878557309799362e-06, Loss Weights: [0.6253704 0.6249249 1.7497048]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.646972102927975e-06, Loss Weights: [0.62545013 0.62500453 1.7495453 ]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.626669114164542e-06, Loss Weights: [0.6255318  0.62508607 1.749382  ]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.1583741979848128e-05, Loss Weights: [0.6256155 0.6251697 1.7492148]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.0987604582624044e-05, Loss Weights: [0.6257013 0.6252554 1.7490431]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.241097930294927e-06, Loss Weights: [0.6257893 0.6253433 1.7488673]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.0030489647760987e-05, Loss Weights: [0.6258795  0.62543344 1.748687  ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.5685774997109547e-05, Loss Weights: [0.62597215 0.62552595 1.748502  ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.619618711236399e-06, Loss Weights: [0.62606716 0.62562084 1.748312  ]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 6.512749223475112e-06, Loss Weights: [0.62616456 0.6257181  1.7481172 ]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.171694389602635e-06, Loss Weights: [0.6262643 0.6258178 1.7479179]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.045972021529451e-05, Loss Weights: [0.62636644 0.6259198  1.7477136 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.443425031146035e-06, Loss Weights: [0.62647104 0.62602425 1.7475046 ]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.1047474799852353e-05, Loss Weights: [0.6265781 0.6261312 1.7472907]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.205144124280196e-06, Loss Weights: [0.62668765 0.62624055 1.7470719 ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.59199769567931e-06, Loss Weights: [0.6267996 0.6263524 1.746848 ]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.110381713777315e-06, Loss Weights: [0.626914  0.6264668 1.7466192]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.998507837532088e-06, Loss Weights: [0.6270309 0.6265836 1.7463853]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.0389183444203809e-05, Loss Weights: [0.62715036 0.6267029  1.7461467 ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.396152225031983e-06, Loss Weights: [0.62727237 0.62682474 1.745903  ]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 7.99658300820738e-06, Loss Weights: [0.62739676 0.626949   1.7456542 ]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 7.640194780833554e-06, Loss Weights: [0.62752366 0.62707573 1.7454004 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.0262260730087291e-05, Loss Weights: [0.6276531 0.627205  1.745142 ]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.616909326519817e-06, Loss Weights: [0.62778497 0.62733674 1.7448783 ]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.173791113425978e-06, Loss Weights: [0.6279193  0.62747097 1.7446098 ]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.006980164675042e-05, Loss Weights: [0.62805617 0.6276077  1.7443361 ]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.721566129883286e-06, Loss Weights: [0.62819564 0.62774694 1.7440574 ]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.0634876161930151e-05, Loss Weights: [0.62833774 0.62788886 1.7437737 ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.439107088837773e-06, Loss Weights: [0.6284823 0.6280333 1.7434845]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.976679055194836e-06, Loss Weights: [0.62862945 0.62818027 1.7431902 ]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.264925781986676e-06, Loss Weights: [0.62877923 0.6283299  1.7428908 ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.88253180164611e-06, Loss Weights: [0.6289316 0.6284821 1.7425865]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.994297215598635e-06, Loss Weights: [0.62908643 0.6286367  1.7422767 ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.1492335033835843e-05, Loss Weights: [0.62924397 0.6287941  1.741962  ]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.5565858120680787e-05, Loss Weights: [0.62940437 0.6289543  1.7416415 ]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.216772014042363e-06, Loss Weights: [0.6295675  0.62911725 1.7413154 ]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.18857915874105e-06, Loss Weights: [0.62973344 0.62928295 1.7409836 ]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.082214748748811e-05, Loss Weights: [0.6299021  0.62945145 1.7406464 ]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.4601635484723374e-05, Loss Weights: [0.6300738  0.62962294 1.7403034 ]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.927735845849384e-06, Loss Weights: [0.6302483 0.6297972 1.7399545]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 7.3715341386559885e-06, Loss Weights: [0.6304256  0.62997437 1.7396    ]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.454089766019024e-06, Loss Weights: [0.6306057 0.6301543 1.7392399]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.6970525191864e-06, Loss Weights: [0.63078856 0.630337   1.7388744 ]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.6189309462788515e-05, Loss Weights: [0.63097435 0.6305226  1.738503  ]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.270667760574725e-06, Loss Weights: [0.6311631 0.6307112 1.7381258]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.0510394531593192e-05, Loss Weights: [0.6313548  0.63090265 1.7377428 ]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.065300421032589e-05, Loss Weights: [0.63154936 0.631097   1.7373537 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.306737072416581e-06, Loss Weights: [0.63174677 0.63129425 1.736959  ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.959105793503113e-05, Loss Weights: [0.6319473 0.6314946 1.736558 ]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.101234920497518e-05, Loss Weights: [0.63215095 0.631698   1.7361507 ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.005019021249609e-05, Loss Weights: [0.63235784 0.63190466 1.7357378 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.223832350660814e-05, Loss Weights: [0.63256764 0.6321143  1.7353182 ]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.0637541890901048e-05, Loss Weights: [0.6327806 0.6323271 1.7348925]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.702932063897606e-06, Loss Weights: [0.63299656 0.6325427  1.7344606 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.268093552032951e-06, Loss Weights: [0.63321555 0.63276154 1.7340231 ]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.056913768290542e-06, Loss Weights: [0.6334374  0.63298315 1.7335794 ]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.200596650771331e-06, Loss Weights: [0.6336621 0.6332076 1.7331302]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.192070067190798e-05, Loss Weights: [0.63388973 0.633435   1.7326753 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 9.682239578978624e-06, Loss Weights: [0.6341202  0.63366526 1.7322146 ]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.1259038728894666e-05, Loss Weights: [0.63435364 0.6338984  1.7317481 ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.077973865903914e-05, Loss Weights: [0.63458985 0.63413423 1.7312756 ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.806791811366566e-06, Loss Weights: [0.63482904 0.63437307 1.7307978 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.276073458546307e-06, Loss Weights: [0.635071   0.63461465 1.7303143 ]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.2598667126439977e-05, Loss Weights: [0.6353158 0.6348591 1.7298253]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.3841101463185623e-05, Loss Weights: [0.63556343 0.6351064  1.7293301 ]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.3229828255134635e-05, Loss Weights: [0.6358142 0.6353568 1.7288291]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.3563784705183934e-05, Loss Weights: [0.63606787 0.6356101  1.728322  ]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 1.0289962119713891e-05, Loss Weights: [0.63632464 0.6358665  1.7278087 ]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 8, Total Loss: 8.04987212177366e-06, Loss Weights: [0.6365844  0.63612586 1.7272897 ]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 9\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.1694767636072356e-05, Loss Weights: [0.6368187  0.63635993 1.7268215 ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.2780818906321656e-05, Loss Weights: [0.6370304  0.63657147 1.726398  ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.971098395704757e-06, Loss Weights: [0.6372222 0.6367631 1.7260147]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.43847737996839e-06, Loss Weights: [0.6373961 0.6369369 1.725667 ]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.626684575574473e-06, Loss Weights: [0.6375542 0.6370949 1.7253509]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.0880195077334065e-05, Loss Weights: [0.6376985  0.63723904 1.7250626 ]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.657060789118987e-06, Loss Weights: [0.6378304 0.6373708 1.7247988]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.736723768583033e-06, Loss Weights: [0.6379515 0.6374918 1.7245567]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.418425179319456e-06, Loss Weights: [0.63806313 0.6376034  1.7243335 ]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.0019604815170169e-05, Loss Weights: [0.6381665 0.6377067 1.7241268]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.3662960554938763e-05, Loss Weights: [0.63826287 0.637803   1.723934  ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 2.4217970349127427e-05, Loss Weights: [0.6383536 0.6378937 1.7237525]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.684603355708532e-06, Loss Weights: [0.63843954 0.63797957 1.7235807 ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.292715731135104e-06, Loss Weights: [0.63852143 0.6380614  1.723417  ]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.60553791426355e-06, Loss Weights: [0.6385999  0.63813984 1.7232602 ]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.281625352741685e-06, Loss Weights: [0.6386756 0.6382155 1.723109 ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.7056478150771e-06, Loss Weights: [0.638749  0.6382888 1.7229621]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.1120740055048373e-05, Loss Weights: [0.6388207  0.63836044 1.722819  ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.094296729017515e-06, Loss Weights: [0.638891  0.6384307 1.7226781]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.1845648259622976e-05, Loss Weights: [0.63896066 0.63850033 1.7225393 ]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 2.4920544092310593e-05, Loss Weights: [0.6390301 0.6385698 1.7224   ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 7.4823492468567565e-06, Loss Weights: [0.63909996 0.63863957 1.7222604 ]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.3884863619750831e-05, Loss Weights: [0.63917035 0.6387099  1.7221196 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.028335625771433e-06, Loss Weights: [0.6392416 0.6387811 1.7219771]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 7.357183676504064e-06, Loss Weights: [0.6393138 0.6388533 1.721833 ]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.0637510968081187e-05, Loss Weights: [0.63938713 0.6389266  1.7216864 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.531212188245263e-06, Loss Weights: [0.63946176 0.63900113 1.7215371 ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.1255780009378213e-05, Loss Weights: [0.63953793 0.63907725 1.7213849 ]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.827901183394715e-06, Loss Weights: [0.6396157 0.639155  1.7212293]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.6939497072598897e-05, Loss Weights: [0.6396955 0.6392347 1.7210698]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.1285619621048681e-05, Loss Weights: [0.6397774  0.63931656 1.720906  ]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.283540859731147e-05, Loss Weights: [0.6398616 0.6394007 1.7207377]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.296323358081281e-06, Loss Weights: [0.6399481  0.63948715 1.7205648 ]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 7.973584615683649e-06, Loss Weights: [0.6400368 0.6395758 1.7203871]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 7.369496415776666e-06, Loss Weights: [0.640128  0.6396669 1.7202053]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.198518116842024e-06, Loss Weights: [0.64022136 0.6397602  1.7200181 ]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.1458765584393404e-05, Loss Weights: [0.64031726 0.6398561  1.7198267 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.02528154256288e-06, Loss Weights: [0.64041555 0.6399543  1.71963   ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.144877367361914e-06, Loss Weights: [0.6405164  0.64005506 1.7194285 ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.922644155973103e-06, Loss Weights: [0.64061975 0.6401583  1.719222  ]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.747068932279944e-06, Loss Weights: [0.6407256  0.64026403 1.7190104 ]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.793728168006055e-06, Loss Weights: [0.64083403 0.6403723  1.7187935 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.396594143443508e-05, Loss Weights: [0.6409452 0.6404834 1.7185714]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 7.691487553529441e-06, Loss Weights: [0.64105904 0.6405971  1.7183437 ]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.0477512660145294e-05, Loss Weights: [0.6411757  0.64071363 1.7181106 ]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.605734703654889e-06, Loss Weights: [0.641295   0.64083284 1.7178719 ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.792658263701014e-06, Loss Weights: [0.64141726 0.6409549  1.717628  ]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.158580724033527e-06, Loss Weights: [0.6415421  0.64107955 1.7173781 ]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.1355552487657405e-05, Loss Weights: [0.64166987 0.6412072  1.717123  ]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.218402738042641e-06, Loss Weights: [0.6418004 0.6413376 1.716862 ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 7.73276678955881e-06, Loss Weights: [0.64193374 0.6414708  1.7165955 ]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.960112609202042e-06, Loss Weights: [0.6420699 0.6416068 1.7163234]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.126802640617825e-06, Loss Weights: [0.64220876 0.6417455  1.7160456 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.494469051976921e-05, Loss Weights: [0.64235055 0.6418872  1.7157621 ]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.7345526430290192e-05, Loss Weights: [0.6424956 0.642032  1.7154725]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.0306480362487491e-05, Loss Weights: [0.64264375 0.64218    1.7151763 ]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.526231224299408e-06, Loss Weights: [0.642795  0.6423311 1.7148738]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.0086533620778937e-05, Loss Weights: [0.64294946 0.6424854  1.714565  ]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.652187716506887e-06, Loss Weights: [0.64310706 0.6426428  1.7142502 ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.73249591171043e-05, Loss Weights: [0.64326787 0.64280343 1.7139287 ]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 7.890852430136874e-06, Loss Weights: [0.6434319 0.6429673 1.7136008]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.352237611892633e-06, Loss Weights: [0.64359915 0.64313436 1.7132666 ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 7.211278898466844e-06, Loss Weights: [0.64376944 0.64330447 1.7129261 ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.62392152560642e-05, Loss Weights: [0.6439431  0.64347786 1.712579  ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.3198742635722738e-05, Loss Weights: [0.64412   0.6436546 1.7122252]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.894298844097648e-06, Loss Weights: [0.6443003 0.6438347 1.7118652]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 7.75885746406857e-06, Loss Weights: [0.6444837  0.64401793 1.7114985 ]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.690867616678588e-06, Loss Weights: [0.64467025 0.64420426 1.7111256 ]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.556715329177678e-06, Loss Weights: [0.64485985 0.6443937  1.7107465 ]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.358332135889214e-06, Loss Weights: [0.6450525  0.64458615 1.7103612 ]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.243265256169252e-06, Loss Weights: [0.64524823 0.6447817  1.7099701 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.754822369548492e-05, Loss Weights: [0.64544725 0.6449805  1.7095724 ]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.1032215297746006e-05, Loss Weights: [0.64564943 0.64518243 1.7091682 ]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.168690328602679e-06, Loss Weights: [0.6458548 0.6453876 1.7087576]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.87377279670909e-06, Loss Weights: [0.6460633  0.64559597 1.7083409 ]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.0743005987023935e-05, Loss Weights: [0.6462749 0.6458074 1.7079175]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.2310295460338239e-05, Loss Weights: [0.64648986 0.64602214 1.7074881 ]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.235583092959132e-06, Loss Weights: [0.64670795 0.64624    1.7070522 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.373205102747306e-06, Loss Weights: [0.6469291 0.6464609 1.7066098]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.6958325431915e-05, Loss Weights: [0.6471536 0.6466852 1.7061613]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.1820232430181932e-05, Loss Weights: [0.6473815 0.6469128 1.7057058]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.0020866284321528e-05, Loss Weights: [0.64761263 0.6471437  1.7052436 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.2153778698120732e-05, Loss Weights: [0.64784724 0.6473781  1.7047749 ]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.440826144971652e-05, Loss Weights: [0.6480852 0.6476158 1.704299 ]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.059717033058405e-05, Loss Weights: [0.6483266  0.64785695 1.7038164 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.0971488336508628e-05, Loss Weights: [0.6485714 0.6481015 1.7033272]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 7.581962563563138e-06, Loss Weights: [0.6488194 0.6483493 1.7028313]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.091049832932185e-06, Loss Weights: [0.6490707 0.6486003 1.702329 ]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.0015053703682497e-05, Loss Weights: [0.6493251  0.64885443 1.7018205 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 9.383752512803767e-06, Loss Weights: [0.6495827 0.6491118 1.7013056]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.0563527212070767e-05, Loss Weights: [0.64984334 0.6493722  1.7007844 ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.382437130814651e-05, Loss Weights: [0.65010726 0.6496359  1.7002568 ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 6.931640200491529e-06, Loss Weights: [0.6503743 0.6499027 1.6997232]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 6.859898348920979e-06, Loss Weights: [0.6506443 0.6501724 1.6991835]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.3734478670812678e-05, Loss Weights: [0.6509173 0.6504452 1.6986376]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.907933079171926e-06, Loss Weights: [0.65119326 0.65072095 1.6980855 ]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 1.1483754860819317e-05, Loss Weights: [0.65147245 0.65099984 1.6975276 ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.726486157684121e-06, Loss Weights: [0.65175456 0.6512817  1.6969638 ]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 7.982620445545763e-06, Loss Weights: [0.6520395  0.65156645 1.696394  ]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 9, Total Loss: 8.838761459628586e-06, Loss Weights: [0.65232736 0.651854   1.6958187 ]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 10\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.0917667168541811e-05, Loss Weights: [0.65258694 0.6521134  1.6952996 ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.966991117631551e-06, Loss Weights: [0.6528214 0.6523477 1.6948309]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.249385246017482e-06, Loss Weights: [0.6530336 0.6525597 1.6944067]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 9.935446541931015e-06, Loss Weights: [0.6532259  0.65275186 1.6940222 ]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.121113751258235e-06, Loss Weights: [0.6534006  0.65292645 1.693673  ]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.5425257515744306e-05, Loss Weights: [0.6535598 0.6530856 1.6933546]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 9.505481102678459e-06, Loss Weights: [0.6537055  0.65323114 1.6930635 ]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.179498212877661e-05, Loss Weights: [0.65383923 0.6533648  1.692796  ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 7.511500825785333e-06, Loss Weights: [0.6539625 0.6534879 1.6925493]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.2980701285414398e-05, Loss Weights: [0.6540768 0.6536021 1.6923211]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 7.193827514129225e-06, Loss Weights: [0.65418315 0.65370846 1.6921084 ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.305574738187715e-06, Loss Weights: [0.65428257 0.6538079  1.6919096 ]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.917516424844507e-06, Loss Weights: [0.65437615 0.65390134 1.6917225 ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.361896107089706e-06, Loss Weights: [0.6544646  0.65398973 1.6915457 ]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 9.056088856596034e-06, Loss Weights: [0.65454876 0.65407383 1.6913774 ]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.0149542504223064e-05, Loss Weights: [0.6546294 0.6541544 1.6912161]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.986064131022431e-06, Loss Weights: [0.65470713 0.6542321  1.6910608 ]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 6.817409030190902e-06, Loss Weights: [0.6547825  0.65430737 1.6909103 ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 9.413944098923821e-06, Loss Weights: [0.65485585 0.6543807  1.6907634 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 9.391188541485462e-06, Loss Weights: [0.6549279 0.6544527 1.6906195]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.006994903553277e-06, Loss Weights: [0.6549989 0.6545236 1.6904774]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 9.082709766516928e-06, Loss Weights: [0.65506935 0.654594   1.6903367 ]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.752886969887186e-06, Loss Weights: [0.65513945 0.6546641  1.6901965 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 9.167270945908967e-06, Loss Weights: [0.65520966 0.65473425 1.6900563 ]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.0136134733329527e-05, Loss Weights: [0.6552802 0.6548047 1.6899154]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.134588824759703e-06, Loss Weights: [0.65535116 0.6548757  1.6897731 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.1802259905380197e-05, Loss Weights: [0.65542316 0.65494764 1.689629  ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 9.836458957579453e-06, Loss Weights: [0.6554963 0.6550207 1.6894829]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.1025746971426997e-05, Loss Weights: [0.6555708  0.65509516 1.6893339 ]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.3616283467854373e-05, Loss Weights: [0.655647  0.6551713 1.6891818]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.2056938430760056e-05, Loss Weights: [0.65572506 0.65524924 1.6890259 ]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.4838838069408666e-05, Loss Weights: [0.65580535 0.6553294  1.6888654 ]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.1712852938217111e-05, Loss Weights: [0.6558879 0.6554119 1.6887002]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.1128721780551132e-05, Loss Weights: [0.65597296 0.65549695 1.6885302 ]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.2876785149273928e-05, Loss Weights: [0.65606064 0.6555846  1.6883547 ]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.610891200078186e-06, Loss Weights: [0.65615106 0.6556749  1.6881741 ]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 7.241526873258408e-06, Loss Weights: [0.65624404 0.6557678  1.6879882 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.005265044630505e-06, Loss Weights: [0.6563397 0.6558634 1.6877971]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.967340363597032e-06, Loss Weights: [0.656438   0.65596163 1.6876005 ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.618222636869177e-06, Loss Weights: [0.6565389 0.6560625 1.6873984]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 9.520577805233188e-06, Loss Weights: [0.6566426  0.65616614 1.6871912 ]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.0013156497734599e-05, Loss Weights: [0.65674907 0.65627253 1.6869786 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 7.838389137759805e-06, Loss Weights: [0.65685827 0.65638167 1.6867602 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.774045454629231e-06, Loss Weights: [0.6569702  0.65649354 1.6865362 ]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.0657779967004899e-05, Loss Weights: [0.65708494 0.6566082  1.6863066 ]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.843438081385102e-06, Loss Weights: [0.65720266 0.6567259  1.6860714 ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.848040124576073e-06, Loss Weights: [0.6573232 0.6568463 1.6858304]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.1024734703823924e-05, Loss Weights: [0.6574467  0.65696967 1.6855836 ]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.792119842837565e-06, Loss Weights: [0.65757304 0.6570959  1.685331  ]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 7.365417332039215e-06, Loss Weights: [0.6577023 0.6572251 1.6850727]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 7.547160294052446e-06, Loss Weights: [0.6578344  0.65735704 1.6848085 ]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 9.571509508532472e-06, Loss Weights: [0.65796936 0.6574919  1.6845386 ]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 9.131611477641854e-06, Loss Weights: [0.6581072  0.65762967 1.6842631 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.59664760355372e-06, Loss Weights: [0.65824795 0.6577703  1.6839819 ]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.4332061255117878e-05, Loss Weights: [0.6583917 0.6579139 1.6836944]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.160632205544971e-06, Loss Weights: [0.6585386  0.65806067 1.6834006 ]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.47809587867232e-06, Loss Weights: [0.6586885  0.65821046 1.6831012 ]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.3640769793710206e-05, Loss Weights: [0.6588415 0.6583633 1.6827953]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.262144547188655e-06, Loss Weights: [0.65899754 0.6585192  1.682483  ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 7.76464912632946e-06, Loss Weights: [0.6591568 0.6586783 1.6821647]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.622377208666876e-06, Loss Weights: [0.65931904 0.6588404  1.6818405 ]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.5222739421005826e-05, Loss Weights: [0.6594845 0.6590057 1.6815097]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.372861884708982e-06, Loss Weights: [0.6596532 0.6591742 1.6811726]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 9.07997127796989e-06, Loss Weights: [0.659825   0.65934587 1.680829  ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 9.49284185480792e-06, Loss Weights: [0.66       0.65952075 1.6804793 ]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 6.497575213870732e-06, Loss Weights: [0.66017807 0.6596986  1.6801232 ]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.801942385616712e-06, Loss Weights: [0.66035926 0.65987957 1.6797613 ]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.724494359223172e-05, Loss Weights: [0.6605437 0.6600638 1.6793926]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 7.856287993490696e-06, Loss Weights: [0.6607313  0.66025126 1.6790174 ]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.921871994971298e-06, Loss Weights: [0.66092217 0.66044194 1.6786358 ]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 7.157727395679103e-06, Loss Weights: [0.6611162  0.66063577 1.6782479 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.0896133062487934e-05, Loss Weights: [0.6613134  0.66083276 1.6778538 ]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 7.557338449259987e-06, Loss Weights: [0.6615137  0.66103286 1.6774535 ]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 7.88910074334126e-06, Loss Weights: [0.661717  0.6612359 1.6770469]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.3515154023480136e-05, Loss Weights: [0.6619236 0.6614423 1.6766342]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 9.071462955034804e-06, Loss Weights: [0.6621333  0.66165173 1.6762149 ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.1709247701219283e-05, Loss Weights: [0.66234624 0.6618645  1.6757894 ]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 7.666035344300326e-06, Loss Weights: [0.6625623  0.66208035 1.6753571 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.22336005512625e-06, Loss Weights: [0.6627816 0.6622994 1.674919 ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.509176945546642e-05, Loss Weights: [0.6630041  0.66252166 1.6744741 ]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.0975822988257278e-05, Loss Weights: [0.66322994 0.66274726 1.6740227 ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 7.367251782852691e-06, Loss Weights: [0.66345906 0.66297615 1.6735649 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.447186701232567e-06, Loss Weights: [0.6636913 0.6632081 1.6731007]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.626892849861179e-06, Loss Weights: [0.6639266 0.6634432 1.6726302]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 9.738011613080744e-06, Loss Weights: [0.66416514 0.6636815  1.6721535 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.503845487604849e-05, Loss Weights: [0.6644069 0.663923  1.67167  ]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 9.25673793972237e-06, Loss Weights: [0.664652   0.66416794 1.67118   ]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 7.168829597503645e-06, Loss Weights: [0.6649003  0.66441596 1.6706836 ]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.905474714993034e-06, Loss Weights: [0.6651518 0.6646672 1.6701812]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 6.845061761850957e-06, Loss Weights: [0.6654062 0.6649214 1.6696725]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.2091489224985708e-05, Loss Weights: [0.6656638 0.6651787 1.6691575]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 9.961029718397185e-06, Loss Weights: [0.66592443 0.6654391  1.6686362 ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 9.820947525440715e-06, Loss Weights: [0.6661883 0.6657027 1.6681087]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 8.369724127987865e-06, Loss Weights: [0.6664553  0.66596943 1.6675754 ]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.016410442389315e-05, Loss Weights: [0.6667254  0.66623914 1.6670355 ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 7.412526429106947e-06, Loss Weights: [0.66699845 0.6665119  1.6664897 ]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 7.953181011544075e-06, Loss Weights: [0.6672745 0.6667876 1.6659381]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.0562093848420773e-05, Loss Weights: [0.6675534  0.66706634 1.6653802 ]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.0687761459848844e-05, Loss Weights: [0.6678354 0.667348  1.6648164]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 10, Total Loss: 1.4032332728675101e-05, Loss Weights: [0.6681206 0.667633  1.6642463]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 11\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 9.772319572221022e-06, Loss Weights: [0.6683778 0.66789   1.6637323]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 9.267901987186633e-06, Loss Weights: [0.6686101 0.6681222 1.6632676]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.0428886525915004e-05, Loss Weights: [0.6688205 0.6683324 1.6628473]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 9.343040801468305e-06, Loss Weights: [0.66901124 0.66852295 1.6624657 ]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.1612057278398424e-05, Loss Weights: [0.6691848 0.6686964 1.6621189]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.0867575838346966e-05, Loss Weights: [0.6693432  0.66885465 1.661802  ]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.236667443066835e-06, Loss Weights: [0.6694882  0.66899955 1.6615123 ]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.887173524068203e-06, Loss Weights: [0.66962135 0.6691326  1.6612462 ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.819050890451763e-06, Loss Weights: [0.66974413 0.66925526 1.6610008 ]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.300274561799597e-05, Loss Weights: [0.669858  0.669369  1.6607733]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.275934305856936e-06, Loss Weights: [0.6699641  0.66947496 1.660561  ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.093590284057427e-06, Loss Weights: [0.67006344 0.66957426 1.6603621 ]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 6.994170689722523e-06, Loss Weights: [0.670157  0.6696677 1.6601751]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.0276597095071338e-05, Loss Weights: [0.6702457  0.66975635 1.659998  ]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.532030728412792e-05, Loss Weights: [0.6703304 0.669841  1.6598285]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.6646174117340706e-05, Loss Weights: [0.6704122 0.6699227 1.6596651]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 9.67003325058613e-06, Loss Weights: [0.6704916  0.67000204 1.6595061 ]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.2644202797673643e-05, Loss Weights: [0.6705694 0.6700798 1.6593508]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.013179467525333e-06, Loss Weights: [0.67064595 0.6701563  1.6591977 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.1770826858992223e-05, Loss Weights: [0.6707218  0.67023206 1.659046  ]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.93818105396349e-06, Loss Weights: [0.67079735 0.6703075  1.6588951 ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.367326699953992e-06, Loss Weights: [0.6708728 0.670383  1.6587441]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.468245141557418e-06, Loss Weights: [0.6709486  0.67045873 1.6585926 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 6.6305224208917934e-06, Loss Weights: [0.6710249  0.67053497 1.6584401 ]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.890555025369395e-06, Loss Weights: [0.6711019 0.6706119 1.6582863]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.951295967563055e-06, Loss Weights: [0.6711798 0.6706897 1.6581304]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.3178623703424819e-05, Loss Weights: [0.67125905 0.6707689  1.6579721 ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 9.454856808588374e-06, Loss Weights: [0.67133975 0.67084956 1.6578107 ]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 9.355101610708516e-06, Loss Weights: [0.6714222  0.67093194 1.657646  ]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.0673357792256866e-05, Loss Weights: [0.6715065 0.6710162 1.6574775]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.484326826874167e-06, Loss Weights: [0.6715928 0.6711024 1.6573048]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 9.544819477014244e-06, Loss Weights: [0.67168117 0.67119074 1.6571279 ]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 9.043708814715501e-06, Loss Weights: [0.6717719  0.67128134 1.6569468 ]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.5331013855757192e-05, Loss Weights: [0.67186505 0.67137444 1.6567605 ]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 9.18954629014479e-06, Loss Weights: [0.67196083 0.67147017 1.656569  ]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.539777016063454e-06, Loss Weights: [0.6720592  0.67156845 1.6563723 ]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.219450137403328e-06, Loss Weights: [0.67216027 0.6716694  1.6561704 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.425966032315046e-06, Loss Weights: [0.6722639 0.671773  1.655963 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.394948054046836e-06, Loss Weights: [0.6723703 0.6718793 1.6557503]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.0858476343855727e-05, Loss Weights: [0.67247945 0.67198837 1.655532  ]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.827949957572855e-06, Loss Weights: [0.6725914 0.6721002 1.6553082]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.389414804492844e-06, Loss Weights: [0.6727061 0.6722148 1.6550791]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.013289177848492e-06, Loss Weights: [0.67282355 0.6723321  1.6548443 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 9.822086212807335e-06, Loss Weights: [0.67294383 0.6724523  1.6546042 ]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.275028110598214e-06, Loss Weights: [0.67306685 0.6725752  1.6543581 ]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.5194991647149436e-05, Loss Weights: [0.67319286 0.67270106 1.6541059 ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.3303613741300069e-05, Loss Weights: [0.6733222 0.6728303 1.6538476]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.069076097337529e-05, Loss Weights: [0.6734547 0.6729627 1.6535826]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.196046287077479e-05, Loss Weights: [0.6735906  0.67309856 1.6533108 ]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 9.071206477528904e-06, Loss Weights: [0.6737299  0.67323774 1.6530323 ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.0139146979781799e-05, Loss Weights: [0.6738726  0.67338026 1.6527472 ]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.939011993585154e-06, Loss Weights: [0.6740186  0.67352617 1.6524553 ]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 6.848850262031192e-06, Loss Weights: [0.67416775 0.67367524 1.6521567 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.0341923371015582e-05, Loss Weights: [0.67432034 0.67382765 1.6518519 ]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.462148460035678e-06, Loss Weights: [0.6744761 0.6739833 1.6515405]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.142626938933972e-06, Loss Weights: [0.67463505 0.67414206 1.6512227 ]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.043077736539999e-05, Loss Weights: [0.6747972 0.6743041 1.6508986]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.962441486597527e-06, Loss Weights: [0.67496264 0.6744695  1.6505681 ]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.89369187259581e-06, Loss Weights: [0.6751311  0.67463785 1.6502312 ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.234919732785784e-06, Loss Weights: [0.67530274 0.67480934 1.6498879 ]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.1165636654768605e-06, Loss Weights: [0.6754774  0.67498386 1.6495385 ]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.3948906598670874e-05, Loss Weights: [0.6756554 0.6751618 1.6491828]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.4648845535703003e-05, Loss Weights: [0.67583686 0.6753431  1.64882   ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.457790616172133e-06, Loss Weights: [0.6760217 0.6755278 1.6484506]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.951180123200174e-06, Loss Weights: [0.6762098 0.6757158 1.6480744]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.0251494131807704e-05, Loss Weights: [0.6764013  0.67590714 1.6476914 ]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.0142524843104184e-05, Loss Weights: [0.6765963 0.6761019 1.6473019]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.522889402229339e-06, Loss Weights: [0.67679447 0.6763     1.6469057 ]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.6199055608012713e-05, Loss Weights: [0.67699623 0.67650163 1.6465023 ]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.714244929957204e-06, Loss Weights: [0.6772015 0.6767068 1.6460917]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.0360314263380133e-05, Loss Weights: [0.6774103 0.6769154 1.6456742]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.1971305866609327e-05, Loss Weights: [0.6776227  0.67712766 1.6452496 ]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 9.995732398238033e-06, Loss Weights: [0.6778387 0.6773435 1.6448178]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.080894986051135e-06, Loss Weights: [0.67805827 0.6775629  1.6443791 ]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 6.247526471270248e-06, Loss Weights: [0.67828107 0.6777855  1.6439334 ]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.549200290668523e-06, Loss Weights: [0.6785072  0.67801154 1.6434813 ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.62895103637129e-06, Loss Weights: [0.6787367  0.67824084 1.6430228 ]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.2153016541560646e-05, Loss Weights: [0.67896944 0.6784734  1.6425573 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.0672598364180885e-05, Loss Weights: [0.6792056 0.6787094 1.6420851]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.60454747453332e-06, Loss Weights: [0.67944515 0.67894876 1.6416061 ]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.668544640182517e-06, Loss Weights: [0.679688  0.6791914 1.6411204]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.004608389455825e-06, Loss Weights: [0.67993414 0.6794374  1.6406283 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.106548193609342e-06, Loss Weights: [0.6801834  0.67968655 1.64013   ]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.869108746177517e-05, Loss Weights: [0.68043625 0.6799392  1.6396247 ]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.855407941155136e-06, Loss Weights: [0.68069255 0.6801953  1.6391122 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.818894457363058e-06, Loss Weights: [0.6809523 0.6804548 1.638593 ]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.214306944864802e-06, Loss Weights: [0.6812154  0.68071765 1.6380669 ]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 9.820530067372601e-06, Loss Weights: [0.68148196 0.68098396 1.6375344 ]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.339350759139052e-06, Loss Weights: [0.68175167 0.68125343 1.6369948 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.764954716549255e-06, Loss Weights: [0.6820247 0.6815262 1.6364491]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 2.0186780602671206e-05, Loss Weights: [0.6823013 0.6818025 1.6358961]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 9.620815944799688e-06, Loss Weights: [0.6825815 0.6820824 1.635336 ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.367791113210842e-06, Loss Weights: [0.68286514 0.6823658  1.634769  ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.0212640518147964e-05, Loss Weights: [0.6831523  0.68265265 1.6341952 ]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.862967661116272e-06, Loss Weights: [0.68344283 0.68294287 1.6336144 ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 7.876889867475256e-06, Loss Weights: [0.68373656 0.68323636 1.6330268 ]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.0073340490635019e-05, Loss Weights: [0.68403375 0.6835333  1.6324329 ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 8.040810826059896e-06, Loss Weights: [0.68433416 0.6838335  1.6318326 ]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 1.2811991837224923e-05, Loss Weights: [0.6846379 0.6841369 1.6312253]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 11, Total Loss: 6.33958325124695e-06, Loss Weights: [0.68494487 0.6844436  1.6306117 ]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 12\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.2191938367323019e-05, Loss Weights: [0.68522173 0.6847203  1.630058  ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.683052328706253e-06, Loss Weights: [0.68547195 0.68497026 1.6295576 ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.335029062640388e-06, Loss Weights: [0.68569857 0.68519664 1.6291049 ]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.623911864764523e-06, Loss Weights: [0.685904 0.685402 1.628694]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.495460977224866e-06, Loss Weights: [0.6860908 0.6855886 1.6283205]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.3679628864338156e-05, Loss Weights: [0.68626136 0.68575907 1.6279798 ]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.48919387155911e-06, Loss Weights: [0.68641746 0.685915   1.6276677 ]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.138687917380594e-06, Loss Weights: [0.68656087 0.6860583  1.6273808 ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.543694093532395e-06, Loss Weights: [0.6866932 0.6861905 1.6271163]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.2293119652895257e-05, Loss Weights: [0.686816  0.6863132 1.626871 ]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.590849574829917e-06, Loss Weights: [0.6869304  0.68642753 1.626642  ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.159381311794277e-06, Loss Weights: [0.68703765 0.6865347  1.6264275 ]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.054883437580429e-06, Loss Weights: [0.68713874 0.68663573 1.6262257 ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 6.7475893956725486e-06, Loss Weights: [0.6872344 0.6867313 1.6260343]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.20151217340026e-06, Loss Weights: [0.6873256 0.6868224 1.6258519]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.635020665475167e-06, Loss Weights: [0.68741304 0.68690974 1.6256773 ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.657644113758579e-06, Loss Weights: [0.68749726 0.68699396 1.6255088 ]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.701929800736252e-06, Loss Weights: [0.6875791  0.68707573 1.6253452 ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.1849785854283255e-06, Loss Weights: [0.68765897 0.6871556  1.6251855 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.4180452126311138e-05, Loss Weights: [0.6877376  0.68723416 1.6250281 ]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.01250337442616e-06, Loss Weights: [0.6878154  0.68731195 1.6248726 ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.7788364857551642e-05, Loss Weights: [0.68789315 0.6873896  1.6247172 ]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.234954864543397e-06, Loss Weights: [0.687971   0.68746746 1.6245615 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.1256767720624339e-05, Loss Weights: [0.68804944 0.6875458  1.6244047 ]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.441589099878911e-06, Loss Weights: [0.6881287 0.687625  1.6242461]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.760511602507904e-06, Loss Weights: [0.68820924 0.6877054  1.6240857 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.2101466381864157e-05, Loss Weights: [0.6882911 0.6877872 1.6239219]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.753519245539792e-05, Loss Weights: [0.6883749 0.6878709 1.623754 ]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.702853847353254e-06, Loss Weights: [0.6884609  0.68795687 1.6235822 ]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.0645742804626934e-05, Loss Weights: [0.6885492  0.68804514 1.6234057 ]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.894201189628802e-06, Loss Weights: [0.6886399 0.6881357 1.6232245]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.360109066212317e-06, Loss Weights: [0.6887329  0.68822867 1.6230385 ]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.2635827260965016e-05, Loss Weights: [0.6888286 0.6883242 1.6228471]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.702343620825559e-06, Loss Weights: [0.688927  0.6884225 1.6226504]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.0408412890683394e-05, Loss Weights: [0.6890282  0.68852365 1.6224482 ]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.2533104381873272e-05, Loss Weights: [0.68913233 0.6886277  1.6222398 ]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.0134308467968367e-05, Loss Weights: [0.6892396  0.68873495 1.6220255 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.942032764025498e-06, Loss Weights: [0.68935    0.68884516 1.6218047 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.340136784885544e-06, Loss Weights: [0.6894635 0.6889586 1.6215777]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.0045802810054738e-05, Loss Weights: [0.6895803 0.6890753 1.6213443]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.346193681063596e-06, Loss Weights: [0.6897003  0.68919516 1.6211045 ]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.502024684275966e-06, Loss Weights: [0.68982357 0.6893183  1.6208582 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.3262124210014e-06, Loss Weights: [0.68995    0.68944466 1.6206053 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.3786723684461322e-05, Loss Weights: [0.69007987 0.6895744  1.6203456 ]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.063903922244208e-06, Loss Weights: [0.69021314 0.68970764 1.6200793 ]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.76827619120013e-06, Loss Weights: [0.69034976 0.68984413 1.6198063 ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.772143362672068e-06, Loss Weights: [0.69048953 0.68998384 1.6195266 ]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.252195246110205e-06, Loss Weights: [0.69063264 0.6901269  1.6192406 ]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 6.15597400610568e-06, Loss Weights: [0.69077885 0.69027305 1.6189481 ]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.521393621980678e-06, Loss Weights: [0.69092834 0.6904224  1.6186492 ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.244330274465028e-06, Loss Weights: [0.69108105 0.690575   1.6183441 ]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.752090591064189e-06, Loss Weights: [0.691237  0.6907308 1.6180322]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.569599802081939e-06, Loss Weights: [0.6913961 0.6908899 1.6177142]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 6.8004637796548195e-06, Loss Weights: [0.69155836 0.691052   1.6173896 ]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.2383747161948122e-05, Loss Weights: [0.691724   0.69121754 1.6170585 ]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 6.5587510107434355e-06, Loss Weights: [0.6918928 0.6913862 1.6167209]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.607332463521743e-06, Loss Weights: [0.6920648 0.6915581 1.6163771]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.2119533494114876e-05, Loss Weights: [0.6922401  0.69173336 1.6160264 ]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.336524504353292e-06, Loss Weights: [0.6924188 0.6919119 1.6156694]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.014677405299153e-06, Loss Weights: [0.69260067 0.6920936  1.6153057 ]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.011779184220359e-06, Loss Weights: [0.69278586 0.6922787  1.6149355 ]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.913546141935512e-06, Loss Weights: [0.69297427 0.6924669  1.6145587 ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.550563507014886e-06, Loss Weights: [0.69316596 0.6926585  1.6141756 ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.686050594202243e-06, Loss Weights: [0.69336087 0.6928533  1.613786  ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.1416327652113978e-05, Loss Weights: [0.69355905 0.69305134 1.6133897 ]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.202354936453048e-06, Loss Weights: [0.6937605 0.6932526 1.6129868]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 6.971235052333213e-06, Loss Weights: [0.69396526 0.6934572  1.6125774 ]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.129174031841103e-06, Loss Weights: [0.6941733 0.693665  1.6121618]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.5548059612629e-06, Loss Weights: [0.6943844 0.693876  1.6117396]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.693359632161446e-06, Loss Weights: [0.69459873 0.6940902  1.6113112 ]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.320359484059736e-06, Loss Weights: [0.6948163  0.69430757 1.6108763 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.119982001313474e-06, Loss Weights: [0.695037  0.6945281 1.610435 ]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.264411007985473e-06, Loss Weights: [0.6952609  0.69475174 1.6099874 ]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.007481599430321e-06, Loss Weights: [0.6954878 0.6949785 1.6095335]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 6.4020910031103995e-06, Loss Weights: [0.6957179 0.6952084 1.6090739]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.0485440725460649e-05, Loss Weights: [0.695951  0.6954413 1.6086076]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.221047326311236e-06, Loss Weights: [0.69618726 0.6956774  1.6081355 ]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.792468179308344e-06, Loss Weights: [0.6964266  0.69591653 1.607657  ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.949242667062208e-06, Loss Weights: [0.69666904 0.6961589  1.6071721 ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.862847607815638e-06, Loss Weights: [0.69691473 0.6964044  1.6066809 ]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.265600743266987e-06, Loss Weights: [0.6971636  0.69665307 1.6061835 ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.49608898331644e-06, Loss Weights: [0.6974155 0.6969048 1.6056798]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.553186151199043e-06, Loss Weights: [0.6976705  0.69715965 1.60517   ]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.715977855899837e-06, Loss Weights: [0.69792855 0.6974175  1.6046537 ]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 8.963099389802665e-06, Loss Weights: [0.69818985 0.69767857 1.6041316 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.827357876522001e-06, Loss Weights: [0.6984542  0.69794273 1.6036031 ]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.602932328154566e-06, Loss Weights: [0.6987216 0.6982099 1.6030686]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.337187293567695e-06, Loss Weights: [0.69899213 0.69848025 1.6025279 ]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 6.7943492467748e-06, Loss Weights: [0.69926566 0.6987536  1.6019808 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.860047844587825e-06, Loss Weights: [0.6995422 0.69903   1.6014279]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.461273293709382e-06, Loss Weights: [0.6998218 0.6993094 1.6008687]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.895278031355701e-06, Loss Weights: [0.7001046  0.69959193 1.6003036 ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.979958354553673e-06, Loss Weights: [0.70039034 0.69987744 1.5997324 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.511492862657178e-06, Loss Weights: [0.7006791  0.70016605 1.5991548 ]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.039780707098544e-06, Loss Weights: [0.7009711 0.7004578 1.5985712]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.648259270354174e-06, Loss Weights: [0.7012661 0.7007526 1.5979812]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 7.45793795431382e-06, Loss Weights: [0.7015642  0.70105046 1.5973853 ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.768833479029126e-06, Loss Weights: [0.7018653 0.7013514 1.5967832]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 1.1325454579491634e-05, Loss Weights: [0.7021697 0.7016556 1.596175 ]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 12, Total Loss: 9.92851892078761e-06, Loss Weights: [0.7024772 0.7019629 1.5955598]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 13\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 3.1494750146521255e-05, Loss Weights: [0.70275545 0.70224094 1.5950036 ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 1.109737695514923e-05, Loss Weights: [0.70300776 0.7024931  1.5944992 ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 6.933575150469551e-06, Loss Weights: [0.70323706 0.7027222  1.5940409 ]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.313647413160652e-06, Loss Weights: [0.7034458 0.7029308 1.5936236]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 9.020527613756713e-06, Loss Weights: [0.70363635 0.70312124 1.5932425 ]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 1.1118731890746858e-05, Loss Weights: [0.70381105 0.7032958  1.5928931 ]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 1.0578619367151987e-05, Loss Weights: [0.7039718 0.7034565 1.5925716]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 6.07756874160259e-06, Loss Weights: [0.70412034 0.70360494 1.5922749 ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.5826706051884685e-06, Loss Weights: [0.704258  0.7037425 1.5919995]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 1.0919714441115502e-05, Loss Weights: [0.7043864 0.7038708 1.5917428]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.051625743770273e-06, Loss Weights: [0.70450675 0.703991   1.5915023 ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.96202982403338e-06, Loss Weights: [0.7046201 0.7041043 1.5912757]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.215833986469079e-06, Loss Weights: [0.7047274  0.70421153 1.5910609 ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.643778189958539e-06, Loss Weights: [0.7048298 0.7043139 1.5908564]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 1.1590456779231317e-05, Loss Weights: [0.70492804 0.70441204 1.5906601 ]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.362571861653123e-06, Loss Weights: [0.7050228  0.70450675 1.5904703 ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.3592100306996144e-06, Loss Weights: [0.70511496 0.70459884 1.5902863 ]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.894122063589748e-06, Loss Weights: [0.70520484 0.70468867 1.5901062 ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 6.715698873449583e-06, Loss Weights: [0.7052932  0.70477694 1.5899298 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.030201570363715e-06, Loss Weights: [0.70538026 0.7048639  1.5897557 ]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 6.805317298130831e-06, Loss Weights: [0.7054666 0.7049502 1.5895834]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.386305125895888e-06, Loss Weights: [0.7055524 0.7050359 1.5894115]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.393143278022762e-06, Loss Weights: [0.7056383  0.70512176 1.5892401 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.768594852881506e-06, Loss Weights: [0.70572436 0.70520777 1.5890679 ]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.5920711424259935e-06, Loss Weights: [0.70581096 0.7052943  1.5888946 ]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.027104740904178e-06, Loss Weights: [0.7058984  0.70538175 1.5887198 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 6.4560663304291666e-06, Loss Weights: [0.70598686 0.7054701  1.5885429 ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.4102858889091294e-06, Loss Weights: [0.70607656 0.7055597  1.5883638 ]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.565607458876912e-06, Loss Weights: [0.7061676 0.7056506 1.5881817]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.882838301360607e-06, Loss Weights: [0.7062603 0.7057433 1.5879965]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 1.0198139534622896e-05, Loss Weights: [0.70635486 0.7058378  1.5878073 ]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.368088856514078e-06, Loss Weights: [0.70645154 0.7059344  1.5876142 ]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.83727864472894e-06, Loss Weights: [0.70655024 0.70603305 1.5874166 ]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 1.019868523144396e-05, Loss Weights: [0.7066514  0.70613414 1.5872147 ]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 1.0073637895402499e-05, Loss Weights: [0.706755  0.7062377 1.5870075]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 9.82319215836469e-06, Loss Weights: [0.70686114 0.70634377 1.5867949 ]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 1.265139326278586e-05, Loss Weights: [0.70697033 0.7064529  1.5865769 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 1.0091287549585104e-05, Loss Weights: [0.7070825  0.70656496 1.5863526 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 6.136148840596434e-06, Loss Weights: [0.7071976 0.70668   1.5861223]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.84430176281603e-06, Loss Weights: [0.70731574 0.706798   1.5858861 ]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.15927251096582e-06, Loss Weights: [0.7074369 0.7069191 1.585644 ]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.141104561014799e-06, Loss Weights: [0.7075611 0.7070431 1.5853958]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 9.240358849638142e-06, Loss Weights: [0.7076883  0.70717025 1.5851415 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.591615940327756e-06, Loss Weights: [0.70781857 0.7073004  1.5848811 ]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.855689884512685e-06, Loss Weights: [0.70795196 0.70743376 1.5846143 ]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 6.492851753137074e-06, Loss Weights: [0.70808846 0.7075702  1.5843413 ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 6.971296897972934e-06, Loss Weights: [0.70822805 0.70770967 1.5840622 ]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.417017513944302e-06, Loss Weights: [0.7083707  0.70785224 1.583777  ]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 6.07941547059454e-06, Loss Weights: [0.7085164  0.70799786 1.5834858 ]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.050625183386728e-06, Loss Weights: [0.70866513 0.70814645 1.5831885 ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 1.1369494131940883e-05, Loss Weights: [0.708817  0.7082982 1.5828849]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.0379032877099235e-06, Loss Weights: [0.7089721 0.7084532 1.5825748]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 1.0580314665276092e-05, Loss Weights: [0.7091304  0.70861137 1.5822582 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.432750291831326e-06, Loss Weights: [0.709292  0.7087728 1.581935 ]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.157615073083434e-06, Loss Weights: [0.709457   0.70893764 1.5816054 ]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.722067832422908e-06, Loss Weights: [0.7096251  0.70910573 1.5812691 ]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.74214458942879e-06, Loss Weights: [0.7097966 0.7092771 1.5809264]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.780104508332442e-06, Loss Weights: [0.7099713 0.7094517 1.5805768]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.464695383736398e-06, Loss Weights: [0.71014947 0.7096297  1.5802207 ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.754515874898061e-06, Loss Weights: [0.71033096 0.7098111  1.579858  ]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 1.431858618161641e-05, Loss Weights: [0.71051604 0.70999604 1.579488  ]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.34407182992436e-06, Loss Weights: [0.7107047 0.7101846 1.5791109]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.876875315560028e-06, Loss Weights: [0.71089685 0.7103766  1.5787265 ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 6.4832265707082115e-06, Loss Weights: [0.7110925 0.7105721 1.5783353]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 1.077176148100989e-05, Loss Weights: [0.7112917 0.7107712 1.5779369]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.940052794059739e-06, Loss Weights: [0.71149457 0.710974   1.5775318 ]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.565473879367346e-06, Loss Weights: [0.71170074 0.71118    1.5771192 ]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 1.6621854229015298e-05, Loss Weights: [0.7119109  0.71138996 1.5766993 ]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.772531716909725e-06, Loss Weights: [0.7121247 0.7116036 1.5762715]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 6.513926109619206e-06, Loss Weights: [0.71234226 0.71182096 1.5758368 ]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.738385986362118e-06, Loss Weights: [0.71256346 0.712042   1.5753947 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 9.680358743935358e-06, Loss Weights: [0.7127882  0.71226656 1.574945  ]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 9.442449481866788e-06, Loss Weights: [0.7130168  0.71249497 1.5744882 ]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.296341664186912e-06, Loss Weights: [0.71324897 0.712727   1.574024  ]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.544502295786515e-06, Loss Weights: [0.7134847 0.7129626 1.5735528]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 1.0549036232987419e-05, Loss Weights: [0.7137241 0.7132018 1.5730741]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.449291842931416e-06, Loss Weights: [0.713967  0.7134446 1.5725882]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.4076518760412e-06, Loss Weights: [0.7142136 0.713691  1.5720954]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 1.7900931197800674e-05, Loss Weights: [0.71446407 0.7139413  1.5715947 ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 6.823372586950427e-06, Loss Weights: [0.7147183  0.71419525 1.5710862 ]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.022543624974787e-06, Loss Weights: [0.7149763 0.7144531 1.5705705]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.918664207158145e-06, Loss Weights: [0.715238  0.7147146 1.5700474]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.152745067491196e-06, Loss Weights: [0.7155034 0.7149798 1.5695169]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 9.050902917806525e-06, Loss Weights: [0.7157724  0.71524864 1.5689789 ]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.562453331251163e-06, Loss Weights: [0.7160451  0.71552116 1.5684338 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 9.421301911061164e-06, Loss Weights: [0.71632147 0.7157973  1.5678813 ]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 9.007985681819264e-06, Loss Weights: [0.71660143 0.7160771  1.5673215 ]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 6.525391199829755e-06, Loss Weights: [0.7168849  0.71636033 1.5667546 ]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 8.310577868542168e-06, Loss Weights: [0.717172  0.7166472 1.5661808]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 9.306957508670166e-06, Loss Weights: [0.7174626  0.71693754 1.5655999 ]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 9.060902812052518e-06, Loss Weights: [0.71775675 0.71723145 1.565012  ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 6.322381523204967e-06, Loss Weights: [0.71805423 0.7175287  1.5644171 ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 9.066178790817503e-06, Loss Weights: [0.7183552  0.71782947 1.5638155 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.695407475694083e-06, Loss Weights: [0.7186595 0.7181336 1.5632069]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 7.612242825416615e-06, Loss Weights: [0.7189672  0.71844107 1.5625917 ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 9.57165684667416e-06, Loss Weights: [0.7192783 0.7187519 1.5619698]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 6.318392934190342e-06, Loss Weights: [0.71959263 0.719066   1.5613413 ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 6.807781119277934e-06, Loss Weights: [0.71991026 0.7193834  1.5607063 ]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 9.009339919430204e-06, Loss Weights: [0.7202311  0.71970403 1.5600647 ]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 13, Total Loss: 1.043823613144923e-05, Loss Weights: [0.7205553  0.72002804 1.5594167 ]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 14\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 9.162434253084939e-06, Loss Weights: [0.7208477 0.7203202 1.5588323]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.0030759767687414e-05, Loss Weights: [0.7211118  0.72058415 1.5583038 ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.620540938863996e-06, Loss Weights: [0.72135097 0.72082317 1.5578259 ]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.961535291338805e-06, Loss Weights: [0.72156787 0.7210399  1.5573925 ]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.578353112563491e-05, Loss Weights: [0.72176534 0.7212372  1.5569978 ]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 9.393704203830566e-06, Loss Weights: [0.7219456  0.72141725 1.5566372 ]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.132773705758154e-06, Loss Weights: [0.72211075 0.7215823  1.5563071 ]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.81730557011906e-06, Loss Weights: [0.7222625 0.7217339 1.5560035]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.1711042437527794e-06, Loss Weights: [0.7224027  0.72187406 1.5557234 ]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 9.23745483305538e-06, Loss Weights: [0.72253263 0.72200394 1.5554634 ]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.4972702047089115e-05, Loss Weights: [0.72265416 0.72212535 1.5552204 ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.7484024839359336e-06, Loss Weights: [0.7227683  0.72223943 1.5549922 ]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.28619897927274e-06, Loss Weights: [0.7228761  0.72234714 1.5547768 ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.760868695389945e-06, Loss Weights: [0.7229785 0.7224495 1.5545721]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.674900305370102e-06, Loss Weights: [0.72307634 0.7225473  1.5543764 ]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.317495116381906e-05, Loss Weights: [0.72317064 0.7226416  1.5541878 ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.769759577058721e-06, Loss Weights: [0.72326213 0.722733   1.554005  ]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.766994713165332e-06, Loss Weights: [0.7233513 0.7228221 1.5538266]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.585113391745836e-06, Loss Weights: [0.7234388  0.72290957 1.5536516 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.060349040926667e-05, Loss Weights: [0.7235253 0.722996  1.5534787]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.359291036351351e-05, Loss Weights: [0.72361135 0.723082   1.5533066 ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.4885181371937506e-05, Loss Weights: [0.7236977 0.7231684 1.553134 ]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.475004506180994e-06, Loss Weights: [0.7237847 0.7232553 1.55296  ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.0436121556267608e-05, Loss Weights: [0.72387266 0.72334325 1.5527842 ]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.78801893122727e-06, Loss Weights: [0.72396183 0.72343236 1.5526056 ]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.853449576738058e-06, Loss Weights: [0.72405255 0.723523   1.5524244 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.5779081523942295e-06, Loss Weights: [0.7241448 0.7236152 1.5522399]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.299384717247449e-06, Loss Weights: [0.7242389 0.7237092 1.5520518]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.335012469411595e-06, Loss Weights: [0.7243349 0.7238052 1.55186  ]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.937897069292376e-06, Loss Weights: [0.7244329  0.72390306 1.551664  ]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.1877072211063933e-05, Loss Weights: [0.7245332  0.72400326 1.5514634 ]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.35437299933983e-06, Loss Weights: [0.72463596 0.7241059  1.5512581 ]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.659475497552194e-06, Loss Weights: [0.7247412  0.72421104 1.5510478 ]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.305078154080547e-06, Loss Weights: [0.724849   0.72431874 1.5508322 ]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.20540026325034e-06, Loss Weights: [0.72495955 0.7244292  1.5506113 ]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.5183845789579209e-05, Loss Weights: [0.7250732  0.72454274 1.5503843 ]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.556004220532486e-06, Loss Weights: [0.72518986 0.7246593  1.5501509 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.1769829143304378e-05, Loss Weights: [0.72530985 0.72477925 1.5499109 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.4920043213351164e-05, Loss Weights: [0.72543347 0.72490275 1.5496635 ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.693742190895136e-06, Loss Weights: [0.7255608  0.72502995 1.5494095 ]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.0235345143883023e-05, Loss Weights: [0.72569156 0.72516066 1.5491477 ]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.067967428360134e-06, Loss Weights: [0.72582614 0.7252952  1.5488788 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.459495918737957e-06, Loss Weights: [0.7259643  0.72543323 1.5486026 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.0547613783273846e-05, Loss Weights: [0.72610617 0.725575   1.5483189 ]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.827166998846224e-06, Loss Weights: [0.72625166 0.7257204  1.548028  ]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 9.070812666323036e-06, Loss Weights: [0.72640085 0.7258695  1.5477297 ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.61671629131888e-06, Loss Weights: [0.72655356 0.72602206 1.5474243 ]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.0426518201711588e-05, Loss Weights: [0.72671   0.7261784 1.5471115]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.0192291483690497e-05, Loss Weights: [0.7268703 0.7263385 1.5467913]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.12722840034985e-06, Loss Weights: [0.72703415 0.72650224 1.5464635 ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.824693057045806e-06, Loss Weights: [0.7272018 0.7266698 1.5461285]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.3445293916447554e-05, Loss Weights: [0.7273733  0.72684115 1.5457857 ]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.052479643083643e-06, Loss Weights: [0.7275486 0.7270163 1.545435 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.919735369592672e-06, Loss Weights: [0.7277278 0.7271954 1.5450771]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.139948138501495e-06, Loss Weights: [0.7279106 0.7273781 1.5447116]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.625858754385263e-06, Loss Weights: [0.728097   0.72756433 1.5443385 ]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.784008630551398e-06, Loss Weights: [0.7282872 0.7277544 1.5439584]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.601193829032127e-06, Loss Weights: [0.72848105 0.72794807 1.5435709 ]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.167066996771609e-06, Loss Weights: [0.7286785 0.7281454 1.5431762]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.697679393459111e-06, Loss Weights: [0.7288795 0.7283462 1.5427742]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 9.095626410271507e-06, Loss Weights: [0.7290842  0.72855073 1.5423651 ]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.061436008370947e-06, Loss Weights: [0.7292924 0.7287588 1.541949 ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.852121027302928e-06, Loss Weights: [0.7295041  0.72897035 1.5415256 ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.657783837406896e-06, Loss Weights: [0.7297194 0.7291855 1.541095 ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 9.727429642225616e-06, Loss Weights: [0.72993845 0.7294044  1.5406573 ]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 9.469282304053195e-06, Loss Weights: [0.7301612 0.7296269 1.5402119]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.508501767006237e-06, Loss Weights: [0.7303876  0.72985315 1.5397593 ]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.446831321227364e-06, Loss Weights: [0.73061764 0.730083   1.5392995 ]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.009527846297715e-06, Loss Weights: [0.7308511 0.7303163 1.5388324]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 9.269173460779712e-06, Loss Weights: [0.7310883  0.73055327 1.5383582 ]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 5.890294232813176e-06, Loss Weights: [0.731329   0.73079383 1.5378771 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.0244117220281623e-05, Loss Weights: [0.73157334 0.731038   1.5373888 ]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.536486009485088e-06, Loss Weights: [0.73182124 0.7312857  1.5368932 ]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 9.212236363964621e-06, Loss Weights: [0.7320727 0.731537  1.5363904]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.723200724285562e-06, Loss Weights: [0.7323277  0.73179185 1.5358804 ]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.1792601071647368e-05, Loss Weights: [0.73258644 0.7320504  1.535363  ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.921183285157895e-06, Loss Weights: [0.73284894 0.7323127  1.5348383 ]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.3037277312832884e-05, Loss Weights: [0.73311526 0.73257875 1.534306  ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.056922640913399e-06, Loss Weights: [0.73338526 0.7328486  1.5337662 ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.782581633364316e-06, Loss Weights: [0.733659  0.7331221 1.5332189]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.672614628972951e-06, Loss Weights: [0.7339365 0.7333994 1.5326643]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.562213457073085e-06, Loss Weights: [0.7342175 0.7336802 1.5321023]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.869159162510186e-06, Loss Weights: [0.7345021  0.73396456 1.5315332 ]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.0951078365906142e-05, Loss Weights: [0.73479044 0.7342527  1.5309572 ]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.320239208434941e-06, Loss Weights: [0.73508215 0.7345442  1.5303736 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.189911684690742e-06, Loss Weights: [0.73537755 0.7348393  1.5297832 ]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.26588711788645e-06, Loss Weights: [0.7356764  0.73513794 1.5291857 ]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.696116088278359e-06, Loss Weights: [0.7359787 0.73544   1.5285813]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.590412107878365e-06, Loss Weights: [0.7362845  0.73574555 1.5279698 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.308909971470712e-06, Loss Weights: [0.7365937  0.73605454 1.5273517 ]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.927627055119956e-06, Loss Weights: [0.73690635 0.7363669  1.526727  ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.1377256669220515e-05, Loss Weights: [0.7372223  0.73668265 1.5260949 ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 1.2462696759030223e-05, Loss Weights: [0.7375421  0.73700213 1.5254556 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.027489457163028e-06, Loss Weights: [0.7378655 0.7373253 1.5248091]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 7.641570846317336e-06, Loss Weights: [0.7381925  0.73765206 1.5241554 ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 8.410413101955783e-06, Loss Weights: [0.7385231  0.73798245 1.5234945 ]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 9.747183867148124e-06, Loss Weights: [0.73885727 0.7383164  1.5228263 ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.6401908043189906e-06, Loss Weights: [0.7391949  0.73865384 1.522151  ]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.619485702685779e-06, Loss Weights: [0.73953617 0.73899484 1.5214689 ]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 14, Total Loss: 6.404559371731011e-06, Loss Weights: [0.7398807 0.7393391 1.5207801]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 15\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 9.728203622216824e-06, Loss Weights: [0.74019146 0.73964965 1.520159  ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.693293810007162e-06, Loss Weights: [0.740472   0.73993003 1.5195976 ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.609659067180473e-06, Loss Weights: [0.740726  0.7401838 1.5190899]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.328222636715509e-06, Loss Weights: [0.7409562 0.7404138 1.5186299]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.063392331474461e-06, Loss Weights: [0.74116516 0.74062264 1.5182121 ]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.4900394793075975e-06, Loss Weights: [0.7413555 0.7408128 1.5178317]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 5.973150564386742e-06, Loss Weights: [0.7415291 0.7409863 1.5174844]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.277928943949519e-06, Loss Weights: [0.74168813 0.74114525 1.5171665 ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.1895248109067325e-06, Loss Weights: [0.74183434 0.74129134 1.5168746 ]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.5788693720824085e-06, Loss Weights: [0.74196917 0.74142605 1.516605  ]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.817983714630827e-06, Loss Weights: [0.74209416 0.7415509  1.516355  ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.828020104876487e-06, Loss Weights: [0.7422106 0.7416673 1.5161222]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.8353983806446195e-06, Loss Weights: [0.74231964 0.7417762  1.5159041 ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.985420441196766e-06, Loss Weights: [0.74242234 0.74187887 1.5156987 ]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.847187928040512e-06, Loss Weights: [0.74251974 0.74197614 1.5155039 ]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.14855593489483e-06, Loss Weights: [0.7426127  0.74206907 1.5153182 ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 1.258813699678285e-05, Loss Weights: [0.74270225 0.74215853 1.5151393 ]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 1.3034483345109038e-05, Loss Weights: [0.74278927 0.74224544 1.5149653 ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.074570359895006e-06, Loss Weights: [0.7428744  0.74233043 1.5147951 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.598569365858566e-06, Loss Weights: [0.7429582  0.74241424 1.5146277 ]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.43419911689125e-06, Loss Weights: [0.74304116 0.74249715 1.5144618 ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.875353159965016e-06, Loss Weights: [0.74312377 0.7425797  1.5142965 ]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.302562153199688e-06, Loss Weights: [0.7432064 0.7426623 1.5141311]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 1.3107734957884531e-05, Loss Weights: [0.7432897 0.7427455 1.5139644]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.980070560937747e-06, Loss Weights: [0.7433741 0.7428298 1.5137961]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.648187420272734e-06, Loss Weights: [0.7434596  0.74291515 1.5136251 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.381452633126173e-06, Loss Weights: [0.74354655 0.74300206 1.5134515 ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.474964266089955e-06, Loss Weights: [0.74363506 0.7430905  1.5132747 ]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.854653747723205e-06, Loss Weights: [0.74372524 0.74318063 1.5130942 ]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.235778982954798e-06, Loss Weights: [0.7438173  0.74327266 1.51291   ]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.002431968634482e-06, Loss Weights: [0.74391145 0.7433667  1.5127219 ]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.840636615379481e-06, Loss Weights: [0.7440077 0.7434629 1.5125295]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.70953374740202e-06, Loss Weights: [0.74410623 0.7435614  1.5123324 ]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.377110250672558e-06, Loss Weights: [0.74420714 0.74366224 1.5121305 ]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.61144781083567e-06, Loss Weights: [0.7443107 0.7437657 1.5119236]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.633362318098079e-06, Loss Weights: [0.74441683 0.7438718  1.5117114 ]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 1.0306467629561666e-05, Loss Weights: [0.74452585 0.7439807  1.5114937 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.4686355472076684e-06, Loss Weights: [0.7446376  0.74409235 1.51127   ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.308380529342685e-06, Loss Weights: [0.7447523  0.74420696 1.5110407 ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.416255695919972e-06, Loss Weights: [0.74487007 0.7443247  1.5108054 ]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 9.783306268218439e-06, Loss Weights: [0.74499094 0.7444455  1.5105636 ]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.316867256828118e-06, Loss Weights: [0.745115  0.7445695 1.5103154]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.298839020426385e-06, Loss Weights: [0.7452423  0.74469674 1.5100608 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.258234290929977e-06, Loss Weights: [0.7453729  0.74482715 1.5097997 ]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.830115464457776e-06, Loss Weights: [0.7455068 0.7449609 1.5095322]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 9.043739737535361e-06, Loss Weights: [0.74564403 0.74509805 1.5092579 ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.2711651480640285e-06, Loss Weights: [0.7457845 0.7452385 1.5089768]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.431421520072035e-06, Loss Weights: [0.7459285  0.74538237 1.5086892 ]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 9.377954484079964e-06, Loss Weights: [0.7460759  0.74552965 1.5083945 ]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 1.2659807907766663e-05, Loss Weights: [0.74622715 0.7456807  1.5080922 ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.983557341300184e-06, Loss Weights: [0.746382   0.74583536 1.5077825 ]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.814217497070786e-06, Loss Weights: [0.74654055 0.74599385 1.5074656 ]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.267469416343374e-06, Loss Weights: [0.7467027  0.74615586 1.5071415 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.511318810633384e-06, Loss Weights: [0.7468685  0.74632156 1.5068102 ]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 1.0637971172400285e-05, Loss Weights: [0.74703795 0.74649084 1.5064712 ]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 1.069478730642004e-05, Loss Weights: [0.74721146 0.7466642  1.5061245 ]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.028213531157235e-06, Loss Weights: [0.7473887 0.7468413 1.50577  ]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.4765498538909014e-06, Loss Weights: [0.7475698 0.7470223 1.5054078]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.381434781767894e-06, Loss Weights: [0.7477547  0.74720705 1.5050383 ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 1.106426407204708e-05, Loss Weights: [0.74794346 0.7473957  1.5046606 ]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.499875325971516e-06, Loss Weights: [0.7481362 0.7475883 1.5042754]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.031344921415439e-06, Loss Weights: [0.74833274 0.7477846  1.5038826 ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.4267036325181834e-06, Loss Weights: [0.74853295 0.7479847  1.5034822 ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.293701062531909e-06, Loss Weights: [0.748737  0.7481885 1.5030745]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.411426511476748e-06, Loss Weights: [0.7489446 0.7483959 1.5026596]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.57505074236542e-06, Loss Weights: [0.7491558 0.748607  1.5022373]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 1.1630605513346381e-05, Loss Weights: [0.7493709  0.74882185 1.5018072 ]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 9.862111255642958e-06, Loss Weights: [0.74958986 0.74904066 1.5013694 ]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 9.740581845107954e-06, Loss Weights: [0.74981284 0.74926347 1.5009238 ]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.1566005317436066e-06, Loss Weights: [0.7500396  0.74949014 1.5004702 ]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.670061106386129e-06, Loss Weights: [0.75027037 0.74972075 1.5000088 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.679852504021255e-06, Loss Weights: [0.750505  0.7499552 1.4995397]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.689515198057052e-06, Loss Weights: [0.7507435 0.7501936 1.4990631]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 1.071131100616185e-05, Loss Weights: [0.750986  0.7504358 1.4985783]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 1.318036356678931e-05, Loss Weights: [0.75123256 0.75068223 1.498085  ]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.234995337057626e-06, Loss Weights: [0.75148344 0.7509329  1.4975839 ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 5.935064564255299e-06, Loss Weights: [0.7517381 0.7511873 1.4970746]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 9.416537977813277e-06, Loss Weights: [0.7519968 0.7514459 1.4965574]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.552207080152584e-06, Loss Weights: [0.7522595 0.7517084 1.4960322]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.446432962547988e-06, Loss Weights: [0.75252604 0.75197464 1.4954994 ]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 1.2695384612015914e-05, Loss Weights: [0.75279665 0.752245   1.4949584 ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.964256838022266e-06, Loss Weights: [0.7530712  0.75251937 1.4944093 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.348177976178704e-06, Loss Weights: [0.7533498 0.7527977 1.4938526]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.3281967161165085e-06, Loss Weights: [0.7536322 0.7530799 1.493288 ]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 1.0994582225976046e-05, Loss Weights: [0.7539184 0.753366  1.4927156]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.911738405004144e-06, Loss Weights: [0.7542087 0.753656  1.4921353]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.890751476224978e-06, Loss Weights: [0.754503  0.7539501 1.4915471]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.993806659418624e-06, Loss Weights: [0.75480115 0.754248   1.4909508 ]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 1.2313736988289747e-05, Loss Weights: [0.7551035 0.7545501 1.4903464]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.79433594289003e-06, Loss Weights: [0.75540984 0.7548561  1.4897338 ]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.444919108616887e-06, Loss Weights: [0.75572026 0.7551663  1.4891136 ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.623710305575514e-06, Loss Weights: [0.7560344 0.7554802 1.4884855]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.850457561493386e-06, Loss Weights: [0.75635237 0.755798   1.4878496 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 5.162336037756177e-06, Loss Weights: [0.75667405 0.7561195  1.4872065 ]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.022729732852895e-06, Loss Weights: [0.7569994  0.75644463 1.4865559 ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 7.7987842814764e-06, Loss Weights: [0.75732833 0.75677335 1.4858983 ]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 1.045598037308082e-05, Loss Weights: [0.7576611 0.7571059 1.4852331]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 6.488667622761568e-06, Loss Weights: [0.75799745 0.75744206 1.4845607 ]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 1.0120774277311284e-05, Loss Weights: [0.75833756 0.75778186 1.4838806 ]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 15, Total Loss: 8.266021723102313e-06, Loss Weights: [0.7586813 0.7581254 1.4831932]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 16\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.488591563742375e-06, Loss Weights: [0.7589913  0.75843525 1.4825735 ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.036838385625742e-06, Loss Weights: [0.75927114 0.7587149  1.482014  ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 9.405672244611196e-06, Loss Weights: [0.75952435 0.758968   1.4815077 ]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.787560323573416e-06, Loss Weights: [0.75975394 0.75919735 1.481049  ]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 8.909746611607261e-06, Loss Weights: [0.75996244 0.75940573 1.4806318 ]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 8.218361472245306e-06, Loss Weights: [0.7601525 0.7595957 1.4802517]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 1.513862662250176e-05, Loss Weights: [0.7603267 0.7597697 1.4799037]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.464300779247424e-06, Loss Weights: [0.76048684 0.75992966 1.4795836 ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.165005288494285e-06, Loss Weights: [0.7606346  0.76007736 1.4792881 ]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.591018402308691e-06, Loss Weights: [0.7607716 0.7602143 1.479014 ]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.080049726937432e-06, Loss Weights: [0.76089925 0.760342   1.4787587 ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 1.1870087291754317e-05, Loss Weights: [0.7610191 0.7604618 1.478519 ]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 1.0373150871600956e-05, Loss Weights: [0.7611324  0.76057506 1.4782926 ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.197349987109192e-06, Loss Weights: [0.76124007 0.7606827  1.4780773 ]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 9.271379894926213e-06, Loss Weights: [0.7613431 0.7607857 1.4778712]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.780316653021146e-06, Loss Weights: [0.7614425 0.760885  1.4776728]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 5.629988663713448e-06, Loss Weights: [0.7615385  0.76098096 1.4774804 ]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 8.087768947007135e-06, Loss Weights: [0.7616322  0.76107454 1.477293  ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 1.0380349522165488e-05, Loss Weights: [0.76172423 0.76116645 1.4771092 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.5034854489786085e-06, Loss Weights: [0.7618151  0.76125723 1.4769278 ]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.119084784790175e-06, Loss Weights: [0.7619052 0.7613473 1.4767478]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 9.430587851966266e-06, Loss Weights: [0.761995   0.76143706 1.476568  ]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.1132153607322834e-06, Loss Weights: [0.7620851  0.76152694 1.4763877 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 9.126859367825091e-06, Loss Weights: [0.7621758  0.76161766 1.4762067 ]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.792932592565194e-06, Loss Weights: [0.76226735 0.7617091  1.4760236 ]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 1.0604559975035954e-05, Loss Weights: [0.76236033 0.76180196 1.4758378 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 2.2182841348694637e-05, Loss Weights: [0.76245546 0.761897   1.4756474 ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.775232006679289e-06, Loss Weights: [0.762553  0.7619945 1.4754522]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 8.362540938833263e-06, Loss Weights: [0.76265323 0.7620946  1.4752519 ]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 1.0247609679936431e-05, Loss Weights: [0.7627564  0.76219773 1.4750462 ]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 8.682530278747436e-06, Loss Weights: [0.7628623  0.76230365 1.4748341 ]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.707692930125631e-06, Loss Weights: [0.7629714  0.76241267 1.4746158 ]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 5.869393135071732e-06, Loss Weights: [0.76308364 0.7625247  1.4743918 ]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 8.265540600405075e-06, Loss Weights: [0.76319885 0.7626399  1.4741611 ]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 1.479707225371385e-05, Loss Weights: [0.7633178  0.76275873 1.4739237 ]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 1.2383287867123727e-05, Loss Weights: [0.7634404 0.7628812 1.4736784]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.432373877236387e-06, Loss Weights: [0.7635668 0.7630075 1.4734256]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 8.491877451888286e-06, Loss Weights: [0.763697   0.76313764 1.4731652 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 8.071509000728838e-06, Loss Weights: [0.76383126 0.76327175 1.4728972 ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.7863488766306546e-06, Loss Weights: [0.7639691 0.7634095 1.4726212]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.932612905075075e-06, Loss Weights: [0.7641108 0.7635511 1.472338 ]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 1.012713346426608e-05, Loss Weights: [0.7642565 0.7636967 1.472047 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.627353286603466e-06, Loss Weights: [0.76440585 0.7638459  1.4717482 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.221062787721166e-06, Loss Weights: [0.76455915 0.7639991  1.4714419 ]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.2050288508762605e-06, Loss Weights: [0.7647162 0.7641561 1.471128 ]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.958573405630887e-06, Loss Weights: [0.76487696 0.76431674 1.4708064 ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.45353884465294e-06, Loss Weights: [0.7650416  0.76448125 1.4704773 ]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.306674094957998e-06, Loss Weights: [0.7652098  0.76464933 1.4701408 ]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.664327313250396e-06, Loss Weights: [0.76538175 0.7648212  1.469797  ]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 1.357050769001944e-05, Loss Weights: [0.7655577 0.764997  1.4694452]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.3508227867714595e-06, Loss Weights: [0.76573765 0.76517683 1.4690856 ]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.118248049664544e-06, Loss Weights: [0.7659215 0.7653606 1.4687182]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 8.13884980743751e-06, Loss Weights: [0.7661091 0.7655481 1.4683428]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 8.893618542060722e-06, Loss Weights: [0.7663007  0.76573956 1.4679595 ]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.463558176823426e-06, Loss Weights: [0.7664963  0.76593506 1.4675686 ]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 1.1375445865269285e-05, Loss Weights: [0.76669604 0.7661346  1.4671695 ]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.330200787691865e-06, Loss Weights: [0.7668997 0.7663381 1.4667622]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.679221314698225e-06, Loss Weights: [0.76710737 0.76654565 1.466347  ]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.086787834647112e-06, Loss Weights: [0.76731896 0.76675713 1.465924  ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.236870831344277e-06, Loss Weights: [0.7675344 0.7669724 1.4654934]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.75269939165446e-06, Loss Weights: [0.76775354 0.7671914  1.4650551 ]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 9.693311767478008e-06, Loss Weights: [0.7679765 0.7674142 1.4646091]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.843277671781834e-06, Loss Weights: [0.7682035  0.76764107 1.4641556 ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.482548426196445e-06, Loss Weights: [0.76843417 0.7678716  1.4636941 ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.917486072983593e-06, Loss Weights: [0.7686689  0.76810616 1.4632249 ]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.2177977017418016e-06, Loss Weights: [0.7689074 0.7683445 1.462748 ]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 8.243580850830767e-06, Loss Weights: [0.7691499 0.7685868 1.4622636]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.182309218478622e-06, Loss Weights: [0.76939607 0.7688328  1.4617712 ]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 1.2409612281771842e-05, Loss Weights: [0.7696464 0.7690829 1.4612709]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 5.141566361999139e-06, Loss Weights: [0.76990044 0.76933676 1.4607626 ]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.763930625515059e-06, Loss Weights: [0.7701586  0.76959467 1.4602468 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.637011210841592e-06, Loss Weights: [0.77042055 0.7698564  1.4597231 ]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.839678917458514e-06, Loss Weights: [0.77068627 0.77012193 1.4591918 ]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.047284725558711e-06, Loss Weights: [0.77095574 0.7703912  1.4586529 ]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.196590559033211e-06, Loss Weights: [0.771229   0.77066433 1.4581065 ]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.911526154202875e-06, Loss Weights: [0.7715061  0.77094114 1.4575527 ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.1981399994692765e-06, Loss Weights: [0.7717868  0.77122164 1.4569914 ]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 8.321692803292535e-06, Loss Weights: [0.77207124 0.77150583 1.4564228 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.236576609808253e-06, Loss Weights: [0.7723594 0.7717937 1.4558469]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 1.0997306162607856e-05, Loss Weights: [0.77265126 0.7720854  1.4552633 ]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.950860097276745e-06, Loss Weights: [0.772947  0.7723809 1.454672 ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 9.605451850802638e-06, Loss Weights: [0.77324665 0.7726803  1.4540732 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 9.249437425751239e-06, Loss Weights: [0.77355015 0.77298355 1.4534663 ]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 8.849337064020801e-06, Loss Weights: [0.7738576 0.7732909 1.4528515]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.379585895250784e-06, Loss Weights: [0.774169  0.7736021 1.4522289]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.634329110966064e-06, Loss Weights: [0.7744843 0.7739172 1.4515984]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.723780072410591e-06, Loss Weights: [0.77480346 0.7742362  1.4509604 ]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.99813733465271e-06, Loss Weights: [0.7751264 0.7745589 1.4503145]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 5.986283213132992e-06, Loss Weights: [0.7754532 0.7748854 1.4496613]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.953051070013316e-06, Loss Weights: [0.7757837  0.77521574 1.4490006 ]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 7.105513304850319e-06, Loss Weights: [0.77611774 0.77554953 1.4483325 ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 5.752287052018801e-06, Loss Weights: [0.7764555 0.7758871 1.4476575]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.849187229818199e-06, Loss Weights: [0.7767968 0.7762281 1.4469751]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.809785645600641e-06, Loss Weights: [0.7771416 0.7765726 1.4462857]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 8.164398423105013e-06, Loss Weights: [0.77748996 0.7769207  1.4455893 ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.363456577673787e-06, Loss Weights: [0.77784187 0.7772722  1.444886  ]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 9.05297292774776e-06, Loss Weights: [0.7781973  0.77762735 1.4441754 ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 6.481559466919862e-06, Loss Weights: [0.77855635 0.77798605 1.4434578 ]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 1.0072652003145777e-05, Loss Weights: [0.77891886 0.77834827 1.4427328 ]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 16, Total Loss: 8.504645848006476e-06, Loss Weights: [0.7792852 0.7787143 1.4420006]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 17\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 1.31709703055094e-05, Loss Weights: [0.7796157  0.77904457 1.4413399 ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.600911547138821e-06, Loss Weights: [0.7799144 0.779343  1.4407425]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.2862039814936e-06, Loss Weights: [0.78018486 0.77961326 1.4402016 ]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.608358944504289e-06, Loss Weights: [0.7804303 0.7798585 1.4397112]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 5.3953021961206105e-06, Loss Weights: [0.78065324 0.78008133 1.4392654 ]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.526468496304005e-06, Loss Weights: [0.7808564 0.7802844 1.4388593]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 8.820638868201058e-06, Loss Weights: [0.7810421 0.78047   1.438488 ]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 9.925975064106751e-06, Loss Weights: [0.78121257 0.78064036 1.4381471 ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 9.259127182303928e-06, Loss Weights: [0.78136986 0.7807976  1.4378326 ]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.709697572659934e-06, Loss Weights: [0.7815156 0.7809432 1.4375412]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.625652870046906e-06, Loss Weights: [0.7816513 0.7810788 1.43727  ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.828616278653499e-06, Loss Weights: [0.7817783 0.7812057 1.437016 ]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.426904630847275e-06, Loss Weights: [0.7818978  0.78132516 1.436777  ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.450682005583076e-06, Loss Weights: [0.7820111  0.78143835 1.4365507 ]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 5.77256514588953e-06, Loss Weights: [0.7821189 0.7815461 1.4363352]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.940315870451741e-06, Loss Weights: [0.7822221  0.78164923 1.4361286 ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 1.063234140019631e-05, Loss Weights: [0.7823218 0.7817489 1.4359291]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 1.1589188034122344e-05, Loss Weights: [0.7824191  0.78184605 1.4357349 ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.472654149547452e-06, Loss Weights: [0.7825143  0.78194106 1.4355445 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.851688340248074e-06, Loss Weights: [0.78260803 0.78203475 1.4353571 ]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 9.497164683125447e-06, Loss Weights: [0.78270096 0.7821276  1.4351712 ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.500636456825305e-06, Loss Weights: [0.7827936  0.78222024 1.4349862 ]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 8.163003258232493e-06, Loss Weights: [0.78288627 0.78231287 1.4348009 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.2400275712425355e-06, Loss Weights: [0.7829795 0.782406  1.4346147]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.744960955984425e-06, Loss Weights: [0.7830734 0.7824999 1.4344268]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 8.250046448665671e-06, Loss Weights: [0.78316855 0.7825949  1.4342366 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 5.97730968365795e-06, Loss Weights: [0.78326494 0.7826913  1.4340439 ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.2198008638224564e-06, Loss Weights: [0.7833629  0.78278923 1.4338479 ]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.407893579307711e-06, Loss Weights: [0.7834627 0.7828889 1.4336485]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 8.761533536016941e-06, Loss Weights: [0.78356445 0.7829906  1.433445  ]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.035965725459391e-06, Loss Weights: [0.7836684 0.7830945 1.4332373]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 8.02093927632086e-06, Loss Weights: [0.7837746  0.78320074 1.4330246 ]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.112651928764535e-06, Loss Weights: [0.78388333 0.78330946 1.4328072 ]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.713004950142931e-06, Loss Weights: [0.7839948 0.7834208 1.4325845]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.378340913215652e-06, Loss Weights: [0.7841089  0.78353477 1.4323564 ]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.034902409941424e-06, Loss Weights: [0.7842257  0.78365153 1.4321227 ]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.887629180913791e-06, Loss Weights: [0.7843454  0.78377116 1.4318831 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.552694230776979e-06, Loss Weights: [0.7844682  0.78389394 1.4316379 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.694469786656555e-06, Loss Weights: [0.78459394 0.7840197  1.4313864 ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.395595846697688e-06, Loss Weights: [0.7847228 0.7841486 1.4311285]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.609471711271908e-06, Loss Weights: [0.78485495 0.7842806  1.4308646 ]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 5.8208552218275145e-06, Loss Weights: [0.78499013 0.7844157  1.4305942 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.345264409901574e-06, Loss Weights: [0.78512853 0.784554   1.4303175 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 8.150008397933561e-06, Loss Weights: [0.7852702 0.7846955 1.4300343]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.253504918480758e-06, Loss Weights: [0.7854153  0.78484046 1.4297444 ]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.461398126906715e-06, Loss Weights: [0.7855636 0.7849887 1.4294474]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.9154043558228295e-06, Loss Weights: [0.78571546 0.7851405  1.4291439 ]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 1.0549335456744302e-05, Loss Weights: [0.78587097 0.7852959  1.428833  ]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.1967502915649675e-06, Loss Weights: [0.7860301  0.78545487 1.428515  ]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.016367362666642e-06, Loss Weights: [0.7861929 0.7856176 1.4281896]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.134097813832341e-06, Loss Weights: [0.7863592  0.78578377 1.4278569 ]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.611197932215873e-06, Loss Weights: [0.7865292  0.78595364 1.4275169 ]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 5.407744083640864e-06, Loss Weights: [0.7867029 0.7861272 1.42717  ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.434569058910711e-06, Loss Weights: [0.78688   0.7863041 1.4268159]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 1.745263216434978e-05, Loss Weights: [0.7870612 0.7864853 1.4264535]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.8546078182407655e-06, Loss Weights: [0.78724647 0.78667057 1.426083  ]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.107179499143967e-06, Loss Weights: [0.7874359 0.7868598 1.4257042]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.614637641177978e-06, Loss Weights: [0.78762937 0.7870531  1.4253176 ]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.72157648295979e-06, Loss Weights: [0.7878268  0.78725034 1.4249231 ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.3646328928589355e-06, Loss Weights: [0.7880281 0.7874515 1.4245205]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.466218110290356e-06, Loss Weights: [0.7882333  0.78765655 1.4241102 ]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.795199053362012e-06, Loss Weights: [0.7884424 0.7878655 1.423692 ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.574856797669781e-06, Loss Weights: [0.78865546 0.7880784  1.4232662 ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 4.867786174145294e-06, Loss Weights: [0.78887224 0.78829503 1.4228327 ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.720927897025831e-06, Loss Weights: [0.78909284 0.78851545 1.4223917 ]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.520670922327554e-06, Loss Weights: [0.78931725 0.7887398  1.4219432 ]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.177113846206339e-06, Loss Weights: [0.78954524 0.78896767 1.4214871 ]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 9.207324183080345e-06, Loss Weights: [0.7897773 0.7891995 1.4210234]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.440254648827249e-06, Loss Weights: [0.7900131 0.7894351 1.420552 ]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.626721642533084e-06, Loss Weights: [0.7902527 0.7896745 1.4200728]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.333986220852239e-06, Loss Weights: [0.7904961 0.7899178 1.4195862]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 8.056980732362717e-06, Loss Weights: [0.7907433 0.7901648 1.4190919]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 5.997133939672494e-06, Loss Weights: [0.7909943  0.79041564 1.41859   ]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.815091637690784e-06, Loss Weights: [0.79124904 0.7906703  1.4180807 ]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 9.100780516746454e-06, Loss Weights: [0.7915077 0.7909287 1.4175637]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.501617346861167e-06, Loss Weights: [0.7917701 0.791191  1.4170387]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 1.0498351912247017e-05, Loss Weights: [0.7920368 0.7914574 1.4165059]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.476720384147484e-06, Loss Weights: [0.7923074 0.7917278 1.415965 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.461484645114979e-06, Loss Weights: [0.7925819  0.79200214 1.415416  ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 1.3572373973147478e-05, Loss Weights: [0.7928608 0.7922808 1.4148585]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 5.684319603460608e-06, Loss Weights: [0.79314387 0.7925636  1.4142926 ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.732072845101357e-06, Loss Weights: [0.79343104 0.7928505  1.4137183 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 1.3083557860227302e-05, Loss Weights: [0.7937227  0.79314196 1.4131354 ]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.377824658760801e-06, Loss Weights: [0.7940186  0.79343766 1.4125434 ]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.967896752030356e-06, Loss Weights: [0.7943189  0.79373777 1.4119432 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.442015092034126e-06, Loss Weights: [0.7946235  0.79404205 1.4113344 ]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.320350505324313e-06, Loss Weights: [0.7949322 0.7943505 1.4107172]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.263109753490426e-06, Loss Weights: [0.79524493 0.79466295 1.4100919 ]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 8.075508958427235e-06, Loss Weights: [0.7955618 0.7949796 1.4094584]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 8.255349712271709e-06, Loss Weights: [0.7958828  0.79530036 1.4088168 ]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.062623353704112e-06, Loss Weights: [0.79620785 0.7956251  1.408167  ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.780088708386756e-06, Loss Weights: [0.79653704 0.795954   1.4075091 ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.494247711292701e-06, Loss Weights: [0.7968702 0.7962869 1.406843 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 8.25235474621877e-06, Loss Weights: [0.7972074 0.7966238 1.4061688]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 6.4096689129655715e-06, Loss Weights: [0.79754853 0.79696465 1.4054866 ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 1.2668304407270625e-05, Loss Weights: [0.797894  0.7973099 1.4047961]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.692413419135846e-06, Loss Weights: [0.79824364 0.7976593  1.404097  ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.980584086908493e-06, Loss Weights: [0.7985975  0.79801285 1.4033895 ]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 1.2714425793092232e-05, Loss Weights: [0.79895586 0.79837096 1.4026732 ]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 17, Total Loss: 7.76207434682874e-06, Loss Weights: [0.79931855 0.7987334  1.4019481 ]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 18\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.143908533180365e-06, Loss Weights: [0.79964554 0.7990601  1.4012942 ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.481326636276208e-06, Loss Weights: [0.79994094 0.79935527 1.4007038 ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.455766535713337e-06, Loss Weights: [0.8002081 0.7996222 1.4001697]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.221690910024336e-06, Loss Weights: [0.8004502 0.7998642 1.3996856]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.913552169862669e-06, Loss Weights: [0.80067015 0.8000839  1.3992457 ]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 8.36712024465669e-06, Loss Weights: [0.8008706  0.80028415 1.3988452 ]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.2959896897373255e-06, Loss Weights: [0.80105376 0.8004672  1.398479  ]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 8.226873433159199e-06, Loss Weights: [0.80122197 0.8006353  1.3981428 ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.237982572405599e-06, Loss Weights: [0.80137694 0.80079013 1.3978329 ]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 8.053754754655529e-06, Loss Weights: [0.80152047 0.8009336  1.3975459 ]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.527696314151399e-06, Loss Weights: [0.8016541 0.8010671 1.3972788]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 8.79176332091447e-06, Loss Weights: [0.8017793  0.80119216 1.3970286 ]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.291303179750685e-06, Loss Weights: [0.8018973  0.80130994 1.3967929 ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 5.629889983538305e-06, Loss Weights: [0.80200887 0.8014214  1.3965695 ]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 1.0484450285730418e-05, Loss Weights: [0.8021155 0.801528  1.3963567]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 9.632890396460425e-06, Loss Weights: [0.80221796 0.8016304  1.3961517 ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 8.406992492382415e-06, Loss Weights: [0.80231726 0.8017296  1.395953  ]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.188487870735116e-06, Loss Weights: [0.8024142 0.8018265 1.3957593]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 9.66806328506209e-06, Loss Weights: [0.8025094  0.80192167 1.395569  ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.781746717228089e-06, Loss Weights: [0.8026035 0.8020157 1.3953807]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.3936994340328965e-06, Loss Weights: [0.802697  0.8021091 1.3951937]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.528587502747541e-06, Loss Weights: [0.8027905 0.8022026 1.3950071]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 1.1453142178652342e-05, Loss Weights: [0.80288446 0.80229646 1.3948191 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.21906656306237e-06, Loss Weights: [0.80297923 0.80239123 1.3946295 ]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.609256499563344e-06, Loss Weights: [0.8030752  0.80248713 1.3944376 ]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.112869414209854e-06, Loss Weights: [0.80317265 0.8025845  1.3942429 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.390805876639206e-06, Loss Weights: [0.8032717 0.8026835 1.3940448]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 8.474070455122273e-06, Loss Weights: [0.80337274 0.80278444 1.3938427 ]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 8.968106158135924e-06, Loss Weights: [0.8034761 0.8028877 1.3936361]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 8.19423257780727e-06, Loss Weights: [0.80358195 0.8029934  1.3934245 ]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.1016598920105025e-06, Loss Weights: [0.80369043 0.8031018  1.3932078 ]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.840158104954753e-06, Loss Weights: [0.80380166 0.8032129  1.3929853 ]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.927947081043385e-06, Loss Weights: [0.80391586 0.8033271  1.392757  ]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.999244189704768e-06, Loss Weights: [0.80403316 0.8034444  1.3925226 ]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 1.4433233445743099e-05, Loss Weights: [0.80415404 0.80356526 1.3922808 ]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 1.081243135558907e-05, Loss Weights: [0.80427873 0.80368984 1.3920313 ]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.297005140571855e-06, Loss Weights: [0.80440736 0.80381835 1.3917742 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.232586995087331e-06, Loss Weights: [0.8045399  0.80395085 1.3915094 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 5.089966634841403e-06, Loss Weights: [0.8046762  0.80408704 1.3912369 ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 5.774234523414634e-06, Loss Weights: [0.80481625 0.804227   1.3909569 ]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 5.886658982490189e-06, Loss Weights: [0.8049601 0.8043707 1.3906695]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.2791154959995765e-06, Loss Weights: [0.8051075  0.80451804 1.3903747 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 9.552834853820968e-06, Loss Weights: [0.80525875 0.80466926 1.3900721 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.1123619161662646e-06, Loss Weights: [0.8054139  0.80482423 1.3897619 ]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.548786470579216e-06, Loss Weights: [0.805573   0.80498314 1.389444  ]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 1.0180061508435756e-05, Loss Weights: [0.80573606 0.80514604 1.3891178 ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.44517456041649e-06, Loss Weights: [0.8059033 0.8053131 1.3887837]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 1.2062516361766029e-05, Loss Weights: [0.8060748 0.8054844 1.3884407]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.125741947471397e-06, Loss Weights: [0.8062507 0.8056601 1.3880893]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.360797215165803e-06, Loss Weights: [0.80643064 0.8058399  1.3877294 ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.24565234122565e-06, Loss Weights: [0.8066149 0.806024  1.3873612]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.299581855273573e-06, Loss Weights: [0.8068032 0.8062122 1.3869846]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 1.0212148481514305e-05, Loss Weights: [0.80699587 0.8064047  1.3865994 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.259099675138714e-06, Loss Weights: [0.8071928 0.8066015 1.3862056]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.906593625899404e-06, Loss Weights: [0.807394  0.8068026 1.3858032]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.933647910045693e-06, Loss Weights: [0.80759954 0.8070079  1.3853927 ]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.656079105800018e-06, Loss Weights: [0.80780923 0.8072174  1.3849734 ]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 1.000160955300089e-05, Loss Weights: [0.8080232 0.8074313 1.3845453]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 1.0901206223934423e-05, Loss Weights: [0.80824196 0.8076498  1.3841083 ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 8.518030881532468e-06, Loss Weights: [0.8084652 0.8078729 1.383662 ]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 9.009530913317576e-06, Loss Weights: [0.80869305 0.8081006  1.3832065 ]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.335857389989542e-06, Loss Weights: [0.8089255  0.80833286 1.3827417 ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.6390293795848265e-06, Loss Weights: [0.8091624 0.8085696 1.3822678]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.718741587974364e-06, Loss Weights: [0.8094039  0.80881095 1.3817852 ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 5.799288373964373e-06, Loss Weights: [0.80964965 0.8090565  1.3812938 ]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 8.791626896709204e-06, Loss Weights: [0.8098998 0.8093065 1.3807937]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 8.430583875451703e-06, Loss Weights: [0.8101543 0.8095609 1.3802845]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 2.060524457192514e-05, Loss Weights: [0.8104142  0.80982053 1.3797653 ]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.432496775232721e-06, Loss Weights: [0.81067896 0.8100852  1.379236  ]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.689389465464046e-06, Loss Weights: [0.8109486 0.8103546 1.3786969]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.439171102101682e-06, Loss Weights: [0.81122303 0.8106288  1.3781483 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.30675731372321e-06, Loss Weights: [0.811502  0.8109076 1.3775904]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 8.635725862404797e-06, Loss Weights: [0.8117857 0.811191  1.3770231]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.95688504492864e-06, Loss Weights: [0.81207407 0.8114792  1.3764467 ]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 1.0118706995854154e-05, Loss Weights: [0.8123671 0.811772  1.3758608]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.791686246288009e-06, Loss Weights: [0.81266475 0.81206936 1.3752658 ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.334872978186468e-06, Loss Weights: [0.8129668  0.81237125 1.3746618 ]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 5.651411811413709e-06, Loss Weights: [0.8132733 0.8126775 1.374049 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.2120302573021036e-06, Loss Weights: [0.8135842  0.81298816 1.3734279 ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.692506758554373e-06, Loss Weights: [0.81389904 0.8133028  1.3727978 ]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.7557211878011e-06, Loss Weights: [0.81421834 0.8136218  1.37216   ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.438740001613041e-06, Loss Weights: [0.81454164 0.8139448  1.3715136 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.090086000971496e-06, Loss Weights: [0.8148689 0.8142719 1.3708589]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.471315711882198e-06, Loss Weights: [0.81520045 0.8146032  1.3701962 ]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.1809014368918724e-06, Loss Weights: [0.815536  0.8149386 1.3695254]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 8.038132364163175e-06, Loss Weights: [0.81587565 0.815278   1.3688464 ]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 5.7972397371486295e-06, Loss Weights: [0.8162192 0.8156213 1.3681593]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.571321475552395e-06, Loss Weights: [0.8165669  0.81596863 1.3674643 ]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.609997399209533e-06, Loss Weights: [0.8169185  0.81632006 1.3667614 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.655180525034666e-06, Loss Weights: [0.817274  0.8166753 1.3660505]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 5.879031505173771e-06, Loss Weights: [0.8176336  0.81703466 1.3653319 ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.857995115045924e-06, Loss Weights: [0.81799704 0.81739783 1.3646052 ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.183990080899093e-06, Loss Weights: [0.8183644  0.81776494 1.3638706 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 5.859171324118506e-06, Loss Weights: [0.8187356  0.81813586 1.3631285 ]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.019036729616346e-06, Loss Weights: [0.81911063 0.81851053 1.3623788 ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 9.360216608911287e-06, Loss Weights: [0.8194895  0.81888914 1.3616211 ]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.033536465110956e-06, Loss Weights: [0.81987244 0.8192718  1.3608558 ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 7.486002687073778e-06, Loss Weights: [0.8202591 0.8196582 1.3600826]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 6.373540600179695e-06, Loss Weights: [0.8206496 0.8200486 1.3593017]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 18, Total Loss: 9.297455108026043e-06, Loss Weights: [0.8210442  0.82044286 1.3585129 ]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 19\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 1.1467859621916432e-05, Loss Weights: [0.82140017 0.82079864 1.3578012 ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 1.0422847481095232e-05, Loss Weights: [0.8217221 0.8211204 1.3571575]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.000682671787217e-06, Loss Weights: [0.82201385 0.82141197 1.3565744 ]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.855101102904882e-06, Loss Weights: [0.8222786 0.8216766 1.3560448]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.841705271654064e-06, Loss Weights: [0.82251966 0.82191753 1.3555628 ]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.06873743183678e-06, Loss Weights: [0.8227397 0.8221375 1.3551228]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 5.748667717853095e-06, Loss Weights: [0.8229412 0.8223387 1.3547199]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.14765849604737e-06, Loss Weights: [0.8231263 0.8225237 1.3543499]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 1.0576092790870462e-05, Loss Weights: [0.8232974  0.82269466 1.3540082 ]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 8.76701142260572e-06, Loss Weights: [0.82345605 0.8228532  1.3536907 ]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 1.1673206245177425e-05, Loss Weights: [0.82360435 0.8230014  1.3533942 ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.12803160038311e-06, Loss Weights: [0.82374376 0.82314074 1.3531156 ]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 9.79763990471838e-06, Loss Weights: [0.82387567 0.82327247 1.352852  ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 1.0095448487845715e-05, Loss Weights: [0.8240013 0.823398  1.3526006]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 8.966510904429015e-06, Loss Weights: [0.82412195 0.8235185  1.3523593 ]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 1.273764246434439e-05, Loss Weights: [0.8242389 0.8236354 1.3521256]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 8.842289389576763e-06, Loss Weights: [0.824353  0.8237494 1.3518978]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.594869202875998e-06, Loss Weights: [0.82446474 0.8238611  1.3516741 ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 2.2497375539387576e-05, Loss Weights: [0.82457596 0.8239723  1.3514518 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.3345451053464785e-06, Loss Weights: [0.824687  0.8240832 1.3512298]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 5.971556674921885e-06, Loss Weights: [0.8247981 0.8241943 1.3510075]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.995445801294409e-06, Loss Weights: [0.82491   0.824306  1.3507841]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.13991994416574e-06, Loss Weights: [0.8250227 0.8244186 1.3505588]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 1.0666093658073805e-05, Loss Weights: [0.8251369  0.82453275 1.3503305 ]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 8.626527232991066e-06, Loss Weights: [0.82525295 0.8246486  1.3500984 ]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.781965905451216e-06, Loss Weights: [0.82537115 0.82476676 1.3498622 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 1.1094439287262503e-05, Loss Weights: [0.82549185 0.8248874  1.3496206 ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 8.62338947626995e-06, Loss Weights: [0.8256155 0.8250109 1.3493733]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 5.727894404117251e-06, Loss Weights: [0.8257422  0.82513744 1.3491206 ]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 5.8097243709198665e-06, Loss Weights: [0.82587165 0.82526684 1.3488617 ]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 8.466141480312217e-06, Loss Weights: [0.82600427 0.8253993  1.3485965 ]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 5.9853773564100266e-06, Loss Weights: [0.82614005 0.82553494 1.3483248 ]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.523176580230938e-06, Loss Weights: [0.8262793  0.82567406 1.3480468 ]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.8509589254972525e-06, Loss Weights: [0.82642174 0.8258164  1.3477619 ]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 9.459823559154756e-06, Loss Weights: [0.8265679 0.8259624 1.3474698]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.348299732257146e-06, Loss Weights: [0.8267175 0.826112  1.3471702]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.927387741801795e-06, Loss Weights: [0.82687116 0.82626545 1.3468633 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 8.423493454756681e-06, Loss Weights: [0.82702863 0.8264228  1.3465484 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.647517122677527e-06, Loss Weights: [0.8271902  0.82658434 1.3462257 ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 5.751282060373342e-06, Loss Weights: [0.8273556 0.8267496 1.3458948]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 1.11681029011379e-05, Loss Weights: [0.82752526 0.82691914 1.3455557 ]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.2181142058980186e-06, Loss Weights: [0.8276992  0.82709295 1.3452082 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 9.511128155281767e-06, Loss Weights: [0.8278774  0.82727104 1.3448517 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 9.365478035761043e-06, Loss Weights: [0.82806015 0.82745373 1.3444862 ]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.449869488278637e-06, Loss Weights: [0.82824737 0.82764083 1.3441119 ]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 8.942725798988249e-06, Loss Weights: [0.8284391 0.8278325 1.3437285]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.1037343332136516e-06, Loss Weights: [0.8286354 0.8280287 1.3433361]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.729702818120131e-06, Loss Weights: [0.8288362 0.8282293 1.3429345]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.8603071667894255e-06, Loss Weights: [0.8290415  0.82843447 1.342524  ]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 1.501005590398563e-05, Loss Weights: [0.82925165 0.8286445  1.342104  ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 8.576443178753834e-06, Loss Weights: [0.8294667  0.82885945 1.3416737 ]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.481763077521464e-06, Loss Weights: [0.8296868 0.8290794 1.341234 ]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 1.2697370038949884e-05, Loss Weights: [0.82991207 0.82930446 1.3407836 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 8.792282642389182e-06, Loss Weights: [0.8301424  0.82953453 1.340323  ]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 8.536354471289087e-06, Loss Weights: [0.83037794 0.82976997 1.3398521 ]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.923924502189038e-06, Loss Weights: [0.8306186 0.8300105 1.339371 ]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.2112853811413515e-06, Loss Weights: [0.8308642  0.83025587 1.33888   ]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 9.449152457818855e-06, Loss Weights: [0.8311148 0.8305063 1.3383789]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 8.324253030878026e-06, Loss Weights: [0.8313705 0.8307618 1.3378677]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.526011020469014e-06, Loss Weights: [0.83163095 0.83102214 1.3373468 ]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.702598850301001e-06, Loss Weights: [0.8318964 0.8312875 1.3368162]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.790446943545248e-06, Loss Weights: [0.8321668  0.83155763 1.3362758 ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 1.2204986887809355e-05, Loss Weights: [0.83244216 0.83183277 1.335725  ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.14100224286085e-06, Loss Weights: [0.83272266 0.832113   1.3351641 ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.896753347973572e-06, Loss Weights: [0.83300817 0.83239836 1.3345937 ]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.206307600426953e-06, Loss Weights: [0.83329844 0.8326884  1.3340131 ]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 8.776746653893497e-06, Loss Weights: [0.83359385 0.8329835  1.3334229 ]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.021295575919794e-06, Loss Weights: [0.8338939 0.8332833 1.3328228]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.9986513153708074e-06, Loss Weights: [0.8341987 0.8335879 1.3322135]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.2566613198432606e-06, Loss Weights: [0.8345082 0.8338971 1.3315947]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.6293846430198755e-06, Loss Weights: [0.8348223 0.834211  1.3309667]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.294145805441076e-06, Loss Weights: [0.835141   0.83452946 1.3303297 ]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 9.647428669268265e-06, Loss Weights: [0.8354643  0.83485246 1.3296833 ]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 5.939133643551031e-06, Loss Weights: [0.83579206 0.83518    1.3290279 ]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 5.922299351368565e-06, Loss Weights: [0.8361244  0.83551204 1.3283637 ]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.037749244569568e-06, Loss Weights: [0.83646095 0.83584833 1.3276905 ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.057332029740792e-06, Loss Weights: [0.8368019  0.83618903 1.3270091 ]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 4.4544890442921314e-06, Loss Weights: [0.8371469  0.83653367 1.3263192 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.2877456912247e-06, Loss Weights: [0.83749604 0.8368826  1.3256216 ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.79583933763206e-06, Loss Weights: [0.83784914 0.83723545 1.3249154 ]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 1.2659333151532337e-05, Loss Weights: [0.83820677 0.83759284 1.3242004 ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.725538125669118e-06, Loss Weights: [0.83856887 0.83795464 1.3234764 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 5.990215413476108e-06, Loss Weights: [0.83893526 0.83832073 1.3227437 ]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 5.970904567220714e-06, Loss Weights: [0.8393061  0.83869135 1.3220026 ]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 1.0074006240756717e-05, Loss Weights: [0.83968127 0.83906627 1.3212526 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 8.6294685388566e-06, Loss Weights: [0.84006095 0.8394457  1.3204935 ]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 5.517913905350724e-06, Loss Weights: [0.840445  0.8398295 1.3197258]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 4.902109139948152e-06, Loss Weights: [0.8408332 0.8402175 1.3189495]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 1.1711202205333393e-05, Loss Weights: [0.84122586 0.84060985 1.3181642 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.597455922019435e-06, Loss Weights: [0.841623   0.84100676 1.3173703 ]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.707536497036926e-06, Loss Weights: [0.84202456 0.841408   1.3165674 ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 5.11131565872347e-06, Loss Weights: [0.84243035 0.84181356 1.3157561 ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 8.290394362120423e-06, Loss Weights: [0.84284043 0.8422234  1.3149363 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.194757017714437e-06, Loss Weights: [0.8432547 0.8426374 1.3141079]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 4.759555849886965e-06, Loss Weights: [0.8436731 0.8430555 1.3132713]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 1.5148470083659049e-05, Loss Weights: [0.8440962 0.8434783 1.3124256]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 7.791230927978177e-06, Loss Weights: [0.8445237  0.84390557 1.3115706 ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.619622581638396e-06, Loss Weights: [0.84495574 0.84433734 1.310707  ]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 6.069784831197467e-06, Loss Weights: [0.84539205 0.84477335 1.3098345 ]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 19, Total Loss: 5.94816674492904e-06, Loss Weights: [0.84583265 0.84521365 1.3089536 ]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 20\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.749824933649506e-06, Loss Weights: [0.8462299 0.8456106 1.3081596]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 9.25405493035214e-06, Loss Weights: [0.84658873 0.8459692  1.3074422 ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.912432127137436e-06, Loss Weights: [0.84691334 0.84629357 1.3067931 ]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.659368864347925e-06, Loss Weights: [0.8472077  0.84658766 1.3062048 ]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 5.483686891238904e-06, Loss Weights: [0.8474749 0.8468547 1.3056704]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.023482001182856e-06, Loss Weights: [0.8477181  0.84709775 1.3051841 ]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.015807568677701e-06, Loss Weights: [0.8479401 0.8473196 1.3047401]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.2293097471410874e-06, Loss Weights: [0.8481436  0.84752285 1.3043336 ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 4.54508244729368e-06, Loss Weights: [0.8483303 0.8477095 1.3039601]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.5640097091090865e-06, Loss Weights: [0.84850264 0.8478817  1.3036157 ]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.179316187626682e-06, Loss Weights: [0.8486622 0.8480412 1.3032966]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 5.577639512921451e-06, Loss Weights: [0.8488107 0.8481896 1.3029997]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.115297310316237e-06, Loss Weights: [0.84894955 0.8483285  1.3027221 ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.597656010853825e-06, Loss Weights: [0.8490802 0.848459  1.3024609]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 9.516807040199637e-06, Loss Weights: [0.849204   0.84858274 1.3022134 ]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 5.733118996431585e-06, Loss Weights: [0.849322   0.84870064 1.3019774 ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.1564923018740956e-06, Loss Weights: [0.8494353  0.84881383 1.301751  ]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.670572813367471e-06, Loss Weights: [0.84954476 0.8489232  1.3015321 ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.506268502766034e-06, Loss Weights: [0.8496512  0.84902954 1.3013194 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.8369199652806856e-06, Loss Weights: [0.8497554 0.8491336 1.3011109]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.30930662737228e-06, Loss Weights: [0.8498581 0.8492362 1.300906 ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.069719686114695e-06, Loss Weights: [0.8499597 0.8493377 1.3007028]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.548222245328361e-06, Loss Weights: [0.8500607  0.84943867 1.3005006 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.023943908279762e-06, Loss Weights: [0.8501618  0.84953964 1.3002986 ]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.87887165643042e-06, Loss Weights: [0.8502633 0.849641  1.3000954]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 5.510094069904881e-06, Loss Weights: [0.85036564 0.8497433  1.2998909 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.678027941437904e-06, Loss Weights: [0.8504693  0.84984684 1.2996838 ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 9.699791007733438e-06, Loss Weights: [0.8505745 0.849952  1.2994734]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.100088623701595e-06, Loss Weights: [0.8506818  0.85005915 1.2992591 ]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.8449871832854114e-06, Loss Weights: [0.85079134 0.8501686  1.2990403 ]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.8371045927051455e-06, Loss Weights: [0.85090315 0.8502804  1.2988167 ]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.397948709491175e-06, Loss Weights: [0.8510176 0.8503947 1.2985877]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 8.102683750621509e-06, Loss Weights: [0.8511349 0.850512  1.2983531]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 4.775367870024638e-06, Loss Weights: [0.85125506 0.8506322  1.2981128 ]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 5.613975645246683e-06, Loss Weights: [0.8513783  0.85075533 1.2978663 ]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.220071554707829e-06, Loss Weights: [0.8515046 0.8508816 1.2976139]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 1.0339565960748587e-05, Loss Weights: [0.85163426 0.85101116 1.2973545 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.766741873638239e-06, Loss Weights: [0.85176766 0.85114443 1.2970881 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 5.285981842462206e-06, Loss Weights: [0.85190445 0.8512811  1.2968146 ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.717406333540566e-06, Loss Weights: [0.852045  0.8514215 1.2965336]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 8.718674507690594e-06, Loss Weights: [0.8521894 0.8515658 1.2962449]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.600186679861508e-06, Loss Weights: [0.85233784 0.851714   1.2959483 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.205633210105589e-06, Loss Weights: [0.8524902 0.8518662 1.2956436]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 1.7809352357289754e-05, Loss Weights: [0.85264724 0.8520232  1.2953293 ]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.856464096927084e-06, Loss Weights: [0.8528092 0.852185  1.295006 ]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.400030426651938e-06, Loss Weights: [0.8529756 0.8523513 1.294673 ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.40449707134394e-06, Loss Weights: [0.85314685 0.85252243 1.2943308 ]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 8.33738249639282e-06, Loss Weights: [0.8533228 0.8526982 1.2939789]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 9.373085049446672e-06, Loss Weights: [0.8535037 0.8528789 1.2936175]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 5.7796401051746216e-06, Loss Weights: [0.8536892  0.85306424 1.2932464 ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.394852334778989e-06, Loss Weights: [0.8538796  0.85325444 1.292866  ]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 8.481662007397972e-06, Loss Weights: [0.8540746 0.8534494 1.2924762]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.387056939478498e-06, Loss Weights: [0.8542744 0.853649  1.2920766]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 9.112041880143806e-06, Loss Weights: [0.8544792 0.8538537 1.2916672]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 5.883781796001131e-06, Loss Weights: [0.85468864 0.85406303 1.2912481 ]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.7856963141821325e-06, Loss Weights: [0.8549031 0.8542773 1.2908198]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.2243989304988645e-06, Loss Weights: [0.855122  0.8544961 1.2903818]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 5.868917014595354e-06, Loss Weights: [0.8553456  0.85471964 1.2899348 ]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.406455668184208e-06, Loss Weights: [0.8555738 0.8549477 1.2894787]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 1.0390667739557102e-05, Loss Weights: [0.8558066 0.8551804 1.2890129]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 5.9003614296671e-06, Loss Weights: [0.8560443  0.85541785 1.288538  ]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.8856488724122755e-06, Loss Weights: [0.8562865 0.8556599 1.2880535]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.485779977083439e-06, Loss Weights: [0.8565334 0.8559066 1.28756  ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.197821560112061e-06, Loss Weights: [0.85678494 0.856158   1.2870572 ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 5.023366611567326e-06, Loss Weights: [0.857041   0.85641384 1.2865453 ]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.045151167199947e-06, Loss Weights: [0.8573014 0.8566741 1.2860245]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.294873401202494e-06, Loss Weights: [0.85756624 0.8569387  1.2854948 ]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 1.0060940439871047e-05, Loss Weights: [0.85783577 0.8572081  1.2849561 ]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.81481242281734e-06, Loss Weights: [0.85810983 0.85748196 1.2844081 ]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.813830961822532e-06, Loss Weights: [0.8583886  0.85776055 1.2838508 ]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.775492693122942e-06, Loss Weights: [0.8586719 0.8580437 1.2832843]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.058747996779857e-06, Loss Weights: [0.8589599  0.85833144 1.2827086 ]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.572287020389922e-06, Loss Weights: [0.85925245 0.85862374 1.2821238 ]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.142502909118775e-06, Loss Weights: [0.8595495 0.8589206 1.2815297]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 1.9046463421545923e-05, Loss Weights: [0.8598521  0.85922295 1.280925  ]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 4.51360529041267e-06, Loss Weights: [0.86015964 0.8595303  1.28031   ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.387135610770201e-06, Loss Weights: [0.8604723 0.8598427 1.279685 ]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.047651822882472e-06, Loss Weights: [0.8607899 0.86016   1.2790499]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 5.802705345558934e-06, Loss Weights: [0.86111236 0.8604822  1.2784053 ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 9.860113095783163e-06, Loss Weights: [0.8614398 0.8608094 1.2777507]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 8.202802746382076e-06, Loss Weights: [0.8617723 0.8611416 1.277086 ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 5.564078946918016e-06, Loss Weights: [0.86210966 0.8614787  1.2764117 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.249758255056804e-06, Loss Weights: [0.8624518 0.8618206 1.2757277]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 9.58133205131162e-06, Loss Weights: [0.86279887 0.86216736 1.2750338 ]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 5.863633759872755e-06, Loss Weights: [0.8631508 0.862519  1.2743303]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.225041488505667e-06, Loss Weights: [0.8635074 0.8628754 1.273617 ]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 9.79751166596543e-06, Loss Weights: [0.86386895 0.86323667 1.2728943 ]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.999361175985541e-06, Loss Weights: [0.8642354 0.8636028 1.2721618]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.356845915433951e-06, Loss Weights: [0.8646065 0.8639737 1.2714196]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 9.270694135921076e-06, Loss Weights: [0.8649826  0.86434954 1.270668  ]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 1.0282612493028864e-05, Loss Weights: [0.8653636  0.86473024 1.269906  ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 8.25171809992753e-06, Loss Weights: [0.8657497 0.8651161 1.269134 ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.735414444847265e-06, Loss Weights: [0.86614084 0.8655069  1.2683522 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 7.298242962860968e-06, Loss Weights: [0.86653686 0.86590266 1.2675606 ]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 5.759927717008395e-06, Loss Weights: [0.86693764 0.8663032  1.2667592 ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.439095614041435e-06, Loss Weights: [0.8673432  0.86670846 1.2659484 ]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.2103204072627705e-06, Loss Weights: [0.86775327 0.8671183  1.2651284 ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 5.428028543974506e-06, Loss Weights: [0.8681679 0.8675326 1.2642994]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.664171905867988e-06, Loss Weights: [0.8685869 0.8679513 1.2634616]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 20, Total Loss: 6.468770152423531e-06, Loss Weights: [0.86901045 0.86837447 1.2626151 ]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 21\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.261642622324871e-06, Loss Weights: [0.8693923  0.86875594 1.2618518 ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.348230155912461e-06, Loss Weights: [0.8697372  0.86910063 1.2611623 ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 8.77698403201066e-06, Loss Weights: [0.8700494  0.86941254 1.260538  ]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 1.0680032573873177e-05, Loss Weights: [0.87033284 0.8696958  1.2599711 ]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 1.0603687769616954e-05, Loss Weights: [0.8705912  0.86995393 1.2594547 ]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 1.8286515114596114e-05, Loss Weights: [0.87082815 0.8701907  1.2589813 ]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.90273873260594e-06, Loss Weights: [0.87104607 0.8704085  1.2585456 ]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.9091480579809286e-06, Loss Weights: [0.8712473 0.8706095 1.258143 ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.2186671786766965e-06, Loss Weights: [0.8714342 0.8707963 1.2577696]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.426520940294722e-06, Loss Weights: [0.8716083 0.8709703 1.2574213]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 8.885103852662724e-06, Loss Weights: [0.87177175 0.8711337  1.2570947 ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.498030986927915e-06, Loss Weights: [0.8719257 0.8712875 1.2567868]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.305030638031894e-06, Loss Weights: [0.87207174 0.8714334  1.2564949 ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.320145191944903e-06, Loss Weights: [0.8722109 0.8715725 1.2562168]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.507204150489997e-06, Loss Weights: [0.87234426 0.87170565 1.2559501 ]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.308857336989604e-06, Loss Weights: [0.87247276 0.87183404 1.2556931 ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.169078915263526e-06, Loss Weights: [0.87259746 0.8719586  1.2554438 ]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 1.4698344784846995e-05, Loss Weights: [0.8727195  0.87208056 1.2551997 ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.790810741425958e-06, Loss Weights: [0.87284   0.8722009 1.2549592]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.241057806415483e-06, Loss Weights: [0.8729591  0.87231994 1.254721  ]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.2035268203762826e-06, Loss Weights: [0.87307763 0.8724384  1.254484  ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.457294941559667e-06, Loss Weights: [0.873196  0.8725567 1.2542472]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.785637767985463e-06, Loss Weights: [0.87331486 0.8726754  1.2540096 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.626174697681563e-06, Loss Weights: [0.87343436 0.87279487 1.2537707 ]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.694127594324527e-06, Loss Weights: [0.8735549  0.87291527 1.2535298 ]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.056943675503135e-06, Loss Weights: [0.8736768  0.87303704 1.2532861 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.228347501746612e-06, Loss Weights: [0.8738002 0.8731604 1.2530392]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.497516212926712e-06, Loss Weights: [0.87392557 0.87328565 1.2527888 ]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 9.071894965018146e-06, Loss Weights: [0.87405306 0.8734131  1.2525337 ]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 9.489715921517927e-06, Loss Weights: [0.8741834 0.8735434 1.2522732]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.602748387900647e-06, Loss Weights: [0.8743166 0.8736764 1.252007 ]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.261706857912941e-06, Loss Weights: [0.8744526 0.8738124 1.251735 ]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.0739394029951654e-06, Loss Weights: [0.8745917  0.87395144 1.2514567 ]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.6090379985107575e-06, Loss Weights: [0.87473404 0.8740938  1.2511722 ]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.901067874627188e-06, Loss Weights: [0.87487984 0.8742394  1.2508808 ]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.213967142481124e-06, Loss Weights: [0.87502897 0.87438834 1.2505827 ]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.86958207754651e-06, Loss Weights: [0.87518173 0.8745409  1.2502773 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 4.7555604396620765e-06, Loss Weights: [0.8753381 0.8746972 1.2499647]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.86377234160318e-06, Loss Weights: [0.8754982  0.87485707 1.2496448 ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.899259460624307e-06, Loss Weights: [0.875662  0.8750208 1.249317 ]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.001052497595083e-06, Loss Weights: [0.87582976 0.87518847 1.2489818 ]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.770703632559162e-06, Loss Weights: [0.8760014 0.87536   1.2486385]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.875752776773879e-06, Loss Weights: [0.8761772 0.8755356 1.2482873]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 4.248663117323304e-06, Loss Weights: [0.8763567 0.875715  1.2479281]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 8.638812687422615e-06, Loss Weights: [0.8765404 0.8758987 1.2475609]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.391457529593026e-06, Loss Weights: [0.8767284  0.87608653 1.2471852 ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.592269867018331e-06, Loss Weights: [0.8769207  0.87627864 1.2468008 ]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.376320015988313e-06, Loss Weights: [0.8771173 0.8764751 1.2464076]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 8.590834113419987e-06, Loss Weights: [0.8773185 0.8766761 1.2460057]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.099133315728977e-06, Loss Weights: [0.877524  0.8768815 1.2455945]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.317060069704894e-06, Loss Weights: [0.8777341  0.87709147 1.2451746 ]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 1.1590458598220721e-05, Loss Weights: [0.87794906 0.8773062  1.2447449 ]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 1.1539043953234795e-05, Loss Weights: [0.87816906 0.87752604 1.2443049 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.471686330973171e-06, Loss Weights: [0.8783943 0.8777511 1.2438546]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.019581633154303e-06, Loss Weights: [0.87862456 0.8779812  1.2433943 ]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.558463271881919e-06, Loss Weights: [0.87885976 0.87821627 1.242924  ]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.73261092742905e-06, Loss Weights: [0.8790999 0.8784562 1.2424439]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.920965799712576e-06, Loss Weights: [0.87934494 0.8787011  1.241954  ]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.036214927007677e-06, Loss Weights: [0.8795949  0.87895083 1.2414541 ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.882680397917284e-06, Loss Weights: [0.8798498  0.87920547 1.2409449 ]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 4.3622662815323565e-06, Loss Weights: [0.8801092 0.8794647 1.2404261]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.289979864959605e-06, Loss Weights: [0.88037336 0.8797286  1.2398982 ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.020769771770574e-06, Loss Weights: [0.880642   0.87999713 1.2393609 ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.5256832638406195e-06, Loss Weights: [0.8809153  0.88027024 1.2388146 ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.376955752784852e-06, Loss Weights: [0.8811931 0.8805479 1.2382591]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 1.2897733540739864e-05, Loss Weights: [0.881476  0.8808305 1.2376937]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.651676241948735e-06, Loss Weights: [0.8817638  0.88111806 1.237118  ]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 8.552457984478679e-06, Loss Weights: [0.88205683 0.8814109  1.2365323 ]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.62925367578282e-06, Loss Weights: [0.882355  0.8817088 1.2359365]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.070467068435391e-06, Loss Weights: [0.88265777 0.8820114  1.2353306 ]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.540249276236864e-06, Loss Weights: [0.8829655 0.882319  1.2347155]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.53646145312814e-06, Loss Weights: [0.8832781 0.8826313 1.2340906]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.519436854228843e-06, Loss Weights: [0.88359547 0.8829484  1.2334561 ]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.557666776847327e-06, Loss Weights: [0.88391757 0.88327026 1.232812  ]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.115879503136966e-06, Loss Weights: [0.88424444 0.8835969  1.2321587 ]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.3263260017265566e-06, Loss Weights: [0.8845759 0.8839282 1.231496 ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.2954289862536825e-06, Loss Weights: [0.8849121  0.88426405 1.230824  ]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.370309736463241e-06, Loss Weights: [0.88525283 0.8846045  1.2301428 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.660705821559532e-06, Loss Weights: [0.88559806 0.88494956 1.2294526 ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 7.838968485884834e-06, Loss Weights: [0.88594806 0.8852992  1.2287529 ]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.06898913954501e-06, Loss Weights: [0.88630253 0.8856534  1.2280442 ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 8.43860561872134e-06, Loss Weights: [0.8866616 0.8860122 1.227326 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.840340120106703e-06, Loss Weights: [0.8870255  0.88637584 1.2265987 ]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 1.1199617802049033e-05, Loss Weights: [0.8873942  0.88674426 1.2258613 ]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.658068741671741e-06, Loss Weights: [0.8877679  0.88711774 1.2251142 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 8.28015345177846e-06, Loss Weights: [0.88814664 0.88749623 1.2243572 ]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.892199169466039e-06, Loss Weights: [0.88853014 0.8878795  1.2235904 ]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.569650511461077e-06, Loss Weights: [0.8889186  0.88826764 1.2228141 ]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 1.1669154446281027e-05, Loss Weights: [0.88931197 0.8886607  1.2220275 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 1.0188792657572776e-05, Loss Weights: [0.88971066 0.8890591  1.2212304 ]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.734266778745223e-06, Loss Weights: [0.8901145 0.8894626 1.220423 ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.748809028067626e-06, Loss Weights: [0.89052325 0.889871   1.2196054 ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 9.875589967123233e-06, Loss Weights: [0.89093745 0.8902849  1.2187777 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 4.752293079945957e-06, Loss Weights: [0.8913565 0.8907037 1.2179397]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.725936716771685e-06, Loss Weights: [0.8917806  0.89112735 1.2170922 ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.125083473307313e-06, Loss Weights: [0.8922094 0.8915558 1.2162348]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 8.284214345621876e-06, Loss Weights: [0.8926431 0.8919892 1.2153678]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 6.501813004433643e-06, Loss Weights: [0.89308155 0.89242727 1.2144911 ]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 4.281167548469966e-06, Loss Weights: [0.8935245 0.89287   1.2136054]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 21, Total Loss: 5.991430953145027e-06, Loss Weights: [0.89397216 0.89331734 1.2127106 ]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 22\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 1.1219209227419924e-05, Loss Weights: [0.89437604 0.89372087 1.2119032 ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.142996426206082e-06, Loss Weights: [0.89474106 0.8940856  1.2111733 ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.232980467757443e-06, Loss Weights: [0.8950716 0.894416  1.2105126]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.1229561651998665e-06, Loss Weights: [0.8953713 0.8947154 1.2099131]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.727583695465e-06, Loss Weights: [0.89564407 0.89498794 1.2093682 ]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 9.387248610437382e-06, Loss Weights: [0.89589286 0.8952365  1.2088706 ]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.455700829770649e-06, Loss Weights: [0.89612055 0.89546406 1.2084152 ]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 7.293579074030276e-06, Loss Weights: [0.89633   0.8956734 1.2079968]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.217865120561328e-06, Loss Weights: [0.8965231 0.8958663 1.2076107]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 7.207215276139323e-06, Loss Weights: [0.8967022 0.8960451 1.2072527]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.544494681293145e-06, Loss Weights: [0.89686906 0.89621186 1.2069192 ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 1.0096870028064586e-05, Loss Weights: [0.89702564 0.8963684  1.206606  ]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.290776127571007e-06, Loss Weights: [0.89717335 0.896516   1.2063105 ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.354602192004677e-06, Loss Weights: [0.8973137 0.8966563 1.2060299]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.2173218136886135e-06, Loss Weights: [0.8974477  0.89679027 1.2057619 ]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 9.157138265436515e-06, Loss Weights: [0.8975767  0.89691913 1.2055042 ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.82460040479782e-06, Loss Weights: [0.89770156 0.8970439  1.2052544 ]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 7.729255230515264e-06, Loss Weights: [0.89782333 0.89716554 1.2050109 ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.639898063236615e-06, Loss Weights: [0.8979429 0.897285  1.2047722]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.307985247782199e-06, Loss Weights: [0.89806056 0.8974025  1.2045369 ]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.854633855051361e-06, Loss Weights: [0.898177  0.8975189 1.204304 ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.251525635685539e-06, Loss Weights: [0.8982929 0.8976347 1.2040725]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 1.8166574591305107e-05, Loss Weights: [0.89840937 0.8977511  1.2038394 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 7.5114157880307175e-06, Loss Weights: [0.89852715 0.89786875 1.203604  ]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.14656073594233e-06, Loss Weights: [0.8986464  0.89798796 1.2033656 ]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 8.969590453489218e-06, Loss Weights: [0.8987677 0.8981092 1.203123 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 7.66920766182011e-06, Loss Weights: [0.89889145 0.8982328  1.2028757 ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.415129064407665e-06, Loss Weights: [0.8990178  0.89835906 1.2026232 ]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 8.304024959215894e-06, Loss Weights: [0.8991471 0.8984883 1.2023647]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.7885599744622596e-06, Loss Weights: [0.8992795 0.8986206 1.2020999]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.644791483267909e-06, Loss Weights: [0.89941514 0.8987562  1.2018286 ]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 7.879018085077405e-06, Loss Weights: [0.8995544 0.8988953 1.2015501]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.430066605389584e-06, Loss Weights: [0.8996974 0.8990382 1.2012646]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 8.159261597029399e-06, Loss Weights: [0.89984417 0.8991848  1.2009711 ]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.693734576401766e-06, Loss Weights: [0.89999497 0.8993355  1.2006696 ]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 4.953782990924083e-06, Loss Weights: [0.9001498  0.89949024 1.2003603 ]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 4.735833954327973e-06, Loss Weights: [0.9003084  0.89964867 1.2000428 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.802519237680826e-06, Loss Weights: [0.9004711  0.89981127 1.1997175 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.292065452522365e-06, Loss Weights: [0.90063787 0.8999779  1.1993841 ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 1.0628985364746768e-05, Loss Weights: [0.90080905 0.900149   1.1990418 ]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 7.83675022830721e-06, Loss Weights: [0.90098494 0.90032476 1.1986907 ]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 7.881876626925077e-06, Loss Weights: [0.90116525 0.900505   1.1983297 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 8.713627721590456e-06, Loss Weights: [0.9013505 0.9006902 1.1979592]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.076862518966664e-06, Loss Weights: [0.9015407 0.9008802 1.1975791]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.196604888624279e-06, Loss Weights: [0.9017356 0.901075  1.1971896]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.697205324395327e-06, Loss Weights: [0.90193516 0.90127444 1.1967906 ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.157078703632578e-06, Loss Weights: [0.9021393 0.9014784 1.1963823]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 7.2503653427702375e-06, Loss Weights: [0.90234816 0.901687   1.1959646 ]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.398147888830863e-06, Loss Weights: [0.9025618 0.9019005 1.1955376]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.116519216448069e-06, Loss Weights: [0.9027802 0.9021186 1.1951013]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 8.861574315233156e-06, Loss Weights: [0.9030034 0.9023416 1.1946551]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 4.643650754587725e-06, Loss Weights: [0.90323126 0.9025693  1.1941993 ]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 9.019425306178164e-06, Loss Weights: [0.9034642  0.90280205 1.1937337 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.484702796820784e-06, Loss Weights: [0.903702  0.9030397 1.1932584]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.2202017286617775e-06, Loss Weights: [0.9039445 0.903282  1.1927735]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.412023594748462e-06, Loss Weights: [0.9041918 0.9035291 1.1922791]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 8.335921847901773e-06, Loss Weights: [0.904444  0.9037812 1.1917748]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 4.837828328163596e-06, Loss Weights: [0.90470105 0.904038   1.191261  ]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.798759048047941e-06, Loss Weights: [0.9049628 0.9042995 1.1907377]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 7.182090939750196e-06, Loss Weights: [0.90522933 0.9045659  1.1902046 ]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.110639449412702e-06, Loss Weights: [0.9055007 0.904837  1.1896623]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.2651766964118e-06, Loss Weights: [0.9057765 0.9051127 1.1891106]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 8.965416782302782e-06, Loss Weights: [0.90605736 0.90539336 1.1885493 ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 7.606659437442431e-06, Loss Weights: [0.9063431  0.90567887 1.187978  ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.1939144870848395e-06, Loss Weights: [0.90663373 0.90596926 1.187397  ]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 7.164133876358392e-06, Loss Weights: [0.90692925 0.90626454 1.1868061 ]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 8.03103466751054e-06, Loss Weights: [0.90722984 0.90656495 1.1862051 ]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 4.935368451697286e-06, Loss Weights: [0.9075353  0.90687025 1.1855943 ]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.252727987681283e-06, Loss Weights: [0.9078457 0.9071804 1.184974 ]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.270865014812443e-06, Loss Weights: [0.90816075 0.90749526 1.1843438 ]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.0181292863271665e-06, Loss Weights: [0.90848064 0.9078149  1.1837044 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 7.515587185480399e-06, Loss Weights: [0.9088052 0.9081393 1.1830554]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.239199137780815e-06, Loss Weights: [0.9091346 0.9084685 1.1823969]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.700279300275724e-06, Loss Weights: [0.9094689 0.9088024 1.1817287]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.663641215709504e-06, Loss Weights: [0.9098079  0.90914106 1.1810508 ]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 7.675883352931123e-06, Loss Weights: [0.91015196 0.90948486 1.1803632 ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.102277893660357e-06, Loss Weights: [0.9105007 0.9098334 1.1796659]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 7.024969363556011e-06, Loss Weights: [0.9108544  0.91018677 1.1789588 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 1.4049413948669098e-05, Loss Weights: [0.9112135 0.9105456 1.1782408]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.026444680173881e-06, Loss Weights: [0.91157794 0.91090983 1.1775122 ]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.819666396040702e-06, Loss Weights: [0.91194767 0.9112793  1.1767728 ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.8508148867986165e-06, Loss Weights: [0.91232264 0.91165406 1.1760232 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.160315140528837e-06, Loss Weights: [0.9127027  0.91203386 1.1752634 ]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 1.2141624210926238e-05, Loss Weights: [0.9130882 0.9124191 1.1744928]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 4.029650881420821e-06, Loss Weights: [0.91347885 0.9128095  1.1737117 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 9.130806574830785e-06, Loss Weights: [0.91387486 0.91320515 1.1729199 ]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.098044312035199e-06, Loss Weights: [0.9142761  0.91360605 1.1721178 ]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 8.410876034758985e-06, Loss Weights: [0.9146826  0.91401225 1.1713053 ]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.268560355238151e-06, Loss Weights: [0.91509426 0.9144236  1.1704822 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.94850768923061e-06, Loss Weights: [0.91551113 0.91484016 1.1696489 ]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 7.732103767921217e-06, Loss Weights: [0.9159331 0.9152618 1.168805 ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.159832537377952e-06, Loss Weights: [0.9163604  0.91568875 1.167951  ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.9925828281848226e-06, Loss Weights: [0.9167925  0.91612065 1.1670868 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.051358923286898e-06, Loss Weights: [0.9172298  0.91655755 1.1662127 ]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 7.831109542166814e-06, Loss Weights: [0.91767204 0.91699946 1.1653285 ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 6.600668257306097e-06, Loss Weights: [0.9181193 0.9174464 1.1644344]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.1554516176111065e-06, Loss Weights: [0.91857135 0.9178982  1.1635306 ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.535890522878617e-06, Loss Weights: [0.91902816 0.91835463 1.1626171 ]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 5.615323061647359e-06, Loss Weights: [0.9194897  0.91881585 1.1616943 ]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 22, Total Loss: 7.918774826976005e-06, Loss Weights: [0.919956  0.9192819 1.1607621]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 23\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 1.0415714314149227e-05, Loss Weights: [0.9203768 0.9197023 1.1599209]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 6.012949143041624e-06, Loss Weights: [0.92075706 0.9200823  1.1591606 ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 7.572266440547537e-06, Loss Weights: [0.9211015  0.92042637 1.1584722 ]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 7.3516516749805305e-06, Loss Weights: [0.9214141 0.9207388 1.1578472]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 4.374623131297994e-06, Loss Weights: [0.9216984 0.9210229 1.1572788]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 6.092693183745723e-06, Loss Weights: [0.9219576  0.92128193 1.1567605 ]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 9.047362254932523e-06, Loss Weights: [0.9221951 0.9215192 1.1562858]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 7.485881269531092e-06, Loss Weights: [0.92241335 0.9217374  1.1558493 ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 4.499182978179306e-06, Loss Weights: [0.9226147  0.92193866 1.1554466 ]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 6.7469327404978685e-06, Loss Weights: [0.9228015  0.92212534 1.1550732 ]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.099170721223345e-06, Loss Weights: [0.9229755 0.9222992 1.1547254]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 4.549240657070186e-06, Loss Weights: [0.9231382  0.92246187 1.1544    ]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 9.157462045550346e-06, Loss Weights: [0.92329156 0.92261505 1.1540934 ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 6.378766556736082e-06, Loss Weights: [0.9234369  0.92276037 1.1538028 ]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 6.25297525402857e-06, Loss Weights: [0.9235756  0.92289895 1.1535254 ]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.444337602966698e-06, Loss Weights: [0.9237087 0.923032  1.1532593]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.11360349264578e-06, Loss Weights: [0.9238372 0.9231604 1.1530025]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.306514594849432e-06, Loss Weights: [0.9239619 0.923285  1.1527531]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.363325726648327e-06, Loss Weights: [0.9240837 0.9234067 1.1525098]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.82171469432069e-06, Loss Weights: [0.92420316 0.92352605 1.1522707 ]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.4889546845515724e-06, Loss Weights: [0.9243212  0.92364395 1.152035  ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 4.7696312321932055e-06, Loss Weights: [0.924438   0.92376065 1.1518011 ]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 8.597775376983918e-06, Loss Weights: [0.92455477 0.92387736 1.151568  ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 6.024483354849508e-06, Loss Weights: [0.92467165 0.92399406 1.1513344 ]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 6.961670806049369e-06, Loss Weights: [0.9247893 0.9241116 1.1510991]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.07273898620042e-06, Loss Weights: [0.92490804 0.9242302  1.1508616 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 8.023585905903019e-06, Loss Weights: [0.92502844 0.92435056 1.150621  ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 4.096387783647515e-06, Loss Weights: [0.9251506 0.9244726 1.1503769]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 7.973726496857125e-06, Loss Weights: [0.92527497 0.9245968  1.1501282 ]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 7.0498667810170446e-06, Loss Weights: [0.9254019 0.9247236 1.1498744]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.4907127378100995e-06, Loss Weights: [0.9255316 0.9248532 1.1496152]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 6.514634605991887e-06, Loss Weights: [0.9256642 0.9249857 1.1493499]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.3936396398057695e-06, Loss Weights: [0.9258001  0.92512155 1.1490785 ]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 8.02308841230115e-06, Loss Weights: [0.9259393  0.92526066 1.1488    ]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 6.331572876661085e-06, Loss Weights: [0.92608225 0.9254035  1.1485145 ]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 4.98283225169871e-06, Loss Weights: [0.92622876 0.92554986 1.1482215 ]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 4.781577899848344e-06, Loss Weights: [0.92637897 0.92569995 1.1479213 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.233962838246953e-06, Loss Weights: [0.9265328  0.92585367 1.1476135 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 4.762860498885857e-06, Loss Weights: [0.92669046 0.9260111  1.1472983 ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 6.039185336703667e-06, Loss Weights: [0.926852  0.9261725 1.1469755]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 9.64921582635725e-06, Loss Weights: [0.9270177 0.9263381 1.1466441]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.425965355243534e-06, Loss Weights: [0.9271876  0.92650783 1.1463042 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 7.309863576665521e-06, Loss Weights: [0.92736214 0.92668223 1.1459558 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.830811915075174e-06, Loss Weights: [0.9275409 0.9268608 1.1455982]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.283136033540359e-06, Loss Weights: [0.9277241 0.9270439 1.1452318]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.792367574031232e-06, Loss Weights: [0.9279119  0.92723155 1.1448567 ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 7.830595677660313e-06, Loss Weights: [0.92810416 0.92742366 1.1444721 ]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.613574558083201e-06, Loss Weights: [0.9283011 0.9276204 1.1440784]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.416569820226869e-06, Loss Weights: [0.9285027 0.9278219 1.1436754]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.400823738455074e-06, Loss Weights: [0.9287088  0.92802787 1.1432635 ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 6.559102530445671e-06, Loss Weights: [0.92891955 0.9282385  1.142842  ]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 6.21591198068927e-06, Loss Weights: [0.92913496 0.9284538  1.1424112 ]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.278877324599307e-06, Loss Weights: [0.929355   0.92867374 1.1419711 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 4.933290711051086e-06, Loss Weights: [0.9295798  0.92889833 1.1415219 ]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.351814252207987e-06, Loss Weights: [0.92980903 0.9291274  1.1410636 ]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 9.65768049354665e-06, Loss Weights: [0.9300432  0.92936134 1.1405953 ]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 4.4606172195926774e-06, Loss Weights: [0.9302822 0.9296001 1.1401175]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.545768544834573e-06, Loss Weights: [0.9305259 0.9298437 1.1396303]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 7.957716661621816e-06, Loss Weights: [0.93077457 0.9300922  1.1391332 ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.85881934966892e-06, Loss Weights: [0.9310281  0.93034554 1.1386265 ]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 4.992991307517514e-06, Loss Weights: [0.9312864 0.9306037 1.13811  ]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.423825314210262e-06, Loss Weights: [0.93154943 0.93086654 1.137584  ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 6.773546829208499e-06, Loss Weights: [0.9318175  0.93113434 1.1370484 ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.852854428667342e-06, Loss Weights: [0.9320903 0.9314069 1.1365031]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.3875037338002585e-06, Loss Weights: [0.9323677  0.93168414 1.1359481 ]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.808681635244284e-06, Loss Weights: [0.9326501 0.9319663 1.1353837]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 7.469011052307906e-06, Loss Weights: [0.93293726 0.93225336 1.1348095 ]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 4.610782070813002e-06, Loss Weights: [0.9332293 0.9325452 1.1342256]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 4.56520683655981e-06, Loss Weights: [0.93352604 0.93284166 1.1336323 ]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 1.1638667274382897e-05, Loss Weights: [0.933828  0.9331434 1.1330289]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 4.327527221903438e-06, Loss Weights: [0.93413484 0.93345    1.1324153 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 4.536506367003312e-06, Loss Weights: [0.93444645 0.9337615  1.1317921 ]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 6.204140845511574e-06, Loss Weights: [0.9347631  0.93407786 1.1311592 ]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.681167294824263e-06, Loss Weights: [0.9350846 0.9343991 1.1305165]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.034910373069579e-06, Loss Weights: [0.93541074 0.934725   1.1298642 ]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 6.085601398808649e-06, Loss Weights: [0.9357417  0.93505573 1.1292025 ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.586538009083597e-06, Loss Weights: [0.93607754 0.9353913  1.1285312 ]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.901499662286369e-06, Loss Weights: [0.93641806 0.93573165 1.1278504 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 6.606052011193242e-06, Loss Weights: [0.9367634  0.93607676 1.12716   ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.418462023953907e-06, Loss Weights: [0.9371136  0.93642664 1.12646   ]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 7.24751453162753e-06, Loss Weights: [0.9374685  0.93678135 1.1257501 ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.7521760936651845e-06, Loss Weights: [0.9378284  0.93714094 1.1250305 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 7.916067261248827e-06, Loss Weights: [0.9381933  0.93750554 1.1243011 ]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 8.753016118134838e-06, Loss Weights: [0.9385634 0.9378754 1.1235613]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 7.780385203659534e-06, Loss Weights: [0.93893874 0.9382505  1.1228108 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.737746050726855e-06, Loss Weights: [0.9393194 0.9386307 1.1220498]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 4.914369128528051e-06, Loss Weights: [0.93970513 0.9390162  1.1212789 ]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.048547336627962e-06, Loss Weights: [0.9400958 0.9394065 1.1204977]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.680812137143221e-06, Loss Weights: [0.94049144 0.9398019  1.1197069 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.457208771986188e-06, Loss Weights: [0.94089186 0.940202   1.1189061 ]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.984071322018281e-06, Loss Weights: [0.9412972 0.9406071 1.1180956]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.668910034728469e-06, Loss Weights: [0.9417075  0.94101703 1.1172756 ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 9.369223334942944e-06, Loss Weights: [0.9421227  0.94143194 1.1164453 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.98179349253769e-06, Loss Weights: [0.9425431 0.941852  1.1156049]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 6.677573765045963e-06, Loss Weights: [0.9429685 0.942277  1.1147543]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.447706826089416e-06, Loss Weights: [0.94339895 0.94270724 1.113894  ]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 4.9365930863132235e-06, Loss Weights: [0.94383407 0.94314206 1.1130236 ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 9.961656360246707e-06, Loss Weights: [0.94427454 0.9435823  1.1121432 ]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.1310794333403464e-06, Loss Weights: [0.94472003 0.94402754 1.1112524 ]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 23, Total Loss: 5.8218765843776055e-06, Loss Weights: [0.9451706 0.9444778 1.1103518]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 24\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.062895525043132e-06, Loss Weights: [0.94557655 0.94488347 1.1095399 ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.975910542270867e-06, Loss Weights: [0.94594324 0.9452499  1.1088068 ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.3827211559109855e-06, Loss Weights: [0.94627476 0.94558114 1.1081438 ]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.3143384068098385e-06, Loss Weights: [0.9465753 0.9458815 1.1075432]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.192354703671299e-06, Loss Weights: [0.9468483  0.94615436 1.1069976 ]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.679585345002124e-06, Loss Weights: [0.94709677 0.9464026  1.1065006 ]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.7569346861564554e-06, Loss Weights: [0.9473238 0.9466294 1.1060469]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.972753569949418e-06, Loss Weights: [0.9475318 0.9468372 1.1056311]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.446055183710996e-06, Loss Weights: [0.94772327 0.94702846 1.1052485 ]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 8.204479854612146e-06, Loss Weights: [0.9479003 0.9472054 1.1048944]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 7.491771157219773e-06, Loss Weights: [0.94806516 0.9473702  1.1045648 ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.032829332980327e-06, Loss Weights: [0.94821954 0.9475244  1.1042562 ]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.913519205729244e-06, Loss Weights: [0.94836473 0.9476695  1.1039655 ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.780287665402284e-06, Loss Weights: [0.9485024 0.947807  1.1036905]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.3232265599945094e-06, Loss Weights: [0.9486335  0.94793797 1.1034282 ]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.197529273777036e-06, Loss Weights: [0.9487594 0.9480638 1.1031768]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 8.080213774519507e-06, Loss Weights: [0.94888103 0.9481854  1.1029334 ]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.198939106776379e-06, Loss Weights: [0.94899964 0.9483038  1.1026967 ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.553724688274087e-06, Loss Weights: [0.94911563 0.9484197  1.1024646 ]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.842918653797824e-06, Loss Weights: [0.9492301  0.94853413 1.1022358 ]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.275125658954494e-06, Loss Weights: [0.94934356 0.9486475  1.102009  ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.236083779891487e-06, Loss Weights: [0.94945645 0.9487603  1.1017833 ]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.953688171051908e-06, Loss Weights: [0.9495696 0.9488733 1.1015573]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.470619387575425e-06, Loss Weights: [0.9496831 0.9489868 1.1013302]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.785843313788064e-06, Loss Weights: [0.94979775 0.9491013  1.101101  ]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 7.0420082920463756e-06, Loss Weights: [0.94991374 0.9492172  1.1008689 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.017903731641127e-06, Loss Weights: [0.9500315  0.94933486 1.1006335 ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 1.427264760422986e-05, Loss Weights: [0.95015204 0.9494553  1.1003926 ]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.864201855525607e-06, Loss Weights: [0.95027566 0.94957876 1.1001458 ]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 7.023801117611583e-06, Loss Weights: [0.9504023 0.9497053 1.0998924]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.4572602746484336e-06, Loss Weights: [0.9505323 0.9498352 1.0996325]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.050835625297623e-06, Loss Weights: [0.9506657 0.9499685 1.0993657]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.109327048558043e-06, Loss Weights: [0.9508027 0.9501054 1.0990918]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.860214853077196e-06, Loss Weights: [0.95094347 0.9502461  1.0988106 ]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.8733648984343745e-06, Loss Weights: [0.9510881 0.9503906 1.0985215]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.1170004553569015e-06, Loss Weights: [0.9512366 0.950539  1.0982245]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 8.528601938451175e-06, Loss Weights: [0.9513894  0.95069164 1.0979187 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.339367246255279e-06, Loss Weights: [0.95154667 0.9508488  1.0976045 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 7.280943918885896e-06, Loss Weights: [0.95170844 0.95101047 1.097281  ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.160283762961626e-06, Loss Weights: [0.95187485 0.95117676 1.0969484 ]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.0240768107178155e-06, Loss Weights: [0.9520459 0.9513476 1.0966064]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.851580681337509e-06, Loss Weights: [0.95222175 0.9515232  1.0962551 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.997704076638911e-06, Loss Weights: [0.95240235 0.95170367 1.0958941 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.5352921915764455e-06, Loss Weights: [0.9525877 0.9518889 1.0955236]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.079840775579214e-06, Loss Weights: [0.9527776 0.9520787 1.0951434]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.649822353210766e-06, Loss Weights: [0.9529726 0.9522735 1.0947539]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.742131295643048e-06, Loss Weights: [0.9531722 0.952473  1.0943547]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.357026450132253e-06, Loss Weights: [0.9533767  0.95267737 1.093946  ]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 7.1406798269890714e-06, Loss Weights: [0.9535862 0.9528867 1.0935273]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.288208169280551e-06, Loss Weights: [0.95380056 0.9531009  1.0930984 ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 8.1415128079243e-06, Loss Weights: [0.9540204  0.95332056 1.0926592 ]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.390075668605277e-06, Loss Weights: [0.9542453  0.95354533 1.0922095 ]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.946395049249986e-06, Loss Weights: [0.9544755 0.9537754 1.0917491]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.382979336194694e-06, Loss Weights: [0.9547111 0.9540108 1.0912781]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.799075668415753e-06, Loss Weights: [0.9549519 0.9542514 1.0907967]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 7.438894954248099e-06, Loss Weights: [0.95519805 0.95449734 1.0903046 ]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.122566446720157e-06, Loss Weights: [0.9554495  0.95474863 1.0898019 ]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.325190159055637e-06, Loss Weights: [0.95570624 0.95500505 1.0892887 ]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.671207989304094e-06, Loss Weights: [0.9559681 0.9552667 1.0887651]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.714477538276697e-06, Loss Weights: [0.95623505 0.9555335  1.0882313 ]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.862348760070745e-06, Loss Weights: [0.9565071  0.95580536 1.0876875 ]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 8.031591278268024e-06, Loss Weights: [0.95678437 0.95608246 1.0871332 ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.139211109257303e-06, Loss Weights: [0.957067   0.95636487 1.0865684 ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.567079824686516e-06, Loss Weights: [0.95735466 0.9566523  1.0859929 ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.7599813771958e-06, Loss Weights: [0.9576477 0.9569451 1.0854073]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 7.600308890687302e-06, Loss Weights: [0.95794606 0.9572433  1.0848107 ]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 7.138202363421442e-06, Loss Weights: [0.95824975 0.95754683 1.0842034 ]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.262130460119806e-06, Loss Weights: [0.9585589 0.9578557 1.0835855]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.621624040941242e-06, Loss Weights: [0.95887315 0.9581697  1.082957  ]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 8.640612577437423e-06, Loss Weights: [0.9591929 0.9584893 1.0823178]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.985844836686738e-06, Loss Weights: [0.95951796 0.95881414 1.0816677 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 9.476922059548087e-06, Loss Weights: [0.959849  0.9591449 1.0810062]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.490545506996568e-06, Loss Weights: [0.9601854  0.95948106 1.0803335 ]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.754305220762035e-06, Loss Weights: [0.9605274 0.9598228 1.0796498]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.649485501635354e-06, Loss Weights: [0.9608749 0.9601699 1.0789552]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.269734174362384e-06, Loss Weights: [0.9612277 0.9605225 1.0782499]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.3886291172821075e-06, Loss Weights: [0.9615859 0.9608804 1.0775338]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.835412023065146e-06, Loss Weights: [0.96194947 0.96124375 1.076807  ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.587894520431291e-06, Loss Weights: [0.9623184  0.96161246 1.0760694 ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.045091711508576e-06, Loss Weights: [0.9626926 0.9619864 1.0753211]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.3066082728037145e-06, Loss Weights: [0.96307194 0.9623655  1.0745623 ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.1342830122157466e-06, Loss Weights: [0.96345663 0.96274984 1.0737933 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.920059265918098e-06, Loss Weights: [0.96384656 0.9631394  1.0730139 ]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.321907908888534e-06, Loss Weights: [0.9642415  0.96353406 1.0722244 ]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.8407654250913765e-06, Loss Weights: [0.96464145 0.9639337  1.0714247 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.482063559407834e-06, Loss Weights: [0.9650464  0.96433836 1.0706153 ]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.222274805622874e-06, Loss Weights: [0.9654563 0.9647479 1.0697958]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 9.560724720358849e-06, Loss Weights: [0.9658715  0.96516275 1.0689658 ]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 7.089897280820878e-06, Loss Weights: [0.966292   0.96558297 1.0681249 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 8.35961509437766e-06, Loss Weights: [0.9667183 0.9660089 1.067273 ]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.36790060120984e-06, Loss Weights: [0.96714973 0.9664401  1.0664103 ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 7.723862836428452e-06, Loss Weights: [0.9675867  0.96687675 1.0655367 ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.590145858353935e-06, Loss Weights: [0.96802914 0.96731883 1.0646521 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.74189334656694e-06, Loss Weights: [0.968477  0.9677664 1.0637566]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 7.495157660741825e-06, Loss Weights: [0.96893036 0.9682194  1.06285   ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 6.018949534336571e-06, Loss Weights: [0.96938944 0.9686781  1.0619324 ]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.04014360558358e-06, Loss Weights: [0.96985376 0.9691421  1.0610042 ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.3563222789089195e-06, Loss Weights: [0.97032326 0.9696112  1.0600654 ]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 5.424054506875109e-06, Loss Weights: [0.9707979 0.9700855 1.0591166]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 24, Total Loss: 4.8879683163249865e-06, Loss Weights: [0.9712776  0.97056484 1.0581577 ]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 25\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.438528660306474e-06, Loss Weights: [0.97170985 0.97099686 1.0572932 ]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.609876668837387e-06, Loss Weights: [0.9721003 0.971387  1.0565126]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.431639692687895e-06, Loss Weights: [0.97245336 0.9717398  1.0558066 ]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.42342922926764e-06, Loss Weights: [0.9727734  0.97205955 1.0551672 ]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 6.660824965365464e-06, Loss Weights: [0.97306395 0.97234994 1.0545862 ]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.164149231655756e-06, Loss Weights: [0.9733286 0.9726144 1.0540571]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 8.6657373685739e-06, Loss Weights: [0.9735706 0.9728563 1.0535734]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 1.0298645065631717e-05, Loss Weights: [0.97379297 0.9730785  1.0531285 ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.125914412928978e-06, Loss Weights: [0.9739984  0.97328377 1.0527179 ]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.968379355181241e-06, Loss Weights: [0.97418886 0.973474   1.0523369 ]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.678939603763865e-06, Loss Weights: [0.9743666  0.97365165 1.0519819 ]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.740786946262233e-06, Loss Weights: [0.9745331 0.973818  1.0516491]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 6.818736437708139e-06, Loss Weights: [0.9746901  0.97397494 1.0513351 ]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 6.904753718117718e-06, Loss Weights: [0.9748392  0.97412395 1.0510366 ]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 6.025203219905961e-06, Loss Weights: [0.9749819 0.9742665 1.0507513]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.700068075180752e-06, Loss Weights: [0.97511923 0.97440374 1.050477  ]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.850043296755757e-06, Loss Weights: [0.9752519 0.9745363 1.0502115]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 6.543528343172511e-06, Loss Weights: [0.9753814  0.97466564 1.049953  ]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.214532964397222e-06, Loss Weights: [0.9755081 0.9747922 1.0496998]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.405865638545947e-06, Loss Weights: [0.97563267 0.9749167  1.0494506 ]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.579315711656818e-06, Loss Weights: [0.97575605 0.97504    1.0492041 ]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.907125457975781e-06, Loss Weights: [0.9758786 0.9751625 1.0489589]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 7.16281465429347e-06, Loss Weights: [0.97600126 0.97528505 1.0487137 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.794966000394197e-06, Loss Weights: [0.9761244 0.9754082 1.0484674]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.276817773847142e-06, Loss Weights: [0.9762485 0.9755322 1.0482191]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 8.827912097331136e-06, Loss Weights: [0.9763745  0.97565806 1.0479676 ]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.817171768285334e-06, Loss Weights: [0.97650236 0.97578585 1.0477117 ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.885921043751296e-06, Loss Weights: [0.9766326 0.975916  1.0474514]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.047671038482804e-06, Loss Weights: [0.9767653 0.9760487 1.0471859]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 6.358770860970253e-06, Loss Weights: [0.97690105 0.9761844  1.0469146 ]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 8.168527529051062e-06, Loss Weights: [0.9770402  0.97632337 1.0466366 ]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.203111413720762e-06, Loss Weights: [0.97718275 0.9764659  1.0463514 ]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.197229827695992e-06, Loss Weights: [0.97732884 0.97661185 1.0460591 ]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.18332399224164e-06, Loss Weights: [0.97747874 0.97676164 1.0457596 ]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.129094461153727e-06, Loss Weights: [0.97763246 0.97691524 1.0454524 ]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.299670763430186e-06, Loss Weights: [0.9777899 0.9770726 1.0451375]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.175925369054312e-06, Loss Weights: [0.97795117 0.97723377 1.0448151 ]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.337958555173827e-06, Loss Weights: [0.9781164  0.97739893 1.0444846 ]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.858595730183879e-06, Loss Weights: [0.9782858  0.97756815 1.0441461 ]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.43363785254769e-06, Loss Weights: [0.97845924 0.9777415  1.0437993 ]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 7.62400304665789e-06, Loss Weights: [0.9786371 0.9779192 1.0434436]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.4985871429380495e-06, Loss Weights: [0.9788196 0.9781016 1.043079 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 7.571710739284754e-06, Loss Weights: [0.97900665 0.97828853 1.0427046 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.892066954198526e-06, Loss Weights: [0.9791987  0.97848046 1.042321  ]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.173282715986716e-06, Loss Weights: [0.9793955 0.9786771 1.0419277]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 9.211929864250124e-06, Loss Weights: [0.97959733 0.9788788  1.041524  ]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.28339080826845e-06, Loss Weights: [0.9798043 0.9790855 1.0411103]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.252391474641627e-06, Loss Weights: [0.98001635 0.9792973  1.0406865 ]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.101353053760249e-06, Loss Weights: [0.98023343 0.9795141  1.0402526 ]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 6.204506007634336e-06, Loss Weights: [0.9804555  0.97973603 1.0398084 ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 6.221805051609408e-06, Loss Weights: [0.98068285 0.9799632  1.0393538 ]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 6.646349902439397e-06, Loss Weights: [0.9809155  0.98019564 1.0388887 ]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.936684490530752e-06, Loss Weights: [0.9811535 0.9804334 1.038413 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.39380926056765e-06, Loss Weights: [0.9813967 0.9806764 1.0379268]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.9250334086536895e-06, Loss Weights: [0.9816451 0.9809247 1.0374303]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.420633104018634e-06, Loss Weights: [0.9818986 0.981178  1.0369236]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.700560111814411e-06, Loss Weights: [0.9821571 0.9814362 1.0364068]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.610002517641988e-06, Loss Weights: [0.9824207 0.9816996 1.0358797]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 1.1106852980447002e-05, Loss Weights: [0.98268974 0.9819685  1.0353415 ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 7.910062777227722e-06, Loss Weights: [0.9829649 0.9822434 1.034792 ]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.829607744090026e-06, Loss Weights: [0.9832455 0.9825239 1.0342306]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.393839273892809e-06, Loss Weights: [0.98353195 0.9828102  1.0336578 ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.534394065558445e-06, Loss Weights: [0.983824  0.983102  1.0330739]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.369573616713751e-06, Loss Weights: [0.98412144 0.9833992  1.0324792 ]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 6.348516762955114e-06, Loss Weights: [0.9844245  0.98370206 1.0318735 ]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 8.075242476479616e-06, Loss Weights: [0.98473316 0.98401046 1.0312563 ]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.950225957145449e-06, Loss Weights: [0.9850475 0.9843246 1.0306281]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.946511580783408e-06, Loss Weights: [0.9853673 0.9846441 1.0299886]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.4488810999609996e-06, Loss Weights: [0.9856925 0.984969  1.0293384]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.832898866879987e-06, Loss Weights: [0.98602307 0.9852993  1.0286776 ]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 6.2428712226392236e-06, Loss Weights: [0.98635894 0.9856349  1.0280061 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 8.466261533612851e-06, Loss Weights: [0.98670053 0.9859763  1.0273232 ]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.8623700169846416e-06, Loss Weights: [0.98704773 0.9863232  1.0266292 ]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 3.8325993045873474e-06, Loss Weights: [0.9874003 0.9866755 1.0259242]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.977730441169115e-06, Loss Weights: [0.9877583 0.9870331 1.0252086]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.011674718640279e-06, Loss Weights: [0.9881215  0.98739606 1.0244824 ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.0791622925316915e-06, Loss Weights: [0.98849    0.98776424 1.0237459 ]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.856355983269168e-06, Loss Weights: [0.9888636 0.9881376 1.022999 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.8764650273369625e-06, Loss Weights: [0.9892422 0.988516  1.0222417]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 7.13893496140372e-06, Loss Weights: [0.9896263 0.9888998 1.021474 ]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 7.510807790822582e-06, Loss Weights: [0.99001575 0.989289   1.0206952 ]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.374403372115921e-06, Loss Weights: [0.9904107 0.9896836 1.0199056]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 7.699702109675854e-06, Loss Weights: [0.99081135 0.990084   1.0191047 ]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 6.63998525851639e-06, Loss Weights: [0.9912176 0.9904899 1.0182924]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 6.317994575510966e-06, Loss Weights: [0.99162966 0.9909016  1.0174688 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.100907856103731e-06, Loss Weights: [0.9920472 0.9913188 1.016634 ]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.677614353771787e-06, Loss Weights: [0.99247044 0.9917418  1.0157881 ]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.309048108552815e-06, Loss Weights: [0.9928989 0.99217   1.0149311]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.303443685988896e-06, Loss Weights: [0.993333   0.99260366 1.0140635 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.746030299429549e-06, Loss Weights: [0.99377215 0.99304247 1.0131853 ]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.472297289088601e-06, Loss Weights: [0.9942167  0.99348664 1.0122967 ]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.3501739785133395e-06, Loss Weights: [0.99466634 0.993936   1.0113976 ]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.97863084092387e-06, Loss Weights: [0.99512124 0.99439055 1.0104882 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 6.060691703169141e-06, Loss Weights: [0.99558145 0.9948504  1.0095683 ]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 6.874447080917889e-06, Loss Weights: [0.9960468  0.99531543 1.0086378 ]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.8183118198940065e-06, Loss Weights: [0.99651754 0.99578583 1.0076966 ]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.027731731388485e-06, Loss Weights: [0.99699354 0.9962615  1.0067449 ]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.363436801213538e-06, Loss Weights: [0.99747473 0.9967423  1.005783  ]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 4.1608109313528985e-06, Loss Weights: [0.9979609  0.99722815 1.004811  ]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 25, Total Loss: 5.731940291298088e-06, Loss Weights: [0.99845207 0.99771893 1.003829  ]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 26\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.569742825173307e-06, Loss Weights: [0.9988949 0.9981614 1.0029436]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 1.0931134966085665e-05, Loss Weights: [0.9992954 0.9985616 1.0021429]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.181632903055288e-06, Loss Weights: [0.9996582 0.9989242 1.0014176]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 7.994804946065415e-06, Loss Weights: [0.9999878 0.9992535 1.0007586]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.605471985996701e-06, Loss Weights: [1.0002879  0.99955344 1.0001587 ]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.742616965813795e-06, Loss Weights: [1.0005618  0.99982727 0.9996108 ]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.8068485486728605e-06, Loss Weights: [1.000813   1.0000782  0.99910873]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.230113972880645e-06, Loss Weights: [1.0010438 1.000309  0.9986471]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 1.361806698696455e-05, Loss Weights: [1.0012578 1.0005229 0.9982193]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.0597882363945246e-06, Loss Weights: [1.0014571 1.0007219 0.9978209]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.8532418734102976e-06, Loss Weights: [1.0016437 1.0009084 0.9974479]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.118055130675202e-06, Loss Weights: [1.0018193 1.0010839 0.997097 ]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.423662969405996e-06, Loss Weights: [1.0019854  1.0012498  0.99676466]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 9.887748092296533e-06, Loss Weights: [1.0021443 1.0014085 0.9964473]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 6.727087111357832e-06, Loss Weights: [1.0022969 1.0015609 0.996142 ]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.383894404076273e-06, Loss Weights: [1.0024447  1.0017086  0.99584675]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.890011496172519e-06, Loss Weights: [1.0025885 1.0018523 0.9955592]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 1.0015242878580466e-05, Loss Weights: [1.0027297  1.0019934  0.99527675]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 7.278466000570916e-06, Loss Weights: [1.0028694 1.002133  0.9949975]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.438741143530933e-06, Loss Weights: [1.003008  1.0022717 0.9947202]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 6.624957677558996e-06, Loss Weights: [1.0031465 1.00241   0.9944435]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.232610419625416e-06, Loss Weights: [1.0032853 1.0025487 0.9941659]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.385053671285277e-06, Loss Weights: [1.0034249  1.0026882  0.99388695]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.731321951112477e-06, Loss Weights: [1.0035655  1.0028288  0.99360555]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.9367613428330515e-06, Loss Weights: [1.0037079 1.002971  0.9933212]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.38607309863437e-06, Loss Weights: [1.003852  1.0031152 0.9930328]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 7.790837116772309e-06, Loss Weights: [1.0039988  1.0032618  0.99273944]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.011166194890393e-06, Loss Weights: [1.0041482 1.0034112 0.9924406]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 7.174784514063504e-06, Loss Weights: [1.0043011 1.0035638 0.9921353]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 7.37618256607675e-06, Loss Weights: [1.0044575 1.00372   0.9918226]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.7283283493015915e-06, Loss Weights: [1.0046176  1.00388    0.99150234]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.6517224038543645e-06, Loss Weights: [1.0047817  1.004044   0.99117434]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 1.0013435712608043e-05, Loss Weights: [1.0049504 1.0042126 0.990837 ]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.985908162780106e-06, Loss Weights: [1.0051237 1.0043858 0.9904903]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.538125606108224e-06, Loss Weights: [1.0053018  1.0045639  0.99013436]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.02135538024595e-06, Loss Weights: [1.0054846  1.0047464  0.98976886]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 6.412342372641433e-06, Loss Weights: [1.0056722 1.004934  0.9893938]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.157432951818919e-06, Loss Weights: [1.0058647 1.0051264 0.9890088]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.690097168553621e-06, Loss Weights: [1.0060624  1.0053239  0.98861384]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 8.134908966894727e-06, Loss Weights: [1.0062653 1.0055267 0.9882082]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 6.21956405666424e-06, Loss Weights: [1.0064735 1.0057348 0.9877916]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 8.372720913030207e-06, Loss Weights: [1.0066876 1.0059488 0.9873636]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.752068434754619e-06, Loss Weights: [1.0069075 1.0061685 0.9869242]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.706800154963275e-06, Loss Weights: [1.0071328 1.0063937 0.9864737]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.109313522349112e-06, Loss Weights: [1.0073636 1.0066242 0.9860121]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.306802449922543e-06, Loss Weights: [1.0076    1.0068604 0.9855397]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.550579888018547e-06, Loss Weights: [1.0078416 1.0071019 0.9850565]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.750347216031514e-06, Loss Weights: [1.0080887  1.0073488  0.98456264]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.321202595747309e-06, Loss Weights: [1.008341   1.0076009  0.98405826]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 6.43937028144137e-06, Loss Weights: [1.0085986  1.0078584  0.98354304]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.0826835174812e-06, Loss Weights: [1.0088615 1.0081213 0.9830173]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 6.101208327891072e-06, Loss Weights: [1.0091299 1.0083895 0.9824808]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 6.767116246919613e-06, Loss Weights: [1.0094037  1.0086632  0.98193324]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 6.342009328363929e-06, Loss Weights: [1.0096833 1.0089425 0.9813743]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.5592677199456375e-06, Loss Weights: [1.0099685 1.0092275 0.9808041]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.752518634631997e-06, Loss Weights: [1.0102593 1.0095181 0.9802227]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 6.297601430560462e-06, Loss Weights: [1.0105557 1.0098143 0.9796299]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.338703547546174e-06, Loss Weights: [1.0108578 1.0101161 0.9790261]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 7.287961580004776e-06, Loss Weights: [1.0111656 1.0104237 0.9784107]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.518536570685683e-06, Loss Weights: [1.0114791  1.0107368  0.97778404]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.702232217823621e-06, Loss Weights: [1.0117981 1.0110557 0.9771464]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.9682548706186935e-06, Loss Weights: [1.0121226  1.01138    0.97649753]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 7.952125997690018e-06, Loss Weights: [1.0124528 1.01171   0.9758371]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.673154762713239e-06, Loss Weights: [1.0127888  1.0120457  0.97516525]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.283683549350826e-06, Loss Weights: [1.0131307 1.0123874 0.9744822]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.737973540613893e-06, Loss Weights: [1.0134779 1.0127344 0.9737878]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.175169578957139e-06, Loss Weights: [1.0138307  1.0130869  0.97308236]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.643605279852636e-06, Loss Weights: [1.0141888 1.0134449 0.9723662]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 6.03375428909203e-06, Loss Weights: [1.0145525  1.0138083  0.97163904]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.58060446564923e-06, Loss Weights: [1.0149217 1.0141772 0.9709009]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.37385142504354e-06, Loss Weights: [1.0152965 1.0145516 0.970152 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.377968707558466e-06, Loss Weights: [1.0156763  1.0149312  0.96939236]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.0858029680966865e-06, Loss Weights: [1.0160617 1.0153162 0.9686222]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.9779717958008405e-06, Loss Weights: [1.0164523  1.0157065  0.96784115]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.026234364573611e-06, Loss Weights: [1.0168483 1.0161022 0.9670496]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 6.5955036916420795e-06, Loss Weights: [1.0172497 1.0165032 0.9662471]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.263107595965266e-06, Loss Weights: [1.0176564  1.0169097  0.96543384]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.2233341446262784e-06, Loss Weights: [1.0180686 1.0173216 0.96461  ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.201764452067437e-06, Loss Weights: [1.0184859 1.0177386 0.9637754]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.81873712487868e-06, Loss Weights: [1.0189086 1.018161  0.9629303]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.958485417068005e-06, Loss Weights: [1.0193367 1.0185888 0.9620746]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.800451733899536e-06, Loss Weights: [1.01977   1.0190217 0.9612082]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 3.4645304367586505e-06, Loss Weights: [1.0202085  1.01946    0.96033156]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.56451425634441e-06, Loss Weights: [1.0206519  1.0199032  0.95944476]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.236655058775796e-06, Loss Weights: [1.0211005 1.0203514 0.958548 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.9787527132139076e-06, Loss Weights: [1.0215541  1.0208046  0.95764136]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 7.608542091475101e-06, Loss Weights: [1.0220128  1.0212631  0.95672405]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.2988739298598375e-06, Loss Weights: [1.0224769 1.0217268 0.9557961]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.378193807497155e-06, Loss Weights: [1.0229464  1.0221959  0.95485795]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 8.190890184778254e-06, Loss Weights: [1.023421   1.0226703  0.95390856]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 3.653461362773669e-06, Loss Weights: [1.0239012  1.0231501  0.95294863]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.697447820944944e-06, Loss Weights: [1.0243866 1.0236351 0.9519781]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.3943808779877145e-06, Loss Weights: [1.0248773 1.0241256 0.9509971]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.0730392356636e-06, Loss Weights: [1.0253731  1.024621   0.95000577]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.098157205589814e-06, Loss Weights: [1.025874  1.0251216 0.9490044]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 6.680902060907101e-06, Loss Weights: [1.0263801 1.0256273 0.9479927]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.3033118092571385e-06, Loss Weights: [1.0268912  1.0261381  0.94697046]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 4.196208465145901e-06, Loss Weights: [1.0274076 1.0266541 0.9459382]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 6.586241397599224e-06, Loss Weights: [1.0279293 1.0271754 0.9448954]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 26, Total Loss: 5.088523266749689e-06, Loss Weights: [1.0284561 1.0277019 0.943842 ]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 27\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 7.316382379940478e-06, Loss Weights: [1.0289314  1.0281768  0.94289196]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.681849986809539e-06, Loss Weights: [1.0293608  1.0286058  0.94203347]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.8588935896987095e-06, Loss Weights: [1.0297493  1.0289941  0.94125664]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 3.8452117223641835e-06, Loss Weights: [1.0301015 1.0293461 0.9405525]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.328606675902847e-06, Loss Weights: [1.0304215  1.029666   0.93991256]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.800047008757247e-06, Loss Weights: [1.0307131 1.0299573 0.9393296]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.8821125346876215e-06, Loss Weights: [1.0309795  1.0302235  0.93879694]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.4489092942967545e-06, Loss Weights: [1.0312238 1.0304676 0.9383086]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.452447228686651e-06, Loss Weights: [1.0314486 1.0306922 0.9378592]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 3.833996288449271e-06, Loss Weights: [1.0316561 1.0308998 0.937444 ]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.29714134245296e-06, Loss Weights: [1.031849   1.0310924  0.93705857]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.270498720870819e-06, Loss Weights: [1.0320289  1.0312722  0.93669903]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.899662144453032e-06, Loss Weights: [1.0321975  1.0314407  0.93636155]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.4852017708763015e-06, Loss Weights: [1.0323567  1.0316     0.93604326]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.815937129227677e-06, Loss Weights: [1.032508  1.0317512 0.9357408]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.522687959251925e-06, Loss Weights: [1.0326526 1.0318956 0.9354517]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 9.59351564233657e-06, Loss Weights: [1.0327923  1.0320352  0.93517244]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.7525886657240335e-06, Loss Weights: [1.0329281 1.0321709 0.9349011]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.9525419854035135e-06, Loss Weights: [1.0330608  1.0323035  0.93463576]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.675699412677204e-06, Loss Weights: [1.0331914 1.032434  0.9343746]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.303156285663135e-06, Loss Weights: [1.0333208  1.0325632  0.93411595]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.547148364508757e-06, Loss Weights: [1.0334495  1.0326917  0.93385875]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.231497769069392e-06, Loss Weights: [1.033578   1.0328202  0.93360174]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.228083071211586e-06, Loss Weights: [1.0337069 1.032949  0.9333441]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 8.118291589198634e-06, Loss Weights: [1.033837   1.0330789  0.93308413]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.038548806624021e-06, Loss Weights: [1.0339687 1.0332105 0.9328208]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 6.009236130921636e-06, Loss Weights: [1.0341026 1.0333443 0.9325532]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.033893219457241e-06, Loss Weights: [1.0342388 1.0334804 0.9322809]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 3.997163730673492e-06, Loss Weights: [1.0343776  1.0336192  0.93200326]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 6.104749445512425e-06, Loss Weights: [1.0345194 1.0337609 0.9317198]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 7.510505838581594e-06, Loss Weights: [1.0346649  1.0339062  0.93142915]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.451233846542891e-06, Loss Weights: [1.0348139 1.0340551 0.9311308]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.395775249577127e-06, Loss Weights: [1.034967 1.034208 0.930825]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.28355497206212e-06, Loss Weights: [1.0351241  1.034365   0.93051106]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 3.451461225267849e-06, Loss Weights: [1.035285  1.0345259 0.930189 ]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 7.742875823169015e-06, Loss Weights: [1.0354506 1.0346913 0.9298582]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 7.421895588777261e-06, Loss Weights: [1.0356208 1.0348616 0.9295176]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.628354756481713e-06, Loss Weights: [1.0357962  1.0350368  0.92916715]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.0276939873583615e-06, Loss Weights: [1.0359765  1.035217   0.92880654]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.824845291295787e-06, Loss Weights: [1.0361619 1.0354023 0.9284358]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.312009307090193e-06, Loss Weights: [1.0363524 1.0355928 0.9280547]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.307521066948539e-06, Loss Weights: [1.0365481  1.0357885  0.92766327]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.716437160823261e-06, Loss Weights: [1.0367491 1.0359894 0.9272615]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.628442184184678e-06, Loss Weights: [1.0369554  1.0361955  0.92684937]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.543473096418893e-06, Loss Weights: [1.0371665  1.0364065  0.92642677]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.735135462397011e-06, Loss Weights: [1.0373831  1.0366229  0.92599404]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.460981926968088e-06, Loss Weights: [1.0376048 1.0368444 0.9255508]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.814164978801273e-06, Loss Weights: [1.0378318 1.0370712 0.9250969]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.655994871427538e-06, Loss Weights: [1.038064  1.0373034 0.9246324]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 7.322283636312932e-06, Loss Weights: [1.038302   1.0375412  0.92415667]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 6.896548711665673e-06, Loss Weights: [1.0385458  1.0377848  0.92366934]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.5553623496962246e-06, Loss Weights: [1.0387955 1.0380343 0.9231701]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 3.5301695788803045e-06, Loss Weights: [1.0390508  1.0382894  0.92265964]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.740355845773593e-06, Loss Weights: [1.039312   1.0385504  0.92213756]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.376399374450557e-06, Loss Weights: [1.0395789  1.038817   0.92160404]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.518761670624372e-06, Loss Weights: [1.0398514 1.0390894 0.9210593]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 6.860577286715852e-06, Loss Weights: [1.0401297 1.0393674 0.9205028]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.2042165659950115e-06, Loss Weights: [1.0404137  1.0396513  0.91993487]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 6.554987521667499e-06, Loss Weights: [1.0407039  1.0399412  0.91935515]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 6.253428182390053e-06, Loss Weights: [1.0409999  1.040237   0.91876316]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 3.95806773667573e-06, Loss Weights: [1.0413018  1.0405387  0.91815937]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 3.850944267469458e-06, Loss Weights: [1.0416095 1.0408462 0.9175442]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 6.320692591543775e-06, Loss Weights: [1.0419233  1.0411596  0.91691726]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.204612650937634e-06, Loss Weights: [1.0422425 1.0414786 0.9162787]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 3.609855184549815e-06, Loss Weights: [1.0425676 1.0418034 0.9156291]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.9911454880202655e-06, Loss Weights: [1.0428982  1.0421338  0.91496813]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.773884484166047e-06, Loss Weights: [1.0432343 1.0424697 0.9142959]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 3.8658390622003935e-06, Loss Weights: [1.043576  1.0428112 0.9136128]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.1410403355257586e-06, Loss Weights: [1.0439231 1.043158  0.9129188]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.54499774807482e-06, Loss Weights: [1.0442758 1.0435104 0.9122138]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.453534529602621e-06, Loss Weights: [1.0446339  1.0438683  0.91149783]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 6.1340106185525656e-06, Loss Weights: [1.0449977 1.0442318 0.9107707]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.257762611814542e-06, Loss Weights: [1.0453669 1.0446007 0.9100325]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.397491349867778e-06, Loss Weights: [1.0457417  1.0449753  0.90928304]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.3543317335424945e-06, Loss Weights: [1.0461221 1.0453554 0.9085223]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.1826078813755885e-06, Loss Weights: [1.0465081  1.0457413  0.90775055]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 6.3415586737392005e-06, Loss Weights: [1.0468999  1.0461328  0.90696734]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 3.927279522031313e-06, Loss Weights: [1.0472972 1.0465298 0.906173 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.203223852528026e-06, Loss Weights: [1.0477    1.0469323 0.9053675]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.2936030695273075e-06, Loss Weights: [1.0481083  1.0473404  0.90455115]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 8.385076398553792e-06, Loss Weights: [1.0485225 1.0477543 0.9037231]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.5894198592577595e-06, Loss Weights: [1.0489424 1.0481739 0.9028835]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 9.181871064356528e-06, Loss Weights: [1.0493686 1.0485998 0.9020314]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 3.984018349001417e-06, Loss Weights: [1.049801  1.0490319 0.9011673]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 3.040763431272353e-06, Loss Weights: [1.0502391  1.0494695  0.90029144]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 3.914594344678335e-06, Loss Weights: [1.0506828 1.0499129 0.8994043]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.821513695991598e-06, Loss Weights: [1.0511322 1.050362  0.8985057]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.030785021313932e-06, Loss Weights: [1.0515873 1.0508168 0.8975959]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.112476290174527e-06, Loss Weights: [1.052048 1.051277 0.896675]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.751833330374211e-06, Loss Weights: [1.0525141  1.0517428  0.89574313]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.992163096379954e-06, Loss Weights: [1.0529858  1.0522141  0.89480007]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.15799013353535e-06, Loss Weights: [1.053463  1.052691  0.8938459]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.929325197939761e-06, Loss Weights: [1.053946   1.0531735  0.89288056]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 8.587147021899e-06, Loss Weights: [1.0544349  1.0536621  0.89190304]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.191376774542732e-06, Loss Weights: [1.0549297 1.0541565 0.8909138]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 6.291697900451254e-06, Loss Weights: [1.0554304 1.054657  0.8899125]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 4.345978595665656e-06, Loss Weights: [1.0559372  1.0551634  0.88889956]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 3.7615495784848463e-06, Loss Weights: [1.0564495 1.0556754 0.8878752]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 5.001374574931106e-06, Loss Weights: [1.0569675 1.0561929 0.8868394]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 27, Total Loss: 3.915712113666814e-06, Loss Weights: [1.0574911  1.0567162  0.88579273]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 28\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.852469712408492e-06, Loss Weights: [1.0579633 1.057188  0.8848487]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 6.268858669500332e-06, Loss Weights: [1.05839   1.0576146 0.8839955]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.293277470424073e-06, Loss Weights: [1.0587764 1.0580007 0.883223 ]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 6.5382355387555435e-06, Loss Weights: [1.059127   1.0583512  0.88252175]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.160608114034403e-06, Loss Weights: [1.0594461  1.05867    0.88188374]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.727925897896057e-06, Loss Weights: [1.0597373  1.058961   0.88130164]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 6.593729722226271e-06, Loss Weights: [1.060004   1.0592276  0.88076824]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.6616361285268795e-06, Loss Weights: [1.0602493 1.0594728 0.880278 ]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.770722964371089e-06, Loss Weights: [1.0604758 1.059699  0.8798251]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.708618573407875e-06, Loss Weights: [1.0606861 1.0599092 0.8794046]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.6328894970647525e-06, Loss Weights: [1.0608826 1.0601056 0.8790119]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 7.3428759606031235e-06, Loss Weights: [1.0610673  1.0602902  0.87864256]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.273077593097696e-06, Loss Weights: [1.0612421 1.0604649 0.8782931]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.792883257527137e-06, Loss Weights: [1.0614085 1.0606312 0.8779602]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 6.127597771410365e-06, Loss Weights: [1.0615684  1.0607909  0.87764084]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.345133675087709e-06, Loss Weights: [1.0617225 1.0609449 0.8773325]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.271749276085757e-06, Loss Weights: [1.0618722 1.0610945 0.8770332]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.3802659749635495e-06, Loss Weights: [1.0620186  1.0612408  0.87674063]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.303939476812957e-06, Loss Weights: [1.0621624  1.0613846  0.87645316]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.4271887418290135e-06, Loss Weights: [1.0623045  1.0615264  0.87616915]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.006495030102087e-06, Loss Weights: [1.0624455  1.0616673  0.87588704]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.4735458029899746e-06, Loss Weights: [1.0625863  1.0618079  0.87560594]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 6.305119313765317e-06, Loss Weights: [1.0627272 1.0619487 0.8753241]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.618846560333623e-06, Loss Weights: [1.0628691 1.0620905 0.8750405]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.3879281292902306e-06, Loss Weights: [1.0630121 1.0622336 0.8747541]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.215702003624756e-06, Loss Weights: [1.0631573  1.0623786  0.87446415]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.9269480112125166e-06, Loss Weights: [1.0633044 1.0625256 0.8741698]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.9553660826641135e-06, Loss Weights: [1.063454   1.0626751  0.87387073]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.963109520555008e-06, Loss Weights: [1.0636064 1.0628273 0.8735664]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.377594339326606e-06, Loss Weights: [1.0637614 1.0629822 0.8732563]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.666694510684465e-06, Loss Weights: [1.0639195 1.0631402 0.8729405]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.1982248148997314e-06, Loss Weights: [1.0640807 1.0633012 0.8726182]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.703448550775647e-06, Loss Weights: [1.0642455 1.0634658 0.8722887]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.969125828007236e-06, Loss Weights: [1.064414   1.0636342  0.87195194]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.7073767746041995e-06, Loss Weights: [1.0645864  1.0638064  0.87160724]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.374831744120456e-06, Loss Weights: [1.064763  1.0639827 0.8712541]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.503639840753749e-06, Loss Weights: [1.064944   1.0641637  0.87089217]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.125024588574888e-06, Loss Weights: [1.0651298 1.0643492 0.8705211]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.2501733332755975e-06, Loss Weights: [1.06532   1.0645392 0.8701409]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.362626325222664e-06, Loss Weights: [1.0655149 1.064734  0.869751 ]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.364772848930443e-06, Loss Weights: [1.0657148 1.0649338 0.8693514]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.595962647930719e-06, Loss Weights: [1.0659198  1.0651386  0.86894166]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.3086075745814014e-06, Loss Weights: [1.0661297 1.0653483 0.868522 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 6.7984292400069535e-06, Loss Weights: [1.066345  1.0655633 0.8680917]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 6.183657660585595e-06, Loss Weights: [1.0665656 1.0657839 0.8676503]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.356275323720183e-06, Loss Weights: [1.0667921  1.0660102  0.86719763]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.034617631987203e-06, Loss Weights: [1.0670241 1.0662421 0.8667337]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.7038120101206005e-06, Loss Weights: [1.0672619 1.0664797 0.8662585]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 7.750123586447444e-06, Loss Weights: [1.0675057 1.0667233 0.8657711]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 6.065987236070214e-06, Loss Weights: [1.0677556  1.066973   0.86527133]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.837388132727938e-06, Loss Weights: [1.0680118 1.067229  0.8647594]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 6.929649771336699e-06, Loss Weights: [1.0682743  1.0674914  0.86423445]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.85102703148732e-06, Loss Weights: [1.068543   1.0677599  0.86369693]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.9458573155570775e-06, Loss Weights: [1.068818  1.0680346 0.8631474]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.626261104727746e-06, Loss Weights: [1.0690988 1.0683154 0.8625858]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.901617558061844e-06, Loss Weights: [1.0693858  1.0686021  0.86201215]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.908813363930676e-06, Loss Weights: [1.0696788 1.0688949 0.8614263]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.9218173191766255e-06, Loss Weights: [1.0699781 1.069194  0.8608279]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.541407633951167e-06, Loss Weights: [1.0702837  1.0694993  0.86021715]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.470652013173094e-06, Loss Weights: [1.0705954 1.0698107 0.8595938]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.989450306107756e-06, Loss Weights: [1.0709133  1.0701284  0.85895824]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.057956514065154e-06, Loss Weights: [1.0712374  1.0704522  0.85831034]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.95517679155455e-06, Loss Weights: [1.0715678 1.0707822 0.8576501]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 6.175720955070574e-06, Loss Weights: [1.0719043 1.0711186 0.8569771]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.2904348447336815e-06, Loss Weights: [1.0722471 1.0714612 0.8562918]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.277040261513321e-06, Loss Weights: [1.0725961 1.0718098 0.8555941]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.6204660318617243e-06, Loss Weights: [1.0729511 1.0721645 0.8548845]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.8637845136690885e-06, Loss Weights: [1.0733118  1.072525   0.85416305]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.312238615966635e-06, Loss Weights: [1.0736785  1.0728915  0.85343003]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.797646852239268e-06, Loss Weights: [1.074051   1.0732636  0.85268515]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.570313649310265e-06, Loss Weights: [1.0744295 1.0736418 0.8519288]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.0130943236581516e-06, Loss Weights: [1.0748137 1.0740256 0.8511605]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.4096358376700664e-06, Loss Weights: [1.0752037 1.0744153 0.8503809]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.021267952542985e-06, Loss Weights: [1.0755994 1.0748107 0.8495897]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 6.598629170184722e-06, Loss Weights: [1.0760012 1.0752122 0.8487865]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 7.80527352617355e-06, Loss Weights: [1.0764093 1.0756202 0.8479705]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.2983015191566665e-06, Loss Weights: [1.0768237  1.0760343  0.84714186]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.73885654375772e-06, Loss Weights: [1.0772446 1.0764549 0.8463004]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 6.473055691458285e-06, Loss Weights: [1.077672  1.0768821 0.845446 ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.8260903895425145e-06, Loss Weights: [1.0781059  1.0773157  0.84457844]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.911165549652651e-06, Loss Weights: [1.0785462 1.0777556 0.8436983]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.212878022575751e-06, Loss Weights: [1.0789928 1.0782018 0.8428055]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.4206076381669845e-06, Loss Weights: [1.0794456 1.0786542 0.8419001]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.993349309894256e-06, Loss Weights: [1.0799046  1.0791129  0.84098256]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.371037448436255e-06, Loss Weights: [1.0803696  1.0795776  0.84005284]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.776743935508421e-06, Loss Weights: [1.0808406 1.0800483 0.8391111]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.7270920074661262e-06, Loss Weights: [1.0813175 1.0805249 0.8381576]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.6251710702781565e-06, Loss Weights: [1.0818005  1.0810075  0.83719206]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.8011683045624522e-06, Loss Weights: [1.0822893 1.0814959 0.8362148]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.511258910293691e-06, Loss Weights: [1.0827838  1.08199    0.83522606]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.81716949454858e-06, Loss Weights: [1.0832841  1.08249    0.83422565]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.391886134020751e-06, Loss Weights: [1.0837905  1.082996   0.83321357]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.7828781387361232e-06, Loss Weights: [1.0843025 1.0835077 0.8321898]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.975146228185622e-06, Loss Weights: [1.0848203 1.084025  0.8311546]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 5.9099029385834e-06, Loss Weights: [1.085344   1.0845484  0.83010775]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.095934400538681e-06, Loss Weights: [1.0858732  1.0850773  0.82904935]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 7.1181698331201915e-06, Loss Weights: [1.0864087  1.0856124  0.82797885]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 3.877843937516445e-06, Loss Weights: [1.0869501  1.0861534  0.82689655]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 1.0155495147046167e-05, Loss Weights: [1.087498   1.0867009  0.82580113]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 28, Total Loss: 4.322370386944385e-06, Loss Weights: [1.0880523 1.0872549 0.8246927]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 29\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.3756532502593473e-06, Loss Weights: [1.088552  1.0877542 0.8236937]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 7.554461717518279e-06, Loss Weights: [1.0890036 1.0882056 0.822791 ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.852362508245278e-06, Loss Weights: [1.0894122  1.088614   0.82197356]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.633479875337798e-06, Loss Weights: [1.0897832  1.0889847  0.82123214]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.28353450843133e-06, Loss Weights: [1.0901204 1.0893219 0.8205577]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 1.2223271369293798e-05, Loss Weights: [1.0904291 1.0896304 0.8199407]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.402588274388108e-06, Loss Weights: [1.0907123 1.0899134 0.8193741]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.959120022045681e-06, Loss Weights: [1.0909736 1.0901744 0.8188521]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.496858764468925e-06, Loss Weights: [1.0912153 1.0904158 0.8183689]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.041406555188587e-06, Loss Weights: [1.09144   1.0906403 0.8179196]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.535881998890545e-06, Loss Weights: [1.09165   1.0908502 0.8174999]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.925497705698945e-06, Loss Weights: [1.0918474 1.0910474 0.8171051]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 5.023732228437439e-06, Loss Weights: [1.0920342  1.091234   0.81673175]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.020854703412624e-06, Loss Weights: [1.0922118  1.0914115  0.81637657]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.542985607258743e-06, Loss Weights: [1.092382  1.0915815 0.8160365]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 7.134103725547902e-06, Loss Weights: [1.0925462 1.0917456 0.8157082]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.891662800015183e-06, Loss Weights: [1.0927057 1.0919049 0.8153894]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.686497504735598e-06, Loss Weights: [1.0928615 1.0920606 0.8150779]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 7.193202236521756e-06, Loss Weights: [1.093015   1.0922139  0.81477106]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.6248146645666566e-06, Loss Weights: [1.0931671 1.0923659 0.8144673]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.334096845719614e-06, Loss Weights: [1.0933181  1.0925168  0.81416535]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.422672191140009e-06, Loss Weights: [1.0934688  1.0926673  0.81386364]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 5.743855126638664e-06, Loss Weights: [1.0936203 1.0928187 0.813561 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.951513346895808e-06, Loss Weights: [1.0937729 1.0929713 0.8132559]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.773179969357443e-06, Loss Weights: [1.093927   1.0931253  0.81294763]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.480810730456142e-06, Loss Weights: [1.0940833 1.0932815 0.8126353]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.7721738408436067e-06, Loss Weights: [1.0942419  1.0934399  0.81231827]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.802030505539733e-06, Loss Weights: [1.094403 1.093601 0.811996]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.475233254197519e-06, Loss Weights: [1.0945672 1.093765  0.8116678]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.974826879333705e-06, Loss Weights: [1.0947347  1.0939324  0.81133294]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.4998001865460537e-06, Loss Weights: [1.0949056 1.0941033 0.8109911]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.519592948781792e-06, Loss Weights: [1.0950804  1.094278   0.81064177]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.03227704737219e-06, Loss Weights: [1.095259  1.0944564 0.8102845]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 7.659966286155395e-06, Loss Weights: [1.0954423 1.0946397 0.8099182]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.1011950341053307e-06, Loss Weights: [1.0956299  1.0948273  0.80954266]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.04828733735485e-06, Loss Weights: [1.0958223  1.0950196  0.80915785]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.815675765712513e-06, Loss Weights: [1.0960197 1.0952169 0.8087634]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.925283635908272e-06, Loss Weights: [1.096222   1.0954189  0.80835915]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.8001214761607116e-06, Loss Weights: [1.0964292 1.0956259 0.8079449]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.3236068449914455e-06, Loss Weights: [1.0966414 1.095838  0.8075207]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.218120920995716e-06, Loss Weights: [1.0968586  1.096055   0.80708617]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.04700494982535e-06, Loss Weights: [1.0970812  1.0962774  0.80664134]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.104043798884959e-06, Loss Weights: [1.0973088 1.0965048 0.8061864]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.137724772590445e-06, Loss Weights: [1.0975416 1.0967374 0.8057211]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 6.10076585871866e-06, Loss Weights: [1.0977798 1.0969753 0.8052448]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 5.5948066801647656e-06, Loss Weights: [1.0980238  1.0972191  0.80475724]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.847173047688557e-06, Loss Weights: [1.0982733 1.0974684 0.8042582]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.4206661894131685e-06, Loss Weights: [1.0985285  1.0977234  0.80374813]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 5.241500275587896e-06, Loss Weights: [1.0987895 1.0979841 0.8032266]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.6883125176245812e-06, Loss Weights: [1.099056  1.0982504 0.8026936]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.2328383642598055e-06, Loss Weights: [1.0993283 1.0985224 0.8021492]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.180374162388034e-06, Loss Weights: [1.0996064 1.0988003 0.8015934]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.147181243752129e-06, Loss Weights: [1.0998901 1.0990839 0.8010262]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 5.328306087903911e-06, Loss Weights: [1.1001797  1.0993732  0.80044717]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.683643965108786e-06, Loss Weights: [1.1004752 1.0996685 0.7998563]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.265788564021932e-06, Loss Weights: [1.1007766 1.0999696 0.7992538]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.1386587124870857e-06, Loss Weights: [1.1010836 1.1002765 0.79864  ]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.044762135890778e-06, Loss Weights: [1.1013963  1.1005888  0.79801476]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.36994241681532e-06, Loss Weights: [1.1017148 1.1009071 0.7973782]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 6.487241080321837e-06, Loss Weights: [1.1020392 1.1012312 0.7967293]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 5.180932021175977e-06, Loss Weights: [1.1023699 1.1015617 0.7960684]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.455413090909133e-06, Loss Weights: [1.1027067 1.1018983 0.795395 ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 5.54318694412359e-06, Loss Weights: [1.1030498 1.1022412 0.794709 ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.2196617212321144e-06, Loss Weights: [1.103399  1.1025902 0.7940109]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 6.107750778028276e-06, Loss Weights: [1.1037546 1.1029456 0.7932999]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.4060824418702396e-06, Loss Weights: [1.1041164  1.1033071  0.79257643]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.591504875861574e-06, Loss Weights: [1.1044846  1.103675   0.79184055]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.894322617270518e-06, Loss Weights: [1.1048588  1.104049   0.79109234]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.784369593835436e-06, Loss Weights: [1.1052392  1.104429   0.79033166]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 5.084701115265489e-06, Loss Weights: [1.105626  1.1048155 0.7895585]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.5046232369495556e-06, Loss Weights: [1.1060189  1.105208   0.78877294]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.241302121954504e-06, Loss Weights: [1.1064179 1.1056068 0.7879752]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.6455960525927367e-06, Loss Weights: [1.106823  1.1060116 0.7871654]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.962331902584992e-06, Loss Weights: [1.107234  1.1064224 0.7863436]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.875170477840584e-06, Loss Weights: [1.107651   1.1068391  0.78550994]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.10355687563424e-06, Loss Weights: [1.1080738  1.1072617  0.78466463]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 9.686560588306747e-06, Loss Weights: [1.1085033  1.1076908  0.78380585]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.378838300704956e-06, Loss Weights: [1.1089393 1.1081265 0.7829342]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.188166712992825e-06, Loss Weights: [1.1093817 1.1085687 0.7820498]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 1.1128770893265028e-05, Loss Weights: [1.1098313 1.109018  0.7811508]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.057856585859554e-06, Loss Weights: [1.1102881  1.1094744  0.78023756]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.454207100934582e-06, Loss Weights: [1.1107519 1.1099379 0.7793103]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.93080745197949e-06, Loss Weights: [1.1112225 1.1104082 0.7783693]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.445409558684332e-06, Loss Weights: [1.1116999 1.1108854 0.7774148]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.4146103189414134e-06, Loss Weights: [1.1121839 1.111369  0.7764471]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 4.362008894531755e-06, Loss Weights: [1.1126745  1.1118591  0.77546644]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 5.28429109181161e-06, Loss Weights: [1.1131716 1.1123558 0.7744726]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.650423877843423e-06, Loss Weights: [1.1136751 1.112859  0.7734659]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.1544554985885043e-06, Loss Weights: [1.1141849 1.1133684 0.7724467]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 5.291762136039324e-06, Loss Weights: [1.1147009  1.1138841  0.77141494]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.996891791757662e-06, Loss Weights: [1.1152233 1.1144061 0.7703707]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.473942570053623e-06, Loss Weights: [1.1157515 1.114934  0.7693142]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.7384909319371218e-06, Loss Weights: [1.1162859 1.115468  0.768246 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 5.029759904573439e-06, Loss Weights: [1.1168263 1.116008  0.7671656]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 9.277353456127457e-06, Loss Weights: [1.1173735 1.1165547 0.7660717]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 5.129011242388515e-06, Loss Weights: [1.1179273 1.1171083 0.7649644]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.5433965877018636e-06, Loss Weights: [1.1184878  1.1176684  0.76384395]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 2.6760901619127253e-06, Loss Weights: [1.1190544 1.1182346 0.7627109]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 3.931533228751505e-06, Loss Weights: [1.1196272 1.1188071 0.7615657]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 29, Total Loss: 5.100384441902861e-06, Loss Weights: [1.1202062  1.1193857  0.76040804]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 30\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 6.1897490013507195e-06, Loss Weights: [1.1207285  1.1199076  0.75936365]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 1.1498476851556916e-05, Loss Weights: [1.1212016  1.1203804  0.75841784]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.254352006682893e-06, Loss Weights: [1.121631  1.1208096 0.7575594]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.082605755684199e-06, Loss Weights: [1.1220216  1.1211998  0.75677866]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 6.025459697411861e-06, Loss Weights: [1.122378  1.121556  0.7560661]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.3422218166379025e-06, Loss Weights: [1.1227041  1.121882   0.75541395]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 9.516116733720992e-06, Loss Weights: [1.1230044 1.1221821 0.7548135]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.968063992942916e-06, Loss Weights: [1.1232821  1.1224597  0.75425845]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.6610369988920866e-06, Loss Weights: [1.1235397 1.1227171 0.7537432]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 5.154148766450817e-06, Loss Weights: [1.1237803 1.1229575 0.7532624]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.145768914691871e-06, Loss Weights: [1.1240057  1.1231828  0.75281155]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.7045119825052097e-06, Loss Weights: [1.1242181 1.1233951 0.7523866]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.428034005992231e-06, Loss Weights: [1.1244196 1.1235964 0.7519841]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.5259661217423854e-06, Loss Weights: [1.1246114 1.1237881 0.7516006]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.7172919746808475e-06, Loss Weights: [1.1247951 1.1239717 0.7512332]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 2.6266129680152517e-06, Loss Weights: [1.124972  1.1241485 0.7508796]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.661352249968331e-06, Loss Weights: [1.1251434 1.1243198 0.7505368]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.819340690824902e-06, Loss Weights: [1.1253105 1.1244867 0.7502028]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 5.754287030867999e-06, Loss Weights: [1.1254746  1.1246506  0.74987495]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.014033609360922e-06, Loss Weights: [1.1256361  1.1248121  0.74955165]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.071231160196476e-06, Loss Weights: [1.1257963  1.1249723  0.74923134]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.213717036487651e-06, Loss Weights: [1.1259557 1.1251316 0.7489127]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.681132850237191e-06, Loss Weights: [1.126115   1.1252908  0.74859416]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.000083208666183e-06, Loss Weights: [1.1262748 1.1254505 0.7482745]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.846870640700217e-06, Loss Weights: [1.1264359 1.1256114 0.7479527]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.9577330426254775e-06, Loss Weights: [1.1265985  1.1257739  0.74762774]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.5022885640501045e-06, Loss Weights: [1.1267629 1.1259382 0.7472988]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.5747505080507835e-06, Loss Weights: [1.1269298 1.1261048 0.7469654]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.239097506797407e-06, Loss Weights: [1.1270993  1.1262741  0.74662656]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.214809905533912e-06, Loss Weights: [1.1272719 1.1264466 0.7462815]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.6011690554005327e-06, Loss Weights: [1.1274478  1.1266224  0.74592984]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.6285922508104704e-06, Loss Weights: [1.1276274 1.126802  0.7455707]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.831148205790669e-06, Loss Weights: [1.1278108 1.1269853 0.7452038]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.582737008400727e-06, Loss Weights: [1.1279985 1.1271727 0.7448288]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.05486389354337e-06, Loss Weights: [1.1281903 1.1273644 0.7444452]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 2.90564275928773e-06, Loss Weights: [1.1283865 1.1275604 0.7440529]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.40890414918249e-06, Loss Weights: [1.1285872 1.127761  0.7436519]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.831668436760083e-06, Loss Weights: [1.1287923  1.1279659  0.74324167]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.4079080251103733e-06, Loss Weights: [1.1290021 1.1281755 0.7428223]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 5.475883426697692e-06, Loss Weights: [1.1292169  1.1283902  0.74239296]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.5574510093283607e-06, Loss Weights: [1.1294367  1.1286099  0.74195343]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.4625363696250133e-06, Loss Weights: [1.1296616 1.1288347 0.7415037]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 8.07454671303276e-06, Loss Weights: [1.1298923  1.1290653  0.74104244]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.1364882033813046e-06, Loss Weights: [1.1301287  1.1293014  0.74056965]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 1.1094449291704223e-05, Loss Weights: [1.1303722 1.1295447 0.7400833]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 7.952818123158067e-06, Loss Weights: [1.1306229  1.1297952  0.73958206]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.4272345601493726e-06, Loss Weights: [1.1308806 1.1300528 0.7390665]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.621665655373363e-06, Loss Weights: [1.1311455  1.1303176  0.73853695]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.3491221529402537e-06, Loss Weights: [1.1314172  1.1305891  0.73799366]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 2.9213620109658223e-06, Loss Weights: [1.1316955 1.1308672 0.7374372]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.5018806556763593e-06, Loss Weights: [1.1319804  1.1311518  0.73686767]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.768988674186403e-06, Loss Weights: [1.132272  1.1314431 0.7362851]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.7816964777448447e-06, Loss Weights: [1.1325699 1.1317408 0.7356894]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 2.536409965614439e-06, Loss Weights: [1.132874  1.1320448 0.7350811]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.203135631541954e-06, Loss Weights: [1.1331844  1.1323551  0.73446023]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.1226004466589075e-06, Loss Weights: [1.1335012 1.1326716 0.7338271]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 5.051302196079632e-06, Loss Weights: [1.1338243  1.1329945  0.73318136]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.8049424802011345e-06, Loss Weights: [1.1341535  1.1333234  0.73252285]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.363572659509373e-06, Loss Weights: [1.134489  1.1336588 0.7318521]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.7544546103163157e-06, Loss Weights: [1.1348307 1.1340002 0.731169 ]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.1577355912304483e-06, Loss Weights: [1.1351784  1.1343476  0.73047376]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.531025751930429e-06, Loss Weights: [1.1355324  1.1347013  0.72976637]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.494316388241714e-06, Loss Weights: [1.1358923 1.1350609 0.7290467]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.7909974253125256e-06, Loss Weights: [1.1362584  1.1354268  0.72831506]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.27342320108437e-06, Loss Weights: [1.1366304  1.1357986  0.72757107]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 7.478741281374823e-06, Loss Weights: [1.1370093 1.1361771 0.7268138]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.5159189337719e-06, Loss Weights: [1.1373945  1.1365621  0.72604334]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.005639766546665e-06, Loss Weights: [1.1377864  1.1369537  0.72525984]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.5542082059691893e-06, Loss Weights: [1.1381848 1.1373518 0.7244635]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.913467935490189e-06, Loss Weights: [1.1385894 1.1377561 0.7236543]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 2.785035803753999e-06, Loss Weights: [1.1390003  1.1381668  0.72283286]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.4001885726174805e-06, Loss Weights: [1.1394176 1.1385838 0.7219989]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 2.8393646971380804e-06, Loss Weights: [1.1398408 1.1390066 0.7211526]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.7227630400593625e-06, Loss Weights: [1.1402702  1.1394356  0.72029424]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.9869437387096696e-06, Loss Weights: [1.1407056 1.1398706 0.7194237]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.257066282458254e-06, Loss Weights: [1.141147  1.1403117 0.7185413]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 2.8135577849752735e-06, Loss Weights: [1.1415942 1.1407586 0.7176473]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.445173433647142e-06, Loss Weights: [1.142047  1.1412112 0.7167417]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 2.998299578393926e-06, Loss Weights: [1.1425058 1.1416695 0.7158247]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.243708533773315e-06, Loss Weights: [1.14297    1.1421335  0.71489656]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.660993570520077e-06, Loss Weights: [1.1434398  1.142603   0.71395713]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 6.4845003180380445e-06, Loss Weights: [1.1439158  1.1430787  0.71300566]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.013430159626296e-06, Loss Weights: [1.1443976 1.1435602 0.7120423]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.450935648492305e-06, Loss Weights: [1.1448854  1.1440477  0.71106684]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.644035470846575e-06, Loss Weights: [1.1453795  1.1445415  0.71007913]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.0732496725249803e-06, Loss Weights: [1.1458795 1.1450411 0.7090794]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.49691242465633e-06, Loss Weights: [1.1463857  1.1455469  0.70806754]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.49258812093467e-06, Loss Weights: [1.1468978 1.1460588 0.7070435]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.1742304145154776e-06, Loss Weights: [1.1474159 1.1465765 0.7060077]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.4954371130879736e-06, Loss Weights: [1.1479398 1.1471001 0.7049601]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.00731744573568e-06, Loss Weights: [1.1484694  1.1476295  0.70390105]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.1143972591962665e-06, Loss Weights: [1.1490048 1.1481645 0.7028307]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.7278996387613006e-06, Loss Weights: [1.1495459 1.1487051 0.701749 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.2226366784016136e-06, Loss Weights: [1.1500925 1.1492512 0.7006562]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 2.9119250939402264e-06, Loss Weights: [1.1506445 1.1498029 0.6995525]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.3789723349618725e-06, Loss Weights: [1.1512022 1.1503602 0.6984376]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 4.097188138985075e-06, Loss Weights: [1.1517655 1.1509231 0.6973113]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.4798006254277425e-06, Loss Weights: [1.1523346  1.1514919  0.69617385]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 2.842009507730836e-06, Loss Weights: [1.1529088 1.1520658 0.6950253]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 30, Total Loss: 3.366303872098797e-06, Loss Weights: [1.1534888 1.1526452 0.6938659]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 31\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 2.591349584690761e-06, Loss Weights: [1.1540115  1.1531676  0.69282097]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 2.916380708484212e-06, Loss Weights: [1.1544833  1.1536391  0.69187784]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.64980678568827e-06, Loss Weights: [1.1549096  1.1540651  0.69102526]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 2.83650706478511e-06, Loss Weights: [1.1552957 1.1544509 0.6902534]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 4.062080734001938e-06, Loss Weights: [1.1556461 1.154801  0.6895528]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 2.481160890965839e-06, Loss Weights: [1.1559647 1.1551195 0.6889158]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 1.0768035281216726e-05, Loss Weights: [1.1562566 1.1554111 0.6883323]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.928102614736417e-06, Loss Weights: [1.1565249 1.1556792 0.6877959]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 5.098808742332039e-06, Loss Weights: [1.1567729 1.1559272 0.6873001]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.1789925287739607e-06, Loss Weights: [1.157003  1.1561571 0.6868398]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.8032521842978895e-06, Loss Weights: [1.1572179 1.1563718 0.6864104]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.7165862067922717e-06, Loss Weights: [1.1574193  1.156573   0.68600744]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 4.821393304155208e-06, Loss Weights: [1.1576097  1.1567633  0.68562675]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.3773631002986804e-06, Loss Weights: [1.1577908 1.1569443 0.685265 ]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 5.340632924344391e-06, Loss Weights: [1.1579642 1.1571175 0.6849184]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.2504992759641027e-06, Loss Weights: [1.1581311 1.1572843 0.6845844]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.7683221307815984e-06, Loss Weights: [1.1582932 1.1574463 0.6842606]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 5.248509296507109e-06, Loss Weights: [1.1584516 1.1576045 0.6839441]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.3634062219789485e-06, Loss Weights: [1.1586071  1.1577599  0.68363297]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.6065923723072046e-06, Loss Weights: [1.1587609 1.1579136 0.6833256]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 5.8397640714247245e-06, Loss Weights: [1.158914   1.1580665  0.68301964]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.079328507737955e-06, Loss Weights: [1.1590669 1.1582193 0.6827138]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.6788906072615646e-06, Loss Weights: [1.1592205 1.1583726 0.6824069]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 5.635851266561076e-06, Loss Weights: [1.1593754 1.1585275 0.6820971]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 4.552839982352452e-06, Loss Weights: [1.1595324 1.1586845 0.6817831]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.898811883118469e-06, Loss Weights: [1.159692  1.158844  0.6814641]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 5.1585197979875375e-06, Loss Weights: [1.1598548 1.1590066 0.6811387]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.2035795811680146e-06, Loss Weights: [1.1600208 1.1591725 0.6808065]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.235482154195779e-06, Loss Weights: [1.1601907  1.1593423  0.68046725]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 5.752447577833664e-06, Loss Weights: [1.1603646  1.1595161  0.68011934]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 6.803037649660837e-06, Loss Weights: [1.1605436 1.1596949 0.6797615]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.311151203888585e-06, Loss Weights: [1.1607275  1.1598788  0.67939365]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 7.2680209086684044e-06, Loss Weights: [1.1609174 1.1600685 0.6790142]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.8808152567071375e-06, Loss Weights: [1.161113   1.160264   0.67862284]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.636053634181735e-06, Loss Weights: [1.1613147  1.1604655  0.67821974]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.649602604127722e-06, Loss Weights: [1.1615223 1.1606729 0.6778047]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 8.928201168600935e-06, Loss Weights: [1.1617368 1.1608874 0.6773759]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 4.378282483230578e-06, Loss Weights: [1.1619582  1.1611086  0.67693317]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 2.958662435048609e-06, Loss Weights: [1.1621865  1.1613368  0.67647684]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.741808086488163e-06, Loss Weights: [1.1624216 1.1615716 0.6760069]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.936821030947613e-06, Loss Weights: [1.1626633 1.1618131 0.6755234]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 4.348915354057681e-06, Loss Weights: [1.162912  1.1620617 0.6750263]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 4.257704858900979e-06, Loss Weights: [1.1631676 1.1623172 0.6745153]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.7848988085897872e-06, Loss Weights: [1.16343   1.1625793 0.6739904]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 5.002378202334512e-06, Loss Weights: [1.1636996 1.1628487 0.6734516]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 5.210941708355676e-06, Loss Weights: [1.1639766 1.1631254 0.6728982]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 4.903527951682918e-06, Loss Weights: [1.1642609 1.1634095 0.6723299]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 4.422569418238709e-06, Loss Weights: [1.1645525  1.1637008  0.67174673]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.397192131160409e-06, Loss Weights: [1.1648514 1.1639996 0.6711491]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 6.122621925896965e-06, Loss Weights: [1.1651579  1.1643058  0.67053616]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.3778894703573314e-06, Loss Weights: [1.1654719  1.1646196  0.66990834]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.2931984605966136e-06, Loss Weights: [1.1657933 1.1649407 0.669266 ]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.525231704770704e-06, Loss Weights: [1.1661217  1.1652689  0.66860914]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.3460721624578582e-06, Loss Weights: [1.1664574  1.1656044  0.66793835]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.022902546945261e-06, Loss Weights: [1.1667998 1.1659465 0.6672537]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 4.457453087525209e-06, Loss Weights: [1.1671492 1.1662956 0.6665551]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.9986716728890315e-06, Loss Weights: [1.1675057 1.1666518 0.6658426]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.2307095807482256e-06, Loss Weights: [1.1678691 1.1670148 0.6651163]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.2736077173467493e-06, Loss Weights: [1.168239  1.1673844 0.6643765]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.4852516819228185e-06, Loss Weights: [1.1686157 1.1677608 0.6636234]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 4.977324806532124e-06, Loss Weights: [1.1689993  1.1681441  0.66285646]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.1616032174497377e-06, Loss Weights: [1.1693897 1.1685343 0.662076 ]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.2821533295646077e-06, Loss Weights: [1.1697868 1.168931  0.6612822]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 5.385641998145729e-06, Loss Weights: [1.1701908 1.1693347 0.6604744]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.630646688179695e-06, Loss Weights: [1.1706017  1.1697452  0.65965295]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 2.9907687348895706e-06, Loss Weights: [1.1710193 1.1701626 0.658818 ]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.291182110842783e-06, Loss Weights: [1.1714437  1.1705866  0.65796983]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.4315814900764963e-06, Loss Weights: [1.1718745 1.1710172 0.6571084]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.528433808241971e-06, Loss Weights: [1.1723118 1.1714542 0.6562339]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.040458750547259e-06, Loss Weights: [1.1727556 1.1718976 0.6553466]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.1769434372108663e-06, Loss Weights: [1.1732059 1.1723475 0.6544466]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 4.02005252908566e-06, Loss Weights: [1.1736624  1.1728038  0.65353376]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.1430020044354023e-06, Loss Weights: [1.1741254  1.1732664  0.65260834]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 2.7787632461695466e-06, Loss Weights: [1.1745945 1.1737351 0.6516704]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.182881755492417e-06, Loss Weights: [1.1750698 1.1742101 0.6507202]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.091374537689262e-06, Loss Weights: [1.1755512  1.1746911  0.64975786]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.976546850026352e-06, Loss Weights: [1.1760387  1.1751783  0.64878327]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 2.9924885893706232e-06, Loss Weights: [1.1765321  1.1756713  0.64779645]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.27502129948698e-06, Loss Weights: [1.1770318  1.1761706  0.64679766]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.296793693152722e-06, Loss Weights: [1.1775373 1.1766757 0.6457868]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.0108767532510683e-06, Loss Weights: [1.1780488 1.1771868 0.6447642]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 2.8283750452828826e-06, Loss Weights: [1.1785662 1.1777039 0.6437299]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.4556423997855745e-06, Loss Weights: [1.1790894  1.1782267  0.64268386]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.0667881674162345e-06, Loss Weights: [1.1796185 1.1787553 0.6416261]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 2.6262630399287445e-06, Loss Weights: [1.1801533 1.1792897 0.6405571]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 2.91895753434801e-06, Loss Weights: [1.1806936  1.1798296  0.63947666]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 4.118507604289334e-06, Loss Weights: [1.1812398 1.1803753 0.6383847]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.5605335142463446e-06, Loss Weights: [1.1817919 1.180927  0.6372812]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.409454620850738e-06, Loss Weights: [1.1823497  1.1814843  0.63616586]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 2.723153784245369e-06, Loss Weights: [1.1829133 1.1820476 0.6350392]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.5904160995414713e-06, Loss Weights: [1.1834826 1.1826165 0.6339009]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 2.4429305085504893e-06, Loss Weights: [1.1840576  1.183191   0.63275135]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 2.5745068796823034e-06, Loss Weights: [1.1846381 1.183771  0.6315908]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 4.616738351614913e-06, Loss Weights: [1.1852244 1.1843568 0.6304187]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 2.9382088087004377e-06, Loss Weights: [1.1858164  1.1849483  0.62923527]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.157228093186859e-06, Loss Weights: [1.186414   1.1855454  0.62804043]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.5382522582949605e-06, Loss Weights: [1.1870174 1.1861484 0.6268342]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 3.3895128126459895e-06, Loss Weights: [1.1876266 1.1867571 0.6256165]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 4.290645847504493e-06, Loss Weights: [1.1882416  1.1873715  0.62438697]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 31, Total Loss: 5.0363491936877836e-06, Loss Weights: [1.1888628  1.1879921  0.62314504]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 32\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.0261792289820733e-06, Loss Weights: [1.1894228  1.1885517  0.62202555]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 4.295024609746179e-06, Loss Weights: [1.1899285  1.1890571  0.62101424]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 6.4206515162368305e-06, Loss Weights: [1.1903868 1.189515  0.6200982]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.0467651868093526e-06, Loss Weights: [1.1908026 1.1899306 0.6192667]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.377647660978255e-06, Loss Weights: [1.1911808  1.1903086  0.61851054]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 4.998428721592063e-06, Loss Weights: [1.1915262  1.1906536  0.61782044]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.004007112394902e-06, Loss Weights: [1.1918422 1.1909692 0.6171886]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.220502321710228e-06, Loss Weights: [1.1921325 1.1912594 0.6166081]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.272877620474901e-06, Loss Weights: [1.1924003 1.1915271 0.6160726]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.768326567093027e-06, Loss Weights: [1.1926484  1.1917751  0.61557657]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.3387323128408752e-06, Loss Weights: [1.1928794  1.1920059  0.61511487]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.4654955268488266e-06, Loss Weights: [1.1930953  1.1922216  0.61468303]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.504328560666181e-06, Loss Weights: [1.1932985 1.1924247 0.6142769]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.7504318040882936e-06, Loss Weights: [1.1934906 1.1926167 0.6138928]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.942936018574983e-06, Loss Weights: [1.1936735  1.1927994  0.61352694]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.8759536689904053e-06, Loss Weights: [1.1938488  1.1929747  0.61317647]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.8254478365852265e-06, Loss Weights: [1.1940178  1.1931435  0.61283886]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.9145720620581415e-06, Loss Weights: [1.1941816  1.1933072  0.61251116]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.640588945723721e-06, Loss Weights: [1.1943415  1.1934669  0.61219144]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.028576884389622e-06, Loss Weights: [1.1944984 1.1936237 0.6118778]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.9659092888323357e-06, Loss Weights: [1.1946533  1.1937783  0.61156845]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.432450284890365e-06, Loss Weights: [1.1948068  1.1939317  0.61126155]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.7449170829640934e-06, Loss Weights: [1.1949596  1.1940845  0.61095583]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 4.207663550914731e-06, Loss Weights: [1.1951128 1.1942377 0.6106495]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.660174797914806e-06, Loss Weights: [1.195267  1.1943917 0.6103413]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.2724560696806293e-06, Loss Weights: [1.1954226  1.1945474  0.61003006]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.766554871413973e-06, Loss Weights: [1.1955802 1.1947048 0.609715 ]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.8960846520931227e-06, Loss Weights: [1.1957401  1.1948645  0.60939527]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.0863484425935894e-06, Loss Weights: [1.1959028  1.195027   0.60907024]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.106164967903169e-06, Loss Weights: [1.1960684 1.1951925 0.6087392]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.81894494946755e-06, Loss Weights: [1.1962372  1.1953611  0.60840166]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 4.3758404899563175e-06, Loss Weights: [1.19641    1.1955338  0.60805655]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.0999237878859276e-06, Loss Weights: [1.1965866  1.1957102  0.60770327]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.560733375707059e-06, Loss Weights: [1.1967676  1.195891   0.60734135]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.6995281789131695e-06, Loss Weights: [1.1969533 1.1960766 0.6069702]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.919781647709897e-06, Loss Weights: [1.1971438 1.1962671 0.6065891]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.9416728466458153e-06, Loss Weights: [1.1973394 1.1964626 0.6061979]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.6104157768713776e-06, Loss Weights: [1.1975402  1.1966631  0.60579664]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 5.023763151257299e-06, Loss Weights: [1.1977465  1.1968694  0.60538423]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.643257630552398e-06, Loss Weights: [1.1979582 1.197081  0.6049607]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.9155764877941692e-06, Loss Weights: [1.1981758 1.1972983 0.6045261]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.7832159048557514e-06, Loss Weights: [1.1983986 1.197521  0.6040803]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.136060513497796e-06, Loss Weights: [1.1986272  1.1977495  0.60362333]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 6.242245035537053e-06, Loss Weights: [1.1988622 1.1979842 0.6031537]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.4255680273199687e-06, Loss Weights: [1.1991032 1.1982251 0.6026717]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.443124569457723e-06, Loss Weights: [1.1993505  1.1984723  0.60217714]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.455313844824559e-06, Loss Weights: [1.1996042 1.1987258 0.60167  ]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.561238716225489e-06, Loss Weights: [1.1998641  1.1989856  0.60115045]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.2113678116729716e-06, Loss Weights: [1.2001302 1.1992515 0.6006183]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.3018059184541926e-06, Loss Weights: [1.2004027  1.1995238  0.60007364]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.950414454971906e-06, Loss Weights: [1.2006814 1.1998023 0.5995164]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.791351789710461e-06, Loss Weights: [1.2009662  1.2000868  0.59894675]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.311324806214543e-06, Loss Weights: [1.2012572 1.2003776 0.5983651]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 7.191317308752332e-06, Loss Weights: [1.2015551  1.2006752  0.59776974]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.8457761800382286e-06, Loss Weights: [1.2018597 1.2009797 0.5971607]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 4.086539320269367e-06, Loss Weights: [1.2021712  1.201291   0.59653777]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.672852926683845e-06, Loss Weights: [1.2024899  1.2016094  0.59590095]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.9805457870679675e-06, Loss Weights: [1.2028153 1.2019346 0.5952503]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.3561285615869565e-06, Loss Weights: [1.2031474  1.2022665  0.59458625]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 4.358274509286275e-06, Loss Weights: [1.2034863  1.2026051  0.59390837]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.554366003299947e-06, Loss Weights: [1.2038324 1.202951  0.5932167]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.3383549887512345e-06, Loss Weights: [1.2041851  1.2033035  0.59251153]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 4.891687694907887e-06, Loss Weights: [1.2045448 1.2036629 0.5917922]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 4.420963705342729e-06, Loss Weights: [1.2049118 1.2040297 0.5910585]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.435349753999617e-06, Loss Weights: [1.205286  1.2044036 0.5903103]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.4659515222301707e-06, Loss Weights: [1.2056675  1.2047849  0.58954763]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 6.911571745149558e-06, Loss Weights: [1.2060568  1.205174   0.58876926]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.77547928817512e-06, Loss Weights: [1.2064538 1.2055706 0.5879755]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.055653451156104e-06, Loss Weights: [1.2068584  1.2059748  0.58716667]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.8355532322166255e-06, Loss Weights: [1.2072704  1.2063866  0.58634317]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.4972762275865534e-06, Loss Weights: [1.2076895  1.2068053  0.58550537]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.1019358175399248e-06, Loss Weights: [1.2081155  1.207231   0.58465344]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.8769818527507596e-06, Loss Weights: [1.2085485 1.2076638 0.5837877]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.40962219524954e-06, Loss Weights: [1.2089885  1.2081034  0.58290803]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.731967015279224e-06, Loss Weights: [1.2094353  1.2085499  0.58201474]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.18306024382764e-06, Loss Weights: [1.2098889 1.2090032 0.581108 ]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.7034724300610833e-06, Loss Weights: [1.2103493 1.2094632 0.5801874]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.544986611814238e-06, Loss Weights: [1.2108166 1.2099303 0.579253 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 5.293749381962698e-06, Loss Weights: [1.2112913  1.2104046  0.57830405]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.946374252132955e-06, Loss Weights: [1.2117732 1.2108861 0.5773407]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.3837433218432125e-06, Loss Weights: [1.212262   1.2113746  0.57636356]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.3806453555152984e-06, Loss Weights: [1.2127573  1.2118697  0.57537293]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.8137733352195937e-06, Loss Weights: [1.2132595 1.2123716 0.5743691]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.0796761620877078e-06, Loss Weights: [1.213768  1.2128799 0.573352 ]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.1027724415034754e-06, Loss Weights: [1.2142831 1.2133946 0.5723222]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.6792522476171143e-06, Loss Weights: [1.2148044 1.2139156 0.5712799]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.183583430654835e-06, Loss Weights: [1.2153322  1.214443   0.57022494]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.770673063423601e-06, Loss Weights: [1.215866  1.2149765 0.5691575]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 4.375683147372911e-06, Loss Weights: [1.2164063 1.2155166 0.568077 ]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.361134531587595e-06, Loss Weights: [1.2169534  1.2160631  0.56698346]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.2923487651714822e-06, Loss Weights: [1.217507  1.2166163 0.5658768]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.465869783918606e-06, Loss Weights: [1.2180669 1.2171758 0.5647572]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.9649991120095365e-06, Loss Weights: [1.2186333 1.2177417 0.563625 ]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.8038411983288825e-06, Loss Weights: [1.219206   1.2183139  0.56248015]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 5.630632585962303e-06, Loss Weights: [1.2197855 1.2188929 0.5613216]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.174883659085026e-06, Loss Weights: [1.2203717  1.2194786  0.56014955]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.8673284759861417e-06, Loss Weights: [1.2209647 1.2200712 0.5589642]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.8093779746996006e-06, Loss Weights: [1.2215642 1.2206702 0.5577656]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 2.5286492473242106e-06, Loss Weights: [1.2221701 1.2212757 0.5565542]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 32, Total Loss: 3.6605235891329357e-06, Loss Weights: [1.2227825 1.2218876 0.5553297]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 33\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.116539917551563e-06, Loss Weights: [1.2233346  1.2224393  0.55422616]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.6647835511539597e-06, Loss Weights: [1.2238328 1.2229372 0.5532299]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.4984212814160855e-06, Loss Weights: [1.2242833 1.2233874 0.5523294]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.0129447168292245e-06, Loss Weights: [1.2246914 1.223795  0.5515138]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.106634494542959e-06, Loss Weights: [1.2250618  1.2241651  0.55077326]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.5838412511802744e-06, Loss Weights: [1.2253988 1.2245018 0.5500993]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.7539830373134464e-06, Loss Weights: [1.2257067 1.2248095 0.5494837]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.6528974760585697e-06, Loss Weights: [1.2259892 1.2250918 0.5489191]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.846227289410308e-06, Loss Weights: [1.2262492 1.2253516 0.548399 ]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.7816979581984924e-06, Loss Weights: [1.2264899  1.225592   0.54791796]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 4.46718468083418e-06, Loss Weights: [1.2267139 1.2258159 0.5474701]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 4.588850060827099e-06, Loss Weights: [1.2269241 1.2260258 0.5470501]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.2668518795398995e-06, Loss Weights: [1.2271222  1.2262237  0.54665416]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.501840526747401e-06, Loss Weights: [1.22731   1.2264113 0.5462788]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.905313522205688e-06, Loss Weights: [1.2274891 1.2265903 0.5459206]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.1938092231721384e-06, Loss Weights: [1.227661   1.226762   0.54557693]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.6913712645182386e-06, Loss Weights: [1.227827  1.2269279 0.5452451]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.0360641883598873e-06, Loss Weights: [1.227988   1.2270888  0.54492307]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.2597513381915633e-06, Loss Weights: [1.2281454 1.2272462 0.5446084]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.3391048671328463e-06, Loss Weights: [1.2283     1.2274007  0.54429936]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.7057739064039197e-06, Loss Weights: [1.2284529 1.2275535 0.5439936]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.298864728800254e-06, Loss Weights: [1.2286049  1.2277052  0.54368985]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.54994040208112e-06, Loss Weights: [1.2287568 1.227857  0.5433863]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.3541817881778115e-06, Loss Weights: [1.228909  1.2280092 0.5430818]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.5338483737868955e-06, Loss Weights: [1.2290623  1.2281624  0.54277533]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.6129666821361752e-06, Loss Weights: [1.229217  1.228317  0.5424659]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.9973723485454684e-06, Loss Weights: [1.2293738 1.2284737 0.5421525]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.9563291263912106e-06, Loss Weights: [1.2295331 1.2286328 0.5418342]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.4145017505361466e-06, Loss Weights: [1.2296951  1.2287947  0.54151016]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.7003621855546953e-06, Loss Weights: [1.2298604 1.2289599 0.5411795]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.1955888769298326e-06, Loss Weights: [1.2300293  1.2291288  0.54084176]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.842318735929439e-06, Loss Weights: [1.2302022  1.2293015  0.54049635]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.533602239258471e-06, Loss Weights: [1.2303791 1.2294784 0.5401424]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.219883183191996e-06, Loss Weights: [1.2305608 1.2296598 0.5397794]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.843759830284398e-06, Loss Weights: [1.2307471 1.229846  0.5394069]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.412951627979055e-06, Loss Weights: [1.2309386 1.2300372 0.5390242]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.881052751035895e-06, Loss Weights: [1.2311351 1.2302337 0.5386311]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.8100432700739475e-06, Loss Weights: [1.2313373  1.2304356  0.53822726]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 4.060300398123218e-06, Loss Weights: [1.231545   1.2306432  0.53781176]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.5807648853515275e-06, Loss Weights: [1.2317586  1.2308567  0.53738475]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.1591470158455195e-06, Loss Weights: [1.2319779 1.2310758 0.5369463]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.3528459678345826e-06, Loss Weights: [1.232203  1.2313006 0.5364965]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.1438373753189808e-06, Loss Weights: [1.2324338 1.2315311 0.536035 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.5800170533329947e-06, Loss Weights: [1.2326705  1.2317678  0.53556174]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.829595132425311e-06, Loss Weights: [1.2329131 1.2320102 0.5350765]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 5.808976766275009e-06, Loss Weights: [1.2331626  1.2322595  0.53457797]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.6927009457722306e-06, Loss Weights: [1.2334187 1.2325153 0.5340661]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.0229248295654543e-06, Loss Weights: [1.2336813 1.2327778 0.5335408]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.276632241977495e-06, Loss Weights: [1.2339509  1.2330472  0.53300196]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.79074822376424e-06, Loss Weights: [1.2342274 1.2333237 0.532449 ]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.885036565203336e-06, Loss Weights: [1.2345109 1.233607  0.5318821]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.2325539248413406e-06, Loss Weights: [1.2348013  1.2338972  0.53130156]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.5221679607057013e-06, Loss Weights: [1.2350984  1.234194   0.53070754]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 4.375432581582572e-06, Loss Weights: [1.2354026 1.234498  0.5300994]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.365165755691123e-06, Loss Weights: [1.2357137 1.2348089 0.5294773]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.21242623613216e-06, Loss Weights: [1.2360319 1.2351269 0.5288412]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 4.534060281002894e-06, Loss Weights: [1.2363576  1.2354522  0.52819043]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.991015207953751e-06, Loss Weights: [1.2366903 1.2357848 0.5275248]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.473575932526728e-06, Loss Weights: [1.2370304 1.2361246 0.526845 ]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.203459300493705e-06, Loss Weights: [1.2373776 1.2364717 0.5261506]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 4.944889496982796e-06, Loss Weights: [1.2377326 1.2368264 0.5254408]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.617327936604852e-06, Loss Weights: [1.2380953  1.2371888  0.52471596]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.8842998744949e-06, Loss Weights: [1.2384652  1.2375586  0.52397615]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.0933406378608197e-06, Loss Weights: [1.2388427  1.2379358  0.52322143]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.418899268581299e-06, Loss Weights: [1.2392278  1.2383206  0.52245176]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.5447354801144684e-06, Loss Weights: [1.2396201  1.2387125  0.52166724]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.6927768885798287e-06, Loss Weights: [1.2400198 1.239112  0.5208682]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.963743554573739e-06, Loss Weights: [1.2404268  1.2395186  0.52005464]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.6747261472337414e-06, Loss Weights: [1.2408409 1.2399324 0.5192267]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.389699375271448e-06, Loss Weights: [1.2412622 1.2403533 0.5183846]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.452211785770487e-06, Loss Weights: [1.2416905 1.2407813 0.5175282]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.843250967998756e-06, Loss Weights: [1.242126  1.2412164 0.5166576]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.60012120634201e-06, Loss Weights: [1.2425685  1.2416586  0.51577294]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.5099780032178387e-06, Loss Weights: [1.243018   1.2421077  0.51487446]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.1087640763871605e-06, Loss Weights: [1.2434745 1.2425638 0.5139619]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.972894774051383e-06, Loss Weights: [1.243938   1.243027   0.51303494]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.394649300185847e-06, Loss Weights: [1.2444087  1.2434974  0.51209384]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.277687599416822e-06, Loss Weights: [1.2448864  1.2439747  0.51113886]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.0938331292418297e-06, Loss Weights: [1.2453711 1.2444589 0.51017  ]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.4647155189304613e-06, Loss Weights: [1.2458628  1.2449503  0.50918686]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.877330073009944e-06, Loss Weights: [1.2463619 1.245449  0.5081891]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.4484820642101113e-06, Loss Weights: [1.2468683 1.245955  0.507177 ]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.6469938347872812e-06, Loss Weights: [1.2473814 1.2464678 0.5061506]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.6743580292531988e-06, Loss Weights: [1.2479019  1.2469879  0.50511026]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.5594019916752586e-06, Loss Weights: [1.2484292 1.2475148 0.504056 ]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.0796323951799423e-06, Loss Weights: [1.2489632 1.2480485 0.5029883]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.494322188795195e-06, Loss Weights: [1.249504  1.2485888 0.5019073]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.622555484776967e-06, Loss Weights: [1.2500513 1.2491357 0.500813 ]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 7.995210580702405e-06, Loss Weights: [1.2506064  1.2496905  0.49970293]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 1.996258561121067e-06, Loss Weights: [1.2511692 1.250253  0.4985777]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.673477865755558e-06, Loss Weights: [1.2517395  1.2508229  0.49743766]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.145365215255879e-06, Loss Weights: [1.252317   1.2513999  0.49628314]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.732263965299353e-06, Loss Weights: [1.2529017 1.2519841 0.4951144]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.282164359712624e-06, Loss Weights: [1.2534932 1.2525753 0.4939316]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.301011591043789e-06, Loss Weights: [1.2540916 1.2531732 0.4927352]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 1.894369006549823e-06, Loss Weights: [1.2546966  1.2537777  0.49152565]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.2017404717189493e-06, Loss Weights: [1.255308   1.2543888  0.49030325]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 3.2630396162858233e-06, Loss Weights: [1.255926   1.2550064  0.48906764]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.7644600777421147e-06, Loss Weights: [1.2565506  1.2556305  0.48781884]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 33, Total Loss: 2.335872977710096e-06, Loss Weights: [1.2571816  1.2562611  0.48655713]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 34\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.4141743324435083e-06, Loss Weights: [1.2577505 1.2568297 0.4854197]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 5.824238996865461e-06, Loss Weights: [1.2582651 1.257344  0.4843908]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.165328396586119e-06, Loss Weights: [1.2587314  1.2578099  0.48345876]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 1.8897194422606844e-06, Loss Weights: [1.2591544 1.2582326 0.4826129]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 3.1335769108409295e-06, Loss Weights: [1.2595395  1.2586174  0.48184317]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.20813785745122e-06, Loss Weights: [1.2598907 1.2589684 0.4811408]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.1140306216693716e-06, Loss Weights: [1.2602122  1.2592896  0.48049808]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.1754863155365456e-06, Loss Weights: [1.2605075  1.2595847  0.47990793]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 1.9518656699801795e-06, Loss Weights: [1.2607794  1.2598563  0.47936413]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.552015075707459e-06, Loss Weights: [1.2610313 1.260108  0.4788608]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.8287238365010126e-06, Loss Weights: [1.2612655  1.260342   0.47839236]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.8644049052672926e-06, Loss Weights: [1.2614849  1.2605612  0.47795397]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 1.9351698483660584e-06, Loss Weights: [1.2616911 1.2607673 0.4775415]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 3.5721850508707576e-06, Loss Weights: [1.2618866 1.2609627 0.4771506]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.7818907710752683e-06, Loss Weights: [1.2620732 1.2611492 0.4767776]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.979826831506216e-06, Loss Weights: [1.2622523  1.2613282  0.47641924]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.2789738522988046e-06, Loss Weights: [1.2624257 1.2615014 0.4760728]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.5463032216066495e-06, Loss Weights: [1.2625942  1.2616699  0.47573572]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.6929189971269807e-06, Loss Weights: [1.2627594  1.261835   0.47540572]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.4484718323947163e-06, Loss Weights: [1.2629219  1.2619973  0.47508067]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.313456207048148e-06, Loss Weights: [1.263083   1.2621583  0.47475898]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.8938632112840423e-06, Loss Weights: [1.263243  1.2623181 0.4744386]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 3.191057203366654e-06, Loss Weights: [1.2634035 1.2624786 0.474118 ]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.450065039738547e-06, Loss Weights: [1.2635647  1.2626396  0.47379565]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.0027748632855946e-06, Loss Weights: [1.2637272  1.2628021  0.47347063]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 1.8023550865109428e-06, Loss Weights: [1.2638915  1.2629662  0.47314233]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.3099819372873753e-06, Loss Weights: [1.2640578  1.2631325  0.47280985]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.394230705249356e-06, Loss Weights: [1.2642266  1.2633011  0.47247225]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.398341166554019e-06, Loss Weights: [1.2643985 1.2634728 0.4721288]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 1.8260411707160529e-06, Loss Weights: [1.2645733  1.2636476  0.47177905]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 4.434698894328903e-06, Loss Weights: [1.2647524  1.2638264  0.47142124]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.098350705637131e-06, Loss Weights: [1.2649356  1.2640095  0.47105503]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.5109843591053504e-06, Loss Weights: [1.2651232  1.264197   0.47067994]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.3581826553709107e-06, Loss Weights: [1.2653155  1.2643892  0.47029555]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.5160409222735325e-06, Loss Weights: [1.2655125  1.264586   0.46990138]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.1504304186237277e-06, Loss Weights: [1.2657146  1.2647879  0.46949726]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.056067614830681e-06, Loss Weights: [1.265922   1.2649951  0.46908307]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 3.097794660789077e-06, Loss Weights: [1.2661345 1.2652075 0.4686581]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.434366933812271e-06, Loss Weights: [1.2663525  1.2654253  0.46822205]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 4.352408723207191e-06, Loss Weights: [1.2665768  1.2656494  0.46777374]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 5.117540695209755e-06, Loss Weights: [1.2668079 1.2658805 0.4673115]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 3.114406126769609e-06, Loss Weights: [1.2670463  1.2661186  0.46683514]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 3.4614920423337026e-06, Loss Weights: [1.2672919 1.2663641 0.466344 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.808955059663276e-06, Loss Weights: [1.267545  1.266617  0.4658382]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.8071090127923526e-06, Loss Weights: [1.2678053 1.2668772 0.4653175]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.0780669274245156e-06, Loss Weights: [1.268073   1.2671447  0.46478224]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.6348936899012187e-06, Loss Weights: [1.268348  1.2674195 0.4642325]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.4410142032138538e-06, Loss Weights: [1.2686301  1.2677015  0.46366835]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.029414190474199e-06, Loss Weights: [1.2689193  1.2679906  0.46309006]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.509135811123997e-06, Loss Weights: [1.2692157  1.2682867  0.46249768]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.0796960598090664e-06, Loss Weights: [1.269519  1.2685897 0.4618914]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 4.964547770214267e-06, Loss Weights: [1.2698298  1.2689004  0.46126986]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.608744125609519e-06, Loss Weights: [1.2701482  1.2692187  0.46063316]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 3.262940026615979e-06, Loss Weights: [1.2704743  1.2695447  0.45998102]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.177162969019264e-06, Loss Weights: [1.2708081 1.2698783 0.4593137]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.641745822984376e-06, Loss Weights: [1.2711494 1.2702193 0.4586312]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.557522520874045e-06, Loss Weights: [1.2714983  1.2705679  0.45793366]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.6277862161805388e-06, Loss Weights: [1.2718546 1.2709241 0.4572211]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.3373547719529597e-06, Loss Weights: [1.2722185  1.2712877  0.45649368]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.481506726326188e-06, Loss Weights: [1.2725897  1.2716587  0.45575154]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.348874659219291e-06, Loss Weights: [1.2729683 1.2720369 0.4549948]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.3912759843369713e-06, Loss Weights: [1.273354  1.2724224 0.4542235]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 4.759514467878034e-06, Loss Weights: [1.2737477  1.2728157  0.45343646]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.333497832296416e-06, Loss Weights: [1.2741491  1.2732168  0.45263395]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.2545266347151482e-06, Loss Weights: [1.2745581  1.2736256  0.45181623]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.1562800611718558e-06, Loss Weights: [1.2749746  1.2740418  0.45098358]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.5490974167041713e-06, Loss Weights: [1.2753985  1.2744653  0.45013607]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.2829617591924034e-06, Loss Weights: [1.2758298  1.2748964  0.44927388]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.4797011519694934e-06, Loss Weights: [1.2762684 1.2753346 0.4483971]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 1.92174320545746e-06, Loss Weights: [1.276714   1.27578    0.44750595]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.7284302177577047e-06, Loss Weights: [1.277167   1.2762326  0.44660044]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.076434384434833e-06, Loss Weights: [1.2776269 1.2766923 0.4456808]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.2107183212938253e-06, Loss Weights: [1.2780938  1.277159   0.44474718]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.3803484054951696e-06, Loss Weights: [1.2785678  1.2776325  0.44379961]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.6263815016136505e-06, Loss Weights: [1.2790488  1.2781131  0.44283798]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.2194853954715654e-06, Loss Weights: [1.2795368  1.2786008  0.44186246]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.125850187439937e-06, Loss Weights: [1.2800317  1.2790952  0.44087315]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 1.7896618373924866e-06, Loss Weights: [1.2805332  1.2795963  0.43987042]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.8023612230754225e-06, Loss Weights: [1.2810416  1.2801044  0.43885404]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 3.0720304948772537e-06, Loss Weights: [1.281557  1.2806194 0.4378236]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.146237420674879e-06, Loss Weights: [1.2820793  1.2811414  0.43677926]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.765977114904672e-06, Loss Weights: [1.2826087  1.2816705  0.43572083]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.3097177290765103e-06, Loss Weights: [1.2831451 1.2822064 0.4346484]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.0660540940298233e-06, Loss Weights: [1.2836884 1.2827494 0.4335622]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.336880925213336e-06, Loss Weights: [1.2842386  1.2832992  0.43246222]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.1870669115742203e-06, Loss Weights: [1.2847955  1.2838558  0.43134865]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.0945083178958157e-06, Loss Weights: [1.2853591 1.2844191 0.4302216]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.0915435925417114e-06, Loss Weights: [1.2859296 1.2849891 0.4290812]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.4980606667668326e-06, Loss Weights: [1.2865067 1.2855659 0.4279274]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.2216681827558205e-06, Loss Weights: [1.2870905  1.2861493  0.42676026]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.326829417143017e-06, Loss Weights: [1.287681   1.2867393  0.42557973]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 1.946937118191272e-06, Loss Weights: [1.2882781  1.2873361  0.42438602]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 1.9723627247003606e-06, Loss Weights: [1.2888815  1.2879391  0.42317933]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 1.8162652395403711e-06, Loss Weights: [1.2894914  1.2885486  0.42195994]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 3.1812132874620147e-06, Loss Weights: [1.290108   1.2891648  0.42072728]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 1.9206368051527534e-06, Loss Weights: [1.290731   1.2897874  0.41948158]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.314210860276944e-06, Loss Weights: [1.2913607 1.2904167 0.4182228]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 4.1456264625594486e-06, Loss Weights: [1.2919974 1.2910528 0.4169498]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 1.8097073279932374e-06, Loss Weights: [1.292641 1.291696 0.415663]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 34, Total Loss: 2.4018142994464142e-06, Loss Weights: [1.2932916  1.292346   0.41436243]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 35\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.710914941417286e-06, Loss Weights: [1.2938782  1.2929323  0.41318953]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.7798471364803845e-06, Loss Weights: [1.2944084  1.293462   0.41212958]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 3.389735184100573e-06, Loss Weights: [1.2948887 1.293942  0.4111693]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.4514724827895407e-06, Loss Weights: [1.2953249  1.2943778  0.41029727]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.6613565751176793e-06, Loss Weights: [1.295722   1.2947748  0.40950316]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.7941008536581649e-06, Loss Weights: [1.2960846  1.2951372  0.40877813]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.8209517520517693e-06, Loss Weights: [1.2964169 1.2954692 0.4081142]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.1559926608460955e-06, Loss Weights: [1.296722   1.2957742  0.40750384]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.4120593025145354e-06, Loss Weights: [1.2970039  1.2960558  0.40694034]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.316790641998523e-06, Loss Weights: [1.2972653  1.2963171  0.40641752]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.5276879114244366e-06, Loss Weights: [1.2975092 1.2965609 0.4059298]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.0907059479213785e-06, Loss Weights: [1.2977381  1.2967896  0.40547234]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.5792337510210928e-06, Loss Weights: [1.2979541  1.2970055  0.40504047]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.7849272353487322e-06, Loss Weights: [1.2981591  1.2972103  0.40463048]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.3795353172317846e-06, Loss Weights: [1.2983551  1.2974062  0.40423876]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.7209124507644447e-06, Loss Weights: [1.2985433  1.2975943  0.40386236]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.9803344457614003e-06, Loss Weights: [1.2987254  1.2977762  0.40349853]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.0382115053507732e-06, Loss Weights: [1.2989023 1.297953  0.4031446]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.8287514649273362e-06, Loss Weights: [1.2990756 1.2981261 0.4027985]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 3.09703955281293e-06, Loss Weights: [1.2992462  1.2982966  0.40245736]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 3.5839411793858744e-06, Loss Weights: [1.2994156  1.2984658  0.40211838]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.806463271554094e-06, Loss Weights: [1.2995851 1.2986352 0.4017797]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.4164935439330293e-06, Loss Weights: [1.2997552  1.2988052  0.40143952]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.9109500044578454e-06, Loss Weights: [1.2999268  1.2989765  0.40109682]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.9148635601595743e-06, Loss Weights: [1.3001     1.2991495  0.40075058]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 3.711257477334584e-06, Loss Weights: [1.3002758  1.2993252  0.40039873]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.8421816321279039e-06, Loss Weights: [1.300455   1.2995043  0.40004075]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.7454067346989177e-06, Loss Weights: [1.3006374 1.2996866 0.3996759]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.7248909216505126e-06, Loss Weights: [1.3008236  1.2998726  0.39930385]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.7102439642258105e-06, Loss Weights: [1.3010135  1.3000623  0.39892414]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.1910334453423275e-06, Loss Weights: [1.3012075  1.3002563  0.39853615]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 3.6695253129437333e-06, Loss Weights: [1.3014066  1.3004551  0.39813823]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.8323770518691163e-06, Loss Weights: [1.3016108 1.3006592 0.3977302]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.4861165027468815e-06, Loss Weights: [1.3018199 1.3008682 0.397312 ]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.636722458897566e-06, Loss Weights: [1.3020341  1.3010821  0.39688355]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.2394781353796134e-06, Loss Weights: [1.3022538  1.3013017  0.39644453]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.9949557099607773e-06, Loss Weights: [1.3024789  1.3015265  0.39599445]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.02183264264022e-06, Loss Weights: [1.3027097  1.3017571  0.39553326]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.6084335331688635e-06, Loss Weights: [1.3029463  1.3019935  0.39506018]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.350299610043294e-06, Loss Weights: [1.303189   1.3022361  0.39457485]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.9528220036590938e-06, Loss Weights: [1.303438  1.3024848 0.3940772]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.9259523469372652e-06, Loss Weights: [1.303693  1.3027396 0.3935672]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.462550128257135e-06, Loss Weights: [1.3039546  1.3030009  0.39304438]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.996602804865688e-06, Loss Weights: [1.3042226  1.3032687  0.39250866]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.5336362366724643e-06, Loss Weights: [1.3044969  1.3035427  0.39196032]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.142698804163956e-06, Loss Weights: [1.3047776  1.3038234  0.39139912]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.7726167698128847e-06, Loss Weights: [1.3050647  1.3041103  0.39082512]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.7668928649072768e-06, Loss Weights: [1.305358  1.3044035 0.3902384]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.7784684587240918e-06, Loss Weights: [1.3056579  1.3047031  0.38963908]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.6313125570377451e-06, Loss Weights: [1.3059638  1.3050089  0.38902724]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.2926392375666182e-06, Loss Weights: [1.3062762  1.3053212  0.38840255]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.5999979698099196e-06, Loss Weights: [1.3065953  1.3056402  0.38776454]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.9925375909224385e-06, Loss Weights: [1.306921   1.3059657  0.38711312]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.0550853605527664e-06, Loss Weights: [1.3072537  1.3062981  0.38644832]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.880244781204965e-06, Loss Weights: [1.3075929  1.306637   0.38577008]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.1970113266434055e-06, Loss Weights: [1.3079389 1.3069829 0.3850783]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.7811015595725621e-06, Loss Weights: [1.3082917 1.3073354 0.384373 ]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.8122209439752623e-06, Loss Weights: [1.3086511  1.3076946  0.38365436]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.792559146451822e-06, Loss Weights: [1.3090172  1.3080604  0.38292244]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.4469688924000366e-06, Loss Weights: [1.3093902  1.308433   0.38217694]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.563923089837772e-06, Loss Weights: [1.3097701  1.3088126  0.38141733]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.444485744490521e-06, Loss Weights: [1.3101573  1.3091995  0.38064337]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.0684626633737935e-06, Loss Weights: [1.3105516  1.3095934  0.37985504]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 4.635498498828383e-06, Loss Weights: [1.310954   1.3099955  0.37905058]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.0152190245426027e-06, Loss Weights: [1.3113643  1.3104055  0.37823018]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.044074335572077e-06, Loss Weights: [1.3117825  1.3108234  0.37739405]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.1828172975801863e-06, Loss Weights: [1.3122087  1.3112493  0.37654215]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.6512516367583885e-06, Loss Weights: [1.3126425  1.3116827  0.37567493]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.7989171965382411e-06, Loss Weights: [1.3130836  1.3121235  0.37479267]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.7977915831579594e-06, Loss Weights: [1.3135324  1.312572   0.37389562]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.7885743091028417e-06, Loss Weights: [1.3139883 1.3130276 0.372984 ]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.2495153189083794e-06, Loss Weights: [1.3144517  1.3134907  0.37205762]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.7826074554250226e-06, Loss Weights: [1.3149223  1.313961   0.37111676]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.6225917534029577e-06, Loss Weights: [1.3154001  1.3144385  0.37016165]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.480354058003286e-06, Loss Weights: [1.3158848  1.3149228  0.36919272]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.83067447526264e-06, Loss Weights: [1.3163764  1.3154142  0.36820924]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.6003465361791314e-06, Loss Weights: [1.3168755  1.3159128  0.36721167]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.9045641010961845e-06, Loss Weights: [1.3173815  1.3164186  0.36619997]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.4874952967147692e-06, Loss Weights: [1.3178942  1.3169311  0.36517447]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.568550942465663e-06, Loss Weights: [1.318414   1.3174505  0.36413556]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.7660277080722153e-06, Loss Weights: [1.3189403  1.3179765  0.36308324]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.210627371823648e-06, Loss Weights: [1.3194734  1.3185092  0.36201724]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.509610456196242e-06, Loss Weights: [1.3200133  1.3190488  0.36093792]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.309242972842185e-06, Loss Weights: [1.32056    1.3195951  0.35984492]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.8429539068165468e-06, Loss Weights: [1.3211135  1.3201482  0.35873824]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.0692439193226164e-06, Loss Weights: [1.321674  1.3207083 0.3576178]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.4933046941223438e-06, Loss Weights: [1.3222412  1.321275   0.35648394]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.1092905626574066e-06, Loss Weights: [1.3228151  1.3218485  0.35533643]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.809755644899269e-06, Loss Weights: [1.3233958 1.3224288 0.3541754]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.5493011460421258e-06, Loss Weights: [1.3239832  1.3230158  0.35300094]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.3867698953617946e-06, Loss Weights: [1.3245771  1.3236092  0.35181352]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.038844513663207e-06, Loss Weights: [1.3251777  1.3242092  0.35061294]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.0416291590663604e-06, Loss Weights: [1.3257849 1.3248161 0.3493991]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.218810095655499e-06, Loss Weights: [1.3263988  1.3254296  0.34817156]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.427681809218484e-06, Loss Weights: [1.3270195 1.3260496 0.3469308]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.7447144955440308e-06, Loss Weights: [1.3276467  1.3266765  0.34567684]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.266525825689314e-06, Loss Weights: [1.3282808  1.32731    0.34440932]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.3287188949107076e-06, Loss Weights: [1.3289213  1.32795    0.34312862]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 2.168022547266446e-06, Loss Weights: [1.3295686  1.3285968  0.34183455]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 35, Total Loss: 1.7565696452948032e-06, Loss Weights: [1.3302226  1.3292503  0.34052715]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 36\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.7514248611405492e-06, Loss Weights: [1.3308122 1.3298395 0.3393484]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.6226155139520415e-06, Loss Weights: [1.3313446  1.3303715  0.33828402]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.8603276430440019e-06, Loss Weights: [1.3318262 1.3308527 0.3373211]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 2.1050516352261184e-06, Loss Weights: [1.3322629  1.331289   0.33644804]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 2.427493882350973e-06, Loss Weights: [1.33266    1.3316859  0.33565408]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.4875917031531571e-06, Loss Weights: [1.333022   1.3320477  0.33493018]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.587150677551108e-06, Loss Weights: [1.3333533  1.3323787  0.33426812]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.6742555999371689e-06, Loss Weights: [1.3336571  1.3326824  0.33366045]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.635714966141677e-06, Loss Weights: [1.3339372  1.3329623  0.33310044]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.6902145034691785e-06, Loss Weights: [1.3341966 1.3332214 0.3325821]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.6623864667053567e-06, Loss Weights: [1.3344377  1.3334625  0.33209988]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.5402109738715808e-06, Loss Weights: [1.3346633  1.3336878  0.33164904]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 4.762514890899183e-06, Loss Weights: [1.3348765  1.3339009  0.33122256]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 2.1317318896763027e-06, Loss Weights: [1.3350797 1.3341038 0.3308164]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.9819278804789064e-06, Loss Weights: [1.3352746  1.3342985  0.33042687]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.982952198886778e-06, Loss Weights: [1.3354627  1.3344865  0.33005077]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.6916490039875498e-06, Loss Weights: [1.3356454  1.3346691  0.32968536]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.5382647688966244e-06, Loss Weights: [1.3358241 1.3348477 0.3293283]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.9211508970329305e-06, Loss Weights: [1.3359997  1.3350232  0.32897723]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 3.2657837891747477e-06, Loss Weights: [1.3361739  1.3351972  0.32862884]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.4001686849951511e-06, Loss Weights: [1.3363475 1.3353707 0.3282818]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 4.1503813008603174e-06, Loss Weights: [1.3365222  1.3355453  0.32793254]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.9026480231332243e-06, Loss Weights: [1.3366988  1.3357216  0.32757974]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.304026341131248e-06, Loss Weights: [1.3368772  1.3359     0.32722265]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.4509878383250907e-06, Loss Weights: [1.3370585  1.336081   0.32686055]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.7475508684583474e-06, Loss Weights: [1.3372426 1.336265  0.3264924]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.6707169834262459e-06, Loss Weights: [1.33743   1.3364522 0.3261175]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.4727727375429822e-06, Loss Weights: [1.3376215  1.3366435  0.32573527]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.5089790394995362e-06, Loss Weights: [1.3378165 1.3368382 0.3253451]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.359328962280415e-06, Loss Weights: [1.3380158  1.3370373  0.32494676]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.7313761873083422e-06, Loss Weights: [1.3382195  1.3372409  0.32453957]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 2.4993994429678423e-06, Loss Weights: [1.3384283 1.3374494 0.3241223]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.3618212051369483e-06, Loss Weights: [1.3386421  1.3376632  0.32369485]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.505538079982216e-06, Loss Weights: [1.3388611  1.337882   0.32325688]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 2.1497351099242223e-06, Loss Weights: [1.3390858 1.3381065 0.3228077]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.8064284859065083e-06, Loss Weights: [1.3393164  1.338337   0.32234693]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.4319064121082192e-06, Loss Weights: [1.3395526  1.338573   0.32187444]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.8906316654465627e-06, Loss Weights: [1.339795   1.3388152  0.32138982]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 2.0914990273013245e-06, Loss Weights: [1.3400438 1.3390638 0.3208925]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.4936814523025532e-06, Loss Weights: [1.3402988  1.3393186  0.32038248]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.6724554825486848e-06, Loss Weights: [1.3405604  1.33958    0.31985962]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 2.5097008347074734e-06, Loss Weights: [1.3408288 1.3398482 0.319323 ]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.7011577710945858e-06, Loss Weights: [1.3411041 1.3401234 0.3187726]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.5066740388647304e-06, Loss Weights: [1.3413862  1.3404052  0.31820843]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.2338240367171238e-06, Loss Weights: [1.3416752 1.340694  0.3176309]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.3100600426696474e-06, Loss Weights: [1.3419707 1.3409892 0.3170401]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.6223565353357117e-06, Loss Weights: [1.3422728  1.3412911  0.31643593]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.421951765223639e-06, Loss Weights: [1.3425817 1.3415997 0.3158186]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.3498838598025031e-06, Loss Weights: [1.342897   1.3419147  0.31518817]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.5145927818593918e-06, Loss Weights: [1.343219   1.3422364  0.31454465]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.5763394003442954e-06, Loss Weights: [1.3435475 1.3425646 0.3138879]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.2647209359784028e-06, Loss Weights: [1.3438824  1.3428993  0.31321818]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.2508169220382115e-06, Loss Weights: [1.3442239 1.3432405 0.3125357]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 2.516117547202157e-06, Loss Weights: [1.344572  1.3435884 0.3118395]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.3347413414521725e-06, Loss Weights: [1.3449271 1.3439431 0.3111298]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.5084625601957669e-06, Loss Weights: [1.3452889  1.3443047  0.31040663]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.7062096731024212e-06, Loss Weights: [1.3456573  1.3446729  0.30966973]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 3.901452600985067e-06, Loss Weights: [1.3460338  1.345049   0.30891714]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.407809577358421e-06, Loss Weights: [1.3464179  1.3454329  0.30814913]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.6050191788963275e-06, Loss Weights: [1.3468096  1.3458242  0.30736583]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 2.52957238444651e-06, Loss Weights: [1.3472097  1.346224   0.30656657]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.2079756288585486e-06, Loss Weights: [1.3476171  1.346631   0.30575174]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 2.2713968519383343e-06, Loss Weights: [1.3480327 1.3470464 0.304921 ]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.3328233308129711e-06, Loss Weights: [1.348456   1.3474693  0.30407467]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.3781645975541323e-06, Loss Weights: [1.348887   1.3478999  0.30321312]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.5640277979400707e-06, Loss Weights: [1.3493255 1.3483381 0.3023364]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.7327449768345105e-06, Loss Weights: [1.3497715  1.3487839  0.30144447]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.4143308817438083e-06, Loss Weights: [1.3502252  1.3492372  0.30053765]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.1864274256367935e-06, Loss Weights: [1.3506861  1.3496977  0.29961625]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.2847110610891832e-06, Loss Weights: [1.3511541  1.3501654  0.29868057]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.1922536486963509e-06, Loss Weights: [1.351629 1.35064  0.297731]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.1676839903884684e-06, Loss Weights: [1.3521107  1.3511214  0.29676783]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 2.9038023967586923e-06, Loss Weights: [1.3525999  1.3516103  0.29578978]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.7763346704668947e-06, Loss Weights: [1.3530967 1.3521068 0.2947967]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.931694669110584e-06, Loss Weights: [1.353601   1.3526107  0.29378834]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.8569638768894947e-06, Loss Weights: [1.3541131  1.3531224  0.29276448]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.308625542151276e-06, Loss Weights: [1.3546329  1.3536417  0.29172555]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.5994362456694944e-06, Loss Weights: [1.3551599  1.3541684  0.29067147]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.5101859389687888e-06, Loss Weights: [1.3556948  1.3547028  0.28960246]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.3987790907776798e-06, Loss Weights: [1.3562368  1.3552445  0.28851867]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.3706323898077244e-06, Loss Weights: [1.3567863  1.3557935  0.28742033]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.4702372936881147e-06, Loss Weights: [1.3573428 1.3563497 0.2863075]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.1309668934700312e-06, Loss Weights: [1.3579065 1.3569129 0.2851806]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.476214265494491e-06, Loss Weights: [1.3584771  1.3574831  0.28403962]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.4073327747610165e-06, Loss Weights: [1.3590548  1.3580605  0.28288472]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.2589563311848906e-06, Loss Weights: [1.3596394  1.3586446  0.28171608]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.5374313306892873e-06, Loss Weights: [1.3602308 1.3592356 0.2805336]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.5157340840232791e-06, Loss Weights: [1.3608291 1.3598335 0.2793373]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 4.277540938346647e-06, Loss Weights: [1.3614359  1.3604398  0.27812445]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.440867208657437e-06, Loss Weights: [1.3620505  1.3610541  0.27689534]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.140334461524617e-06, Loss Weights: [1.3626733  1.3616763  0.27565062]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 2.3975971998879686e-06, Loss Weights: [1.363304   1.3623066  0.27438945]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.2287846402614377e-06, Loss Weights: [1.3639427  1.3629448  0.27311236]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.2808442306777579e-06, Loss Weights: [1.3645893  1.363591   0.27181977]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.4375734735949663e-06, Loss Weights: [1.3652434  1.3642447  0.27051184]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.2456301874408382e-06, Loss Weights: [1.3659052  1.364906   0.26918897]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.2952116321685025e-06, Loss Weights: [1.3665742  1.3655745  0.26785138]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.396418156218715e-06, Loss Weights: [1.3672504  1.3662503  0.26649922]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.6864250937942415e-06, Loss Weights: [1.3679341 1.3669335 0.2651323]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 36, Total Loss: 1.0859050689759897e-06, Loss Weights: [1.368625   1.3676238  0.26375115]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 37\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 8.883385476110561e-07, Loss Weights: [1.3692476  1.3682458  0.26250646]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.2528605566330953e-06, Loss Weights: [1.3698095 1.3688073 0.261383 ]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.1444866458987235e-06, Loss Weights: [1.3703175  1.3693149  0.26036763]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.2136844134147395e-06, Loss Weights: [1.3707772 1.3697743 0.2594483]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.0357011888117995e-06, Loss Weights: [1.3711944  1.3701912  0.25861448]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.0804612884385278e-06, Loss Weights: [1.3715734  1.3705701  0.25785655]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.4849420040263794e-06, Loss Weights: [1.371919   1.3709154  0.25716543]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.3285532531881472e-06, Loss Weights: [1.3722353  1.3712314  0.25653312]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.3119018831275753e-06, Loss Weights: [1.3725259  1.3715218  0.25595236]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.2430970173227252e-06, Loss Weights: [1.3727939 1.3717896 0.2554167]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.0859708936550305e-06, Loss Weights: [1.373042   1.3720375  0.25492048]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.0343201211071573e-06, Loss Weights: [1.3732729 1.3722683 0.2544587]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.184908001050644e-06, Loss Weights: [1.373489   1.3724843  0.25402665]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.3087962997815339e-06, Loss Weights: [1.3736925 1.3726876 0.25362  ]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.6331657661794452e-06, Loss Weights: [1.3738853 1.3728802 0.2532344]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.1264930890320102e-06, Loss Weights: [1.3740695  1.3730642  0.25286657]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.738663854666811e-06, Loss Weights: [1.3742464 1.373241  0.2525128]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.9022081687580794e-06, Loss Weights: [1.374418  1.3734124 0.2521697]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.5614587027812377e-06, Loss Weights: [1.3745856  1.3735797  0.25183445]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.0296186019331799e-06, Loss Weights: [1.3747504  1.3737444  0.25150514]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.6158008975253324e-06, Loss Weights: [1.3749135 1.3739073 0.2511794]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 2.43270437749743e-06, Loss Weights: [1.375076  1.3740698 0.2508542]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.7610703935133643e-06, Loss Weights: [1.3752394  1.374233   0.25052753]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.3258120361570036e-06, Loss Weights: [1.3754042  1.3743978  0.25019813]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.1648365898508928e-06, Loss Weights: [1.3755708  1.3745643  0.24986489]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.412889787388849e-06, Loss Weights: [1.37574    1.3747334  0.24952668]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.2937335895912838e-06, Loss Weights: [1.3759122  1.3749055  0.24918249]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.2813900411856594e-06, Loss Weights: [1.3760875  1.3750808  0.24883151]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.251720050277072e-06, Loss Weights: [1.376267   1.37526    0.24847305]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 3.768287569982931e-06, Loss Weights: [1.3764518  1.3754448  0.24810359]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.453201548429206e-06, Loss Weights: [1.3766423 1.3756351 0.2477226]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.0807999615281005e-06, Loss Weights: [1.3768387  1.3758314  0.24733001]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 2.0476659301493783e-06, Loss Weights: [1.3770413  1.3760339  0.24692467]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.2284111789995222e-06, Loss Weights: [1.3772506  1.3762431  0.24650648]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.043689735524822e-06, Loss Weights: [1.377466   1.3764584  0.24607547]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.6936469364736695e-06, Loss Weights: [1.3776883  1.3766806  0.24563102]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.2646540881178225e-06, Loss Weights: [1.3779174  1.3769095  0.24517304]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.6671356206643395e-06, Loss Weights: [1.3781536  1.3771454  0.24470092]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.2946208016728633e-06, Loss Weights: [1.3783969  1.3773885  0.24421462]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 2.1612811451632297e-06, Loss Weights: [1.3786478  1.3776393  0.24371307]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 2.6993816391041037e-06, Loss Weights: [1.3789071  1.3778985  0.24319467]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.4142382269710652e-06, Loss Weights: [1.3791747  1.378166   0.24265948]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.2800084050468286e-06, Loss Weights: [1.3794506  1.3784417  0.24210767]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.3613632745546056e-06, Loss Weights: [1.3797348  1.3787258  0.24153933]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.3138741223883699e-06, Loss Weights: [1.3800274 1.3790182 0.2409546]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.005039734991442e-06, Loss Weights: [1.3803278  1.3793182  0.24035387]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.1753400031011552e-06, Loss Weights: [1.3806362  1.3796263  0.23973739]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.1237531225560815e-06, Loss Weights: [1.3809524 1.3799423 0.2391054]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.2101650099793915e-06, Loss Weights: [1.3812762 1.380266  0.238458 ]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.023456889015506e-06, Loss Weights: [1.3816075  1.380597   0.23779549]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.218715510731272e-06, Loss Weights: [1.3819464  1.3809357  0.23711796]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.2050251143591595e-06, Loss Weights: [1.3822927  1.3812817  0.23642546]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 2.122574187524151e-06, Loss Weights: [1.3826472 1.381636  0.235717 ]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.363130195386475e-06, Loss Weights: [1.3830094  1.3819981  0.23499244]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.2768724673151155e-06, Loss Weights: [1.3833798  1.3823681  0.23425195]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.0837949275810388e-06, Loss Weights: [1.3837582  1.3827461  0.23349577]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.0843481277333922e-06, Loss Weights: [1.3841441  1.3831317  0.23272413]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.1872130016854499e-06, Loss Weights: [1.3845378  1.3835251  0.23193718]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.1270598179180524e-06, Loss Weights: [1.3849391  1.383926   0.23113503]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.1723116131179268e-06, Loss Weights: [1.3853477  1.3843343  0.23031776]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.2227920933582936e-06, Loss Weights: [1.3857641  1.3847504  0.22948545]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 8.104224775706825e-07, Loss Weights: [1.3861878  1.3851738  0.22863856]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 9.024368523569137e-07, Loss Weights: [1.3866185  1.3856041  0.22777736]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.5302595102184569e-06, Loss Weights: [1.3870566  1.3860419  0.22690147]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.300694748351816e-06, Loss Weights: [1.3875022  1.3864871  0.22601074]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.1693941814883146e-06, Loss Weights: [1.3879551  1.3869398  0.22510515]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.1205964938199031e-06, Loss Weights: [1.3884155  1.3873998  0.22418484]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.1064765885748784e-06, Loss Weights: [1.3888831  1.387867   0.22324982]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.4639967957918998e-06, Loss Weights: [1.3893583  1.3883419  0.22229981]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 9.192147558678698e-07, Loss Weights: [1.3898408  1.388824   0.22133508]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.72063175796211e-06, Loss Weights: [1.390331   1.3893139  0.22035496]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.314424594056618e-06, Loss Weights: [1.3908291  1.3898116  0.21935932]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.9550857359718066e-06, Loss Weights: [1.3913352  1.3903174  0.21834722]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.1618382131928229e-06, Loss Weights: [1.3918495  1.3908315  0.21731883]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 8.994516633720195e-07, Loss Weights: [1.3923718  1.3913534  0.21627465]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.0143380677618552e-06, Loss Weights: [1.3929019  1.3918831  0.21521494]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.16981755127199e-06, Loss Weights: [1.3934397  1.3924205  0.21413973]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.1695181001414312e-06, Loss Weights: [1.3939852  1.3929657  0.21304905]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 9.450215543438389e-07, Loss Weights: [1.3945383  1.3935184  0.21194324]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.0997628123732284e-06, Loss Weights: [1.3950989  1.3940787  0.21082237]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.048776994139189e-06, Loss Weights: [1.3956671  1.3946464  0.20968658]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 9.864637604550808e-07, Loss Weights: [1.3962425  1.3952215  0.20853606]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 2.2656668079434894e-06, Loss Weights: [1.396826  1.3958046 0.2073693]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 8.635448693894432e-07, Loss Weights: [1.3974175 1.3963957 0.2061868]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.5653408809157554e-06, Loss Weights: [1.398017   1.3969948  0.20498805]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 9.203075705954689e-07, Loss Weights: [1.3986245  1.397602   0.20377345]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 9.809155017137527e-07, Loss Weights: [1.39924   1.3982168 0.2025433]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.112683776227641e-06, Loss Weights: [1.399863   1.3988395  0.20129764]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 2.000245558519964e-06, Loss Weights: [1.4004943 1.3994703 0.2000353]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 9.436258210371307e-07, Loss Weights: [1.401134   1.4001094  0.19875675]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.0421373417557334e-06, Loss Weights: [1.4017816  1.4007564  0.19746214]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 9.064438586392498e-07, Loss Weights: [1.4024369  1.4014112  0.19615191]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 9.718086175780627e-07, Loss Weights: [1.4030999  1.4020737  0.19482628]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 2.8910583296237746e-06, Loss Weights: [1.4037719  1.4027454  0.19348276]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 2.1387777451309375e-06, Loss Weights: [1.4044534  1.4034264  0.19212016]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 8.738100518712599e-07, Loss Weights: [1.4051442  1.4041166  0.19073927]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 1.3335808262127102e-06, Loss Weights: [1.4058441  1.404816   0.18934003]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 9.64977061812533e-07, Loss Weights: [1.4065528  1.4055243  0.18792294]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 9.741221447256976e-07, Loss Weights: [1.4072703  1.4062413  0.18648851]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 37, Total Loss: 8.15349835647794e-07, Loss Weights: [1.4079962 1.4069664 0.1850373]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 38\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.160329798556631e-07, Loss Weights: [1.4086505 1.4076203 0.1837292]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 7.720460075688607e-07, Loss Weights: [1.4092412  1.4082105  0.18254842]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.560019182368706e-07, Loss Weights: [1.409775   1.4087439  0.18148102]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 9.658336921347654e-07, Loss Weights: [1.4102585  1.409227   0.18051435]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.338922157236084e-07, Loss Weights: [1.4106973  1.4096656  0.17963713]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 7.708772500336636e-07, Loss Weights: [1.4110963 1.4100642 0.1788393]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 7.360440577031113e-07, Loss Weights: [1.4114602  1.4104278  0.17811185]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.838225653562404e-07, Loss Weights: [1.4117931  1.4107606  0.17744642]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 9.859261353994953e-07, Loss Weights: [1.4120988  1.411066   0.17683524]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 7.976148594934784e-07, Loss Weights: [1.4123807 1.4113477 0.1762717]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.0352063100071973e-06, Loss Weights: [1.4126418  1.4116087  0.17574939]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.981132850749418e-07, Loss Weights: [1.4128852  1.411852   0.17526281]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.026129876270716e-07, Loss Weights: [1.4131131 1.4120798 0.1748071]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.98230508078268e-07, Loss Weights: [1.4133277  1.4122941  0.17437807]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.5178225112322252e-06, Loss Weights: [1.4135315 1.4124978 0.1739706]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 9.678229844212183e-07, Loss Weights: [1.4137264  1.4126925  0.17358097]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.0539203003645525e-06, Loss Weights: [1.4139142  1.4128801  0.17320567]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 9.715503210827592e-07, Loss Weights: [1.4140962  1.413062   0.17284171]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.698179504383006e-07, Loss Weights: [1.4142739  1.4132394  0.17248686]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 9.310064115197747e-07, Loss Weights: [1.414448   1.4134134  0.17213863]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.154679562721867e-07, Loss Weights: [1.4146198  1.4135851  0.17179506]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.278105383396905e-07, Loss Weights: [1.4147903  1.4137554  0.17145428]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.917301101973862e-07, Loss Weights: [1.4149603  1.4139253  0.17111453]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.949848506745184e-07, Loss Weights: [1.4151304  1.4140953  0.17077422]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 7.311732019843475e-07, Loss Weights: [1.4153016 1.4142663 0.1704322]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.0816285112014157e-06, Loss Weights: [1.4154744  1.4144391  0.17008677]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.3691195590581628e-06, Loss Weights: [1.4156497  1.4146142  0.16973597]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.677298524162325e-07, Loss Weights: [1.4158283  1.4147928  0.16937892]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 9.948099659595755e-07, Loss Weights: [1.4160106  1.4149749  0.16901451]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 7.123044838408532e-07, Loss Weights: [1.4161968  1.4151609  0.16864228]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.1345874781909515e-06, Loss Weights: [1.4163876  1.4153514  0.16826105]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 9.627751751395408e-07, Loss Weights: [1.4165831 1.4155468 0.1678701]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.5558545101157506e-06, Loss Weights: [1.4167844  1.415748   0.16746773]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.8110428072759532e-06, Loss Weights: [1.4169922  1.4159558  0.16705194]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.0428865380163188e-06, Loss Weights: [1.4172071  1.4161705  0.16662233]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.433580779230397e-07, Loss Weights: [1.4174289 1.416392  0.1661791]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 7.961224355312879e-07, Loss Weights: [1.4176574  1.4166203  0.16572224]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.95384403065691e-07, Loss Weights: [1.4178928  1.4168556  0.16525154]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.7226041109097423e-06, Loss Weights: [1.418136   1.4170986  0.16476537]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.0300684607500443e-06, Loss Weights: [1.4183869  1.4173496  0.16426349]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.21989386218047e-07, Loss Weights: [1.4186456  1.417608   0.16374633]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 7.908644192866632e-07, Loss Weights: [1.4189118  1.4178741  0.16321401]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.948449021772831e-07, Loss Weights: [1.4191856  1.4181478  0.16266647]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 9.631876309867948e-07, Loss Weights: [1.4194672  1.4184291  0.16210349]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.092170350602828e-06, Loss Weights: [1.4197567  1.4187185  0.16152465]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.95592883756035e-06, Loss Weights: [1.4200552  1.4190168  0.16092807]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.3772462352790171e-06, Loss Weights: [1.4203627  1.4193243  0.16031303]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.1165464002260705e-06, Loss Weights: [1.4206797  1.4196409  0.15967935]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 7.848654490771878e-07, Loss Weights: [1.4210058  1.4199668  0.15902749]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.714224127790658e-07, Loss Weights: [1.4213407  1.4203014  0.15835798]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.3315205933395191e-06, Loss Weights: [1.4216846  1.4206451  0.15767017]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 7.537322517237044e-07, Loss Weights: [1.4220376  1.420998   0.15696451]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.661210250058502e-07, Loss Weights: [1.4223992 1.4213593 0.1562415]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 7.007877229625592e-07, Loss Weights: [1.4227693  1.4217291  0.15550162]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.498447078229219e-07, Loss Weights: [1.4231477  1.4221071  0.15474528]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.351161682185193e-07, Loss Weights: [1.4235342  1.4224932  0.15397257]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.720561481823097e-07, Loss Weights: [1.4239289  1.4228877  0.15318345]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.0665751233318588e-06, Loss Weights: [1.4243319  1.4232905  0.15237758]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.574301659791672e-07, Loss Weights: [1.4247434  1.4237018  0.15155497]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.06507911823428e-06, Loss Weights: [1.4251634  1.4241215  0.15071528]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 7.673787649764563e-07, Loss Weights: [1.4255917  1.4245496  0.14985873]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.352203622052912e-07, Loss Weights: [1.4260285  1.424986   0.14898539]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.243583806688548e-07, Loss Weights: [1.4264737  1.425431   0.14809534]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.494980198112899e-07, Loss Weights: [1.4269271  1.425884   0.14718893]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 7.059069844217447e-07, Loss Weights: [1.4273885  1.4263451  0.14626646]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.053874370882113e-06, Loss Weights: [1.4278581 1.4268143 0.1453274]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.534374392686004e-07, Loss Weights: [1.428336   1.4272919  0.14437217]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 7.295221280401165e-07, Loss Weights: [1.4288218  1.4277773  0.14340086]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.414183530978335e-07, Loss Weights: [1.4293154  1.4282706  0.14241382]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 9.515480314803426e-07, Loss Weights: [1.4298172 1.428772  0.1414107]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.620735462092853e-07, Loss Weights: [1.4303269  1.4292814  0.14039175]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 8.005379754649766e-07, Loss Weights: [1.4308445  1.4297986  0.13935691]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.194124466674111e-07, Loss Weights: [1.4313699  1.4303236  0.13830647]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.317900442809332e-07, Loss Weights: [1.4319029  1.4308562  0.13724071]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.783842536606244e-07, Loss Weights: [1.4324436  1.4313966  0.13615976]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.870130278002762e-07, Loss Weights: [1.4329919  1.4319444  0.13506365]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 9.3004211976222e-07, Loss Weights: [1.433548   1.4325001  0.13395195]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 5.873251893717679e-07, Loss Weights: [1.4341117  1.4330634  0.13282497]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 7.466845204362471e-07, Loss Weights: [1.4346831  1.4336343  0.13168263]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.070600875318632e-07, Loss Weights: [1.4352621  1.4342128  0.13052517]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 5.301209284880315e-07, Loss Weights: [1.4358484  1.4347987  0.12935291]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 7.595010060867935e-07, Loss Weights: [1.4364421 1.4353921 0.1281657]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.001501446917246e-07, Loss Weights: [1.4370433  1.435993   0.12696372]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.146915438876022e-07, Loss Weights: [1.4376518  1.436601   0.12574705]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 5.396149163061637e-07, Loss Weights: [1.4382676  1.4372165  0.12451598]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.1362501481926301e-06, Loss Weights: [1.438891   1.4378395  0.12326934]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 7.757718663015112e-07, Loss Weights: [1.4395225  1.4384706  0.12200697]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 4.666965480737417e-07, Loss Weights: [1.4401615  1.4391091  0.12072934]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.232718305909657e-07, Loss Weights: [1.4408082  1.4397553  0.11943658]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 5.926297035330208e-07, Loss Weights: [1.4414623  1.440409   0.11812879]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 5.302721319822012e-07, Loss Weights: [1.4421239  1.44107    0.11680625]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.119435624896141e-07, Loss Weights: [1.4427927  1.4417384  0.11546896]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.94516302246484e-07, Loss Weights: [1.443469   1.4424143  0.11411676]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 4.916753937322937e-07, Loss Weights: [1.4441526  1.4430974  0.11274995]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 4.888776743428025e-07, Loss Weights: [1.4448434  1.4437876  0.11136881]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 4.823505719286914e-07, Loss Weights: [1.4455414  1.4444851  0.10997361]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 6.053675747352827e-07, Loss Weights: [1.4462463  1.4451895  0.10856422]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.2067629313605721e-06, Loss Weights: [1.4469593  1.4459019  0.10713902]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 5.989070928080764e-07, Loss Weights: [1.44768    1.446622   0.10569805]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 38, Total Loss: 1.0696310255298158e-06, Loss Weights: [1.4484092 1.4473507 0.1042401]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 39\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 6.388572160176409e-07, Loss Weights: [1.4490668  1.4480078  0.10292542]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 5.42967995897925e-07, Loss Weights: [1.4496608  1.4486014  0.10173783]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 5.399615474743769e-07, Loss Weights: [1.4501984  1.4491385  0.10066324]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 7.282166620825592e-07, Loss Weights: [1.4506859 1.4496256 0.0996884]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 5.659483122144593e-07, Loss Weights: [1.4511294  1.4500688  0.09880179]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 6.689366500722826e-07, Loss Weights: [1.451534   1.4504732  0.09799273]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.1918079318747914e-07, Loss Weights: [1.4519044  1.4508433  0.09725229]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.968767370883143e-07, Loss Weights: [1.4522448  1.4511833  0.09657219]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 6.975243991291791e-07, Loss Weights: [1.4525588  1.4514971  0.09594434]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 6.54297650726221e-07, Loss Weights: [1.4528501  1.4517883  0.09536158]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 5.988736120343674e-07, Loss Weights: [1.4531221  1.4520602  0.09481761]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 7.240385002660332e-07, Loss Weights: [1.4533778  1.4523158  0.09430636]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 7.892429607636586e-07, Loss Weights: [1.45362    1.4525578  0.09382215]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 7.802590289429645e-07, Loss Weights: [1.4538512  1.452789   0.09335988]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 7.244142352647032e-07, Loss Weights: [1.4540737 1.4530113 0.0929151]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 6.212587209120102e-07, Loss Weights: [1.4542892 1.4532267 0.0924841]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.2571983271955105e-07, Loss Weights: [1.4544992  1.4534366  0.09206418]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.954284579776868e-07, Loss Weights: [1.4547049  1.4536421  0.09165297]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 5.374527063395362e-07, Loss Weights: [1.4549074  1.4538445  0.09124789]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.6889411464690056e-07, Loss Weights: [1.4551082  1.4540452  0.09084681]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.86080301950642e-07, Loss Weights: [1.4553076  1.4542445  0.09044808]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.297787654650165e-07, Loss Weights: [1.4555066  1.4544433  0.09005006]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.186361195479549e-07, Loss Weights: [1.455706  1.4546425 0.0896513]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.522820861689979e-07, Loss Weights: [1.4559064  1.4548428  0.08925073]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 5.413139660959132e-07, Loss Weights: [1.4561085  1.4550447  0.08884672]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.204064509849559e-07, Loss Weights: [1.4563128  1.455249   0.08843822]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 5.506882985173434e-07, Loss Weights: [1.4565201  1.4554561  0.08802383]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.0750748553364247e-07, Loss Weights: [1.4567307  1.4556665  0.08760276]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.810693556260958e-07, Loss Weights: [1.456945  1.4558806 0.0871744]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.5294106598703365e-07, Loss Weights: [1.4571633  1.4560988  0.08673792]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.0874439832805365e-07, Loss Weights: [1.457386   1.4563212  0.08629271]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 6.337968443403952e-07, Loss Weights: [1.4576137  1.4565488  0.08583749]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 7.26824168850726e-07, Loss Weights: [1.4578471  1.4567821  0.08537074]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.503012351302459e-07, Loss Weights: [1.4580864  1.4570212  0.08489238]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.863319986725401e-07, Loss Weights: [1.4583317  1.4572664  0.08440188]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.9255334627341654e-07, Loss Weights: [1.4585832  1.4575179  0.08389903]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 6.806400278946967e-07, Loss Weights: [1.4588414  1.4577758  0.08338266]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.514277520684118e-07, Loss Weights: [1.4591067  1.4580408  0.08285251]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.8051490491852746e-07, Loss Weights: [1.4593787  1.4583127  0.08230858]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.879281618741516e-07, Loss Weights: [1.4596578  1.4585916  0.08175046]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.6554379196095397e-07, Loss Weights: [1.4599442  1.4588778  0.08117788]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.2030367808365554e-07, Loss Weights: [1.460238   1.4591713  0.08059072]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.8893472265044693e-07, Loss Weights: [1.460539  1.4594721 0.079989 ]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.8046627537369204e-07, Loss Weights: [1.4608473  1.4597801  0.07937272]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.322356008084171e-07, Loss Weights: [1.4611627  1.4600953  0.07874207]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.1248455318054766e-07, Loss Weights: [1.4614854  1.4604177  0.07809693]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.6493923377965984e-07, Loss Weights: [1.4618155  1.4607476  0.07743696]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.3544858385757834e-07, Loss Weights: [1.4621532  1.461085   0.07676195]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.943827948660328e-07, Loss Weights: [1.4624984  1.46143    0.07607187]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.005893063345866e-07, Loss Weights: [1.4628509  1.4617822  0.07536702]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 6.649330543950782e-07, Loss Weights: [1.4632114  1.4621425  0.07464623]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.8025481785552984e-07, Loss Weights: [1.4635798  1.4625106  0.07390959]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.977367780156783e-07, Loss Weights: [1.4639564  1.4628869  0.07315665]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.241726744818152e-07, Loss Weights: [1.464341   1.4632713  0.07238772]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.5746182902585133e-07, Loss Weights: [1.4647336 1.4636635 0.0716029]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.196435838821344e-07, Loss Weights: [1.4651341  1.4640636  0.07080202]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 5.108507821205421e-07, Loss Weights: [1.4655432  1.4644723  0.06998454]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 5.021495326218428e-07, Loss Weights: [1.4659606  1.4648894  0.06914997]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 5.120975288264162e-07, Loss Weights: [1.4663869  1.4653153  0.06829783]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.0232558856368996e-07, Loss Weights: [1.4668217  1.4657497  0.06742852]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 2.7681579695126857e-07, Loss Weights: [1.4672648  1.4661925  0.06654254]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 1.119698936236091e-06, Loss Weights: [1.467718   1.4666454  0.06563658]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 2.70421395498488e-07, Loss Weights: [1.4681808  1.4671078  0.06471138]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 2.9122369937795156e-07, Loss Weights: [1.468653   1.4675795  0.06376757]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.201500646810018e-07, Loss Weights: [1.4691342  1.4680605  0.06280546]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.1056754323799396e-07, Loss Weights: [1.4696243  1.4685502  0.06182542]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.4313902119720296e-07, Loss Weights: [1.4701234  1.469049   0.06082762]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.105271275671839e-07, Loss Weights: [1.4706312  1.4695563  0.05981229]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.475423397958366e-07, Loss Weights: [1.4711479  1.4700726  0.05877947]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 2.8782454819520353e-07, Loss Weights: [1.471673   1.4705974  0.05772945]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 2.787702158002503e-07, Loss Weights: [1.4722068  1.4711307  0.05666254]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.057781441384577e-07, Loss Weights: [1.4727489  1.4716724  0.05557881]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.3380979402863886e-07, Loss Weights: [1.4732994  1.4722226  0.05447818]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.3370957908118726e-07, Loss Weights: [1.4738584  1.4727812  0.05336053]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 2.687887104002584e-07, Loss Weights: [1.4744258 1.4733481 0.0522261]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 2.8792607054128894e-07, Loss Weights: [1.4750016  1.4739234  0.05107493]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 2.898875095525e-07, Loss Weights: [1.4755858  1.4745072  0.04990705]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 2.2216543982267467e-07, Loss Weights: [1.476178  1.475099  0.0487228]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 2.3177464925083768e-07, Loss Weights: [1.4767785  1.475699   0.04752246]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 3.8060446172494267e-07, Loss Weights: [1.4773874  1.4763074  0.04630528]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 2.1590588517028664e-07, Loss Weights: [1.4780045 1.476924  0.0450716]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 2.4631282258269493e-07, Loss Weights: [1.4786298  1.4775487  0.04382149]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 4.1597678546168027e-07, Loss Weights: [1.4792639  1.4781823  0.04255382]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 1.8309948757178063e-07, Loss Weights: [1.4799066  1.4788245  0.04126913]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 1.934227640276731e-07, Loss Weights: [1.4805574  1.4794749  0.03996776]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 1.7422765097308002e-07, Loss Weights: [1.4812164  1.4801334  0.03865015]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 1.9977296972228942e-07, Loss Weights: [1.4818835  1.4807999  0.03731643]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 2.328551147456892e-07, Loss Weights: [1.4825588  1.4814748  0.03596643]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 1.918166816494704e-07, Loss Weights: [1.4832422  1.4821576  0.03460025]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 1.90345858186447e-07, Loss Weights: [1.4839334  1.4828484  0.03321796]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 2.014485005474853e-07, Loss Weights: [1.4846331  1.4835476  0.03181946]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 1.7720083178573987e-07, Loss Weights: [1.4853406  1.4842546  0.03040477]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 2.450918259455648e-07, Loss Weights: [1.4860566  1.4849701  0.02897323]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 1.7933732010533276e-07, Loss Weights: [1.4867811 1.485694  0.0275248]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 1.1888425888173515e-07, Loss Weights: [1.4875139  1.4864262  0.02605997]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 1.3509988150417485e-07, Loss Weights: [1.4882547  1.4871664  0.02457893]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 1.3854297264970228e-07, Loss Weights: [1.4890034  1.4879147  0.02308175]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 1.5566975264391658e-07, Loss Weights: [1.4897606  1.4886713  0.02156816]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 1.1743725991664178e-07, Loss Weights: [1.490526   1.4894359  0.02003832]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 39, Total Loss: 9.03646366623434e-08, Loss Weights: [1.4912989  1.4902084  0.01849261]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 40\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 9.72085487660479e-08, Loss Weights: [1.491996   1.490905   0.01709908]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 9.046907223364542e-08, Loss Weights: [1.4926255  1.491534   0.01584062]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 1.8701911130847293e-07, Loss Weights: [1.4931958  1.4921039  0.01470039]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 7.548015190650403e-08, Loss Weights: [1.4937136  1.4926213  0.01366519]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 7.039619021043109e-08, Loss Weights: [1.4941847 1.4930922 0.0127231]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 7.664356616032819e-08, Loss Weights: [1.494615   1.4935222  0.01186312]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 6.098291294165392e-08, Loss Weights: [1.4950087  1.4939156  0.01107559]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 6.800235041737324e-08, Loss Weights: [1.495371   1.4942775  0.01035151]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 6.570321176013749e-08, Loss Weights: [1.4957055 1.4946117 0.0096827]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 4.479787207856134e-08, Loss Weights: [1.4960158  1.4949219  0.00906231]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 4.7228159161250005e-08, Loss Weights: [1.496305   1.4952109  0.00848398]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 3.7951107145772767e-08, Loss Weights: [1.4965761  1.4954817  0.00794222]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 4.0535223178039814e-08, Loss Weights: [1.4968313  1.4957368  0.00743187]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 3.5455883562462986e-08, Loss Weights: [1.497073   1.4959784  0.00694839]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 3.5419784438772695e-08, Loss Weights: [1.4973037 1.4962088 0.0064876]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 3.214116617300533e-08, Loss Weights: [1.4975246  1.4964296  0.00604576]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 4.4776179208838585e-08, Loss Weights: [1.4977381  1.496643   0.00561879]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 3.056603858908602e-08, Loss Weights: [1.4979459  1.4968505  0.00520359]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 3.658859881738863e-08, Loss Weights: [1.4981493  1.4970536  0.00479688]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 3.2263713478641876e-08, Loss Weights: [1.4983501  1.4972543  0.00439583]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 3.3242482544437735e-08, Loss Weights: [1.4985492 1.4974532 0.0039976]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 2.2471128957590736e-08, Loss Weights: [1.4987478  1.4976517  0.00360025]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 2.111355890122013e-08, Loss Weights: [1.4989473  1.4978509  0.00320195]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 1.4584909280301872e-08, Loss Weights: [1.4991475  1.498051   0.00280144]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 1.3830204537157442e-08, Loss Weights: [1.4993496  1.498253   0.00239748]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 1.4109337698187119e-08, Loss Weights: [1.4995542  1.4984574  0.00198868]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 2.0445881432351598e-08, Loss Weights: [1.4997623  1.4986655  0.00157245]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 7.519370903708023e-09, Loss Weights: [1.4999745e+00 1.4988775e+00 1.1481761e-03]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 8.203169699072532e-09, Loss Weights: [1.5001912e+00 1.4990941e+00 7.1458344e-04]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 4.637285666575508e-09, Loss Weights: [1.5004132e+00 1.4993160e+00 2.7078812e-04]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: 2.2166453117478113e-09, Loss Weights: [ 1.5006406e+00  1.4995434e+00 -1.8424852e-04]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -5.197004493417978e-10, Loss Weights: [ 1.5008743e+00  1.4997768e+00 -6.5092347e-04]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -5.144572767790123e-09, Loss Weights: [ 1.5011140e+00  1.5000165e+00 -1.1306689e-03]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -7.2265438078034094e-09, Loss Weights: [ 1.5013609   1.5002632  -0.00162424]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.6433116201142184e-08, Loss Weights: [ 1.5016155   1.5005176  -0.00213341]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -9.93694548867552e-09, Loss Weights: [ 1.501878    1.50078    -0.00265811]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.3241126417540272e-08, Loss Weights: [ 1.5021483   1.50105    -0.00319838]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.773402580340644e-08, Loss Weights: [ 1.5024265  1.501328  -0.0037544]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.8268609736082908e-08, Loss Weights: [ 1.5027125   1.5016136  -0.00432613]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -2.274798838186598e-08, Loss Weights: [ 1.5030065   1.5019072  -0.00491365]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -2.4870443482427618e-08, Loss Weights: [ 1.5033083   1.5022087  -0.00551698]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -2.6686993948032978e-08, Loss Weights: [ 1.503618    1.502518   -0.00613605]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -3.981565299682188e-08, Loss Weights: [ 1.5039357   1.5028355  -0.00677131]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -3.3344516481292885e-08, Loss Weights: [ 1.5042615   1.5031611  -0.00742269]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -4.003475240210719e-08, Loss Weights: [ 1.5045955   1.5034947  -0.00809024]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -6.094104776366294e-08, Loss Weights: [ 1.5049378   1.5038369  -0.00877469]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -4.230367878221841e-08, Loss Weights: [ 1.5052886   1.5041873  -0.00947586]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -3.979874563242447e-08, Loss Weights: [ 1.5056474   1.5045459  -0.01019338]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -8.682243901603215e-08, Loss Weights: [ 1.506015    1.5049133  -0.01092825]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -5.8264003399699504e-08, Loss Weights: [ 1.5063912  1.5052891 -0.0116804]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -6.643113437121428e-08, Loss Weights: [ 1.506776    1.5056736  -0.01244986]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -4.83025459629971e-08, Loss Weights: [ 1.5071694   1.5060668  -0.01323611]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -5.72796281517185e-08, Loss Weights: [ 1.5075707   1.506468   -0.01403884]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -7.598899998129127e-08, Loss Weights: [ 1.5079806   1.5068775  -0.01485809]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -7.58370291009669e-08, Loss Weights: [ 1.5083985   1.5072951  -0.01569377]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.318198172839402e-07, Loss Weights: [ 1.5088253   1.5077215  -0.01654684]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.0139874007109029e-07, Loss Weights: [ 1.5092608   1.5081565  -0.01741744]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.1198549998425733e-07, Loss Weights: [ 1.5097051   1.5086006  -0.01830581]\n",
      "Material 59: tensor([ 0.5391, -1.1539,  0.6148], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -7.882838559680749e-08, Loss Weights: [ 1.5101581   1.5090533  -0.01921151]\n",
      "Material 60: tensor([-0.8408,  1.1058, -0.2650], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.1712439373923189e-07, Loss Weights: [ 1.5106198   1.5095147  -0.02013468]\n",
      "Material 61: tensor([ 0.1236,  0.9325, -1.0560], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.1624409523847135e-07, Loss Weights: [ 1.5110904   1.509985   -0.02107536]\n",
      "Material 62: tensor([ 0.6790,  0.4693, -1.1483], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.0874283162820575e-07, Loss Weights: [ 1.5115696   1.5104638  -0.02203339]\n",
      "Material 63: tensor([ 1.0130, -0.0265, -0.9865], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.0105156178497054e-07, Loss Weights: [ 1.5120573   1.510951   -0.02300845]\n",
      "Material 64: tensor([ 0.7404,  0.3972, -1.1376], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.1599331628531218e-07, Loss Weights: [ 1.5125535  1.511447  -0.0240004]\n",
      "Material 65: tensor([ 1.1538, -0.6168, -0.5370], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.564883831406405e-07, Loss Weights: [ 1.5130582   1.5119514  -0.02500955]\n",
      "Material 66: tensor([-1.1086,  0.8341,  0.2745], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.2448874997517123e-07, Loss Weights: [ 1.5135713  1.5124643 -0.0260357]\n",
      "Material 67: tensor([ 0.3788, -1.1341,  0.7553], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.4181085816744599e-07, Loss Weights: [ 1.514093    1.5129857  -0.02707884]\n",
      "Material 68: tensor([ 1.0931, -0.2242, -0.8689], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.4998910558006173e-07, Loss Weights: [ 1.5146234   1.5135157  -0.02813895]\n",
      "Material 69: tensor([-0.5305, -0.6230,  1.1535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.5572373968097963e-07, Loss Weights: [ 1.5151622   1.5140541  -0.02921604]\n",
      "Material 70: tensor([-1.1522,  0.6413,  0.5109], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.2961130835265067e-07, Loss Weights: [ 1.5157092   1.5146005  -0.03030976]\n",
      "Material 71: tensor([-0.2383, -0.8593,  1.0976], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.3872961801553174e-07, Loss Weights: [ 1.5162644   1.5151553  -0.03141986]\n",
      "Material 72: tensor([ 0.3229,  0.7987, -1.1215], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.594525400605562e-07, Loss Weights: [ 1.5168278   1.5157182  -0.03254624]\n",
      "Material 73: tensor([ 0.6398, -1.1524,  0.5126], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.8237224708173017e-07, Loss Weights: [ 1.5173995   1.5162895  -0.03368899]\n",
      "Material 74: tensor([-0.5815, -0.5732,  1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.764243364732465e-07, Loss Weights: [ 1.5179794   1.5168688  -0.03484806]\n",
      "Material 75: tensor([ 0.8439,  0.2606, -1.1045], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.6168092997759231e-07, Loss Weights: [ 1.5185671   1.5174562  -0.03602322]\n",
      "Material 76: tensor([-1.0862,  0.2039,  0.8824], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.663407971363995e-07, Loss Weights: [ 1.5191628   1.5180514  -0.03721427]\n",
      "Material 77: tensor([-0.1242,  1.0563, -0.9321], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -2.0027894720442418e-07, Loss Weights: [ 1.5197666   1.5186548  -0.03842125]\n",
      "Material 78: tensor([ 0.6251, -1.1533,  0.5282], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.8170470639233827e-07, Loss Weights: [ 1.5203781  1.5192659 -0.039644 ]\n",
      "Material 79: tensor([-1.1517,  0.5040,  0.6477], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -1.9508475190832542e-07, Loss Weights: [ 1.5209974   1.5198848  -0.04088241]\n",
      "Material 80: tensor([-0.1259,  1.0570, -0.9311], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -2.10645069387283e-07, Loss Weights: [ 1.5216248   1.5205117  -0.04213648]\n",
      "Material 81: tensor([-0.1929,  1.0824, -0.8895], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -2.43176231151665e-07, Loss Weights: [ 1.52226     1.5211463  -0.04340638]\n",
      "Material 82: tensor([-1.0351,  0.9608,  0.0742], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -2.463283124143345e-07, Loss Weights: [ 1.522903    1.5217891  -0.04469223]\n",
      "Material 83: tensor([-0.6662, -0.4836,  1.1499], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -2.85387756093769e-07, Loss Weights: [ 1.5235544   1.5224401  -0.04599433]\n",
      "Material 84: tensor([ 0.3231, -1.1216,  0.7985], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -2.165562023037637e-07, Loss Weights: [ 1.5242138   1.5230988  -0.04731246]\n",
      "Material 85: tensor([-0.4208, -0.7208,  1.1416], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -2.187532430752981e-07, Loss Weights: [ 1.5248809   1.5237654  -0.04864641]\n",
      "Material 86: tensor([ 0.4033, -1.1387,  0.7354], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -2.4769710194050276e-07, Loss Weights: [ 1.5255558   1.5244399  -0.04999608]\n",
      "Material 87: tensor([-0.0223,  1.0109, -0.9887], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -2.5819838356255786e-07, Loss Weights: [ 1.5262389   1.5251226  -0.05136146]\n",
      "Material 88: tensor([ 1.1103, -0.2805, -0.8298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -2.4409951038251165e-07, Loss Weights: [ 1.5269296   1.5258129  -0.05274235]\n",
      "Material 89: tensor([-0.0167, -0.9916,  1.0082], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -2.3248122715813224e-07, Loss Weights: [ 1.527628    1.5265106  -0.05413852]\n",
      "Material 90: tensor([ 0.0206,  0.9896, -1.0101], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -2.712669413540425e-07, Loss Weights: [ 1.5283339  1.527216  -0.0555499]\n",
      "Material 91: tensor([ 1.1360, -0.7471, -0.3889], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -2.6064958547067363e-07, Loss Weights: [ 1.5290475   1.527929   -0.05697636]\n",
      "Material 92: tensor([ 1.0998, -0.8546, -0.2452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -2.6348422466071497e-07, Loss Weights: [ 1.5297685   1.5286493  -0.05841772]\n",
      "Material 93: tensor([-1.0100,  0.9897,  0.0203], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -4.768447752212523e-07, Loss Weights: [ 1.5304973   1.5293777  -0.05987491]\n",
      "Material 94: tensor([-0.9350,  1.0543, -0.1193], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -3.436512372445577e-07, Loss Weights: [ 1.531234   1.5301139 -0.061348 ]\n",
      "Material 95: tensor([ 0.6423, -1.1522,  0.5098], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -2.6197227498414577e-07, Loss Weights: [ 1.5319787   1.530858   -0.06283664]\n",
      "Material 96: tensor([ 0.5934, -1.1546,  0.5612], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -4.986205226487073e-07, Loss Weights: [ 1.5327313   1.5316103  -0.06434159]\n",
      "Material 97: tensor([ 0.8579, -1.0983,  0.2404], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -3.219761026684864e-07, Loss Weights: [ 1.5334922   1.5323706  -0.06586266]\n",
      "Material 98: tensor([-1.1010,  0.2491,  0.8519], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -9.253428174815781e-07, Loss Weights: [ 1.5342624   1.5331402  -0.06740234]\n",
      "Material 99: tensor([ 0.5295, -1.1534,  0.6239], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -3.555443299774197e-07, Loss Weights: [ 1.5350415   1.5339186  -0.06896025]\n",
      "Material 100: tensor([-0.4630, -0.6846,  1.1476], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 40, Total Loss: -3.1797623023521737e-07, Loss Weights: [ 1.5358297  1.5347064 -0.0705359]\n",
      "Finished epoch\n",
      "\n",
      "--> Epoch 41\n",
      "Material 1: tensor([ 0.6178,  0.5359, -1.1537], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -4.4613597083298373e-07, Loss Weights: [ 1.5365405   1.5354166  -0.07195675]\n",
      "Material 2: tensor([ 0.4027,  0.7358, -1.1386], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -4.024994098017487e-07, Loss Weights: [ 1.5371823   1.536058   -0.07324034]\n",
      "Material 3: tensor([-1.1545,  0.5965,  0.5579], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -3.1044703519000905e-07, Loss Weights: [ 1.5377631   1.5366385  -0.07440153]\n",
      "Material 4: tensor([ 0.6443, -1.1520,  0.5077], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -5.328617476152431e-07, Loss Weights: [ 1.5382898   1.5371647  -0.07545459]\n",
      "Material 5: tensor([-1.0280,  0.9695,  0.0585], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -3.2165465313482855e-07, Loss Weights: [ 1.5387685   1.537643   -0.07641156]\n",
      "Material 6: tensor([ 0.3948,  0.7423, -1.1371], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -3.680420661567041e-07, Loss Weights: [ 1.5392048   1.5380788  -0.07728341]\n",
      "Material 7: tensor([-1.0929,  0.2237,  0.8692], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -4.0493489450454945e-07, Loss Weights: [ 1.5396032   1.5384768  -0.07808018]\n",
      "Material 8: tensor([-1.0010,  0.9990,  0.0020], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -4.3478496536408784e-07, Loss Weights: [ 1.5399688   1.5388423  -0.07881105]\n",
      "Material 9: tensor([-0.3338,  1.1242, -0.7904], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -3.914889248335385e-07, Loss Weights: [ 1.5403056   1.5391786  -0.07948405]\n",
      "Material 10: tensor([-0.3614,  1.1305, -0.7690], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -3.681399505239824e-07, Loss Weights: [ 1.5406169   1.5394896  -0.08010636]\n",
      "Material 11: tensor([ 1.1476, -0.4627, -0.6848], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -3.100902574715292e-07, Loss Weights: [ 1.5409058   1.5397785  -0.08068421]\n",
      "Material 12: tensor([-1.1361,  0.7470,  0.3891], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -3.4314396657464385e-07, Loss Weights: [ 1.5411755   1.5400479  -0.08122332]\n",
      "Material 13: tensor([ 1.0795, -0.1847, -0.8948], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -4.5216012267701444e-07, Loss Weights: [ 1.5414286   1.5403007  -0.08172926]\n",
      "Material 14: tensor([ 0.8587,  0.2392, -1.0979], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -4.006159599612147e-07, Loss Weights: [ 1.5416675   1.5405395  -0.08220685]\n",
      "Material 15: tensor([ 0.4449,  0.7003, -1.1452], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -4.765570906783978e-07, Loss Weights: [ 1.5418943   1.5407664  -0.08266068]\n",
      "Material 16: tensor([-0.3951,  1.1372, -0.7421], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -4.616461808382155e-07, Loss Weights: [ 1.5421114   1.5409834  -0.08309485]\n",
      "Material 17: tensor([ 1.1543, -0.6048, -0.5494], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -3.5061191283602966e-07, Loss Weights: [ 1.5423205   1.5411923  -0.08351263]\n",
      "Material 18: tensor([ 1.1398, -0.4100, -0.7298], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -4.1136323147838993e-07, Loss Weights: [ 1.5425229   1.5413944  -0.08391718]\n",
      "Material 19: tensor([ 1.0791, -0.1836, -0.8955], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -3.467397391432314e-07, Loss Weights: [ 1.5427197  1.541591  -0.0843111]\n",
      "Material 20: tensor([ 0.5628, -1.1546,  0.5918], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -6.272718451327819e-07, Loss Weights: [ 1.5429132   1.5417843  -0.08469775]\n",
      "Material 21: tensor([-1.1546,  0.5667,  0.5879], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -3.4826788919417595e-07, Loss Weights: [ 1.5431039   1.541975   -0.08507915]\n",
      "Material 22: tensor([ 0.8898,  0.1924, -1.0822], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -6.883170158289431e-07, Loss Weights: [ 1.5432937   1.5421647  -0.08545834]\n",
      "Material 23: tensor([-0.6979, -0.4478,  1.1456], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -4.2639840103220195e-07, Loss Weights: [ 1.543483    1.5423539  -0.08583708]\n",
      "Material 24: tensor([ 0.7646, -1.1317,  0.3670], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -3.4956997296831105e-07, Loss Weights: [ 1.543673    1.5425436  -0.08621672]\n",
      "Material 25: tensor([-1.1535,  0.6219,  0.5317], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -3.563381767435203e-07, Loss Weights: [ 1.543864    1.5427344  -0.08659844]\n",
      "Material 26: tensor([ 0.8842,  0.2011, -1.0853], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -4.880909614257689e-07, Loss Weights: [ 1.5440567   1.542927   -0.08698383]\n",
      "Material 27: tensor([ 1.1546, -0.5623, -0.5923], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -7.104458745743614e-07, Loss Weights: [ 1.5442524   1.5431225  -0.08737509]\n",
      "Material 28: tensor([ 0.5743,  0.5804, -1.1547], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -3.9959914488463255e-07, Loss Weights: [ 1.5444515   1.5433214  -0.08777313]\n",
      "Material 29: tensor([-0.2684,  1.1068, -0.8384], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -5.121218009662698e-07, Loss Weights: [ 1.5446548  1.5435245 -0.0881792]\n",
      "Material 30: tensor([-0.9730, -0.0519,  1.0249], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -3.572196760615043e-07, Loss Weights: [ 1.5448623   1.5437318  -0.08859401]\n",
      "Material 31: tensor([ 0.7562, -1.1338,  0.3776], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -4.6422138666457613e-07, Loss Weights: [ 1.5450747   1.5439441  -0.08901884]\n",
      "Material 32: tensor([ 0.5334, -1.1536,  0.6202], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -1.187004272651393e-07, Loss Weights: [ 1.5452925   1.5441618  -0.08945429]\n",
      "Material 33: tensor([-1.1024,  0.8488,  0.2535], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 3.5902064610127127e-07, Loss Weights: [ 1.5455158  1.544385  -0.0899006]\n",
      "Material 34: tensor([-1.0454,  0.0980,  0.9474], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 1.014542363009241e-06, Loss Weights: [ 1.5457447   1.5446137  -0.09035832]\n",
      "Material 35: tensor([-0.7710, -0.3589,  1.1299], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 2.7242983833275503e-06, Loss Weights: [ 1.5459795   1.5448483  -0.09082777]\n",
      "Material 36: tensor([-0.9055,  1.0733, -0.1677], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 6.101689905335661e-06, Loss Weights: [ 1.5462203   1.545089   -0.09130921]\n",
      "Material 37: tensor([-1.0787,  0.1825,  0.8962], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 1.2823936231143307e-05, Loss Weights: [ 1.5464673   1.545336   -0.09180324]\n",
      "Material 38: tensor([ 1.1438, -0.4346, -0.7092], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 2.831847086781636e-05, Loss Weights: [ 1.546721    1.5455894  -0.09231052]\n",
      "Material 39: tensor([-1.0630,  0.1411,  0.9220], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 6.485871563199908e-05, Loss Weights: [ 1.5469813  1.5458497 -0.0928311]\n",
      "Material 40: tensor([ 0.1065,  0.9425, -1.0490], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 0.0001375657884636894, Loss Weights: [ 1.5472487  1.5461168 -0.0933655]\n",
      "Material 41: tensor([-0.9265, -0.1335,  1.0601], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 0.00030618711025454104, Loss Weights: [ 1.5475233   1.546391   -0.09391405]\n",
      "Material 42: tensor([-0.0785, -0.9584,  1.0369], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 0.0006786139565519989, Loss Weights: [ 1.5478046   1.5466722  -0.09447701]\n",
      "Material 43: tensor([-0.6986,  1.1455, -0.4469], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 0.001499554724432528, Loss Weights: [ 1.5480938  1.5469612 -0.0950551]\n",
      "Material 44: tensor([-0.7960, -0.3264,  1.1224], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 0.003537694690749049, Loss Weights: [ 1.548391    1.5472581  -0.09564889]\n",
      "Material 45: tensor([ 0.3365, -1.1248,  0.7884], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 0.008446349762380123, Loss Weights: [ 1.5486957   1.5475626  -0.09625848]\n",
      "Material 46: tensor([ 1.1199, -0.8036, -0.3163], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 0.019021037966012955, Loss Weights: [ 1.5490091   1.5478759  -0.09688485]\n",
      "Material 47: tensor([-0.0147, -0.9926,  1.0073], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 0.04716081544756889, Loss Weights: [ 1.5493312   1.5481977  -0.09752901]\n",
      "Material 48: tensor([ 0.8597,  0.2377, -1.0974], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 0.11647626012563705, Loss Weights: [ 1.5496638   1.5485301  -0.09819396]\n",
      "Material 49: tensor([-0.5195,  1.1528, -0.6333], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 0.3226904273033142, Loss Weights: [ 1.5500109   1.5488768  -0.09888782]\n",
      "Material 50: tensor([ 1.0042, -0.9958, -0.0084], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 1.0367608070373535, Loss Weights: [ 1.5503855   1.5492506  -0.09963606]\n",
      "Material 51: tensor([ 1.1325, -0.7613, -0.3712], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 3.5321526527404785, Loss Weights: [ 1.5508282   1.5496914  -0.10051973]\n",
      "Material 52: tensor([-1.0660,  0.9173,  0.1488], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 9.943778038024902, Loss Weights: [ 1.5514452   1.5503036  -0.10174882]\n",
      "Material 53: tensor([-0.6113,  1.1540, -0.5427], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 779.0008544921875, Loss Weights: [ 1.5675871   1.5659392  -0.13352653]\n",
      "Material 54: tensor([-0.5250, -0.6281,  1.1532], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -40165208752128.0, Loss Weights: [1.4999347e+00 1.5000319e+00 3.3122273e-05]\n",
      "Material 55: tensor([-1.0130,  0.9865,  0.0265], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 560956375040.0, Loss Weights: [1.4999354e+00 1.5000329e+00 3.1741747e-05]\n",
      "Material 56: tensor([-1.1309,  0.7675,  0.3633], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 2800688128.0, Loss Weights: [1.4999355e+00 1.5000331e+00 3.1640520e-05]\n",
      "Material 57: tensor([ 0.7801,  0.3472, -1.1273], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: 2472444160.0, Loss Weights: [-0.0178652  -0.01786636  3.0357318 ]\n",
      "Material 58: tensor([-1.0906,  0.2167,  0.8739], device='mps:0', grad_fn=<ToCopyBackward0>), Epoch: 41, Total Loss: -1.4445665515575706e+17, Loss Weights: [-0.01786627 -0.01786743  3.0357337 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/torch/autograd/__init__.py:266: UserWarning: Error detected in LinearBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/r8/9jdwwqz11dq7_2m0n6cds_k40000gn/T/ipykernel_1338/1313515995.py\", line 33, in <module>\n",
      "    material_penalty = loss_function.compute_material_penalty(model, nodes, material_params_1, material_params_2, concatenate).to(device) * 1e10\n",
      "  File \"/Users/pauloakira/Main/_repos/ai-pinn/core/loss.py\", line 94, in compute_material_penalty\n",
      "    uh_2 = model(nodes, material_params_2)\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py\", line 110, in forward\n",
      "    z_combined = self.final_out(z_combined)\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 116, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      " (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:118.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'LinearBackward0' returned nan values in its 0th output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m loss_weights[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m loss \u001b[38;5;241m+\u001b[39m loss_weights[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m sobolev_loss \u001b[38;5;241m+\u001b[39m loss_weights[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m material_penalty\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Backpropagation for the model weights using total loss\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Step 3: Perform the optimizer step to update the model weights using the total loss\u001b[39;00m\n\u001b[1;32m     70\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Function 'LinearBackward0' returned nan values in its 0th output."
     ]
    }
   ],
   "source": [
    "## CLASSICAL APPROACH ##\n",
    "\n",
    "# Loop through epochs (train across all materials in each epoch)\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    print(f\"--> Epoch {epoch + 1}\")\n",
    "    \n",
    "    # Loop through each material in the dataset\n",
    "    for i, data in enumerate(dataset):\n",
    "        \n",
    "        # Move material parameters and nodes to the correct device\n",
    "        material_params_1 = data['material_params']\n",
    "        material_params_2 = data['distorted_material_params']\n",
    "        nodes = data['nodes']\n",
    "        uh_vem = data['uh_vem']\n",
    "\n",
    "        # Normalize inputs\n",
    "        nodes, material_params_1 = neural.normalize_inputs(nodes, material_params_1)\n",
    "        _, material_params_2 = neural.normalize_inputs(nodes, material_params_2)\n",
    "\n",
    "        material_params_1 = material_params_1.to(device)\n",
    "        material_params_2 = material_params_2.to(device)\n",
    "\n",
    "        nodes = nodes.flatten()\n",
    "        nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True).to(device)\n",
    "        \n",
    "        # Forward pass using the current material parameters\n",
    "        uh = model(nodes, material_params_1.to(device))  # Adjust input to include material params\n",
    "        uh_vem = torch.tensor(uh_vem, dtype=torch.float32, requires_grad=True).to(device)\n",
    "        # Compute individual losses\n",
    "        loss = loss_function.compute_loss_with_uh(uh_vem, uh).to(device)\n",
    "        sobolev_loss = loss_function.compute_sobolev_loss(model, nodes, material_params_1, loss, concatenate).to(device)\n",
    "        material_penalty = loss_function.compute_material_penalty(model, nodes, material_params_1, material_params_2, concatenate).to(device) * 1e10\n",
    "\n",
    "        # Weighted sum of losses (with GradNorm weights)\n",
    "        weighted_losses = [\n",
    "            loss_weights[0] * loss, \n",
    "            loss_weights[1] * sobolev_loss, \n",
    "            loss_weights[2] * material_penalty\n",
    "        ]\n",
    "\n",
    "        # Store the initial loss weights\n",
    "        if epoch == 0 and i == 0:\n",
    "            initial_loss_weights = [\n",
    "                loss_weights[0] * loss, \n",
    "                loss_weights[1] * sobolev_loss, \n",
    "                loss_weights[2] * material_penalty\n",
    "            ]\n",
    "\n",
    "        # Calculate the gradient norms for each task\n",
    "        grad_norms = gn.calculate_gradient_norm(model, weighted_losses)\n",
    "        tilde_losses = [gn.compute_loss_ratio(weighted_losses[i].item(), initial_loss_weights[i].item()) for i in range(len(weighted_losses))]\n",
    "\n",
    "        # Compute the grad norm loss\n",
    "        loss_grad = gn.compute_grad_norm_loss(grad_norms, tilde_losses, alpha=100)\n",
    "\n",
    "        # Backpropagation of the gradient loss (update the grad_loss weights)\n",
    "        loss_grad.backward(retain_graph=True)\n",
    "\n",
    "        # Step 1: Perform the optimizer step to update the task weights using the gradient loss\n",
    "        optimizer_w.step()\n",
    "\n",
    "        # Step 2: Compute the total loss (sum of the weighted loss)\n",
    "        total_loss = loss_weights[0] * loss + loss_weights[1] * sobolev_loss + loss_weights[2] * material_penalty\n",
    "\n",
    "        # Backpropagation for the model weights using total loss\n",
    "        total_loss.backward()\n",
    "\n",
    "        # Step 3: Perform the optimizer step to update the model weights using the total loss\n",
    "        optimizer.step()\n",
    "\n",
    "        # Step 4: Renormalize the loss weights (no in-place operation)\n",
    "        T = len(weighted_losses)\n",
    "        sum_w = torch.sum(loss_weights).item()\n",
    "\n",
    "        # Instead of modifying in-place, re-assign to a new tensor\n",
    "        with torch.no_grad():\n",
    "            loss_weights.copy_((loss_weights / sum_w) * T)\n",
    "\n",
    "        # Store losses for analysis\n",
    "        if epoch > 0:\n",
    "            total_loss_values.append(total_loss.item())\n",
    "            loss_values.append(loss_weights[0].item() * loss.item())\n",
    "            material_loss_values.append(loss_weights[2].item() * material_penalty.item())\n",
    "            sobolev_loss_values.append(loss_weights[1].item() * sobolev_loss.item())\n",
    "\n",
    "        # Print progress\n",
    "        print(f'Material {i+1}: {material_params_1}, Epoch: {epoch + 1}, Total Loss: {total_loss.item()}, Loss Weights: {loss_weights.detach().cpu().numpy()}')\n",
    "\n",
    "    print(\"Finished epoch\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geometry parameter\n",
    "I_new = 1e-4\n",
    "A_new = 1\n",
    "E_new = 110e6\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new, A_new, I_new, load, q, t)\n",
    "\n",
    "# Testing the model with new parameters\n",
    "material_params = torch.tensor([E_new , A_new , I_new ], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"data/models/neural_vem_64.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of the model (with the same architecture)\n",
    "loaded_model = neural.BeamApproximatorWithMaterials(\n",
    "    input_dim_nodes=input_dim_nodes, \n",
    "    input_dim_materials=input_dim_materials, \n",
    "    nodes_layers=nodes_layers, \n",
    "    material_layers=material_layers, \n",
    "    final_layers=final_layers, \n",
    "    ndof=ndof\n",
    ")\n",
    "\n",
    "# Load the saved model state\n",
    "loaded_model.load_state_dict(torch.load(\"data/models/neural_vem_8.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode (important for inference)\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geometry parameters for inference\n",
    "I_new = 1e-4\n",
    "A_new = 1\n",
    "E_new = 110e6\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new, A_new, I_new, load, q, t)\n",
    "\n",
    "# Prepare the input for the model\n",
    "material_params = torch.tensor([E_new, A_new, I_new], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "\n",
    "# Normalize inputs before passing to the model\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "\n",
    "# Test the model using the new material parameters\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=loaded_model,  # Use the loaded model for inference\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
