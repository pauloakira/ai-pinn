{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points:\n",
    "\n",
    "1. **Using VEM/FEM Solutions for Efficient Training**:\n",
    "   - By training the neural network on the displacement field computed using VEM/FEM, you're providing the model with a high-quality reference solution. This allows the model to learn the underlying physical relationships between the parameters (such as Young’s modulus \\(E\\), cross-sectional area \\(A\\), and moment of inertia \\(I\\)) and the displacement field.\n",
    "\n",
    "2. **Generalization with Fewer Data**:\n",
    "   - Since the model is grounded in physically informed solutions, you likely need **fewer training examples** to generalize to new material and geometrical configurations. Unlike traditional machine learning models that require vast amounts of labeled data, your approach can rely on solving a **few instances** of VEM/FEM solutions and using that information to generalize.\n",
    "\n",
    "3. **Parameter Sensitivity and Inference**:\n",
    "   - The network’s sensitivity to material and geometrical parameters (\\(E\\), \\(A\\), \\(I\\)) is key. Once trained, the model will allow for **rapid inference** with new combinations of these parameters without needing to solve the full VEM/FEM system again.\n",
    "   - In an engineering context, this is particularly advantageous, as engineers often need to explore various material or geometric configurations during design optimization. Having a trained neural network that provides **instant predictions** without solving a full VEM/FEM problem would significantly improve efficiency.\n",
    "\n",
    "4. **Efficiency Compared to Traditional VEM/FEM**:\n",
    "   - Solving a full VEM/FEM problem repeatedly for different parameter values can be computationally expensive, especially for large or complex systems. By training a neural network to approximate the displacement field based on these parameters, you essentially create a **surrogate model** that can make predictions more efficiently.\n",
    "\n",
    "### Challenges and Considerations:\n",
    "- **Accuracy vs. Efficiency**: While the neural network may provide fast predictions, the trade-off is the potential for reduced accuracy compared to solving the full VEM/FEM system. This can be mitigated by fine-tuning the network and introducing additional regularization techniques like Sobolev training.\n",
    "  \n",
    "- **Extrapolation Limits**: The network might struggle with extrapolating far beyond the range of material and geometrical parameters it was trained on. Ensuring that the training data includes a representative range of parameters will be crucial for reliable generalization.\n",
    "\n",
    "- **Hybrid Model Validation**: You could validate your hypothesis by comparing the **computational cost** (in terms of time) and **accuracy** between solving multiple VEM/FEM instances and using the trained neural network for inference over a variety of material/geometrical configurations.\n",
    "\n",
    "### Conclusion:\n",
    "The approach of training a neural network using VEM/FEM solutions to enable efficient inference of displacement fields for different material and geometric configurations is a practical and promising solution in engineering contexts. It leverages the strengths of both numerical methods and machine learning to balance accuracy and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import core.vem as vem\n",
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "\n",
    "import utils.mesh as mesh\n",
    "import core.loss as loss_function\n",
    "import core.errors as errors\n",
    "import core.neural_backend as neural\n",
    "\n",
    "import solve_vem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS backend is available!\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS backend is available!\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS backend is not available. Using CPU.\")\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of elements per edge\n",
    "num_elements_per_edge = 32\n",
    "\n",
    "# geometry data\n",
    "L = 2.0\n",
    "I = 1e-4\n",
    "A = 1\n",
    "\n",
    "# material data\n",
    "E = 27e6\n",
    "\n",
    "# Define load parameters\n",
    "q = -400\n",
    "t = 0\n",
    "\n",
    "# Time sampling size\n",
    "time_sampling_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving time [s]: 0.0009\n",
      "######################### Beam ##########################\n",
      "[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -6.11294039e-19\n",
      " -1.94881114e-06  2.00665681e-18 -1.07225777e-18 -3.89762227e-06\n",
      " -4.81056994e-18 -1.20533083e-18 -5.84643341e-06 -8.48584458e-18\n",
      " -1.20465840e-18 -7.79524455e-06 -9.09042567e-18 -1.17311919e-18\n",
      " -9.74405568e-06 -9.47358127e-18 -1.20009988e-18 -1.16928668e-05\n",
      " -7.21778913e-18 -1.06211412e-18 -1.36416780e-05 -1.47525077e-17\n",
      " -1.56704915e-18 -1.55904891e-05  1.33556765e-17  2.95131067e-19\n",
      " -1.75393002e-05 -9.05001960e-17 -6.58894322e-18 -1.94881114e-05\n",
      "  2.93235821e-16  1.88480147e-17 -2.14369225e-05 -1.12477323e-15\n",
      " -7.51477879e-17 -2.33857336e-05  4.11508416e-15  2.72187318e-16\n",
      " -2.53345448e-05 -1.52473623e-14 -1.01129425e-15 -2.72833559e-05\n",
      "  5.63012177e-14  3.73145723e-15 -2.92321670e-05 -2.08086820e-13\n",
      " -1.37940730e-14 -3.11809782e-05  7.68886231e-13  5.09666882e-14\n",
      " -3.31297893e-05 -2.84124814e-12 -1.88338838e-13 -3.50786005e-05\n",
      "  1.04990074e-11  6.95948712e-13 -3.70274116e-05 -3.87962266e-11\n",
      " -2.57169197e-12 -3.89762227e-05  1.43360711e-10  9.50297265e-12\n",
      " -4.09250339e-05 -5.29749996e-10 -3.51156192e-11 -4.28738450e-05\n",
      "  1.95754492e-09  1.29760077e-10 -4.48226561e-05 -7.23356722e-09\n",
      " -4.79492571e-10 -4.67714673e-05  2.67296519e-08  1.77183250e-09\n",
      " -4.87202784e-05 -9.87720544e-08 -6.54731819e-09 -5.06690896e-05\n",
      "  3.64984877e-07  2.41938080e-08 -5.26179007e-05 -1.34870092e-06\n",
      " -8.94015428e-08 -5.45667118e-05  4.98375214e-06  3.30358736e-07\n",
      " -5.65155230e-05 -1.84160811e-05 -1.22074957e-06 -5.84643341e-05\n",
      "  6.80515468e-05  4.51094324e-06 -6.04131452e-05 -2.51465717e-04\n",
      " -1.66689462e-05 -6.23619564e-05  9.29222179e-04 -1.66689462e-05\n",
      " -2.49403084e-05  4.68257634e-04 -1.66689462e-05 -1.14713779e-05\n",
      "  1.56707057e-04 -1.66689462e-05 -1.02158223e-05  7.14014743e-05\n",
      " -1.66689462e-05 -1.13480773e-05  7.42689527e-05 -1.66689462e-05\n",
      " -1.18228193e-05  8.64137252e-05 -1.66689462e-05 -1.16199620e-05\n",
      "  8.99239695e-05 -1.66689462e-05 -1.11843858e-05  8.78325676e-05\n",
      " -1.66689462e-05 -1.07363370e-05  8.42949259e-05 -1.66689462e-05\n",
      " -1.03169442e-05  8.08874125e-05 -1.66689462e-05 -9.91340720e-06\n",
      "  7.77593785e-05 -1.66689462e-05 -9.51333441e-06  7.47483930e-05\n",
      " -1.66689462e-05 -9.11258594e-06  7.17528371e-05 -1.66689462e-05\n",
      " -8.71099027e-06  6.87473397e-05 -1.66689462e-05 -8.30908177e-06\n",
      "  6.57346839e-05 -1.66689462e-05 -7.90714701e-06  6.27200166e-05\n",
      " -1.66689462e-05 -7.50524612e-06  5.97054363e-05 -1.66689462e-05\n",
      " -7.10336572e-06  5.66911975e-05 -1.66689462e-05 -6.70149018e-06\n",
      "  5.36771172e-05 -1.66689462e-05 -6.29961428e-06  5.06630455e-05\n",
      " -1.66689462e-05 -5.89773628e-06  4.76490206e-05 -1.66689462e-05\n",
      " -5.49586171e-06  4.46347723e-05 -1.66689462e-05 -5.09397289e-06\n",
      "  4.16213132e-05 -1.66689462e-05 -4.69213661e-06  3.86049272e-05\n",
      " -1.66689462e-05 -4.29010633e-06  3.55993577e-05 -1.66689462e-05\n",
      " -3.88879303e-06  3.25538202e-05 -1.66689462e-05 -3.48483035e-06\n",
      "  2.96559744e-05 -1.66689462e-05 -3.09065773e-06  2.62123746e-05\n",
      " -1.66689462e-05 -2.66030863e-06  2.47854582e-05 -1.66689462e-05\n",
      " -2.36363974e-06  1.59064445e-05 -1.66689462e-05 -1.57299253e-06\n",
      "  3.45646005e-05 -1.66689462e-05 -2.60770588e-06 -4.85332570e-05\n",
      " -1.66689462e-05  3.10269711e-06  2.44380160e-04 -4.90681721e-06\n",
      "  3.00573783e-06  1.32007968e-04  9.26621974e-08  2.90877854e-06\n",
      "  2.79753734e-05  7.77873404e-07  2.81181926e-06 -6.04861474e-06\n",
      "  3.66021873e-07  2.71485997e-06 -7.13063427e-06  6.25963471e-08\n",
      "  2.61790069e-06 -2.57898256e-06 -2.40822363e-08  2.52094140e-06\n",
      " -1.94732114e-07 -2.11061147e-08  2.42398212e-06  2.89968006e-07\n",
      " -6.71104246e-09  2.32702283e-06  1.70674305e-07 -1.25888822e-10\n",
      "  2.23006355e-06  4.00506109e-08  9.40533016e-10  2.13310426e-06\n",
      " -5.92511206e-09  4.78084318e-10  2.03614498e-06 -8.87324628e-09\n",
      "  9.30332502e-11  1.93918569e-06 -3.44838788e-09 -2.59508058e-11\n",
      "  1.84222641e-06 -3.59101896e-10 -2.65630429e-11  1.74526713e-06\n",
      "  3.39510326e-10 -9.09682050e-12  1.64830784e-06  2.19408809e-10\n",
      " -4.76171238e-13  1.55134856e-06  5.64519850e-11  1.12569390e-12\n",
      "  1.45438927e-06 -5.19228312e-12  6.20802451e-13  1.35742999e-06\n",
      " -1.09642257e-11  1.35079797e-13  1.26047070e-06 -4.57888174e-12\n",
      " -2.67279550e-14  1.16351142e-06 -5.98948824e-13 -3.32211745e-14\n",
      "  1.06655213e-06  3.91183282e-13 -1.22329051e-14  9.69592847e-07\n",
      "  2.80458819e-13 -1.01426933e-15  8.72633563e-07  7.85550065e-14\n",
      "  1.33039671e-15  7.75674278e-07 -3.50821239e-15  8.00336905e-16\n",
      "  6.78714993e-07 -1.34362207e-14  1.91418290e-16  5.81755708e-07\n",
      " -6.03169426e-15 -2.67919063e-17  4.84796424e-07 -9.33551324e-16\n",
      " -4.24328640e-17  3.87837139e-07  4.50521385e-16 -1.74943124e-17\n",
      "  2.90877854e-07  3.64992977e-16 -2.96629836e-18  1.93918569e-07\n",
      "  1.17384181e-16  3.50978645e-19  9.69592847e-08  6.24939266e-18\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "#########################################################\n"
     ]
    }
   ],
   "source": [
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Plot the nodes\n",
    "mesh.plot_nodes(nodes, elements)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Solving and Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring time for solving using VEM\n",
    "solving_time_list = []\n",
    "for _ in range(time_sampling_size):\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t)\n",
    "    solving_time_list.append(solving_time)\n",
    "\n",
    "print(\"Mean solving time: \", np.mean(solving_time_list))\n",
    "print(\"Std Deviation: \", np.std(solving_time_list))\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 800\n",
    "\n",
    "# Layers definition\n",
    "nodes_layers = [128, 256, 512, 512, 512, 512]  # Layers for nodes sub-network\n",
    "material_layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2048, 2048] # Layers for materials sub-network\n",
    "final_layers = [1024, 1024, 1024, 1024]  # Layers for final combination network\n",
    "\n",
    "# Training pipeline\n",
    "(input_vector, \n",
    " model, \n",
    " total_loss_values, \n",
    " loss_values, \n",
    " material_loss_values, \n",
    " sobolev_loss_values, \n",
    " alpha_values_values) = neural.train_material_portic(\n",
    "    epochs=num_epochs,\n",
    "    nodes=nodes,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    E=E,\n",
    "    A=A,\n",
    "    I=I,\n",
    "    uh_vem=uh_vem,\n",
    "    nodes_layers=nodes_layers,\n",
    "    material_layers=material_layers,\n",
    "    final_layers=final_layers,\n",
    "    verbose=True,\n",
    "    noramlize_inputs=True,\n",
    "    network_type=\"material\"\n",
    " )\n",
    "\n",
    "# Setting up material parameters\n",
    "material_params = torch.tensor([E , A , I ], dtype=torch.float32)\n",
    "# nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "\n",
    "# Measuring time spent for inference\n",
    "inference_time_list = []\n",
    "for _ in range(time_sampling_size):\n",
    "    predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    inference_time_list.append(inference_time)\n",
    "\n",
    "print(\"Mean inference time: \", np.mean(inference_time_list))\n",
    "print(\"Std Deviation: \", np.std(inference_time_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model refers to the disaplcement field and the loss function regards to the calculation of the residual taking in consideration the Virtual Element Method's stiffness matrix and load vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence of Deep Layers in the Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 800\n",
    "\n",
    "# Reading the json with respective layers\n",
    "with open(\"data/layers_20240929.json\", \"r\") as data:\n",
    "    layers = json.load(data)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i,layer in enumerate(layers):\n",
    "\n",
    "    # Define the number of elements per edge\n",
    "    num_elements_per_edge = 128\n",
    "\n",
    "    # geometry data\n",
    "    L = 2.0\n",
    "    I = 1e-4\n",
    "    A = 1\n",
    "\n",
    "    # material data\n",
    "    E = 27e6\n",
    "\n",
    "    # Define load parameters\n",
    "    q = -400\n",
    "    t = 0\n",
    "\n",
    "\n",
    "    # Generate the geometry\n",
    "    nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "    # Solve the problem using the VEM\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t, verbose=False)\n",
    "\n",
    "    print(f\"Training and testing layer {i+1}/{len(layers)}\")\n",
    "    # Defining layers\n",
    "    nodes_layers = list(layer[\"node_layers\"])\n",
    "    material_layers = list(layer[\"material_layers\"])\n",
    "    final_layers = list(layer[\"final_layers\"])\n",
    "\n",
    "    # Training pipeline\n",
    "    (input_vector, \n",
    "    model, \n",
    "    total_loss_values, \n",
    "    loss_values, \n",
    "    material_loss_values, \n",
    "    sobolev_loss_values, \n",
    "    alpha_values_values) = neural.train_material_portic(\n",
    "        epochs=num_epochs,\n",
    "        nodes=nodes,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        E=E,\n",
    "        A=A,\n",
    "        I=I,\n",
    "        uh_vem=uh_vem,\n",
    "        nodes_layers=nodes_layers,\n",
    "        material_layers=material_layers,\n",
    "        final_layers=final_layers,\n",
    "        verbose=False,\n",
    "        noramlize_inputs=True,\n",
    "        network_type=\"material\"\n",
    "    )\n",
    "\n",
    "    # Setting up material parameters\n",
    "    material_params = torch.tensor([E , A , I ], dtype=torch.float32)\n",
    "    nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "\n",
    "    # Testing the model with default parameters\n",
    "    predicted_displacements, l2_error_default, energy_error_default, h1_error_default, inference_time_default = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Setting up new material parameters\n",
    "    I_new = 1e-4\n",
    "    A_new = 2\n",
    "    E_new = 110e5\n",
    "\n",
    "    # Generate the geometry\n",
    "    nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "    # Solve the problem using the VEM\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new, A_new, I_new, load, q, t)\n",
    "\n",
    "    # Testing the model with new parameters\n",
    "    material_params = torch.tensor([E_new , A_new , I_new], dtype=torch.float32)\n",
    "    nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "    nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "    predicted_displacements, l2_error_new, energy_error_new, h1_error_new, inference_time_new = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Setting up new material parameters\n",
    "    I_new_2 = 1e-4\n",
    "    A_new_2 = 3\n",
    "    E_new_2 = 80e3\n",
    "\n",
    "    # Generate the geometry\n",
    "    nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "    # Solve the problem using the VEM\n",
    "    uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new_2, A_new_2, I_new_2, load, q, t)\n",
    "\n",
    "    # Testing the model with new parameters\n",
    "    material_params = torch.tensor([E_new_2 , A_new_2 , I_new_2], dtype=torch.float32)\n",
    "    nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "    nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "    predicted_displacements, l2_error_new, energy_error_new, h1_error_new, inference_time_new = neural.test_portic(\n",
    "        nodes=nodes,\n",
    "        material_params=material_params,\n",
    "        model=model,\n",
    "        uh_vem=uh_vem,\n",
    "        K=K,\n",
    "        f=f,\n",
    "        concatanate=False,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"tag\": layer[\"tag\"],\n",
    "        \"l2_error_default\": l2_error_default,\n",
    "        \"energy_error_default\": energy_error_default,\n",
    "        \"h1_error_default\": h1_error_default,\n",
    "        \"inferece_time_default\": inference_time_default,\n",
    "        \"l2_error_new\": l2_error_new,\n",
    "        \"energy_error_new\": energy_error_new,\n",
    "        \"h1_error_new\": h1_error_new,\n",
    "        \"inferece_time_new\": inference_time_new,\n",
    "        \"l2_error_new_2\": l2_error_new,\n",
    "        \"energy_error_new_2\": energy_error_new,\n",
    "        \"h1_error_new_2\": h1_error_new,\n",
    "        \"inferece_time_new_2\": inference_time_new,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in a dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"data/output/results_20240929.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py:199: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  normalized_nodes = torch.tensor(normalized_nodes, dtype=torch.float32, requires_grad=True)\n",
      "/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py:200: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  normalized_material_params = torch.tensor(normalized_material_params, dtype=torch.float32, requires_grad=True)\n",
      "/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n",
      "/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py:285: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  K = torch.tensor(K, dtype=torch.float32, requires_grad=True)\n",
      "/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  f = torch.tensor(f, dtype=torch.float32, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes shape: torch.Size([194])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x194 and 388x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m      7\u001b[0m final_layers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m1024\u001b[39m] \u001b[38;5;66;03m# Layers for final combination network\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Training pipeline\u001b[39;00m\n\u001b[1;32m     10\u001b[0m (input_vector, \n\u001b[1;32m     11\u001b[0m  model, \n\u001b[1;32m     12\u001b[0m  total_loss_values, \n\u001b[1;32m     13\u001b[0m  loss_values, \n\u001b[1;32m     14\u001b[0m  material_loss_values, \n\u001b[1;32m     15\u001b[0m  sobolev_loss_values, \n\u001b[0;32m---> 16\u001b[0m  alpha_values_values) \u001b[38;5;241m=\u001b[39m \u001b[43mneural\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_material_portic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mI\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mI\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43muh_vem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muh_vem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaterial_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaterial_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnoramlize_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaterial\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Main/_repos/ai-pinn/core/neural_backend.py:300\u001b[0m, in \u001b[0;36mtrain_material_portic\u001b[0;34m(epochs, nodes, K, f, E, A, I, uh_vem, nodes_layers, material_layers, final_layers, verbose, noramlize_inputs, network_type, batch_norm)\u001b[0m\n\u001b[1;32m    298\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# uh = model(input_vector)\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m uh \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaterial_params_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[1;32m    303\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function\u001b[38;5;241m.\u001b[39mcompute_loss_with_uh(uh_vem, uh)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Main/_repos/ai-pinn/core/neural_backend.py:91\u001b[0m, in \u001b[0;36mBeamApproximatorWithMaterials.forward\u001b[0;34m(self, x_nodes, x_materials)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_nodes, x_materials):\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# Pass through the first layer\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     z_nodes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_nodes\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     92\u001b[0m     z_materials \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaterials_in(x_materials))\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# Pass through the hidden layers\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x194 and 388x128)"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 800\n",
    "\n",
    "# Layers definition\n",
    "nodes_layers = [128, 256, 512, 512, 512, 512]  # Layers for nodes sub-network\n",
    "material_layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2048, 2048] # Layers for materials sub-network\n",
    "final_layers = [1024, 1024, 1024, 1024]  # Layers for final combination network\n",
    "\n",
    "# Training pipeline\n",
    "(input_vector, \n",
    " model, \n",
    " total_loss_values, \n",
    " loss_values, \n",
    " material_loss_values, \n",
    " sobolev_loss_values, \n",
    " alpha_values_values) = neural.train_material_portic(\n",
    "    epochs=num_epochs,\n",
    "    nodes=nodes,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    E=E,\n",
    "    A=A,\n",
    "    I=I,\n",
    "    uh_vem=uh_vem,\n",
    "    nodes_layers=nodes_layers,\n",
    "    material_layers=material_layers,\n",
    "    final_layers=final_layers,\n",
    "    verbose=True,\n",
    "    noramlize_inputs=True,\n",
    "    network_type=\"material\",\n",
    "    batch_norm=False\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the reference displacement field calculated by the Virtual Element Method, a displacemente field is supposed to be calculated considering the material parameters contributions to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_total_loss = total_loss_values[150:]\n",
    "plt.plot(filtered_total_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_loss = loss_values[150:]\n",
    "plt.plot(filtered_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_material_loss = material_loss_values[150:]\n",
    "plt.plot(filtered_material_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Material Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_sobolev_loss = sobolev_loss_values[150:]\n",
    "plt.plot(filtered_sobolev_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Sobolev Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_alpha_values = alpha_values_values[150:]\n",
    "plt.plot(filtered_alpha_values)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('alpha')\n",
    "plt.title('Alpha Values over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material_params = torch.tensor([E , A , I ], dtype=torch.float32)\n",
    "# nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geometry parameter\n",
    "I_new = 1e-4\n",
    "A_new = 2\n",
    "E_new = 110e5\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new, A_new, I_new, load, q, t)\n",
    "\n",
    "# Testing the model with new parameters\n",
    "material_params = torch.tensor([E_new , A_new , I_new ], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geometry parameter\n",
    "I_new_2 = 1e-4\n",
    "A_new_2 = 3\n",
    "E_new_2 = 80e3\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new_2, A_new_2, I_new_2, load, q, t)\n",
    "\n",
    "# Testing the model with new parameters\n",
    "material_params = torch.tensor([E_new_2 , A_new_2 , I_new_2 ], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import core.grad_norm as gn\n",
    "import core.neural_backend as neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndof = 3 * len(nodes)\n",
    "input_dim = 2*len(nodes) + 3\n",
    "\n",
    "input_dim_nodes = 2*len(nodes)\n",
    "input_dim_materials = 3\n",
    "\n",
    "# Original material parameters\n",
    "material_params_1 = torch.tensor([E, A, I], dtype=torch.float32)\n",
    "\n",
    "# Perturbed material parameters (slightly changed)\n",
    "material_params_2 = torch.tensor([E *1.1, A * 1.1, I * 0.9], dtype=torch.float32)\n",
    "\n",
    "nodes, material_params_1 = neural.normalize_inputs(nodes, material_params_1)\n",
    "_, material_params_2 = neural.normalize_inputs(nodes, material_params_2)\n",
    "\n",
    "nodes = nodes.flatten()\n",
    "nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "input_vector = torch.cat([nodes, material_params_1])\n",
    "\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers definition\n",
    "nodes_layers = [128, 256, 512, 512, 512, 512]  # Layers for nodes sub-network\n",
    "material_layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2048, 2048] # Layers for materials sub-network\n",
    "final_layers = [1024, 1024, 1024, 1024]  # Layers for final combination network\n",
    "\n",
    "model = neural.BeamApproximatorWithMaterials(\n",
    "                input_dim_nodes=input_dim_nodes, \n",
    "                input_dim_materials=input_dim_materials, \n",
    "                nodes_layers=nodes_layers, \n",
    "                material_layers=material_layers, \n",
    "                final_layers=final_layers, \n",
    "                ndof=ndof)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "K = torch.tensor(K, dtype=torch.float32, requires_grad=True)\n",
    "f = torch.tensor(f, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "total_loss_values = []\n",
    "loss_values = []\n",
    "material_loss_values = []\n",
    "sobolev_loss_values = []\n",
    "alpha_values_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loss weights\n",
    "loss_weights = torch.ones(3, requires_grad=True)  # We have 3 tasks: loss, sobolev_loss, and material_penalty\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 200\n",
    "concatanate = False\n",
    "\n",
    "# Initialize optimizers (including the loss_weights as parameters)\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + [loss_weights], lr=1e-3)\n",
    "optimizer_w = torch.optim.SGD([loss_weights], lr=1e-3)\n",
    "\n",
    "# Initialize lists to store loss values\n",
    "total_loss_values, loss_values, material_loss_values, sobolev_loss_values, alpha_values_values = [], [], [], [], []\n",
    "\n",
    "# Enable anomaly detection for debugging\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Loop through epochs\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    uh = model(nodes, material_params_1)\n",
    "    \n",
    "    # Compute individual losses\n",
    "    loss = loss_function.compute_loss_with_uh(uh_vem, uh)\n",
    "    sobolev_loss = loss_function.compute_sobolev_loss(model, nodes, material_params_1, loss, concatanate)\n",
    "    material_penalty = loss_function.compute_material_penalty(model, nodes, material_params_1, material_params_2, concatanate) * 1e10\n",
    "\n",
    "    # Weighted sum of losses (with GradNorm weights)\n",
    "    weighted_losses = [\n",
    "        loss_weights[0] * loss, \n",
    "        loss_weights[1] * sobolev_loss, \n",
    "        loss_weights[2] * material_penalty\n",
    "    ]\n",
    "\n",
    "    # Store the initial loss weights\n",
    "    if epoch == 0:\n",
    "        initial_loss_weights = [\n",
    "            loss_weights[0] * loss, \n",
    "            loss_weights[1] * sobolev_loss, \n",
    "            loss_weights[2] * material_penalty\n",
    "        ]\n",
    "\n",
    "    # Calculate the gradient norms for each task\n",
    "    grad_norms = gn.calculate_gradient_norm(model, weighted_losses)\n",
    "    tilde_losses = [gn.compute_loss_ratio(weighted_losses[i].item(), initial_loss_weights[i].item()) for i in range(len(weighted_losses))]\n",
    "\n",
    "    # Compute the grad norm loss\n",
    "    loss_grad = gn.compute_grad_norm_loss(grad_norms, tilde_losses, 100)\n",
    "\n",
    "    # Backpropagation of the gradient loss (update the grad_loss weights)\n",
    "    loss_grad.backward(retain_graph=True)\n",
    "\n",
    "    # Step 1: Perform the optimizer step to update the task weights using the gradient loss\n",
    "    optimizer_w.step()\n",
    "\n",
    "    # Step 2: Compute the total loss (sum of the weighted loss)\n",
    "    total_loss = loss_weights[0] * loss + loss_weights[1] * sobolev_loss + loss_weights[2] * material_penalty\n",
    "\n",
    "    # Backpropagation for the model weights using total loss\n",
    "    total_loss.backward()\n",
    "\n",
    "    # Step 3: Perform the optimizer step to update the model weights using the total loss\n",
    "    optimizer.step()\n",
    "\n",
    "    # Step 4: Renormalize the loss weights (no in-place operation)\n",
    "    T = len(weighted_losses)\n",
    "    sum_w = torch.sum(loss_weights).item()\n",
    "\n",
    "    # Instead of modifying in-place, re-assign to a new tensor\n",
    "    with torch.no_grad():\n",
    "        loss_weights.copy_((loss_weights / sum_w) * T)  # Use .copy_ to avoid creating new tensors and keep gradients\n",
    "\n",
    "    # Store losses for analysis\n",
    "    if epoch > 0:\n",
    "        total_loss_values.append(total_loss.item())\n",
    "        loss_values.append(loss_weights[0].item()*loss.item())\n",
    "        material_loss_values.append(loss_weights[2].item()*material_penalty.item())\n",
    "        sobolev_loss_values.append(loss_weights[1].item()*sobolev_loss.item())\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Epoch: {epoch + 1}, Total Loss: {total_loss.item()}, Loss Weights: {loss_weights.detach().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_total_loss = total_loss_values[150:]\n",
    "plt.plot(filtered_total_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_loss = loss_values[150:]\n",
    "plt.plot(filtered_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_material_loss = material_loss_values[150:]\n",
    "plt.plot(filtered_material_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Material Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_sobolev_loss = sobolev_loss_values[150:]\n",
    "plt.plot(filtered_sobolev_loss)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Sobolev Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "filtered_alpha_values = alpha_values_values[150:]\n",
    "plt.plot(filtered_alpha_values)\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('alpha')\n",
    "plt.title('Alpha Values over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geometry parameter\n",
    "I_new = 1e-4\n",
    "A_new = 2\n",
    "E_new = 110e5\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new, A_new, I_new, load, q, t)\n",
    "\n",
    "# Testing the model with new parameters\n",
    "material_params = torch.tensor([E_new , A_new , I_new ], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geometry parameter\n",
    "I_new_2 = 1e-4\n",
    "A_new_2 = 3\n",
    "E_new_2 = 80e2\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new_2, A_new_2, I_new_2, load, q, t)\n",
    "\n",
    "# Testing the model with new parameters\n",
    "material_params = torch.tensor([E_new_2 , A_new_2 , I_new_2 ], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using few material data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import core.grad_norm as gn\n",
    "import core.neural_backend as neural\n",
    "from utils.helpers import generate_beam_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py:199: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  normalized_nodes = torch.tensor(normalized_nodes, dtype=torch.float32, requires_grad=True)\n",
      "/Users/pauloakira/Main/_repos/ai-pinn/core/neural_backend.py:200: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  normalized_material_params = torch.tensor(normalized_material_params, dtype=torch.float32, requires_grad=True)\n",
      "/var/folders/r8/9jdwwqz11dq7_2m0n6cds_k40000gn/T/ipykernel_68800/2093153052.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "ndof = 3 * len(nodes)\n",
    "input_dim = 2*len(nodes) + 3\n",
    "\n",
    "input_dim_nodes = 2*len(nodes)\n",
    "input_dim_materials = 3\n",
    "\n",
    "# Original material parameters\n",
    "material_params_1 = torch.tensor([E, A, I], dtype=torch.float32)\n",
    "\n",
    "# Perturbed material parameters (slightly changed)\n",
    "material_params_2 = torch.tensor([E *1.1, A * 1.1, I * 0.9], dtype=torch.float32)\n",
    "\n",
    "nodes, material_params_1 = neural.normalize_inputs(nodes, material_params_1)\n",
    "_, material_params_2 = neural.normalize_inputs(nodes, material_params_2)\n",
    "\n",
    "nodes = nodes.flatten()\n",
    "nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "input_vector = torch.cat([nodes, material_params_1])\n",
    "\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers definition\n",
    "nodes_layers = [128, 256, 512, 512, 512, 512]  # Layers for nodes sub-network\n",
    "material_layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2048, 2048, 4096, 4096, 2048, 2048, 1024, 1024, 1024, 1024, 512, 512] # Layers for materials sub-network\n",
    "final_layers = [1024, 1024, 1024, 1024, 1024, 1024] # Layers for final combination network\n",
    "\n",
    "model = neural.BeamApproximatorWithMaterials(\n",
    "                input_dim_nodes=input_dim_nodes, \n",
    "                input_dim_materials=input_dim_materials, \n",
    "                nodes_layers=nodes_layers, \n",
    "                material_layers=material_layers, \n",
    "                final_layers=final_layers, \n",
    "                ndof=ndof)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "K = torch.tensor(K, dtype=torch.float32, requires_grad=True)\n",
    "f = torch.tensor(f, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "total_loss_values = []\n",
    "loss_values = []\n",
    "material_loss_values = []\n",
    "sobolev_loss_values = []\n",
    "alpha_values_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalize(value, mean_val, std_val):\n",
    "    \"\"\"Z-score normalization.\"\"\"\n",
    "    return (value - mean_val) / std_val\n",
    "\n",
    "def generate_beam_dataset(elastic_module_range: list, inertia_moment_range: list, area_range: list, num_samples: int):\n",
    "    \"\"\"\n",
    "    Function to generate a dataset of beam parameters with z-score normalized material properties.\n",
    "    \"\"\"\n",
    "    # Initialize lists to store the dataset\n",
    "    dataset = []\n",
    "\n",
    "    # Generate the material parameters\n",
    "    params = generate_beam_parameters(elastic_module_range, inertia_moment_range, area_range, num_samples)\n",
    "\n",
    "    # Extract E, I, and A values for normalization\n",
    "    E_values = [param['E'] for param in params]\n",
    "    I_values = [param['I'] for param in params]\n",
    "    A_values = [param['A'] for param in params]\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    E_mean, E_std = torch.mean(torch.tensor(E_values)), torch.std(torch.tensor(E_values))\n",
    "    I_mean, I_std = torch.mean(torch.tensor(I_values)), torch.std(torch.tensor(I_values))\n",
    "    A_mean, A_std = torch.mean(torch.tensor(A_values)), torch.std(torch.tensor(A_values))\n",
    "\n",
    "    # Normalize each parameter using z-score normalization\n",
    "    for i in range(num_samples):\n",
    "        E, I, A = params[i]['E'], params[i]['I'], params[i]['A']\n",
    "\n",
    "        # Z-score normalization\n",
    "        E_norm = z_score_normalize(E, E_mean, E_std)\n",
    "        I_norm = z_score_normalize(I, I_mean, I_std)\n",
    "        A_norm = z_score_normalize(A, A_mean, A_std)\n",
    "\n",
    "        # Generate the geometry\n",
    "        nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "        # Solve the problem using the VEM\n",
    "        uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E, A, I, load, q, t, verbose=False)\n",
    "\n",
    "        # Convert nodes to tensor\n",
    "        nodes = nodes.flatten()\n",
    "        nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "        # Store the dataset\n",
    "        dataset.append({\n",
    "            \"nodes\": nodes,\n",
    "            \"elements\": elements,\n",
    "            \"supp\": supp,\n",
    "            \"load\": load,\n",
    "            \"uh_vem\": uh_vem,\n",
    "            \"K\": K,\n",
    "            \"f\": f,\n",
    "            \"material_params\": torch.tensor([E_norm, A_norm, I_norm], dtype=torch.float32),\n",
    "            \"distorted_material_params\": torch.tensor([z_score_normalize(E * 1.3, E_mean, E_std), \n",
    "                                                      z_score_normalize(A * 1.1, A_mean, A_std), \n",
    "                                                      z_score_normalize(I * 0.3, I_mean, I_std)], dtype=torch.float32)\n",
    "        })\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loss weights\n",
    "loss_weights = torch.ones(3, requires_grad=True)  # We have 3 tasks: loss, sobolev_loss, and material_penalty\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 20\n",
    "concatenate = False\n",
    "\n",
    "# Initialize optimizers (including the loss_weights as parameters)\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + [loss_weights], lr=1e-3)\n",
    "optimizer_w = torch.optim.SGD([loss_weights], lr=1e-3)\n",
    "\n",
    "# Initialize lists to store loss values\n",
    "total_loss_values, loss_values, material_loss_values, sobolev_loss_values, alpha_values_values = [], [], [], [], []\n",
    "\n",
    "# Enable anomaly detection for debugging\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Different material property configurations (for example, different E, I, A values)\n",
    "dataset = generate_beam_dataset([1e6, 210e9], [1e-6, 1e-3], [1, 10], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r8/9jdwwqz11dq7_2m0n6cds_k40000gn/T/ipykernel_68800/3563643733.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 1, Total Loss: 0.2268836194726876, Loss Weights: [0.99962854 0.99962854 1.0007428 ]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 2, Total Loss: 0.056452432674539914, Loss Weights: [0.9993421 0.9993421 1.0013157]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 3, Total Loss: 0.04749735067712011, Loss Weights: [0.9990816 0.9990816 1.0018365]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 4, Total Loss: 0.00783118003068027, Loss Weights: [0.99886715 0.99886715 1.0022656 ]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 5, Total Loss: 0.008682080728775361, Loss Weights: [0.9986789 0.9986789 1.0026422]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 6, Total Loss: 0.00900018528959242, Loss Weights: [0.9985099 0.9985099 1.0029802]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 7, Total Loss: 0.008322263344041335, Loss Weights: [0.9983563 0.9983563 1.0032873]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 8, Total Loss: 0.007547215039040835, Loss Weights: [0.99821573 0.99821573 1.0035686 ]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 9, Total Loss: 0.005643129123853549, Loss Weights: [0.99808717 0.99808717 1.0038257 ]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 10, Total Loss: 0.0037572303839154956, Loss Weights: [0.99797004 0.99797004 1.0040598 ]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 11, Total Loss: 0.002594665644126684, Loss Weights: [0.9978635 0.9978635 1.0042729]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 12, Total Loss: 0.001761349104967676, Loss Weights: [0.9977666 0.9977666 1.0044669]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 13, Total Loss: 0.001429674156519198, Loss Weights: [0.9976782 0.9976782 1.0046434]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 14, Total Loss: 0.001167356424059007, Loss Weights: [0.9975977 0.9975977 1.0048047]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 15, Total Loss: 0.0010970069376896687, Loss Weights: [0.997524  0.997524  1.0049522]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 16, Total Loss: 0.0010624616081899856, Loss Weights: [0.9974563 0.9974563 1.0050871]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 17, Total Loss: 0.0009877574467246882, Loss Weights: [0.99739444 0.99739444 1.0052112 ]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 18, Total Loss: 0.0009723962005730515, Loss Weights: [0.9973374 0.9973374 1.0053252]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 19, Total Loss: 0.0008591187616548446, Loss Weights: [0.997285  0.997285  1.0054301]\n",
      "Material 1: tensor([ 1.0297, -0.9674, -0.0623], requires_grad=True), Epoch: 20, Total Loss: 0.000744935734241645, Loss Weights: [0.9972367 0.9972367 1.0055264]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 1, Total Loss: 0.0005875798707953422, Loss Weights: [0.9971925 0.9971925 1.005615 ]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 2, Total Loss: 0.0004399378360383593, Loss Weights: [0.99715185 0.99715185 1.0056963 ]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 3, Total Loss: 0.00034642081785147606, Loss Weights: [0.99711466 0.99711466 1.0057708 ]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 4, Total Loss: 0.0002619210094245635, Loss Weights: [0.99708045 0.99708045 1.0058389 ]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 5, Total Loss: 0.0002332606173054627, Loss Weights: [0.9970492 0.9970492 1.0059015]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 6, Total Loss: 0.00021213505564169957, Loss Weights: [0.9970206 0.9970206 1.0059588]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 7, Total Loss: 0.0002058508565206904, Loss Weights: [0.9969944 0.9969944 1.0060112]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 8, Total Loss: 0.0001936242717366957, Loss Weights: [0.9969703 0.9969703 1.0060594]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 9, Total Loss: 0.0001687672990140756, Loss Weights: [0.9969483 0.9969483 1.0061035]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 10, Total Loss: 0.0001590087922326579, Loss Weights: [0.9969281 0.9969281 1.006144 ]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 11, Total Loss: 0.0001417388796365815, Loss Weights: [0.9969094 0.9969094 1.006181 ]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 12, Total Loss: 0.00013728869165482998, Loss Weights: [0.99689245 0.99689245 1.0062151 ]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 13, Total Loss: 0.00012279337640529046, Loss Weights: [0.99687684 0.99687684 1.0062463 ]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 14, Total Loss: 0.00010939881288174972, Loss Weights: [0.99686253 0.99686253 1.0062749 ]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 15, Total Loss: 9.561647753756102e-05, Loss Weights: [0.9968494 0.9968494 1.0063012]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 16, Total Loss: 7.857738929604278e-05, Loss Weights: [0.9968374 0.9968374 1.0063251]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 17, Total Loss: 6.882656510546646e-05, Loss Weights: [0.9968264 0.9968264 1.0063472]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 18, Total Loss: 5.763105201474194e-05, Loss Weights: [0.99681634 0.99681634 1.0063672 ]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 19, Total Loss: 5.49575642822274e-05, Loss Weights: [0.9968071 0.9968071 1.0063856]\n",
      "Material 2: tensor([ 0.5111,  0.6412, -1.1523], requires_grad=True), Epoch: 20, Total Loss: 5.0755965708609946e-05, Loss Weights: [0.9967988 0.9967988 1.0064025]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 1, Total Loss: 4.823117793500941e-05, Loss Weights: [0.996791  0.996791  1.0064179]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 2, Total Loss: 4.3621853643219074e-05, Loss Weights: [0.996784 0.996784 1.006432]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 3, Total Loss: 3.817775849206097e-05, Loss Weights: [0.99677753 0.99677753 1.006445  ]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 4, Total Loss: 3.4264839228802895e-05, Loss Weights: [0.99677163 0.99677163 1.0064569 ]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 5, Total Loss: 2.8526371326646885e-05, Loss Weights: [0.9967662 0.9967662 1.0064676]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 6, Total Loss: 2.4884855341056854e-05, Loss Weights: [0.99676126 0.99676126 1.0064774 ]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 7, Total Loss: 1.992608002826942e-05, Loss Weights: [0.9967568 0.9967568 1.0064864]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 8, Total Loss: 1.884993305103327e-05, Loss Weights: [0.9967527 0.9967527 1.0064946]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 9, Total Loss: 1.729889620290285e-05, Loss Weights: [0.9967489 0.9967489 1.0065022]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 10, Total Loss: 1.797610255123826e-05, Loss Weights: [0.9967455 0.9967455 1.0065091]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 11, Total Loss: 1.7017635231416977e-05, Loss Weights: [0.9967423 0.9967423 1.0065153]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 12, Total Loss: 1.6570207483191952e-05, Loss Weights: [0.99673945 0.99673945 1.006521  ]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 13, Total Loss: 1.44179977888862e-05, Loss Weights: [0.9967369 0.9967369 1.0065262]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 14, Total Loss: 1.2322252767367179e-05, Loss Weights: [0.99673444 0.99673444 1.006531  ]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 15, Total Loss: 9.810242351491329e-06, Loss Weights: [0.9967323 0.9967323 1.0065354]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 16, Total Loss: 8.111650451404756e-06, Loss Weights: [0.9967303 0.9967303 1.0065395]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 17, Total Loss: 7.285139140603968e-06, Loss Weights: [0.9967284 0.9967284 1.0065432]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 18, Total Loss: 6.866188476426995e-06, Loss Weights: [0.9967269 0.9967269 1.0065465]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 19, Total Loss: 6.827679601781752e-06, Loss Weights: [0.9967252 0.9967252 1.0065494]\n",
      "Material 3: tensor([-0.6321, -0.5209,  1.1529], requires_grad=True), Epoch: 20, Total Loss: 6.361299954010772e-06, Loss Weights: [0.996724  0.996724  1.0065522]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 1, Total Loss: 6.075802410168102e-06, Loss Weights: [0.99672264 0.99672264 1.0065546 ]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 2, Total Loss: 5.276716635535132e-06, Loss Weights: [0.99672157 0.99672157 1.006557  ]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 3, Total Loss: 4.8027065276747255e-06, Loss Weights: [0.9967205 0.9967205 1.0065591]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 4, Total Loss: 4.082583991310201e-06, Loss Weights: [0.9967195 0.9967195 1.006561 ]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 5, Total Loss: 3.8378610420669224e-06, Loss Weights: [0.99671865 0.99671865 1.0065627 ]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 6, Total Loss: 3.34092696881314e-06, Loss Weights: [0.9967178 0.9967178 1.0065643]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 7, Total Loss: 3.139007704992355e-06, Loss Weights: [0.9967171 0.9967171 1.0065657]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 8, Total Loss: 2.6996504124062487e-06, Loss Weights: [0.9967165 0.9967165 1.006567 ]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 9, Total Loss: 2.5493251196804356e-06, Loss Weights: [0.9967159 0.9967159 1.0065682]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 10, Total Loss: 2.1966692735893582e-06, Loss Weights: [0.9967154 0.9967154 1.0065693]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 11, Total Loss: 2.034724747595449e-06, Loss Weights: [0.99671483 0.99671483 1.0065702 ]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 12, Total Loss: 1.7175793317932006e-06, Loss Weights: [0.9967144 0.9967144 1.0065712]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 13, Total Loss: 1.6122520872888829e-06, Loss Weights: [0.996714 0.996714 1.006572]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 14, Total Loss: 1.3991608687079175e-06, Loss Weights: [0.9967137 0.9967137 1.0065727]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 15, Total Loss: 1.351402791111918e-06, Loss Weights: [0.99671334 0.99671334 1.0065733 ]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 16, Total Loss: 1.2243468915337784e-06, Loss Weights: [0.996713  0.996713  1.0065739]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 17, Total Loss: 1.2304106064541385e-06, Loss Weights: [0.9967128 0.9967128 1.0065746]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 18, Total Loss: 1.1088859844145812e-06, Loss Weights: [0.99671257 0.99671257 1.0065751 ]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 19, Total Loss: 1.0186156851076046e-06, Loss Weights: [0.99671227 0.99671227 1.0065755 ]\n",
      "Material 4: tensor([-0.5416, -0.6124,  1.1540], requires_grad=True), Epoch: 20, Total Loss: 8.176900534368581e-07, Loss Weights: [0.9967121 0.9967121 1.006576 ]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 1, Total Loss: 6.931506081550726e-07, Loss Weights: [0.99671185 0.99671185 1.0065763 ]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 2, Total Loss: 5.489417536200705e-07, Loss Weights: [0.9967116 0.9967116 1.0065767]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 3, Total Loss: 5.086463814354238e-07, Loss Weights: [0.9967115 0.9967115 1.006577 ]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 4, Total Loss: 4.864916394248144e-07, Loss Weights: [0.9967114 0.9967114 1.0065774]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 5, Total Loss: 5.125852261205825e-07, Loss Weights: [0.9967112 0.9967112 1.0065776]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 6, Total Loss: 4.996962433618771e-07, Loss Weights: [0.99671113 0.99671113 1.0065778 ]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 7, Total Loss: 4.601934819210756e-07, Loss Weights: [0.9967109 0.9967109 1.006578 ]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 8, Total Loss: 3.9843305597599416e-07, Loss Weights: [0.9967109 0.9967109 1.0065783]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 9, Total Loss: 3.2516756496563577e-07, Loss Weights: [0.9967108 0.9967108 1.0065784]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 10, Total Loss: 2.7540650159354925e-07, Loss Weights: [0.99671066 0.99671066 1.0065786 ]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 11, Total Loss: 2.3193577512745212e-07, Loss Weights: [0.99671054 0.99671054 1.0065787 ]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 12, Total Loss: 2.2932503078996556e-07, Loss Weights: [0.9967105 0.9967105 1.0065789]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 13, Total Loss: 2.098977659702405e-07, Loss Weights: [0.9967105 0.9967105 1.006579 ]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 14, Total Loss: 2.0300986616158835e-07, Loss Weights: [0.9967105 0.9967105 1.0065792]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 15, Total Loss: 1.748984287196947e-07, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 16, Total Loss: 1.6391481012969765e-07, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 17, Total Loss: 1.4581049204109586e-07, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 18, Total Loss: 1.3444927018602243e-07, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 19, Total Loss: 1.2345081792160256e-07, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 5: tensor([ 0.6955, -1.1460,  0.4505], requires_grad=True), Epoch: 20, Total Loss: 1.0792337646119008e-07, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 1, Total Loss: 9.627964114358215e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 2, Total Loss: 7.808336031366518e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 3, Total Loss: 7.27492225356334e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 4, Total Loss: 6.502075517205367e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 5, Total Loss: 6.500973414283317e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 6, Total Loss: 6.300890443074063e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 7, Total Loss: 5.8117061557610134e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 8, Total Loss: 5.1504075777106635e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 9, Total Loss: 4.065599731673324e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 10, Total Loss: 3.6475499166345417e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 11, Total Loss: 3.13529833786832e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 12, Total Loss: 2.9084883120121135e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 13, Total Loss: 2.6935028576287847e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 14, Total Loss: 2.5060304905559597e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 15, Total Loss: 2.5646492506676522e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 16, Total Loss: 2.3609956668980223e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 17, Total Loss: 2.178127292679044e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 18, Total Loss: 1.755300726762287e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 19, Total Loss: 1.359005098435462e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 6: tensor([ 0.9761, -1.0223,  0.0462], requires_grad=True), Epoch: 20, Total Loss: 1.2511600353263961e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 1, Total Loss: 1.1788063501856329e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 2, Total Loss: 1.2097434054600301e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 3, Total Loss: 1.1078711184922228e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 4, Total Loss: 9.706513652093862e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 5, Total Loss: 9.006334491359171e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 6, Total Loss: 7.867590684738155e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 7, Total Loss: 7.52135348626248e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 8, Total Loss: 6.811151408866431e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 9, Total Loss: 5.809344293507466e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 10, Total Loss: 5.468562504315845e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 11, Total Loss: 4.901390551568285e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 12, Total Loss: 4.505209798375563e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 13, Total Loss: 4.078751414898745e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 14, Total Loss: 3.487986099893185e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 15, Total Loss: 3.3976354879408313e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 16, Total Loss: 3.31312446938452e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 17, Total Loss: 3.1911041147780047e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 18, Total Loss: 3.0504412270659626e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 19, Total Loss: 2.5371716218852087e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 7: tensor([-0.1996,  1.0847, -0.8852], requires_grad=True), Epoch: 20, Total Loss: 2.167028337353159e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 1, Total Loss: 2.024929151286767e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 2, Total Loss: 1.8340382240351305e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 3, Total Loss: 1.7826017428555291e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 4, Total Loss: 1.7318278006441238e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 5, Total Loss: 1.6055797018243266e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 6, Total Loss: 1.5690828358256251e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 7, Total Loss: 1.471694032462883e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 8, Total Loss: 1.3077954650644567e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 9, Total Loss: 1.211433610612542e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 10, Total Loss: 1.1187619619144866e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 11, Total Loss: 1.054467158919506e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 12, Total Loss: 1.0377085427782716e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 13, Total Loss: 9.792558153593091e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 14, Total Loss: 9.214075443411843e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 15, Total Loss: 8.959610087010643e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 16, Total Loss: 8.478341882443139e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 17, Total Loss: 8.058479479528821e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 18, Total Loss: 7.839744276890201e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 19, Total Loss: 7.438643763595531e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 8: tensor([ 0.8850,  0.1998, -1.0848], requires_grad=True), Epoch: 20, Total Loss: 7.097015569729909e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 1, Total Loss: 6.930711040019553e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 2, Total Loss: 6.63602690100943e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 3, Total Loss: 6.372514641659081e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 4, Total Loss: 6.260309085206103e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 5, Total Loss: 6.062198670921414e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 6, Total Loss: 5.831753537668853e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 7, Total Loss: 5.728833919955424e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 8, Total Loss: 5.631347879843024e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 9, Total Loss: 5.496712212052804e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 10, Total Loss: 5.382114497306917e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 11, Total Loss: 5.222371117753337e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 12, Total Loss: 5.026518135446413e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 13, Total Loss: 4.928851889039183e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 14, Total Loss: 4.917893660184361e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 15, Total Loss: 4.876918719897454e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 16, Total Loss: 4.784592418522852e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 17, Total Loss: 4.677342578708317e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 18, Total Loss: 4.566546799555117e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 19, Total Loss: 4.478649924598368e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 9: tensor([ 0.8739, -1.0906,  0.2166], requires_grad=True), Epoch: 20, Total Loss: 4.441723606742655e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 1, Total Loss: 4.4144163820829453e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 2, Total Loss: 4.347981337620099e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 3, Total Loss: 4.270547189331226e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 4, Total Loss: 4.219069047166612e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 5, Total Loss: 4.170648021074867e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 6, Total Loss: 4.1102670370883536e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 7, Total Loss: 4.061131206167137e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 8, Total Loss: 4.0257103646932986e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 9, Total Loss: 3.9850752923797626e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 10, Total Loss: 3.9393709717122433e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 11, Total Loss: 3.8955394800225287e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 12, Total Loss: 3.8511604229452173e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 13, Total Loss: 3.808399024169225e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 14, Total Loss: 3.7738901745485847e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 15, Total Loss: 3.744379384165078e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 16, Total Loss: 3.7098063352520457e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 17, Total Loss: 3.667159871228667e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 18, Total Loss: 3.626234383268755e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 19, Total Loss: 3.595277290125485e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 10: tensor([ 1.0379, -0.0807, -0.9572], requires_grad=True), Epoch: 20, Total Loss: 3.5675699792443447e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 1, Total Loss: 4.6399281350512943e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 2, Total Loss: 4.1374434546143534e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 3, Total Loss: 3.646528253752694e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 4, Total Loss: 3.5163647659436256e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 5, Total Loss: 3.6774103554802977e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 6, Total Loss: 3.8469695488246974e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 7, Total Loss: 3.840121866401057e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 8, Total Loss: 3.678003361238032e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 9, Total Loss: 3.495980772364192e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 10, Total Loss: 3.4006644081584783e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 11, Total Loss: 3.394745271902982e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 12, Total Loss: 3.4084628279781464e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 13, Total Loss: 3.3849162767374163e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 14, Total Loss: 3.325485880012386e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 15, Total Loss: 3.2621802707760166e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 16, Total Loss: 3.2149018966328736e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 17, Total Loss: 3.182006994799313e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 18, Total Loss: 3.1551908389981863e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 19, Total Loss: 3.125717822775369e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 11: tensor([-1.1179,  0.3087,  0.8093], requires_grad=True), Epoch: 20, Total Loss: 3.0906632208773613e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 1, Total Loss: 4.3296468134689125e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 2, Total Loss: 3.68210453599561e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 3, Total Loss: 3.1620459916593303e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 4, Total Loss: 3.1044607337534695e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 5, Total Loss: 3.3325130931880416e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 6, Total Loss: 3.4983218306079875e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 7, Total Loss: 3.4378471163143014e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 8, Total Loss: 3.2287169328851114e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 9, Total Loss: 3.0417343761812714e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 10, Total Loss: 2.9757675852717784e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 11, Total Loss: 2.9960215898440143e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 12, Total Loss: 3.0087362578018686e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 13, Total Loss: 2.968502876292183e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 14, Total Loss: 2.901043857450685e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 15, Total Loss: 2.8394687413394983e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 16, Total Loss: 2.7927978499475626e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 17, Total Loss: 2.761035864215874e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 18, Total Loss: 2.7402907334634606e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 19, Total Loss: 2.717607232997004e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 12: tensor([-0.4537,  1.1464, -0.6927], requires_grad=True), Epoch: 20, Total Loss: 2.68410285091686e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 1, Total Loss: 2.6445716725401074e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 2, Total Loss: 2.612008485327053e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 3, Total Loss: 2.585692792810718e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 4, Total Loss: 2.5615317980949523e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 5, Total Loss: 2.5394027337648945e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 6, Total Loss: 2.5177623975429343e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 7, Total Loss: 2.4919440064189014e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 8, Total Loss: 2.463436525109996e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 9, Total Loss: 2.438804640349176e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 10, Total Loss: 2.4205268609176035e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 11, Total Loss: 2.403498237349648e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 12, Total Loss: 2.3826662097687754e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 13, Total Loss: 2.3587944864213494e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 14, Total Loss: 2.3361261971300423e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 15, Total Loss: 2.3174300057863803e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 16, Total Loss: 2.3016254562941137e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 17, Total Loss: 2.2851300583039712e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 18, Total Loss: 2.2652890002540443e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 19, Total Loss: 2.2440226546957242e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 13: tensor([ 1.1415, -0.4199, -0.7216], requires_grad=True), Epoch: 20, Total Loss: 2.2251808128980342e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 1, Total Loss: 2.2096489650887884e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 2, Total Loss: 2.194658404579712e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 3, Total Loss: 2.1780971809987185e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 4, Total Loss: 2.160269200041889e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 5, Total Loss: 2.1424336846377303e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 6, Total Loss: 2.1258697319050695e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 7, Total Loss: 2.11064790841811e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 8, Total Loss: 2.0959671116564729e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 9, Total Loss: 2.0807639363289667e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 10, Total Loss: 2.0648776214045345e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 11, Total Loss: 2.0490013446310164e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 12, Total Loss: 2.03386543834334e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 13, Total Loss: 2.0193984661396248e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 14, Total Loss: 2.0052360313184157e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 15, Total Loss: 1.9912179721757185e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 16, Total Loss: 1.9773094195748843e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 17, Total Loss: 1.9636878807728836e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 18, Total Loss: 1.9510710297287783e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 19, Total Loss: 1.940174743478069e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 14: tensor([-0.5306,  1.1535, -0.6229], requires_grad=True), Epoch: 20, Total Loss: 1.9320908324144566e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 1, Total Loss: 1.929202761344129e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 2, Total Loss: 1.936365800845958e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 3, Total Loss: 1.964446065956242e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 4, Total Loss: 2.0359525015698535e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 5, Total Loss: 2.1989997014349578e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 6, Total Loss: 2.559296897839294e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 7, Total Loss: 3.352302752947885e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 8, Total Loss: 5.111137551997416e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 9, Total Loss: 9.06165907289984e-10, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 10, Total Loss: 1.807188442068016e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 11, Total Loss: 3.894958086532046e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 12, Total Loss: 8.814637797017129e-09, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 13, Total Loss: 2.0583371961085985e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 14, Total Loss: 4.921945079905625e-08, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 15, Total Loss: 1.2008970696238423e-07, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 16, Total Loss: 2.9773249442892314e-07, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 17, Total Loss: 7.469004991961476e-07, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 18, Total Loss: 1.8952613948237728e-06, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 19, Total Loss: 4.862401832271725e-06, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 15: tensor([ 0.6610,  0.4895, -1.1504], requires_grad=True), Epoch: 20, Total Loss: 1.2085478367302434e-05, Loss Weights: [0.9967104 0.9967104 1.0065792]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 1, Total Loss: 2.719570607911943e-05, Loss Weights: [0.9967103 0.9967103 1.0065794]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 2, Total Loss: 5.317070196465844e-05, Loss Weights: [0.99671006 0.99671006 1.0065799 ]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 3, Total Loss: 7.470911492712894e-05, Loss Weights: [0.9967096 0.9967096 1.0065807]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 4, Total Loss: 6.020912660126485e-05, Loss Weights: [0.99670905 0.99670905 1.0065818 ]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 5, Total Loss: 1.4408157645608529e-05, Loss Weights: [0.99670863 0.99670863 1.0065829 ]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 6, Total Loss: 2.8079588983473176e-06, Loss Weights: [0.99670815 0.99670815 1.0065838 ]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 7, Total Loss: 2.9191204197995663e-05, Loss Weights: [0.9967076 0.9967076 1.0065848]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 8, Total Loss: 2.434448038401989e-05, Loss Weights: [0.9967071 0.9967071 1.0065858]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 9, Total Loss: 6.85469756773457e-07, Loss Weights: [0.9967066 0.9967066 1.0065868]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 10, Total Loss: 1.2558841965031796e-05, Loss Weights: [0.9967062 0.9967062 1.0065877]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 11, Total Loss: 1.7697016412696723e-05, Loss Weights: [0.99670565 0.99670565 1.0065886 ]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 12, Total Loss: 1.7635652288346102e-06, Loss Weights: [0.9967053 0.9967053 1.0065895]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 13, Total Loss: 6.542389952976599e-06, Loss Weights: [0.99670494 0.99670494 1.0065904 ]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 14, Total Loss: 9.518570527649368e-06, Loss Weights: [0.9967044 0.9967044 1.0065911]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 15, Total Loss: 1.294332380363176e-06, Loss Weights: [0.9967041 0.9967041 1.0065919]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 16, Total Loss: 4.266598853135264e-06, Loss Weights: [0.99670374 0.99670374 1.0065925 ]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 17, Total Loss: 4.884301325002632e-06, Loss Weights: [0.9967035 0.9967035 1.0065932]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 18, Total Loss: 3.3345397727023034e-07, Loss Weights: [0.99670315 0.99670315 1.0065937 ]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 19, Total Loss: 4.327548309333095e-06, Loss Weights: [0.9967029 0.9967029 1.0065942]\n",
      "Material 16: tensor([ 0.6905, -1.1468,  0.4563], requires_grad=True), Epoch: 20, Total Loss: 2.2983991315031645e-06, Loss Weights: [0.9967027 0.9967027 1.0065947]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 1, Total Loss: 7.475276410318889e-07, Loss Weights: [0.99670255 0.99670255 1.0065951 ]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 2, Total Loss: 3.5061376069523594e-06, Loss Weights: [0.99670225 0.99670225 1.0065955 ]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 3, Total Loss: 5.94002600249854e-07, Loss Weights: [0.9967021 0.9967021 1.0065958]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 4, Total Loss: 1.5496245354656762e-06, Loss Weights: [0.9967019 0.9967019 1.0065962]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 5, Total Loss: 2.112851711060358e-06, Loss Weights: [0.9967017 0.9967017 1.0065966]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 6, Total Loss: 1.449022277976523e-07, Loss Weights: [0.9967016 0.9967016 1.0065969]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 7, Total Loss: 1.851082952504147e-06, Loss Weights: [0.9967015 0.9967015 1.0065972]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 8, Total Loss: 7.921915606754835e-07, Loss Weights: [0.99670124 0.99670124 1.0065973 ]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 9, Total Loss: 4.957383719226916e-07, Loss Weights: [0.9967012 0.9967012 1.0065976]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 10, Total Loss: 1.447193371246405e-06, Loss Weights: [0.996701  0.996701  1.0065978]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 11, Total Loss: 1.3680171243747838e-07, Loss Weights: [0.996701  0.996701  1.0065981]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 12, Total Loss: 8.63506880169427e-07, Loss Weights: [0.9967008 0.9967008 1.0065982]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 13, Total Loss: 7.241747820415535e-07, Loss Weights: [0.99670076 0.99670076 1.0065984 ]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 14, Total Loss: 1.2614320100130574e-07, Loss Weights: [0.99670064 0.99670064 1.0065985 ]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 15, Total Loss: 8.500971070257931e-07, Loss Weights: [0.99670064 0.99670064 1.0065987 ]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 16, Total Loss: 2.0126091972966577e-07, Loss Weights: [0.99670064 0.99670064 1.006599  ]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 17, Total Loss: 3.358348161227035e-07, Loss Weights: [0.99670047 0.99670047 1.006599  ]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 18, Total Loss: 5.496866732649559e-07, Loss Weights: [0.99670047 0.99670047 1.0065991 ]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 19, Total Loss: 4.2950217546709274e-08, Loss Weights: [0.99670047 0.99670047 1.0065992 ]\n",
      "Material 17: tensor([ 0.4363,  0.7077, -1.1440], requires_grad=True), Epoch: 20, Total Loss: 4.506989869890165e-07, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 1, Total Loss: 2.1965801384169478e-07, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 2, Total Loss: 1.0527524866772123e-07, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 3, Total Loss: 3.7460468189011534e-07, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 4, Total Loss: 4.747975164613886e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 5, Total Loss: 1.9674064255284178e-07, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 6, Total Loss: 2.052728710747953e-07, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 7, Total Loss: 2.3373728083579564e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 8, Total Loss: 2.149206144061141e-07, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 9, Total Loss: 7.247765630878883e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 10, Total Loss: 6.285021666287671e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 11, Total Loss: 1.586103778444702e-07, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 12, Total Loss: 1.4071659898724432e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 13, Total Loss: 9.588189616978812e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 14, Total Loss: 8.59814519166958e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 15, Total Loss: 1.1912677799335443e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 16, Total Loss: 9.373318140051666e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 17, Total Loss: 3.1473561177720195e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 18, Total Loss: 2.89278108318204e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 19, Total Loss: 6.964436716927861e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 18: tensor([-1.0278,  0.9696,  0.0582], requires_grad=True), Epoch: 20, Total Loss: 7.587587145211368e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 1, Total Loss: 4.0119651765708986e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 2, Total Loss: 4.004299231289582e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 3, Total Loss: 4.214219787693969e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 4, Total Loss: 4.0022922549244845e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 5, Total Loss: 1.8297334149985883e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 6, Total Loss: 8.802353429268514e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 7, Total Loss: 3.1509421109382824e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 8, Total Loss: 6.44739582284858e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 9, Total Loss: 1.347500224019316e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 10, Total Loss: 2.1142982453121784e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 11, Total Loss: 2.0400205457892424e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 12, Total Loss: 1.4699286991935175e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 13, Total Loss: 1.2353760182472753e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 14, Total Loss: 1.870481634357514e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 15, Total Loss: 1.3304832892008613e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 16, Total Loss: 6.291362191865676e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 17, Total Loss: 2.8424890122732326e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 18, Total Loss: 1.0641898774824524e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 19, Total Loss: 2.9341446349604194e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 19: tensor([-0.1954,  1.0833, -0.8879], requires_grad=True), Epoch: 20, Total Loss: 3.6004709823406605e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 1, Total Loss: 7.703365942349914e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 2, Total Loss: 1.4202938988075834e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 3, Total Loss: 3.898316719644368e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 4, Total Loss: 5.211983242349509e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 5, Total Loss: 8.291658437007097e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 6, Total Loss: 3.7236520877152346e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 7, Total Loss: 3.447709874783624e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 8, Total Loss: 6.653369295051331e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 9, Total Loss: 3.2331725675680154e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 10, Total Loss: 2.278301802305589e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 11, Total Loss: 6.840060861952748e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 12, Total Loss: 2.665553833900616e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 13, Total Loss: 1.5239066988054393e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 14, Total Loss: 7.037547835900035e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 15, Total Loss: 2.1425592206571705e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 16, Total Loss: 1.0866006096195763e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 17, Total Loss: 6.971953183549539e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 18, Total Loss: 1.683584299674388e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 19, Total Loss: 8.195441547350586e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 20: tensor([-1.1162,  0.8141,  0.3021], requires_grad=True), Epoch: 20, Total Loss: 6.745076897355547e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 1, Total Loss: 1.3389818668534832e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 2, Total Loss: 6.554619789443677e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 3, Total Loss: 6.196448497432134e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 4, Total Loss: 1.0765625832307824e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 5, Total Loss: 5.586032679485311e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 6, Total Loss: 5.623037867495909e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 7, Total Loss: 8.83706189731882e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 8, Total Loss: 4.962321294193671e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 9, Total Loss: 5.02416931438108e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 10, Total Loss: 7.420681289165217e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 11, Total Loss: 4.5851206669662147e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 12, Total Loss: 4.465772452568811e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 13, Total Loss: 6.330033023762165e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 14, Total Loss: 4.330111519579734e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 15, Total Loss: 4.071630533961234e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 16, Total Loss: 5.494910592150688e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 17, Total Loss: 4.123522368135526e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 18, Total Loss: 3.7450953749165513e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 19, Total Loss: 4.853324433273238e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 21: tensor([ 1.0179, -0.0369, -0.9811], requires_grad=True), Epoch: 20, Total Loss: 3.9608211740093593e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 1, Total Loss: 3.49880859892738e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 2, Total Loss: 4.3542032149133293e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 3, Total Loss: 3.820951313893406e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 4, Total Loss: 3.3153424381518333e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 5, Total Loss: 3.9353444449609453e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 6, Total Loss: 3.6852800235040776e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 7, Total Loss: 3.193989768034264e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 8, Total Loss: 3.5959283821279e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 9, Total Loss: 3.5436747647989576e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 10, Total Loss: 3.112003826274487e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 11, Total Loss: 3.326343619116764e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 12, Total Loss: 3.3956404316412716e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 13, Total Loss: 3.0536813224318266e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 14, Total Loss: 3.1187805041750593e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 15, Total Loss: 3.2439782405430805e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 16, Total Loss: 3.0053691189188895e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 17, Total Loss: 2.963631379825391e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 18, Total Loss: 3.093279699045666e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 19, Total Loss: 2.9543637660079735e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 22: tensor([ 0.0565,  0.9706, -1.0270], requires_grad=True), Epoch: 20, Total Loss: 2.8512735213349216e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 1, Total Loss: 2.952002294291068e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 2, Total Loss: 2.8970526684805614e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 3, Total Loss: 2.7727283382489185e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 4, Total Loss: 2.8194619704526073e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 5, Total Loss: 2.822817913416809e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 6, Total Loss: 2.715247709760426e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 7, Total Loss: 2.7082789219756804e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 8, Total Loss: 2.7355097129389714e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 9, Total Loss: 2.664322832254019e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 10, Total Loss: 2.621014857013782e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 11, Total Loss: 2.643355853762355e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 12, Total Loss: 2.6101050944634445e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 13, Total Loss: 2.553458824934252e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 14, Total Loss: 2.55524255876783e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 15, Total Loss: 2.547664831605629e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 16, Total Loss: 2.497883926614352e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 17, Total Loss: 2.4776142990953223e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 18, Total Loss: 2.4783666654996884e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 19, Total Loss: 2.445874257756551e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 23: tensor([-0.8304,  1.1101, -0.2797], requires_grad=True), Epoch: 20, Total Loss: 2.412689725546164e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 1, Total Loss: 2.410728715044804e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 2, Total Loss: 2.390636919082402e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 3, Total Loss: 2.357259825391232e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 4, Total Loss: 2.341871559758389e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 5, Total Loss: 2.332825879289923e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 6, Total Loss: 2.3077664301283087e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 7, Total Loss: 2.283028011882804e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 8, Total Loss: 2.2708406186416649e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 9, Total Loss: 2.2542275226117429e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 10, Total Loss: 2.230385181163206e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 11, Total Loss: 2.2135153439511257e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 12, Total Loss: 2.2000903632596826e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 13, Total Loss: 2.18018637415848e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 14, Total Loss: 2.1601398802727536e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 15, Total Loss: 2.1458563830501161e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 16, Total Loss: 2.1304793756456286e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 17, Total Loss: 2.111009523465696e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 18, Total Loss: 2.093817369238003e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 19, Total Loss: 2.079754151917389e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 24: tensor([-0.9369,  1.0530, -0.1161], requires_grad=True), Epoch: 20, Total Loss: 2.0634360745098663e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 1, Total Loss: 2.1195853605679822e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 2, Total Loss: 2.057090264526578e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 3, Total Loss: 2.0195890408761288e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 4, Total Loss: 2.0224965620778778e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 5, Total Loss: 2.0249480897711405e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 6, Total Loss: 2.0027025956993357e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 7, Total Loss: 1.970384222662815e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 8, Total Loss: 1.9488153445931e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 9, Total Loss: 1.939607042085141e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 10, Total Loss: 1.9292372379681337e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 11, Total Loss: 1.910699872547496e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 12, Total Loss: 1.8903411309560435e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 13, Total Loss: 1.874982630023491e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 14, Total Loss: 1.8623782871131025e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 15, Total Loss: 1.847770606517805e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 16, Total Loss: 1.8314626995642877e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 17, Total Loss: 1.816372897862478e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 18, Total Loss: 1.8029200854144935e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 19, Total Loss: 1.788808909246811e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 25: tensor([-0.7600, -0.3729,  1.1329], requires_grad=True), Epoch: 20, Total Loss: 1.7742063142888751e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 1, Total Loss: 1.8262764801425835e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 2, Total Loss: 1.771500115954432e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 3, Total Loss: 1.735263844454134e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 4, Total Loss: 1.7395209324292523e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 5, Total Loss: 1.744452946510492e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 6, Total Loss: 1.7243686842691288e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 7, Total Loss: 1.6943257583238833e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 8, Total Loss: 1.676440153395549e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 9, Total Loss: 1.6709483896967116e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 10, Total Loss: 1.6619959769148168e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 11, Total Loss: 1.6442412537063172e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 12, Total Loss: 1.6270329221842589e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 13, Total Loss: 1.6157458701126404e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 14, Total Loss: 1.605326288290475e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 15, Total Loss: 1.5917429997677006e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 16, Total Loss: 1.577543541143659e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 17, Total Loss: 1.5657559815226017e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 18, Total Loss: 1.554981720652699e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 19, Total Loss: 1.5424501392391007e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 26: tensor([-0.4484,  1.1457, -0.6973], requires_grad=True), Epoch: 20, Total Loss: 1.5297129660666368e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 1, Total Loss: 1.5430780704999254e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 2, Total Loss: 1.517354203377324e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 3, Total Loss: 1.4958728176756532e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 4, Total Loss: 1.4907609112257226e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 5, Total Loss: 1.4875509686265472e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 6, Total Loss: 1.4744542724133043e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 7, Total Loss: 1.4563341298498832e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 8, Total Loss: 1.4434408822798579e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 9, Total Loss: 1.4365227574409732e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 10, Total Loss: 1.4276147283655614e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 11, Total Loss: 1.414351905080881e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 12, Total Loss: 1.4021678046950346e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 13, Total Loss: 1.3931799701473172e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 14, Total Loss: 1.3839102741933836e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 15, Total Loss: 1.3726622936671447e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 16, Total Loss: 1.36167163089979e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 17, Total Loss: 1.352426388121457e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 18, Total Loss: 1.343287646172668e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 19, Total Loss: 1.33299912573467e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 27: tensor([-0.5721, -0.5825,  1.1547], requires_grad=True), Epoch: 20, Total Loss: 1.322816103463135e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 1, Total Loss: 1.3415997497441036e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 2, Total Loss: 1.3147724709482392e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 3, Total Loss: 1.2954578922095773e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 4, Total Loss: 1.2942488861659626e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 5, Total Loss: 1.2928143852902401e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 6, Total Loss: 1.2797975994831587e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 7, Total Loss: 1.263145403810305e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 8, Total Loss: 1.253171622314274e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 9, Total Loss: 1.2482442234947153e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 10, Total Loss: 1.240179255775855e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 11, Total Loss: 1.2284663342003775e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 12, Total Loss: 1.2184636690688565e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 13, Total Loss: 1.2110040368483067e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 14, Total Loss: 1.2028865240719295e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 15, Total Loss: 1.1933282387894327e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 16, Total Loss: 1.1843517485801966e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 17, Total Loss: 1.176606522718547e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 18, Total Loss: 1.168609744911749e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 19, Total Loss: 1.1597938371307245e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 28: tensor([ 0.2632,  0.8421, -1.1053], requires_grad=True), Epoch: 20, Total Loss: 1.1515646723207422e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 1, Total Loss: 1.1736012981924592e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 2, Total Loss: 1.1464163936830103e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 3, Total Loss: 1.1287547247023685e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 4, Total Loss: 1.13023233761904e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 5, Total Loss: 1.1298222539268222e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 6, Total Loss: 1.1170024633215669e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 7, Total Loss: 1.1017699968503591e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 8, Total Loss: 1.0943171350951602e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 9, Total Loss: 1.0907772818137667e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 10, Total Loss: 1.0829429596404057e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 11, Total Loss: 1.0725345521519059e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 12, Total Loss: 1.0646944954354773e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 13, Total Loss: 1.0585135078212056e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 14, Total Loss: 1.051023102357777e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 15, Total Loss: 1.0427880342312319e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 16, Total Loss: 1.0355793660901294e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 17, Total Loss: 1.0291341921181032e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 18, Total Loss: 1.0218848204328385e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 19, Total Loss: 1.0142445041436082e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 29: tensor([-1.1049,  0.2620,  0.8429], requires_grad=True), Epoch: 20, Total Loss: 1.007675602724516e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 1, Total Loss: 1.0277848758392496e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 2, Total Loss: 1.0031975415341713e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 3, Total Loss: 9.884703262570804e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 4, Total Loss: 9.908915733951596e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 5, Total Loss: 9.901957689102487e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 6, Total Loss: 9.780849080107078e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 7, Total Loss: 9.652154933050092e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 8, Total Loss: 9.599473199081067e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 9, Total Loss: 9.568703585174213e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 10, Total Loss: 9.493525279888232e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 11, Total Loss: 9.406163492040083e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 12, Total Loss: 9.346136521204068e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 13, Total Loss: 9.292020158882969e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 14, Total Loss: 9.223466107149464e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 15, Total Loss: 9.155364362401805e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 16, Total Loss: 9.097960896615408e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 17, Total Loss: 9.042233010943855e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 18, Total Loss: 8.977350393054159e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 19, Total Loss: 8.914148008743355e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 30: tensor([ 0.6709, -1.1493,  0.4785], requires_grad=True), Epoch: 20, Total Loss: 8.861715685765024e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 1, Total Loss: 8.806479359106508e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 2, Total Loss: 8.743210882105971e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 3, Total Loss: 8.686346194039252e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 4, Total Loss: 8.636054603914012e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 5, Total Loss: 8.581086359365803e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 6, Total Loss: 8.522842619791812e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 7, Total Loss: 8.467748715446112e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 8, Total Loss: 8.417042808715345e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 9, Total Loss: 8.365277579589891e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 10, Total Loss: 8.310753917250484e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 11, Total Loss: 8.258049576549316e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 12, Total Loss: 8.208336505947014e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 13, Total Loss: 8.15796467591429e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 14, Total Loss: 8.106527870905088e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 15, Total Loss: 8.05639878154124e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 16, Total Loss: 8.007612754844651e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 17, Total Loss: 7.959112726188416e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 18, Total Loss: 7.910160209156404e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 19, Total Loss: 7.861650023730681e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 31: tensor([ 0.7350, -1.1388,  0.4038], requires_grad=True), Epoch: 20, Total Loss: 7.814199969070636e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 1, Total Loss: 7.767638561210546e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 2, Total Loss: 7.719773326112441e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 3, Total Loss: 7.673426254961438e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 4, Total Loss: 7.627964801052967e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 5, Total Loss: 7.582171459497116e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 6, Total Loss: 7.536522984084072e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 7, Total Loss: 7.491656808154736e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 8, Total Loss: 7.447516090509168e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 9, Total Loss: 7.403181569934251e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 10, Total Loss: 7.35898473755403e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 11, Total Loss: 7.315844016162862e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 12, Total Loss: 7.273357311938294e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 13, Total Loss: 7.230672024982462e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 14, Total Loss: 7.188082601988887e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 15, Total Loss: 7.146029040353066e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 16, Total Loss: 7.10443561740226e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 17, Total Loss: 7.063136845123405e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 18, Total Loss: 7.02211948560351e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 19, Total Loss: 6.981869233550745e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 32: tensor([ 0.9760, -1.0224,  0.0464], requires_grad=True), Epoch: 20, Total Loss: 6.941965174760775e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 1, Total Loss: 6.911938000321592e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 2, Total Loss: 6.864725019353123e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 3, Total Loss: 6.824102946331136e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 4, Total Loss: 6.788209338952898e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 5, Total Loss: 6.751365339797013e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 6, Total Loss: 6.712230679477826e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 7, Total Loss: 6.672578933980761e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 8, Total Loss: 6.63464872704892e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 9, Total Loss: 6.598021770734564e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 10, Total Loss: 6.561582128985754e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 11, Total Loss: 6.525723953781317e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 12, Total Loss: 6.490451791699144e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 13, Total Loss: 6.45591709364488e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 14, Total Loss: 6.423310839711331e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 15, Total Loss: 6.392177535237347e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 16, Total Loss: 6.36281645393964e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 17, Total Loss: 6.33757111580112e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 18, Total Loss: 6.319558361638357e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 19, Total Loss: 6.313134379428692e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 33: tensor([ 0.4225,  0.7194, -1.1419], requires_grad=True), Epoch: 20, Total Loss: 6.325276829066991e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 1, Total Loss: 6.365408686008159e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 2, Total Loss: 6.450528071648005e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 3, Total Loss: 6.616950762720711e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 4, Total Loss: 6.925117281926195e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 5, Total Loss: 7.480129795002462e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 6, Total Loss: 8.474392666694991e-11, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 7, Total Loss: 1.0263532947065135e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 8, Total Loss: 1.3498318214393317e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 9, Total Loss: 1.939706532103304e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 10, Total Loss: 3.0272287141350575e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 11, Total Loss: 5.053725231224236e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 12, Total Loss: 8.865964312579589e-10, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 13, Total Loss: 1.6102890216407024e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 14, Total Loss: 2.999562164692759e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 15, Total Loss: 5.694339990003365e-09, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 16, Total Loss: 1.098038659181473e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 17, Total Loss: 2.1445852929466073e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 18, Total Loss: 4.2411755761141657e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 19, Total Loss: 8.475732813284279e-08, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 34: tensor([-0.2546,  1.1027, -0.8481], requires_grad=True), Epoch: 20, Total Loss: 1.7136454775886439e-07, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 1, Total Loss: 3.4946458963115837e-07, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 2, Total Loss: 7.209903620632572e-07, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 3, Total Loss: 1.4951062868260007e-06, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 4, Total Loss: 3.1313279211817677e-06, Loss Weights: [0.9967004 0.9967004 1.0065992]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 5, Total Loss: 6.531038701187259e-06, Loss Weights: [0.9967004 0.9967004 1.0065993]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 6, Total Loss: 1.3693602666175005e-05, Loss Weights: [0.9967003 0.9967003 1.0065994]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 7, Total Loss: 2.7975274799266955e-05, Loss Weights: [0.9967001 0.9967001 1.0065999]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 8, Total Loss: 5.768308712374381e-05, Loss Weights: [0.9966996 0.9966996 1.0066007]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 9, Total Loss: 0.00010490400273213369, Loss Weights: [0.9966987 0.9966987 1.0066025]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 10, Total Loss: 0.00016781037722928409, Loss Weights: [0.9966972 0.9966972 1.0066056]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 11, Total Loss: 0.00018563621035506917, Loss Weights: [0.9966949 0.9966949 1.00661  ]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 12, Total Loss: 0.0001389779203530473, Loss Weights: [0.9966923 0.9966923 1.0066154]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 13, Total Loss: 3.226024578278406e-05, Loss Weights: [0.9966898 0.9966898 1.0066204]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 14, Total Loss: 6.2421787666366185e-06, Loss Weights: [0.99668753 0.99668753 1.0066249 ]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 15, Total Loss: 6.622708536737878e-05, Loss Weights: [0.99668515 0.99668515 1.0066297 ]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 16, Total Loss: 6.024789127749995e-05, Loss Weights: [0.99668276 0.99668276 1.0066345 ]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 17, Total Loss: 4.631924126675437e-06, Loss Weights: [0.9966806 0.9966806 1.0066388]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 18, Total Loss: 2.081780336943906e-05, Loss Weights: [0.9966786 0.9966786 1.0066428]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 19, Total Loss: 4.370726183636501e-05, Loss Weights: [0.99667656 0.99667656 1.0066469 ]\n",
      "Material 35: tensor([ 0.9779, -1.0207,  0.0428], requires_grad=True), Epoch: 20, Total Loss: 8.139390053172828e-06, Loss Weights: [0.99667466 0.99667466 1.0066506 ]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 1, Total Loss: 9.593372490884887e-06, Loss Weights: [0.996673 0.996673 1.006654]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 2, Total Loss: 2.957468957675259e-05, Loss Weights: [0.9966713 0.9966713 1.0066574]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 3, Total Loss: 6.340450674789649e-06, Loss Weights: [0.9966697 0.9966697 1.0066605]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 4, Total Loss: 7.027776148442453e-06, Loss Weights: [0.99666834 0.99666834 1.0066633 ]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 5, Total Loss: 2.0156711433503744e-05, Loss Weights: [0.9966669 0.9966669 1.0066661]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 6, Total Loss: 2.5042132673295014e-06, Loss Weights: [0.9966657 0.9966657 1.0066686]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 7, Total Loss: 7.492412899300066e-06, Loss Weights: [0.9966645 0.9966645 1.0066708]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 8, Total Loss: 1.2912502929523019e-05, Loss Weights: [0.99666345 0.99666345 1.0066731 ]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 9, Total Loss: 3.9288402385051763e-07, Loss Weights: [0.9966625 0.9966625 1.006675 ]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 10, Total Loss: 7.924042307536717e-06, Loss Weights: [0.99666154 0.99666154 1.0066769 ]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 11, Total Loss: 9.852976427292973e-06, Loss Weights: [0.9966607 0.9966607 1.0066786]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 12, Total Loss: 4.6547463780833036e-07, Loss Weights: [0.9966599 0.9966599 1.0066801]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 13, Total Loss: 4.9695258904183785e-06, Loss Weights: [0.99665916 0.99665916 1.0066817 ]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 14, Total Loss: 3.842545833782648e-06, Loss Weights: [0.99665844 0.99665844 1.006683  ]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 15, Total Loss: 5.856908009441521e-07, Loss Weights: [0.9966579 0.9966579 1.0066843]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 16, Total Loss: 4.1466989343732775e-06, Loss Weights: [0.99665725 0.99665725 1.0066855 ]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 17, Total Loss: 1.6499852760373025e-06, Loss Weights: [0.9966568 0.9966568 1.0066864]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 18, Total Loss: 1.3286406256989019e-06, Loss Weights: [0.9966563 0.9966563 1.0066874]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 19, Total Loss: 2.945449606540916e-06, Loss Weights: [0.9966558 0.9966558 1.0066884]\n",
      "Material 36: tensor([ 0.8848, -1.0849,  0.2002], requires_grad=True), Epoch: 20, Total Loss: 5.1874768236432e-07, Loss Weights: [0.9966554 0.9966554 1.0066892]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 1, Total Loss: 1.8464608055224195e-06, Loss Weights: [0.99665505 0.99665505 1.00669   ]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 2, Total Loss: 1.5918548825374411e-06, Loss Weights: [0.9966547 0.9966547 1.0066906]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 3, Total Loss: 3.5107528563617467e-07, Loss Weights: [0.99665433 0.99665433 1.0066912 ]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 4, Total Loss: 1.8126813983191903e-06, Loss Weights: [0.99665415 0.99665415 1.0066919 ]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 5, Total Loss: 6.038028228608981e-07, Loss Weights: [0.9966539 0.9966539 1.0066924]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 6, Total Loss: 6.540376620826493e-07, Loss Weights: [0.9966536 0.9966536 1.0066928]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 7, Total Loss: 1.2456593132718996e-06, Loss Weights: [0.99665344 0.99665344 1.0066932 ]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 8, Total Loss: 1.7488420468888826e-07, Loss Weights: [0.9966532 0.9966532 1.0066936]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 9, Total Loss: 8.857379233218254e-07, Loss Weights: [0.99665296 0.99665296 1.006694  ]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 10, Total Loss: 5.985015007569883e-07, Loss Weights: [0.99665284 0.99665284 1.0066943 ]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 11, Total Loss: 1.903288651688503e-07, Loss Weights: [0.9966527 0.9966527 1.0066947]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 12, Total Loss: 7.993226065299189e-07, Loss Weights: [0.99665254 0.99665254 1.0066949 ]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 13, Total Loss: 1.896263640282391e-07, Loss Weights: [0.9966525 0.9966525 1.0066952]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 14, Total Loss: 3.395085670084388e-07, Loss Weights: [0.99665225 0.99665225 1.0066953 ]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 15, Total Loss: 5.122845211727027e-07, Loss Weights: [0.99665225 0.99665225 1.0066956 ]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 16, Total Loss: 7.061457388693123e-08, Loss Weights: [0.9966521 0.9966521 1.0066957]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 17, Total Loss: 4.050092009800097e-07, Loss Weights: [0.996652  0.996652  1.0066959]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 18, Total Loss: 2.2830785778342852e-07, Loss Weights: [0.9966519 0.9966519 1.006696 ]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 19, Total Loss: 1.0818529658387956e-07, Loss Weights: [0.9966519 0.9966519 1.0066962]\n",
      "Material 37: tensor([ 0.4991, -1.1513,  0.6522], requires_grad=True), Epoch: 20, Total Loss: 3.4108149979408896e-07, Loss Weights: [0.9966518 0.9966518 1.0066963]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 1, Total Loss: 6.967935390009056e-08, Loss Weights: [0.9966518 0.9966518 1.0066965]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 2, Total Loss: 1.678152464310902e-07, Loss Weights: [0.99665177 0.99665177 1.0066965 ]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 3, Total Loss: 2.1045080585063982e-07, Loss Weights: [0.99665177 0.99665177 1.0066966 ]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 4, Total Loss: 2.956205153892031e-08, Loss Weights: [0.99665165 0.99665165 1.0066966 ]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 5, Total Loss: 1.8087365374223038e-07, Loss Weights: [0.99665165 0.99665165 1.0066967 ]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 6, Total Loss: 9.49010466313112e-08, Loss Weights: [0.99665165 0.99665165 1.0066968 ]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 7, Total Loss: 5.08416181900506e-08, Loss Weights: [0.99665153 0.99665153 1.0066968 ]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 8, Total Loss: 1.4334489866800204e-07, Loss Weights: [0.99665153 0.99665153 1.0066969 ]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 9, Total Loss: 3.013874697223906e-08, Loss Weights: [0.9966515 0.9966515 1.0066969]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 10, Total Loss: 7.687289211054281e-08, Loss Weights: [0.9966515 0.9966515 1.006697 ]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 11, Total Loss: 8.768175501523523e-08, Loss Weights: [0.9966514 0.9966514 1.006697 ]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 12, Total Loss: 1.3700624401159855e-08, Loss Weights: [0.9966515 0.9966515 1.0066972]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 13, Total Loss: 7.929783637024906e-08, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 14, Total Loss: 4.123511016623425e-08, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 15, Total Loss: 2.155247343003659e-08, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 16, Total Loss: 6.231069671483141e-08, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 17, Total Loss: 1.5161539048688465e-08, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 18, Total Loss: 3.098751526961633e-08, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 19, Total Loss: 3.92184877401305e-08, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 38: tensor([-0.1497,  1.0664, -0.9167], requires_grad=True), Epoch: 20, Total Loss: 6.415723424313752e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 1, Total Loss: 3.316074991053325e-08, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 2, Total Loss: 2.0042560404721092e-08, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 3, Total Loss: 7.140981193440215e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 4, Total Loss: 2.775390695031759e-08, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 5, Total Loss: 8.236263918116845e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 6, Total Loss: 1.0683211038339775e-08, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 7, Total Loss: 1.894512511940331e-08, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 8, Total Loss: 3.197227078526424e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 9, Total Loss: 1.2303210452539242e-08, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 10, Total Loss: 1.0839801548063532e-08, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 11, Total Loss: 2.5287504854955556e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 12, Total Loss: 1.114932116023475e-08, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 13, Total Loss: 5.294122620191674e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 14, Total Loss: 3.3183630871736905e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 15, Total Loss: 8.610449406046927e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 16, Total Loss: 2.232648841896652e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 17, Total Loss: 3.927502684895087e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 18, Total Loss: 5.9070598337572445e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 19, Total Loss: 1.000213052524456e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 39: tensor([-0.9869,  1.0126, -0.0256], requires_grad=True), Epoch: 20, Total Loss: 3.986726227224464e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 1, Total Loss: 3.5228923040198665e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 2, Total Loss: 7.633453982928772e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 3, Total Loss: 3.5739169729547362e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 4, Total Loss: 1.8817698096689338e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 5, Total Loss: 8.717548499144418e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 6, Total Loss: 2.8178952028381502e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 7, Total Loss: 9.267662000893044e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 8, Total Loss: 1.0220915424489445e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 9, Total Loss: 2.047966201458107e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 10, Total Loss: 4.264412364088858e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 11, Total Loss: 1.0666207205416442e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 12, Total Loss: 1.3688641843687188e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 13, Total Loss: 2.428278880468378e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 14, Total Loss: 1.0124379113148798e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 15, Total Loss: 8.282570607033579e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 16, Total Loss: 2.1517939052458595e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 17, Total Loss: 8.730349974142982e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 18, Total Loss: 4.759188084595271e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 19, Total Loss: 2.2166345322208635e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 40: tensor([-1.1547,  0.5771,  0.5776], requires_grad=True), Epoch: 20, Total Loss: 7.006484558301153e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 1, Total Loss: 2.7873227720280144e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 2, Total Loss: 2.3123699376344344e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 3, Total Loss: 5.334299723539527e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 4, Total Loss: 1.6253775459671902e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 5, Total Loss: 2.409321174266274e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 6, Total Loss: 3.8513042891000787e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 7, Total Loss: 1.0045779747636145e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 8, Total Loss: 2.296862819743017e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 9, Total Loss: 2.7252504791762276e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 10, Total Loss: 7.775926539153185e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 11, Total Loss: 2.0296218531159155e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 12, Total Loss: 1.9303954658193094e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 13, Total Loss: 6.747126693587025e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 14, Total Loss: 1.7504320568537394e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 15, Total Loss: 1.3946589935323507e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 16, Total Loss: 6.32985371081696e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 17, Total Loss: 1.4683300843818748e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 18, Total Loss: 1.0395739750349774e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 19, Total Loss: 6.27022205433395e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 41: tensor([-1.1462,  0.4523,  0.6939], requires_grad=True), Epoch: 20, Total Loss: 1.2116583808886217e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 1, Total Loss: 8.661590712697573e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 2, Total Loss: 6.155517441031772e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 3, Total Loss: 1.0325438345403875e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 4, Total Loss: 7.136815785589372e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 5, Total Loss: 5.957773281425971e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 6, Total Loss: 8.835867676763232e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 7, Total Loss: 6.045124922701424e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 8, Total Loss: 5.5480448032648494e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 9, Total Loss: 7.6739211575798e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 10, Total Loss: 5.457224362232532e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 11, Total Loss: 5.236414615317059e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 12, Total Loss: 6.693672970335136e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 13, Total Loss: 5.0200545970753954e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 14, Total Loss: 5.0462801311110856e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 15, Total Loss: 5.986287300566995e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 16, Total Loss: 4.7001572807104624e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 17, Total Loss: 4.835120271905158e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 18, Total Loss: 5.4908482603333277e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 19, Total Loss: 4.5209724914649444e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 42: tensor([-1.1488,  0.6756,  0.4732], requires_grad=True), Epoch: 20, Total Loss: 4.606758014911228e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 1, Total Loss: 5.134390106749358e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 2, Total Loss: 4.422591551906108e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 3, Total Loss: 4.4474307311028946e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 4, Total Loss: 4.8249801202530846e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 5, Total Loss: 4.3360103831148825e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 6, Total Loss: 4.330074394863171e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 7, Total Loss: 4.592671235488255e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 8, Total Loss: 4.25390334623853e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 9, Total Loss: 4.223625959245367e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 10, Total Loss: 4.433963868863486e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 11, Total Loss: 4.182270921034683e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 12, Total Loss: 4.1400790610166616e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 13, Total Loss: 4.3068511238827276e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 14, Total Loss: 4.125253976380948e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 15, Total Loss: 4.0787459918929414e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 16, Total Loss: 4.202294104060275e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 17, Total Loss: 4.077014764275079e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 18, Total Loss: 4.0242056169804236e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 19, Total Loss: 4.118961176925496e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 43: tensor([ 1.1377, -0.7398, -0.3979], requires_grad=True), Epoch: 20, Total Loss: 4.033748614916987e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 1, Total Loss: 3.9841659012461795e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 2, Total Loss: 4.058962277496667e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 3, Total Loss: 4.001075027669696e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 4, Total Loss: 3.9440397950408705e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 5, Total Loss: 3.9984183210273814e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 6, Total Loss: 3.966669107018401e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 7, Total Loss: 3.910157662715387e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 8, Total Loss: 3.9431652343631994e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 9, Total Loss: 3.92982883221085e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 10, Total Loss: 3.8824494334148686e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 11, Total Loss: 3.898425891372015e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 12, Total Loss: 3.895225100469467e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 13, Total Loss: 3.855748012431377e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 14, Total Loss: 3.8599099945791486e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 15, Total Loss: 3.860851241174893e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 16, Total Loss: 3.830034603451352e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 17, Total Loss: 3.826405146562866e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 18, Total Loss: 3.828113339400886e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 19, Total Loss: 3.804858545976367e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 44: tensor([-0.1865,  1.0801, -0.8936], requires_grad=True), Epoch: 20, Total Loss: 3.7960478639881e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 1, Total Loss: 3.8008896269287294e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 2, Total Loss: 3.7800338304607576e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 3, Total Loss: 3.769265277561363e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 4, Total Loss: 3.7688390229523184e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 5, Total Loss: 3.756469274752598e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 6, Total Loss: 3.7438459148042625e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 7, Total Loss: 3.7400864486509834e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 8, Total Loss: 3.730550341725597e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 9, Total Loss: 3.7188448201889855e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 10, Total Loss: 3.7140421418115706e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 11, Total Loss: 3.7053889241136597e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 12, Total Loss: 3.694120245250813e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 13, Total Loss: 3.687853348684436e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 14, Total Loss: 3.6805387368549494e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 15, Total Loss: 3.6704527421338316e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 16, Total Loss: 3.663018579361117e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 17, Total Loss: 3.656097625474739e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 18, Total Loss: 3.6467710284392644e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 19, Total Loss: 3.6390467703770294e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 45: tensor([ 0.8999, -1.0766,  0.1767], requires_grad=True), Epoch: 20, Total Loss: 3.63152238652342e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 1, Total Loss: 3.623370917639132e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 2, Total Loss: 3.615618529827286e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 3, Total Loss: 3.608066098969618e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 4, Total Loss: 3.600032656244823e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 5, Total Loss: 3.592400555497099e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 6, Total Loss: 3.584874665870853e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 7, Total Loss: 3.577034308694342e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 8, Total Loss: 3.5695600847291735e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 9, Total Loss: 3.5621060634818346e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 10, Total Loss: 3.5544234743762965e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 11, Total Loss: 3.546960243394e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 12, Total Loss: 3.539505059835208e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 13, Total Loss: 3.5319624742504e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 14, Total Loss: 3.5246036836722645e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 15, Total Loss: 3.5171205084155686e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 16, Total Loss: 3.509751238390021e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 17, Total Loss: 3.502394177204849e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 18, Total Loss: 3.495037491600833e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 19, Total Loss: 3.487782008376838e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 46: tensor([ 1.1518, -0.5056, -0.6463], requires_grad=True), Epoch: 20, Total Loss: 3.4804307526428964e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 1, Total Loss: 3.5315915584745415e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 2, Total Loss: 3.47566603163878e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 3, Total Loss: 3.4717132293646955e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 4, Total Loss: 3.491298613055284e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 5, Total Loss: 3.472900978297482e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 6, Total Loss: 3.4476286778234987e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 7, Total Loss: 3.4455491526795606e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 8, Total Loss: 3.4439579598121346e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 9, Total Loss: 3.4308142129470124e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 10, Total Loss: 3.419335822869891e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 11, Total Loss: 3.413487158957455e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 12, Total Loss: 3.4064971902009894e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 13, Total Loss: 3.396889258421239e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 14, Total Loss: 3.388733314345794e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 15, Total Loss: 3.381618255575816e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 16, Total Loss: 3.373591315885806e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 17, Total Loss: 3.3661873410109044e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 18, Total Loss: 3.3586704304373166e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 19, Total Loss: 3.3506103334058314e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 47: tensor([-0.8893, -0.1932,  1.0825], requires_grad=True), Epoch: 20, Total Loss: 3.343590084970615e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 1, Total Loss: 3.361159252398232e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 2, Total Loss: 3.332352608072879e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 3, Total Loss: 3.328861097896402e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 4, Total Loss: 3.3325011550901724e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 5, Total Loss: 3.319542026417505e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 6, Total Loss: 3.3052539573390024e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 7, Total Loss: 3.30063595262533e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 8, Total Loss: 3.295962713375962e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 9, Total Loss: 3.286735735180965e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 10, Total Loss: 3.27742884930305e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 11, Total Loss: 3.270889835064222e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 12, Total Loss: 3.264993920832569e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 13, Total Loss: 3.2571279266059896e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 14, Total Loss: 3.248881324466867e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 15, Total Loss: 3.242407367711526e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 16, Total Loss: 3.2362112469735613e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 17, Total Loss: 3.228558134793981e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 18, Total Loss: 3.221116895159057e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 19, Total Loss: 3.214758406202787e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 48: tensor([-1.1543,  0.5495,  0.6048], requires_grad=True), Epoch: 20, Total Loss: 3.208430285458576e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 1, Total Loss: 3.205947780590605e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 2, Total Loss: 3.195346239250276e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 3, Total Loss: 3.188910849595972e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 4, Total Loss: 3.184470931295847e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 5, Total Loss: 3.1769731075418273e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 6, Total Loss: 3.168917346528568e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 7, Total Loss: 3.163058250001253e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 8, Total Loss: 3.156935569197968e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 9, Total Loss: 3.149827573875229e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 10, Total Loss: 3.1432817029322615e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 11, Total Loss: 3.13699086723338e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 12, Total Loss: 3.1304722156557725e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 13, Total Loss: 3.123883329028746e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 14, Total Loss: 3.117566988059525e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 15, Total Loss: 3.111324781416728e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 16, Total Loss: 3.1047241880372335e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 17, Total Loss: 3.098520037322216e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 18, Total Loss: 3.092320214337458e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 19, Total Loss: 3.085964540346512e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 49: tensor([-1.1243,  0.3341,  0.7901], requires_grad=True), Epoch: 20, Total Loss: 3.079653287187911e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 1, Total Loss: 3.0760645586205914e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 2, Total Loss: 3.0679330934635955e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 3, Total Loss: 3.0617328047759834e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 4, Total Loss: 3.056459644051855e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 5, Total Loss: 3.0502715662686876e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 6, Total Loss: 3.0434653903000514e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 7, Total Loss: 3.03734702341901e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 8, Total Loss: 3.031529669324754e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 9, Total Loss: 3.025379578637298e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 10, Total Loss: 3.019182877474067e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 11, Total Loss: 3.013088536914327e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 12, Total Loss: 3.007184540771608e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 13, Total Loss: 3.001153553961173e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 14, Total Loss: 2.995081694038544e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 15, Total Loss: 2.9892124181639626e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 16, Total Loss: 2.983205264405385e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 17, Total Loss: 2.977284299916929e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 18, Total Loss: 2.971398652305621e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 19, Total Loss: 2.9654641524069977e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 50: tensor([ 0.5027,  0.6489, -1.1516], requires_grad=True), Epoch: 20, Total Loss: 2.959644534514414e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 1, Total Loss: 2.9546857420080345e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 2, Total Loss: 2.9479895126440355e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 3, Total Loss: 2.942498841345254e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 4, Total Loss: 2.9370571826832186e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 5, Total Loss: 2.930880099531216e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 6, Total Loss: 2.9249495116415165e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 7, Total Loss: 2.919418734611736e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 8, Total Loss: 2.91365066267151e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 9, Total Loss: 2.907780194844159e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 10, Total Loss: 2.902082685537977e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 11, Total Loss: 2.8964324425053874e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 12, Total Loss: 2.8907469122553754e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 13, Total Loss: 2.8850161587915342e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 14, Total Loss: 2.8793924536222903e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 15, Total Loss: 2.873767714549402e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 16, Total Loss: 2.868147771382754e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 17, Total Loss: 2.8625335681908925e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 18, Total Loss: 2.856952301693116e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 19, Total Loss: 2.851351317779688e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 51: tensor([ 1.1546, -0.5618, -0.5928], requires_grad=True), Epoch: 20, Total Loss: 2.845816940736631e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 1, Total Loss: 2.842790698768291e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 2, Total Loss: 2.835339620877548e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 3, Total Loss: 2.8299531349633596e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 4, Total Loss: 2.825223687590025e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 5, Total Loss: 2.81964799976169e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 6, Total Loss: 2.8134767846624827e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 7, Total Loss: 2.807940204511085e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 8, Total Loss: 2.8027785252854363e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 9, Total Loss: 2.7972352173010928e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 10, Total Loss: 2.7915801380615118e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 11, Total Loss: 2.786168630010262e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 12, Total Loss: 2.780770577916903e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 13, Total Loss: 2.7753407874473517e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 14, Total Loss: 2.7698857750621336e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 15, Total Loss: 2.764591812539681e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 16, Total Loss: 2.7591597595819103e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 17, Total Loss: 2.7538037647639675e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 18, Total Loss: 2.7484509013223287e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 19, Total Loss: 2.743197255331522e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 52: tensor([-1.1547,  0.5684,  0.5863], requires_grad=True), Epoch: 20, Total Loss: 2.7378677745071688e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 1, Total Loss: 2.733051216156949e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 2, Total Loss: 2.7273955670556337e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 3, Total Loss: 2.7221794383343212e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 4, Total Loss: 2.717153314636952e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 5, Total Loss: 2.7117973280240903e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 6, Total Loss: 2.7064233324557735e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 7, Total Loss: 2.701318413655472e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 8, Total Loss: 2.6962205695903827e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 9, Total Loss: 2.6909305862411392e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 10, Total Loss: 2.6857420615288355e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 11, Total Loss: 2.6806162662259827e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 12, Total Loss: 2.6754800253295098e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 13, Total Loss: 2.670343153073302e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 14, Total Loss: 2.6652423111499e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 15, Total Loss: 2.6601135058589358e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 16, Total Loss: 2.655049800136653e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 17, Total Loss: 2.6499510617638658e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 18, Total Loss: 2.6449213641924067e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 19, Total Loss: 2.6398682427358345e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 53: tensor([ 1.1254, -0.7866, -0.3388], requires_grad=True), Epoch: 20, Total Loss: 2.6348341673162778e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 1, Total Loss: 2.6299170570923453e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 2, Total Loss: 2.6248256651510794e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 3, Total Loss: 2.6198808615237056e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 4, Total Loss: 2.6149407246786578e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 5, Total Loss: 2.609906907625319e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 6, Total Loss: 2.604936400524247e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 7, Total Loss: 2.6000146973376337e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 8, Total Loss: 2.5950861757109572e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 9, Total Loss: 2.5901314949283908e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 10, Total Loss: 2.5852252316494962e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 11, Total Loss: 2.580344459900311e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 12, Total Loss: 2.5754852081540467e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 13, Total Loss: 2.5705703404264952e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 14, Total Loss: 2.5657399007415667e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 15, Total Loss: 2.560907402032775e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 16, Total Loss: 2.5560265132000853e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 17, Total Loss: 2.5512094179238812e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 18, Total Loss: 2.5463604523041547e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 19, Total Loss: 2.541593975522044e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 54: tensor([-0.2368, -0.8603,  1.0972], requires_grad=True), Epoch: 20, Total Loss: 2.5367818731824252e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 1, Total Loss: 2.532087476363427e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 2, Total Loss: 2.5272194619236083e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 3, Total Loss: 2.5224987522979392e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 4, Total Loss: 2.5177899418725656e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 5, Total Loss: 2.5129795223555796e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 6, Total Loss: 2.5082590121701505e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 7, Total Loss: 2.5035739943596087e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 8, Total Loss: 2.4988628530936085e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 9, Total Loss: 2.494134785983914e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 10, Total Loss: 2.489461768057749e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 11, Total Loss: 2.4848253265725807e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 12, Total Loss: 2.4801021630285586e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 13, Total Loss: 2.4754804292647983e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 14, Total Loss: 2.4708328553236704e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 15, Total Loss: 2.46620434285229e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 16, Total Loss: 2.4615912666000095e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 17, Total Loss: 2.457003721912595e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 18, Total Loss: 2.4524477821760527e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 19, Total Loss: 2.4478034310517274e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 55: tensor([ 1.1112, -0.2839, -0.8274], requires_grad=True), Epoch: 20, Total Loss: 2.2539740269032745e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 1, Total Loss: 2.2736260518225335e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 2, Total Loss: 2.247941542671144e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 3, Total Loss: 2.2502625754047348e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 4, Total Loss: 2.2546989986101482e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 5, Total Loss: 2.2414178004482584e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 6, Total Loss: 2.2335339454791793e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 7, Total Loss: 2.233289621762256e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 8, Total Loss: 2.2281096968590682e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 9, Total Loss: 2.220992497356165e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 10, Total Loss: 2.217243903093839e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 11, Total Loss: 2.2133875871272234e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 12, Total Loss: 2.207920175726785e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 13, Total Loss: 2.203374445597078e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 14, Total Loss: 2.1989319274837836e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 15, Total Loss: 2.1942310107742168e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 16, Total Loss: 2.1901792807578013e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 17, Total Loss: 2.186000745638966e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 18, Total Loss: 2.181137109056813e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 19, Total Loss: 2.177080672780699e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 56: tensor([-0.2650, -0.8408,  1.1058], requires_grad=True), Epoch: 20, Total Loss: 2.1726789037066073e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 1, Total Loss: 2.1828532551145078e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 2, Total Loss: 2.1655665204556e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 3, Total Loss: 2.16649892873715e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 4, Total Loss: 2.166871468642139e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 5, Total Loss: 2.1566818511483753e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 6, Total Loss: 2.150434119874418e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 7, Total Loss: 2.1494180326205735e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 8, Total Loss: 2.144570639753122e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 9, Total Loss: 2.1380585163938602e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 10, Total Loss: 2.1341571054789177e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 11, Total Loss: 2.13109883247498e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 12, Total Loss: 2.1255078207915774e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 13, Total Loss: 2.120888423096834e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 14, Total Loss: 2.1178689225550663e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 15, Total Loss: 2.1130908105593427e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 16, Total Loss: 2.1084140018110782e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 17, Total Loss: 2.1046758093301472e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 18, Total Loss: 2.1007035984177035e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 19, Total Loss: 2.0962791137504308e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 57: tensor([-0.7961, -0.3263,  1.1224], requires_grad=True), Epoch: 20, Total Loss: 2.092247567087414e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 1, Total Loss: 2.0887451043291086e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 2, Total Loss: 2.0843910789757334e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 3, Total Loss: 2.0804056718163853e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 4, Total Loss: 2.076443995212447e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 5, Total Loss: 2.0725305560878574e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 6, Total Loss: 2.068713972210168e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 7, Total Loss: 2.0647367647555586e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 8, Total Loss: 2.0605830710302577e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 9, Total Loss: 2.056712086255914e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 10, Total Loss: 2.0529472805972656e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 11, Total Loss: 2.0488941424766338e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 12, Total Loss: 2.0450755226195386e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 13, Total Loss: 2.0413287325147452e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 14, Total Loss: 2.0373760258356367e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 15, Total Loss: 2.0335651120986885e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 16, Total Loss: 2.0298092875862884e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 17, Total Loss: 2.0259755260724218e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 18, Total Loss: 2.0220957598885186e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 19, Total Loss: 2.018399210630728e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 58: tensor([ 0.5581, -1.1545,  0.5963], requires_grad=True), Epoch: 20, Total Loss: 2.0147088629301964e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 1, Total Loss: 2.024826098078343e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 2, Total Loss: 2.0086537620979653e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 3, Total Loss: 2.0091380224257295e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 4, Total Loss: 2.010349849938246e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 5, Total Loss: 2.1863298972789558e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 6, Total Loss: 2.1807811987958726e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 7, Total Loss: 2.17944528313547e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 8, Total Loss: 2.1746294360292425e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 9, Total Loss: 2.1691111073798644e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 10, Total Loss: 1.9808565492312816e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 11, Total Loss: 1.9774005584345092e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 12, Total Loss: 1.9729076010966983e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 13, Total Loss: 1.9688956132212507e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 14, Total Loss: 1.9654813323027087e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 15, Total Loss: 1.9612408958988355e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 16, Total Loss: 1.9574182125601215e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 17, Total Loss: 1.9535416210463112e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 18, Total Loss: 1.9498656212559804e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 19, Total Loss: 1.946238602729098e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 59: tensor([-0.3005, -0.8153,  1.1158], requires_grad=True), Epoch: 20, Total Loss: 1.9424070072576736e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 1, Total Loss: 1.9470653421102916e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 2, Total Loss: 1.93578812212161e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 3, Total Loss: 1.935213558893488e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 4, Total Loss: 1.9340000653908648e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 5, Total Loss: 1.9267690540490055e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 6, Total Loss: 1.9223782950735952e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 7, Total Loss: 1.920391024680267e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 8, Total Loss: 1.9159937540970984e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 9, Total Loss: 1.9113422637530717e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 10, Total Loss: 1.908214351069722e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 11, Total Loss: 1.9046958442409114e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 12, Total Loss: 1.9003967617582417e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 13, Total Loss: 1.8969174937321593e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 14, Total Loss: 2.0772340852395294e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 15, Total Loss: 2.0731149646365438e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 16, Total Loss: 1.8860310533289465e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 17, Total Loss: 1.882642269667354e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 18, Total Loss: 1.8789472911316432e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 19, Total Loss: 1.875232459203635e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 60: tensor([ 1.0088, -0.9910, -0.0178], requires_grad=True), Epoch: 20, Total Loss: 1.8717329216731832e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 1, Total Loss: 1.868700750798675e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 2, Total Loss: 1.864980310200937e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 3, Total Loss: 1.861505623802587e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 4, Total Loss: 1.858021737779508e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 5, Total Loss: 1.854395200782166e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 6, Total Loss: 2.033961847545723e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 7, Total Loss: 2.0304166300228998e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 8, Total Loss: 1.8439937738933578e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 9, Total Loss: 1.8407170294319e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 10, Total Loss: 1.8372282203984238e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 11, Total Loss: 1.833793585558083e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 12, Total Loss: 1.8304791356502207e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 13, Total Loss: 1.8270941535797274e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 14, Total Loss: 1.8236496071733264e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 15, Total Loss: 1.8203716625126906e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 16, Total Loss: 1.8169608037533398e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 17, Total Loss: 1.8135755504728608e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 18, Total Loss: 1.992556085092282e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 19, Total Loss: 1.8069744336027557e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 61: tensor([-1.1484,  0.6783,  0.4701], requires_grad=True), Epoch: 20, Total Loss: 1.8035918557810098e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 1, Total Loss: 1.8003486556221607e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 2, Total Loss: 1.7970181814196234e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 3, Total Loss: 1.7936965426894373e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 4, Total Loss: 1.7904597591448573e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 5, Total Loss: 1.9690108073479184e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 6, Total Loss: 1.9656378423884055e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 7, Total Loss: 1.7806083543794472e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 8, Total Loss: 1.7773735964330313e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 9, Total Loss: 1.774078506457374e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 10, Total Loss: 1.7708502663130532e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 11, Total Loss: 1.7675804311987675e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 12, Total Loss: 1.7643619898332393e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 13, Total Loss: 1.7611287526814566e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 14, Total Loss: 1.7579225301146596e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 15, Total Loss: 1.754723529226713e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 16, Total Loss: 1.7514969603368395e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 17, Total Loss: 1.7482922748102366e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 18, Total Loss: 1.9261706620246415e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 19, Total Loss: 1.9229291514061236e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 62: tensor([ 0.7222, -1.1414,  0.4192], requires_grad=True), Epoch: 20, Total Loss: 1.7387442368594144e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 1, Total Loss: 1.7545702647214708e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 2, Total Loss: 1.7377971969167183e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 3, Total Loss: 1.7416441116845178e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 4, Total Loss: 1.749277899100152e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 5, Total Loss: 1.7525119728063537e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 6, Total Loss: 1.762664321438408e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 7, Total Loss: 1.9734417516224094e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 8, Total Loss: 2.0288489594179494e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 9, Total Loss: 2.128848370073449e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 10, Total Loss: 2.3128165813564337e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 11, Total Loss: 2.6539075013048233e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 12, Total Loss: 3.282682648618302e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 13, Total Loss: 4.278380652061528e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 14, Total Loss: 6.489312923043657e-11, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 15, Total Loss: 1.0666827478760603e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 16, Total Loss: 1.8617140896635073e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 17, Total Loss: 3.387040933864833e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 18, Total Loss: 6.336140987097059e-10, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 19, Total Loss: 1.20769129513174e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 63: tensor([ 0.5222,  0.6308, -1.1530], requires_grad=True), Epoch: 20, Total Loss: 2.333603105763363e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 1, Total Loss: 4.549102640742868e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 2, Total Loss: 8.94847432663778e-09, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 3, Total Loss: 1.775051840535269e-08, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 4, Total Loss: 3.551947969502302e-08, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 5, Total Loss: 7.153386502329837e-08, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 6, Total Loss: 1.4532233395883396e-07, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 7, Total Loss: 2.9663730198955454e-07, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 8, Total Loss: 6.114153761851436e-07, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 9, Total Loss: 1.2625845537948351e-06, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 10, Total Loss: 2.6381527601751763e-06, Loss Weights: [0.9966514 0.9966514 1.0066972]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 11, Total Loss: 5.484018438943098e-06, Loss Weights: [0.9966514 0.9966514 1.0066973]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 12, Total Loss: 1.1568154364358886e-05, Loss Weights: [0.9966512 0.9966512 1.0066975]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 13, Total Loss: 2.3806109903078082e-05, Loss Weights: [0.99665093 0.99665093 1.0066981 ]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 14, Total Loss: 4.9637807289151515e-05, Loss Weights: [0.9966504 0.9966504 1.0066993]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 15, Total Loss: 9.6697008362442e-05, Loss Weights: [0.99664915 0.99664915 1.006702  ]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 16, Total Loss: 0.00018199425656455326, Loss Weights: [0.9966465 0.9966465 1.0067067]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 17, Total Loss: 0.0002720169756596897, Loss Weights: [0.9966425 0.9966425 1.0067152]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 18, Total Loss: 0.00032859486121016544, Loss Weights: [0.9966363 0.9966363 1.0067275]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 19, Total Loss: 0.00020263803804956778, Loss Weights: [0.9966293 0.9966293 1.0067414]\n",
      "Material 64: tensor([-0.8171,  1.1151, -0.2980], requires_grad=True), Epoch: 20, Total Loss: 3.327886922970344e-05, Loss Weights: [0.99662286 0.99662286 1.0067544 ]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 1, Total Loss: 1.9317312725623664e-05, Loss Weights: [0.9966168 0.9966168 1.0067663]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 2, Total Loss: 0.00012051265289333908, Loss Weights: [0.9966105 0.9966105 1.0067788]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 3, Total Loss: 0.00010608297648198816, Loss Weights: [0.9966041 0.9966041 1.0067916]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 4, Total Loss: 6.3793538554143e-06, Loss Weights: [0.9965985 0.9965985 1.0068033]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 5, Total Loss: 4.2225184261093596e-05, Loss Weights: [0.9965929 0.9965929 1.0068142]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 6, Total Loss: 8.287880460029844e-05, Loss Weights: [0.9965874 0.9965874 1.0068254]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 7, Total Loss: 1.3122003382767215e-05, Loss Weights: [0.99658215 0.99658215 1.0068356 ]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 8, Total Loss: 1.9198314808592007e-05, Loss Weights: [0.99657744 0.99657744 1.0068451 ]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 9, Total Loss: 5.880066751360011e-05, Loss Weights: [0.9965728 0.9965728 1.0068545]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 10, Total Loss: 1.808747921306087e-05, Loss Weights: [0.9965683 0.9965683 1.0068631]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 11, Total Loss: 8.632906113659331e-06, Loss Weights: [0.9965644 0.9965644 1.0068711]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 12, Total Loss: 3.8633205723248056e-05, Loss Weights: [0.9965606 0.9965606 1.0068789]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 13, Total Loss: 8.030352887612868e-06, Loss Weights: [0.996557  0.996557  1.0068859]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 14, Total Loss: 1.1023548626300212e-05, Loss Weights: [0.9965538 0.9965538 1.0068924]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 15, Total Loss: 2.474144899873724e-05, Loss Weights: [0.9965506 0.9965506 1.0068986]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 16, Total Loss: 1.1271010231447954e-06, Loss Weights: [0.9965478 0.9965478 1.0069044]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 17, Total Loss: 1.524910842424946e-05, Loss Weights: [0.9965451 0.9965451 1.0069096]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 18, Total Loss: 1.2136301482315074e-05, Loss Weights: [0.9965427 0.9965427 1.0069146]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 19, Total Loss: 1.531321044176605e-06, Loss Weights: [0.9965404 0.9965404 1.006919 ]\n",
      "Material 65: tensor([-0.8299, -0.2803,  1.1103], requires_grad=True), Epoch: 20, Total Loss: 1.4822800608805778e-05, Loss Weights: [0.9965384 0.9965384 1.0069233]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 1, Total Loss: 2.7486137234201658e-06, Loss Weights: [0.9965364 0.9965364 1.0069273]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 2, Total Loss: 5.8340086413328e-06, Loss Weights: [0.9965345 0.9965345 1.0069308]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 3, Total Loss: 8.882573174860326e-06, Loss Weights: [0.9965328 0.9965328 1.0069342]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 4, Total Loss: 2.518276040834871e-07, Loss Weights: [0.9965313 0.9965313 1.0069373]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 5, Total Loss: 8.165254546721955e-06, Loss Weights: [0.99652994 0.99652994 1.0069401 ]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 6, Total Loss: 2.8769783496742957e-06, Loss Weights: [0.9965286 0.9965286 1.0069426]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 7, Total Loss: 2.2483940599203543e-06, Loss Weights: [0.99652743 0.99652743 1.0069451 ]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 8, Total Loss: 5.8911531193633715e-06, Loss Weights: [0.9965263 0.9965263 1.0069474]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 9, Total Loss: 2.1643579144026356e-07, Loss Weights: [0.9965253 0.9965253 1.0069494]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 10, Total Loss: 4.133335082569067e-06, Loss Weights: [0.99652445 0.99652445 1.0069513 ]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 11, Total Loss: 2.25567116046463e-06, Loss Weights: [0.99652344 0.99652344 1.006953  ]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 12, Total Loss: 9.393479213246055e-07, Loss Weights: [0.9965227 0.9965227 1.0069547]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 13, Total Loss: 3.5518317140264813e-06, Loss Weights: [0.996522  0.996522  1.0069561]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 14, Total Loss: 2.24671885074796e-07, Loss Weights: [0.9965213 0.9965213 1.0069574]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 15, Total Loss: 2.2367995310003287e-06, Loss Weights: [0.99652064 0.99652064 1.0069586 ]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 16, Total Loss: 1.5665791510793003e-06, Loss Weights: [0.99652004 0.99652004 1.0069597 ]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 17, Total Loss: 4.030814814307464e-07, Loss Weights: [0.9965197 0.9965197 1.0069609]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 18, Total Loss: 2.1555389319059757e-06, Loss Weights: [0.99651915 0.99651915 1.0069618 ]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 19, Total Loss: 1.8494412762290237e-07, Loss Weights: [0.99651873 0.99651873 1.0069625 ]\n",
      "Material 66: tensor([ 1.1381, -0.7379, -0.4002], requires_grad=True), Epoch: 20, Total Loss: 1.2327212119881904e-06, Loss Weights: [0.9965184 0.9965184 1.0069633]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 1, Total Loss: 9.975070421815864e-07, Loss Weights: [0.996518 0.996518 1.006964]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 2, Total Loss: 1.9616333212086837e-07, Loss Weights: [0.9965177 0.9965177 1.0069646]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 3, Total Loss: 1.2793795620369865e-06, Loss Weights: [0.9965174 0.9965174 1.0069652]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 4, Total Loss: 1.3614855078577335e-07, Loss Weights: [0.9965172 0.9965172 1.0069658]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 5, Total Loss: 6.843605414660661e-07, Loss Weights: [0.99651694 0.99651694 1.0069662 ]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 6, Total Loss: 6.315391597323441e-07, Loss Weights: [0.9965167 0.9965167 1.0069667]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 7, Total Loss: 9.349748043863059e-08, Loss Weights: [0.99651647 0.99651647 1.0069671 ]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 8, Total Loss: 7.518082914128205e-07, Loss Weights: [0.9965163 0.9965163 1.0069674]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 9, Total Loss: 1.0338994814766788e-07, Loss Weights: [0.9965161 0.9965161 1.0069678]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 10, Total Loss: 3.7467153103661215e-07, Loss Weights: [0.9965159 0.9965159 1.0069681]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 11, Total Loss: 3.9988913642055695e-07, Loss Weights: [0.99651587 0.99651587 1.0069685 ]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 12, Total Loss: 4.098706738056621e-08, Loss Weights: [0.9965156 0.9965156 1.0069687]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 13, Total Loss: 4.4357392144290604e-07, Loss Weights: [0.9965156 0.9965156 1.006969 ]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 14, Total Loss: 7.73062584484455e-08, Loss Weights: [0.9965154 0.9965154 1.0069691]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 15, Total Loss: 1.9973969794383608e-07, Loss Weights: [0.9965153 0.9965153 1.0069693]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 16, Total Loss: 2.554952435339149e-07, Loss Weights: [0.9965152 0.9965152 1.0069696]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 17, Total Loss: 1.5774353297163625e-08, Loss Weights: [0.99651515 0.99651515 1.0069697 ]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 18, Total Loss: 2.592601953375758e-07, Loss Weights: [0.99651504 0.99651504 1.0069698 ]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 19, Total Loss: 5.795216096626952e-08, Loss Weights: [0.9965149 0.9965149 1.0069699]\n",
      "Material 67: tensor([ 0.1001,  0.9462, -1.0463], requires_grad=True), Epoch: 20, Total Loss: 1.032380012502635e-07, Loss Weights: [0.99651486 0.99651486 1.0069702 ]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 1, Total Loss: 1.6275509971255796e-07, Loss Weights: [0.99651486 0.99651486 1.0069703 ]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 2, Total Loss: 6.247128811110137e-09, Loss Weights: [0.99651486 0.99651486 1.0069704 ]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 3, Total Loss: 1.476166100314964e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 4, Total Loss: 4.588781321427601e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 5, Total Loss: 4.968810405977319e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 6, Total Loss: 1.03594695240167e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 7, Total Loss: 3.4440915722241754e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 8, Total Loss: 8.168744484278187e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 9, Total Loss: 3.629491613373422e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 10, Total Loss: 2.113103830475046e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 11, Total Loss: 6.572158596984268e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 12, Total Loss: 3.0351347818465064e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 13, Total Loss: 4.363101790858482e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 14, Total Loss: 2.762837017284414e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 15, Total Loss: 7.943175864513462e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 16, Total Loss: 4.0278094355043245e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 17, Total Loss: 4.148300793393751e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 18, Total Loss: 2.1414463658251e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 19, Total Loss: 2.081817073450042e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 68: tensor([-1.1282,  0.7770,  0.3512], requires_grad=True), Epoch: 20, Total Loss: 2.304516065958912e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 1, Total Loss: 2.3681381578554464e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 2, Total Loss: 4.767639441489768e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 3, Total Loss: 9.630571398571085e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 4, Total Loss: 1.4838129286449773e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 5, Total Loss: 6.144806583268836e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 6, Total Loss: 1.2975057027076467e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 7, Total Loss: 5.07366190376814e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 8, Total Loss: 3.5204372347661028e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 9, Total Loss: 1.0050867882819868e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 10, Total Loss: 4.861723327054518e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 11, Total Loss: 6.561664930500429e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 12, Total Loss: 4.5482894421914275e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 13, Total Loss: 9.897501119394485e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 14, Total Loss: 6.206637289440412e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 15, Total Loss: 9.394488498104656e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 16, Total Loss: 2.8441027454972533e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 17, Total Loss: 3.655869879372727e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 18, Total Loss: 2.1486314703289838e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 19, Total Loss: 3.4419730907896905e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 69: tensor([ 0.6810, -1.1481,  0.4671], requires_grad=True), Epoch: 20, Total Loss: 1.273501596009948e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 1, Total Loss: 9.540103440988007e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 2, Total Loss: 2.6184340841292137e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 3, Total Loss: 1.8081491471076412e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 4, Total Loss: 1.6537941196055187e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 5, Total Loss: 1.2918970194441617e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 6, Total Loss: 2.2387321531034315e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 7, Total Loss: 1.6177563750582832e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 8, Total Loss: 3.6086197480338707e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 9, Total Loss: 6.362212932085267e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 10, Total Loss: 1.064500667352156e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 11, Total Loss: 7.328163988781592e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 12, Total Loss: 8.445066756738419e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 13, Total Loss: 4.732810033928795e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 14, Total Loss: 1.793419756158551e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 15, Total Loss: 7.297898418769408e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 16, Total Loss: 1.299425286515472e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 17, Total Loss: 3.544175587031705e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 18, Total Loss: 4.500522431621952e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 19, Total Loss: 5.6674088824866185e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 70: tensor([-0.1878, -0.8928,  1.0806], requires_grad=True), Epoch: 20, Total Loss: 4.071401970989272e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 1, Total Loss: 2.0403199884671567e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 2, Total Loss: 1.1381129169999837e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 3, Total Loss: 3.372276876489251e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 4, Total Loss: 7.071162232236449e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 5, Total Loss: 1.8384802630022003e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 6, Total Loss: 2.1237385174638072e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 7, Total Loss: 4.5414939916771765e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 8, Total Loss: 2.00912243710969e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 9, Total Loss: 1.0746517215144583e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 10, Total Loss: 7.153110632229432e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 11, Total Loss: 1.661122071437333e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 12, Total Loss: 5.350112115220404e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 13, Total Loss: 9.744252498770063e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 14, Total Loss: 1.1534656267886133e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 15, Total Loss: 3.985233928435112e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 16, Total Loss: 1.0477594423334203e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 17, Total Loss: 7.158044586115878e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 18, Total Loss: 4.7542470934787345e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 19, Total Loss: 9.346101071827831e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 71: tensor([-0.3078,  1.1177, -0.8099], requires_grad=True), Epoch: 20, Total Loss: 4.5314852200865566e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 1, Total Loss: 5.959431241614375e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 2, Total Loss: 7.362765294044681e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 3, Total Loss: 3.735640368897006e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 4, Total Loss: 6.361213329521362e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 5, Total Loss: 5.4670219184909163e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 6, Total Loss: 3.872605554849236e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 7, Total Loss: 6.028677824740349e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 8, Total Loss: 4.2339576364414425e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 9, Total Loss: 4.234204895554821e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 10, Total Loss: 5.315712248134384e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 11, Total Loss: 3.645836266485932e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 12, Total Loss: 4.46702855508524e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 13, Total Loss: 4.538951903778589e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 14, Total Loss: 3.519180491158836e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 15, Total Loss: 4.450020943822191e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 16, Total Loss: 3.9363986928282576e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 17, Total Loss: 3.596853822425445e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 18, Total Loss: 4.2345524298456163e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 19, Total Loss: 3.585045736945803e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 72: tensor([-0.5170,  1.1527, -0.6357], requires_grad=True), Epoch: 20, Total Loss: 3.6896724174805654e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 1, Total Loss: 3.977670011469729e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 2, Total Loss: 3.429130291751152e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 3, Total Loss: 3.727404310577959e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 4, Total Loss: 3.714936013416973e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 5, Total Loss: 3.3815800622154487e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 6, Total Loss: 3.677616798311081e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 7, Total Loss: 3.509096872399457e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 8, Total Loss: 3.3802149444952124e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 9, Total Loss: 3.58865873853707e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 10, Total Loss: 3.374881942470474e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 11, Total Loss: 3.381950706899098e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 12, Total Loss: 3.478098436047922e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 13, Total Loss: 3.2987255212099946e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 14, Total Loss: 3.367053860746112e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 15, Total Loss: 3.374211786003464e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 16, Total Loss: 3.257128561214017e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 17, Total Loss: 3.33544327072736e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 18, Total Loss: 3.293838438689112e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 19, Total Loss: 3.230217663127511e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 73: tensor([ 1.1103, -0.8299, -0.2804], requires_grad=True), Epoch: 20, Total Loss: 3.2924147631066155e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 1, Total Loss: 3.281025250125844e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 2, Total Loss: 3.219033960558804e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 3, Total Loss: 3.2791743214063274e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 4, Total Loss: 3.218333232703018e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 5, Total Loss: 3.202284295630123e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 6, Total Loss: 3.217980961990612e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 7, Total Loss: 3.168959914560372e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 8, Total Loss: 3.176862879000848e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 9, Total Loss: 3.169362435096822e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 10, Total Loss: 3.133700472378214e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 11, Total Loss: 3.144683789850631e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 12, Total Loss: 3.1271770744594616e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 13, Total Loss: 3.1060392125376244e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 14, Total Loss: 3.1151496423821304e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 15, Total Loss: 3.095093151701746e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 16, Total Loss: 3.0834029450174893e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 17, Total Loss: 3.08982065698952e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 18, Total Loss: 3.07388753996385e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 19, Total Loss: 3.0731526420564107e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 74: tensor([ 0.9290, -1.0584,  0.1294], requires_grad=True), Epoch: 20, Total Loss: 3.0834076839709445e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 1, Total Loss: 3.0823706065206373e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 2, Total Loss: 3.1058555956835694e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 3, Total Loss: 3.144416109947917e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 4, Total Loss: 3.197695286307044e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 5, Total Loss: 3.304917347373916e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 6, Total Loss: 3.473075611951925e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 7, Total Loss: 3.747520623995558e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 8, Total Loss: 4.2104749100678346e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 9, Total Loss: 4.962369483356309e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 10, Total Loss: 6.21077639340574e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 11, Total Loss: 8.303306856983116e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 12, Total Loss: 1.181211158454145e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 13, Total Loss: 1.7755596755545244e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 14, Total Loss: 2.790482709172172e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 15, Total Loss: 4.535969344197789e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 16, Total Loss: 7.563165730840567e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 17, Total Loss: 1.2852826593420717e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 18, Total Loss: 2.2163750673698745e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 19, Total Loss: 3.866456917309316e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 75: tensor([ 0.9846,  0.0302, -1.0147], requires_grad=True), Epoch: 20, Total Loss: 6.809141184723417e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 1, Total Loss: 1.2083768474487778e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 2, Total Loss: 2.1564726983519237e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 3, Total Loss: 3.861985455129355e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 4, Total Loss: 6.912544088591402e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 5, Total Loss: 1.2279148831972826e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 6, Total Loss: 2.139788933358669e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 7, Total Loss: 3.5815857884694883e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 8, Total Loss: 5.564916283923983e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 9, Total Loss: 7.587819896027777e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 10, Total Loss: 8.364019744101623e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 11, Total Loss: 6.571446197898333e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 12, Total Loss: 2.898843318789541e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 13, Total Loss: 2.4280772768603024e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 14, Total Loss: 5.6725682032783456e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 15, Total Loss: 2.70753484758854e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 16, Total Loss: 3.893175331689534e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 17, Total Loss: 2.726292798846092e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 18, Total Loss: 6.662452779672507e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 19, Total Loss: 9.06291668967245e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 76: tensor([-0.0845, -0.9551,  1.0396], requires_grad=True), Epoch: 20, Total Loss: 1.2136252831030362e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 1, Total Loss: 2.160435247975551e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 2, Total Loss: 1.6144097398092078e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 3, Total Loss: 3.940868481281822e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 4, Total Loss: 8.206848893055246e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 5, Total Loss: 7.972725298151265e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 6, Total Loss: 1.2932487119074137e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 7, Total Loss: 8.474144478619843e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 8, Total Loss: 1.3848293555216131e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 9, Total Loss: 9.486878460975465e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 10, Total Loss: 5.836445604448939e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 11, Total Loss: 7.820009206647136e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 12, Total Loss: 4.143947761909645e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 13, Total Loss: 2.935645783472125e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 14, Total Loss: 1.046843384625741e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 15, Total Loss: 4.094989773493637e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 16, Total Loss: 4.512892071881133e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 17, Total Loss: 1.904901687623663e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 18, Total Loss: 7.191334262214574e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 19, Total Loss: 1.0541209818121237e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 77: tensor([-1.1447,  0.4413,  0.7034], requires_grad=True), Epoch: 20, Total Loss: 2.718147034202851e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 1, Total Loss: 2.4577159517220582e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 2, Total Loss: 7.955756161925532e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 3, Total Loss: 6.71698809518765e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 4, Total Loss: 9.169824514303194e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 5, Total Loss: 1.7586513638823723e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 6, Total Loss: 1.32773816262651e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 7, Total Loss: 3.0800342114144686e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 8, Total Loss: 5.273976851804242e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 9, Total Loss: 6.646202503717354e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 10, Total Loss: 1.0983023083916638e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 11, Total Loss: 7.46347818265639e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 12, Total Loss: 1.4361417021696216e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 13, Total Loss: 5.081708664001322e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 14, Total Loss: 4.298433538085173e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 15, Total Loss: 6.5262630731167495e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 16, Total Loss: 4.212215452720391e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 17, Total Loss: 8.007388867364789e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 18, Total Loss: 4.853385592033893e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 19, Total Loss: 2.7425819578610283e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 78: tensor([ 1.1046, -0.2611, -0.8436], requires_grad=True), Epoch: 20, Total Loss: 3.927617052838823e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 1, Total Loss: 2.47164271788477e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 2, Total Loss: 4.3311702814060904e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 3, Total Loss: 2.3879515007243615e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 4, Total Loss: 1.603109351353154e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 5, Total Loss: 2.403428801212657e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 6, Total Loss: 1.6241411357874244e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 7, Total Loss: 3.6368420140377154e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 8, Total Loss: 9.428959355566513e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 9, Total Loss: 8.261581845733904e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 10, Total Loss: 1.3908701351091314e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 11, Total Loss: 1.0635513323016096e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 12, Total Loss: 3.268014088713887e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 13, Total Loss: 5.704947809237509e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 14, Total Loss: 4.1781875954392985e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 15, Total Loss: 8.106719584197154e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 16, Total Loss: 7.188053740353627e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 17, Total Loss: 2.865393344669496e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 18, Total Loss: 2.4624478692944322e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 19, Total Loss: 1.586991200705798e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 79: tensor([ 1.0164, -0.0336, -0.9828], requires_grad=True), Epoch: 20, Total Loss: 4.3090692971353064e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 1, Total Loss: 4.833467095929412e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 2, Total Loss: 2.7457820492601615e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 3, Total Loss: 6.116402860031787e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 4, Total Loss: 5.4788597492090415e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 5, Total Loss: 2.0079856607746056e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 6, Total Loss: 2.9170675780219937e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 7, Total Loss: 2.2253222485914121e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 8, Total Loss: 8.301256731831582e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 9, Total Loss: 2.2596418827577515e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 10, Total Loss: 7.960673572832351e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 11, Total Loss: 1.6268119982454865e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 12, Total Loss: 1.7168158788915817e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 13, Total Loss: 1.0305163931165859e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 14, Total Loss: 3.410880806727628e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 15, Total Loss: 2.7688149697259026e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 16, Total Loss: 7.144837477781524e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 17, Total Loss: 1.0569127311820212e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 18, Total Loss: 9.287423639015065e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 19, Total Loss: 5.0430514523918816e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 80: tensor([-0.1873, -0.8931,  1.0804], requires_grad=True), Epoch: 20, Total Loss: 2.2233436478109906e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 1, Total Loss: 3.014878580215777e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 2, Total Loss: 5.6662079926016733e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 3, Total Loss: 7.032442214427276e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 4, Total Loss: 5.786906738063733e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 5, Total Loss: 3.370155566766108e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 6, Total Loss: 2.0555870109745404e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 7, Total Loss: 2.637640156444969e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 8, Total Loss: 4.021713918554302e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 9, Total Loss: 4.611016207244269e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 10, Total Loss: 3.873235309093968e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 11, Total Loss: 2.6080926953776715e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 12, Total Loss: 1.9487406065916534e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 13, Total Loss: 2.2773137105038707e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 14, Total Loss: 3.035719672881061e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 15, Total Loss: 3.408495827739354e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 16, Total Loss: 3.083408163881444e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 17, Total Loss: 2.4156754966229206e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 18, Total Loss: 1.9861753803813368e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 19, Total Loss: 2.0616959251793033e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 81: tensor([-0.5297,  1.1534, -0.6237], requires_grad=True), Epoch: 20, Total Loss: 2.4332819561402642e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 1, Total Loss: 2.6895611137203994e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 2, Total Loss: 2.596935646039438e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 3, Total Loss: 2.2587535308465068e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 4, Total Loss: 1.9613980210595425e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 5, Total Loss: 1.903402208040187e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 6, Total Loss: 2.056120290942203e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 7, Total Loss: 2.233283383271927e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 8, Total Loss: 2.2679488394553644e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 9, Total Loss: 2.1403141075493113e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 10, Total Loss: 1.9617063345582583e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 11, Total Loss: 1.8612970345302194e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 12, Total Loss: 1.885143407969061e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 13, Total Loss: 1.978532737186704e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 14, Total Loss: 2.047674479701035e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 15, Total Loss: 2.0366986396778915e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 16, Total Loss: 1.9596385902827303e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 17, Total Loss: 1.8752806044691345e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 18, Total Loss: 1.8368885279829776e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 19, Total Loss: 1.855663848306877e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 82: tensor([ 0.5940,  0.5606, -1.1545], requires_grad=True), Epoch: 20, Total Loss: 1.900820286431167e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 1, Total Loss: 1.9307890760048837e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 2, Total Loss: 1.9231786626912927e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 3, Total Loss: 1.8860672151141246e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 4, Total Loss: 1.8455457599218154e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 5, Total Loss: 1.825955995401373e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 6, Total Loss: 1.833546803573579e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 7, Total Loss: 1.8572885842051464e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 8, Total Loss: 1.879618608926695e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 9, Total Loss: 1.8893309048649125e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 10, Total Loss: 1.8881647806362962e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 11, Total Loss: 1.888378362048625e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 12, Total Loss: 1.9050492445289568e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 13, Total Loss: 1.9490898742355978e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 14, Total Loss: 2.026463760114489e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 15, Total Loss: 2.1428966925169728e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 16, Total Loss: 2.3113755198544822e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 17, Total Loss: 2.5606086100786537e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 18, Total Loss: 2.9434647083009975e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 19, Total Loss: 3.545029378059095e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 83: tensor([ 1.0639, -0.9206, -0.1433], requires_grad=True), Epoch: 20, Total Loss: 4.498097253482301e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 1, Total Loss: 6.265164252947422e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 2, Total Loss: 8.314138268859479e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 3, Total Loss: 1.227648827468404e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 4, Total Loss: 1.8279014238432498e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 5, Total Loss: 2.815702548831822e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 6, Total Loss: 4.4710386240516915e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 7, Total Loss: 7.205738086362669e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 8, Total Loss: 1.1802078048732942e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 9, Total Loss: 1.9570188412330725e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 10, Total Loss: 3.277997012799858e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 11, Total Loss: 5.540538893313429e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 12, Total Loss: 9.437982503142816e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 13, Total Loss: 1.618154798116083e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 14, Total Loss: 2.788197366217034e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 15, Total Loss: 4.8150307843916375e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 16, Total Loss: 8.301397547549767e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 17, Total Loss: 1.4184167565219712e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 18, Total Loss: 2.3746482031734214e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 19, Total Loss: 3.816591937774717e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 84: tensor([-1.0956,  0.2321,  0.8635], requires_grad=True), Epoch: 20, Total Loss: 5.706759633004817e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 1, Total Loss: 7.545928828617531e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 2, Total Loss: 8.215007269249107e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 3, Total Loss: 6.611742187540621e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 4, Total Loss: 3.2719583117878635e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 5, Total Loss: 5.7372336480408514e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 6, Total Loss: 3.958380403598655e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 7, Total Loss: 2.1431274425733503e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 8, Total Loss: 3.589886538811051e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 9, Total Loss: 3.116918300202982e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 10, Total Loss: 1.265268202229982e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 11, Total Loss: 5.362462271473419e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 12, Total Loss: 5.2861829826556107e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 13, Total Loss: 1.713580054987244e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 14, Total Loss: 2.0266127626886706e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 15, Total Loss: 1.1419165604911084e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 16, Total Loss: 1.9279267592365787e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 17, Total Loss: 1.9807611718750035e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 18, Total Loss: 8.621072364774888e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 19, Total Loss: 1.1682340318979243e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 85: tensor([ 0.6155,  0.5383, -1.1538], requires_grad=True), Epoch: 20, Total Loss: 7.192958309238842e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 1, Total Loss: 1.1735867795133178e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 2, Total Loss: 5.5835475171354975e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 3, Total Loss: 4.528369818710654e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 4, Total Loss: 6.9367526324283e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 5, Total Loss: 4.7414398468234074e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 6, Total Loss: 1.138933088938692e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 7, Total Loss: 4.760632262782375e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 8, Total Loss: 2.6902967169999108e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 9, Total Loss: 4.227644434491983e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 10, Total Loss: 3.037115612808006e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 11, Total Loss: 7.91401228911379e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 12, Total Loss: 1.486182073664727e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 13, Total Loss: 1.3396194816958909e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 14, Total Loss: 2.3645484538614493e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 15, Total Loss: 1.8346098830617703e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 16, Total Loss: 5.229322571104293e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 17, Total Loss: 1.6030739503763118e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 18, Total Loss: 6.5619746817424824e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 19, Total Loss: 1.3739763653117436e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 86: tensor([ 0.2955,  0.8189, -1.1145], requires_grad=True), Epoch: 20, Total Loss: 1.2269994157487287e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 1, Total Loss: 4.8326246990772375e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 2, Total Loss: 6.682852180187384e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 3, Total Loss: 3.4735340610332946e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 4, Total Loss: 8.144040392483262e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 5, Total Loss: 8.444017729978471e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 6, Total Loss: 4.410456445310639e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 7, Total Loss: 1.0624227056759198e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 8, Total Loss: 1.6954547886911337e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 9, Total Loss: 4.479550364539731e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 10, Total Loss: 5.54349728778262e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 11, Total Loss: 3.731158047738815e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 12, Total Loss: 1.3520657807819929e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 13, Total Loss: 9.296105119488829e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 14, Total Loss: 2.3694337583392082e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 15, Total Loss: 3.586035140919617e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 16, Total Loss: 3.1810412468615436e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 17, Total Loss: 1.8257989517054886e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 18, Total Loss: 1.1287919042892154e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 19, Total Loss: 1.7288164923057286e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 87: tensor([-0.5061,  1.1519, -0.6458], requires_grad=True), Epoch: 20, Total Loss: 2.8174121419676858e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 1, Total Loss: 3.300660186667741e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 2, Total Loss: 3.0254990688575144e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 3, Total Loss: 2.780923237903604e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 4, Total Loss: 3.3261232636805452e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 5, Total Loss: 4.667275502189018e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 6, Total Loss: 6.277758452571724e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 7, Total Loss: 7.851217478324829e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 8, Total Loss: 9.719231253543146e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 9, Total Loss: 1.2603369424466119e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 10, Total Loss: 1.7112221641834096e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 11, Total Loss: 2.3578781761563837e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 12, Total Loss: 3.2336434438614e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 13, Total Loss: 4.4147469457493776e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 14, Total Loss: 6.025404414432512e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 15, Total Loss: 8.214461452784461e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 16, Total Loss: 1.108994335257744e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 17, Total Loss: 1.4665451036091998e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 18, Total Loss: 1.8740210806965482e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 19, Total Loss: 2.2805260473854375e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 88: tensor([-0.9142,  1.0680, -0.1538], requires_grad=True), Epoch: 20, Total Loss: 2.589951142806083e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 1, Total Loss: 2.680036193926992e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 2, Total Loss: 2.444418521995401e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 3, Total Loss: 1.8830457021104341e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 4, Total Loss: 1.1394360587907339e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 5, Total Loss: 4.6149211154607226e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 6, Total Loss: 6.556996729243944e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 7, Total Loss: 2.7685121210438047e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 8, Total Loss: 2.6544321972337796e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 9, Total Loss: 6.024679990596142e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 10, Total Loss: 8.559355807146073e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 11, Total Loss: 9.07103632107439e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 12, Total Loss: 7.437345246087057e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 13, Total Loss: 4.5355432934259146e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 14, Total Loss: 1.7437006937700467e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 15, Total Loss: 1.8007588127619329e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 16, Total Loss: 1.9672725518457063e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 17, Total Loss: 1.353420345979128e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 18, Total Loss: 2.78651454839659e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 19, Total Loss: 3.6867291649063817e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 89: tensor([-0.1296, -0.9289,  1.0585], requires_grad=True), Epoch: 20, Total Loss: 3.6443969635305765e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 1, Total Loss: 2.76448098055461e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 2, Total Loss: 1.5229282746196336e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 3, Total Loss: 4.840460037407447e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 4, Total Loss: 1.690648304751723e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 5, Total Loss: 1.6481217207381415e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 6, Total Loss: 6.941545546351484e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 7, Total Loss: 1.2572670548316846e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 8, Total Loss: 1.5668854571347856e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 9, Total Loss: 1.5038528799978637e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 10, Total Loss: 1.1338369847466046e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 11, Total Loss: 6.403445714769329e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 12, Total Loss: 2.246826373610917e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 13, Total Loss: 1.7492816843656242e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 14, Total Loss: 4.0634935799362446e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 15, Total Loss: 2.2221464042556295e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 16, Total Loss: 4.457252731463539e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 17, Total Loss: 6.047384534964365e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 18, Total Loss: 6.402570016073648e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 19, Total Loss: 5.521736279836472e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 90: tensor([-0.9602,  1.0355, -0.0753], requires_grad=True), Epoch: 20, Total Loss: 3.857906383044534e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 1, Total Loss: 2.058528527570478e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 2, Total Loss: 6.886069984636792e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 3, Total Loss: 5.41435113703362e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 4, Total Loss: 1.5604623218078137e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 5, Total Loss: 7.608039745895108e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 6, Total Loss: 1.5308403987860986e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 7, Total Loss: 2.154967988140186e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 8, Total Loss: 2.437995510584095e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 9, Total Loss: 2.3309868054927645e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 10, Total Loss: 1.9116663976235225e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 11, Total Loss: 1.3308389791696328e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 12, Total Loss: 7.531193988914583e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 13, Total Loss: 3.0759914281068005e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 14, Total Loss: 6.217586313379122e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 15, Total Loss: 2.0730003581778443e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 16, Total Loss: 1.379075307860939e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 17, Total Loss: 3.424556053070619e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 18, Total Loss: 5.607173448832011e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 19, Total Loss: 7.339922737490389e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 91: tensor([ 1.1276, -0.7792, -0.3484], requires_grad=True), Epoch: 20, Total Loss: 8.275640317286784e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 1, Total Loss: 8.320792563172361e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 2, Total Loss: 7.585713033029929e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 3, Total Loss: 6.310240382295192e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 4, Total Loss: 4.779732624099493e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 5, Total Loss: 3.261045155118758e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 6, Total Loss: 1.9560791630737768e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 7, Total Loss: 9.850998195565506e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 8, Total Loss: 3.892830417860628e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 9, Total Loss: 1.461371181917334e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 10, Total Loss: 1.9193110379650167e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 11, Total Loss: 4.432417208216856e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 12, Total Loss: 8.145802008496807e-11, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 13, Total Loss: 1.230876770273445e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 14, Total Loss: 1.6342415922005638e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 15, Total Loss: 1.986088658428414e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 16, Total Loss: 2.2661047473261097e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 17, Total Loss: 2.4678927883068377e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 18, Total Loss: 2.59542111750128e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 19, Total Loss: 2.6594011029797304e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 92: tensor([-1.1480,  0.4668,  0.6813], requires_grad=True), Epoch: 20, Total Loss: 2.674436005545963e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 1, Total Loss: 2.890112128027228e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 2, Total Loss: 2.6082166076751596e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 3, Total Loss: 2.759291676733295e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 4, Total Loss: 2.567200381888356e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 5, Total Loss: 2.527938119022184e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 6, Total Loss: 2.563506776483164e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 7, Total Loss: 2.522971966667321e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 8, Total Loss: 2.616879125253855e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 9, Total Loss: 2.722647410985761e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 10, Total Loss: 2.890864066460063e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 11, Total Loss: 3.1576689620077385e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 12, Total Loss: 3.509434427690194e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 13, Total Loss: 3.995049687532063e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 14, Total Loss: 4.6512131174401125e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 15, Total Loss: 5.532332037284174e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 16, Total Loss: 6.707590860144299e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 17, Total Loss: 8.299510016360486e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 18, Total Loss: 1.0458214952125624e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 19, Total Loss: 1.3394266769607586e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 93: tensor([-0.7605, -0.3723,  1.1327], requires_grad=True), Epoch: 20, Total Loss: 1.744506310382546e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 1, Total Loss: 2.331384789543514e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 2, Total Loss: 3.102104381960659e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 3, Total Loss: 4.236520451589843e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 4, Total Loss: 5.7991199972966345e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 5, Total Loss: 8.050847589656991e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 6, Total Loss: 1.1291418049276113e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 7, Total Loss: 1.595587085059149e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 8, Total Loss: 2.27302794345998e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 9, Total Loss: 3.2544221318352236e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 10, Total Loss: 4.6743637935929146e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 11, Total Loss: 6.70986829948597e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 12, Total Loss: 9.585471463498116e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 13, Total Loss: 1.3527362273825645e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 14, Total Loss: 1.8701179876960867e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 15, Total Loss: 2.497346613256123e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 16, Total Loss: 3.1705113035937143e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 17, Total Loss: 3.7363993952892315e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 18, Total Loss: 3.986663743198634e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 19, Total Loss: 3.731080667908425e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 94: tensor([-0.4205, -0.7211,  1.1416], requires_grad=True), Epoch: 20, Total Loss: 2.9916585167113436e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 1, Total Loss: 2.0503752749462853e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 2, Total Loss: 1.3387665758706078e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 3, Total Loss: 1.1293124653103464e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 4, Total Loss: 1.3791145627111427e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 5, Total Loss: 1.786049948161073e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 6, Total Loss: 2.0023236258319916e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 7, Total Loss: 1.8217235281199316e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 8, Total Loss: 1.2838392421557815e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 9, Total Loss: 6.297237031969343e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 10, Total Loss: 1.494187069864052e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 11, Total Loss: 7.691774292880036e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 12, Total Loss: 1.722565428642666e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 13, Total Loss: 4.686498866519773e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 14, Total Loss: 7.000494580390732e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 15, Total Loss: 7.518819787322228e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 16, Total Loss: 6.322776951531627e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 17, Total Loss: 4.401616000927636e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 18, Total Loss: 2.8776734232870753e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 19, Total Loss: 2.343028266481349e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 95: tensor([-0.9132,  1.0686, -0.1554], requires_grad=True), Epoch: 20, Total Loss: 2.6427423324600206e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 1, Total Loss: 3.155644507708081e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 2, Total Loss: 3.25420128637544e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 3, Total Loss: 2.6885211011860996e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 4, Total Loss: 1.6676878426910484e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 5, Total Loss: 6.790390549578242e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 6, Total Loss: 1.6142036554682193e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 7, Total Loss: 2.6622705167343827e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 8, Total Loss: 8.188635937723186e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 9, Total Loss: 1.462703892763854e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 10, Total Loss: 1.8690438343287675e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 11, Total Loss: 1.886008680917031e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 12, Total Loss: 1.5768452473859756e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 13, Total Loss: 1.1375455496183884e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 14, Total Loss: 7.762336065916853e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 15, Total Loss: 6.0656003959687e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 16, Total Loss: 6.179066042278159e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 17, Total Loss: 7.106744838997832e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 18, Total Loss: 7.681930502825297e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 19, Total Loss: 7.176526753096896e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 96: tensor([-0.2874, -0.8249,  1.1122], requires_grad=True), Epoch: 20, Total Loss: 5.569410210722037e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 1, Total Loss: 3.597281876485566e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 2, Total Loss: 1.5208545082497756e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 3, Total Loss: 4.4380026350525563e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 4, Total Loss: 2.0811071447557284e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 5, Total Loss: 7.042439473217387e-10, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 6, Total Loss: 1.5842283346234371e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 7, Total Loss: 2.3214876477883003e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 8, Total Loss: 2.6708156647930784e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 9, Total Loss: 2.613247188257435e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 10, Total Loss: 2.2554685168063895e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 11, Total Loss: 1.8727830262789283e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 12, Total Loss: 1.645690756539793e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 13, Total Loss: 1.7185853065885686e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 14, Total Loss: 2.1005564547464274e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 15, Total Loss: 2.6999408535238344e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 16, Total Loss: 3.4184762664661704e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 17, Total Loss: 4.161072702298848e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 18, Total Loss: 4.891126041377344e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 19, Total Loss: 5.655588448742989e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 97: tensor([-0.2757,  1.1089, -0.8332], requires_grad=True), Epoch: 20, Total Loss: 6.556340404506621e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 1, Total Loss: 7.844047637437107e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 2, Total Loss: 9.217533719055984e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 3, Total Loss: 1.1447299413091737e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 4, Total Loss: 1.4364065775191502e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 5, Total Loss: 1.835059435833711e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 6, Total Loss: 2.3742428762358074e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 7, Total Loss: 3.0869409269592056e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 8, Total Loss: 4.029591541331424e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 9, Total Loss: 5.272462265240178e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 10, Total Loss: 6.87854740849768e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 11, Total Loss: 8.932528934901176e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 12, Total Loss: 1.1454458883704926e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 13, Total Loss: 1.4435397104193443e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 14, Total Loss: 1.7674851077001567e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 15, Total Loss: 2.0855569042131352e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 16, Total Loss: 2.3326784104923848e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 17, Total Loss: 2.446864333897819e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 18, Total Loss: 2.3591457740584015e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 19, Total Loss: 2.0697678382417454e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 98: tensor([ 1.1503, -0.6621, -0.4882], requires_grad=True), Epoch: 20, Total Loss: 1.6260463095253863e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 1, Total Loss: 1.1510324617440865e-07, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 2, Total Loss: 7.565638031253204e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 3, Total Loss: 5.1763481501958325e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 4, Total Loss: 4.307864951462454e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 5, Total Loss: 4.438625497695948e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 6, Total Loss: 4.854513063633432e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 7, Total Loss: 5.0189346147974086e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 8, Total Loss: 4.6993125305831337e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 9, Total Loss: 3.974584205569767e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 10, Total Loss: 3.126947168699377e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 11, Total Loss: 2.4524981378611085e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 12, Total Loss: 2.1541877853044994e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 13, Total Loss: 2.2454275882315964e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 14, Total Loss: 2.5982405190242522e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 15, Total Loss: 3.00309609165763e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 16, Total Loss: 3.2821011281658916e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 17, Total Loss: 3.32016128330748e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 18, Total Loss: 3.117591593488195e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 19, Total Loss: 2.7346137956258573e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 99: tensor([-1.1177,  0.3078,  0.8099], requires_grad=True), Epoch: 20, Total Loss: 2.276181653877088e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 1, Total Loss: 1.8358589925832297e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 2, Total Loss: 1.4722476346822912e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 3, Total Loss: 1.203650823639281e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 4, Total Loss: 1.011352981529157e-08, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 5, Total Loss: 8.64170454112141e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 6, Total Loss: 7.303677241934178e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 7, Total Loss: 5.947908596015238e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 8, Total Loss: 4.578759677416835e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 9, Total Loss: 3.3446522374010507e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 10, Total Loss: 2.4328955203015905e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 11, Total Loss: 2.001266411823787e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 12, Total Loss: 2.112059062223217e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 13, Total Loss: 2.7226093318578225e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 14, Total Loss: 3.701598709166725e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 15, Total Loss: 4.869059695063042e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 16, Total Loss: 6.050619046610671e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 17, Total Loss: 7.103122379425366e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 18, Total Loss: 7.957567058394718e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 19, Total Loss: 8.596883972660222e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n",
      "Material 100: tensor([ 1.0917, -0.2199, -0.8717], requires_grad=True), Epoch: 20, Total Loss: 9.080382454286655e-09, Loss Weights: [0.9965148 0.9965148 1.0069704]\n"
     ]
    }
   ],
   "source": [
    "# Loop through each material in the dataset\n",
    "for i,data in enumerate(dataset):\n",
    "    \n",
    "    material_params_1 = data['material_params']\n",
    "    material_params_2 = data['distorted_material_params']\n",
    "    nodes = data['nodes']\n",
    "    uh_vem = data['uh_vem']\n",
    "\n",
    "    nodes, material_params_1 = neural.normalize_inputs(nodes, material_params_1)\n",
    "    _, material_params_2 = neural.normalize_inputs(nodes, material_params_2)\n",
    "\n",
    "    nodes = nodes.flatten()\n",
    "    nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n",
    "    \n",
    "    # Loop through epochs for the same material\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass using the current material parameters\n",
    "        uh = model(nodes, material_params_1)  # Adjust input to include material params\n",
    "\n",
    "        # Compute individual losses\n",
    "        loss = loss_function.compute_loss_with_uh(uh_vem, uh)\n",
    "        sobolev_loss = loss_function.compute_sobolev_loss(model, nodes, material_params_1, loss, concatenate)\n",
    "        material_penalty = loss_function.compute_material_penalty(model, nodes, material_params_1, material_params_2, concatenate) \n",
    "\n",
    "        # Weighted sum of losses (with GradNorm weights)\n",
    "        weighted_losses = [\n",
    "            loss_weights[0] * loss, \n",
    "            loss_weights[1] * sobolev_loss, \n",
    "            loss_weights[2] * material_penalty\n",
    "        ]\n",
    "\n",
    "        # Store the initial loss weights\n",
    "        if epoch == 0:\n",
    "            initial_loss_weights = [\n",
    "                loss_weights[0] * loss, \n",
    "                loss_weights[1] * sobolev_loss, \n",
    "                loss_weights[2] * material_penalty\n",
    "            ]\n",
    "\n",
    "        # Calculate the gradient norms for each task\n",
    "        grad_norms = gn.calculate_gradient_norm(model, weighted_losses)\n",
    "        tilde_losses = [gn.compute_loss_ratio(weighted_losses[i].item(), initial_loss_weights[i].item()) for i in range(len(weighted_losses))]\n",
    "\n",
    "        # Compute the grad norm loss\n",
    "        loss_grad = gn.compute_grad_norm_loss(grad_norms, tilde_losses, alpha=100)\n",
    "\n",
    "        # Backpropagation of the gradient loss (update the grad_loss weights)\n",
    "        loss_grad.backward(retain_graph=True)\n",
    "\n",
    "        # Step 1: Perform the optimizer step to update the task weights using the gradient loss\n",
    "        optimizer_w.step()\n",
    "\n",
    "        # Step 2: Compute the total loss (sum of the weighted loss)\n",
    "        total_loss = loss_weights[0] * loss + loss_weights[1] * sobolev_loss + loss_weights[2] * material_penalty\n",
    "\n",
    "        # Perform gradient clipping and check for NaN/Inf before backpropagation\n",
    "        if torch.isnan(total_loss).any() or torch.isinf(total_loss).any():\n",
    "            print(f\"NaN or Inf detected in total_loss at epoch {epoch}\")\n",
    "            continue\n",
    "        \n",
    "        # Break if the total loss is too high\n",
    "        if abs(total_loss.item()) > 100.0 and epoch > 0:\n",
    "            break\n",
    "\n",
    "        # Backpropagation for the model weights using total loss\n",
    "        total_loss.backward()\n",
    "\n",
    "        # Step 3: Perform the optimizer step to update the model weights using the total loss\n",
    "        optimizer.step()\n",
    "\n",
    "        # Step 4: Renormalize the loss weights (no in-place operation)\n",
    "        T = len(weighted_losses)\n",
    "        sum_w = torch.sum(loss_weights).item()\n",
    "\n",
    "        # Instead of modifying in-place, re-assign to a new tensor\n",
    "        with torch.no_grad():\n",
    "            loss_weights.copy_((loss_weights / sum_w) * T)  # Use .copy_ to avoid creating new tensors and keep gradients\n",
    "\n",
    "        # Store losses for analysis\n",
    "        if epoch > 1:\n",
    "            total_loss_values.append(total_loss.item())\n",
    "            loss_values.append(loss_weights[0].item()*loss.item())\n",
    "            material_loss_values.append(loss_weights[2].item()*material_penalty.item())\n",
    "            sobolev_loss_values.append(loss_weights[1].item()*sobolev_loss.item())\n",
    "\n",
    "        # Print progress\n",
    "        print(f'Material {i+1}: {material_params_1}, Epoch: {epoch + 1}, Total Loss: {total_loss.item()}, Loss Weights: {loss_weights.detach().numpy()}')\n",
    "        \n",
    "    # Break if the total loss is too high\n",
    "    if abs(total_loss.item()) > 1.0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving time [s]: 0.0405\n",
      "######################### Beam ##########################\n",
      "[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.48435330e-20\n",
      " -4.78344552e-08  4.87253371e-20 -2.60367997e-20 -9.56689103e-08\n",
      " -1.16808523e-19 -2.92679376e-20 -1.43503366e-07 -2.06062785e-19\n",
      " -2.92523535e-20 -1.91337821e-07 -2.20703626e-19 -2.84839150e-20\n",
      " -2.39172276e-07 -2.30154128e-19 -2.91488169e-20 -2.87006731e-07\n",
      " -1.74836731e-19 -2.57623351e-20 -3.34841186e-07 -3.59798406e-19\n",
      " -3.81560152e-20 -3.82675641e-07  3.30128450e-19  7.55219848e-21\n",
      " -4.30510097e-07 -2.21905901e-18 -1.61420486e-19 -4.78344552e-07\n",
      "  7.19991718e-18  4.62941210e-19 -5.26179007e-07 -2.76057592e-17\n",
      " -1.84422850e-18 -5.74013462e-07  1.01008922e-16  6.68126956e-18\n",
      " -6.21847917e-07 -3.74251128e-16 -2.48223689e-17 -6.69682372e-07\n",
      "  1.38194129e-15  9.15906220e-17 -7.17516828e-07 -5.10758327e-15\n",
      " -3.38581483e-16 -7.65351283e-07  1.88726643e-14  1.25100084e-15\n",
      " -8.13185738e-07 -6.97397248e-14 -4.62286209e-15 -8.61020193e-07\n",
      "  2.57702912e-13  1.70823778e-14 -9.08854648e-07 -9.52271015e-13\n",
      " -6.31233480e-14 -9.56689103e-07  3.51885381e-12  2.33254784e-13\n",
      " -1.00452356e-06 -1.30029544e-11 -8.61928834e-13 -1.05235801e-06\n",
      "  4.80488298e-11  3.18502008e-12 -1.10019247e-06 -1.77551195e-10\n",
      " -1.17693631e-11 -1.14802692e-06  6.56091457e-10  4.34904342e-11\n",
      " -1.19586138e-06 -2.42440497e-09 -1.60706901e-10 -1.24369583e-06\n",
      "  8.95871970e-09  5.93848016e-10 -1.29153029e-06 -3.31044770e-08\n",
      " -2.19440151e-09 -1.33936474e-06  1.22328462e-07  8.10880535e-09\n",
      " -1.38719920e-06 -4.52031081e-07 -2.99638530e-08 -1.43503366e-06\n",
      "  1.67035615e-06  1.10723152e-07 -1.48286811e-06 -6.17234032e-06\n",
      " -4.09146862e-07 -1.53070257e-06  2.28081808e-05 -4.09146862e-07\n",
      " -6.12171206e-07  1.14935965e-05 -4.09146862e-07 -2.81570185e-07\n",
      "  3.84644595e-06 -4.09146862e-07 -2.50752001e-07  1.75258164e-06\n",
      " -4.09146862e-07 -2.78543715e-07  1.82296520e-06 -4.09146862e-07\n",
      " -2.90196475e-07  2.12106416e-06 -4.09146862e-07 -2.85217249e-07\n",
      "  2.20722471e-06 -4.09146862e-07 -2.74525832e-07  2.15589029e-06\n",
      " -4.09146862e-07 -2.63528272e-07  2.06905727e-06 -4.09146862e-07\n",
      " -2.53234086e-07  1.98541831e-06 -4.09146862e-07 -2.43329086e-07\n",
      "  1.90863929e-06 -4.09146862e-07 -2.33509117e-07  1.83473328e-06\n",
      " -4.09146862e-07 -2.23672564e-07  1.76120600e-06 -4.09146862e-07\n",
      " -2.13815216e-07  1.68743470e-06 -4.09146862e-07 -2.03950189e-07\n",
      "  1.61348770e-06 -4.09146862e-07 -1.94084518e-07  1.53949132e-06\n",
      " -4.09146862e-07 -1.84219678e-07  1.46549707e-06 -4.09146862e-07\n",
      " -1.74355341e-07  1.39151121e-06 -4.09146862e-07 -1.64491123e-07\n",
      "  1.31752924e-06 -4.09146862e-07 -1.54626896e-07  1.24354748e-06\n",
      " -4.09146862e-07 -1.44762618e-07  1.16956687e-06 -4.09146862e-07\n",
      " -1.34898424e-07  1.09558077e-06 -4.09146862e-07 -1.25033880e-07\n",
      "  1.02161405e-06 -4.09146862e-07 -1.15170626e-07  9.47575485e-07\n",
      " -4.09146862e-07 -1.05302610e-07  8.73802416e-07 -4.09146862e-07\n",
      " -9.54521926e-08  7.99048313e-07 -4.09146862e-07 -8.55367450e-08\n",
      "  7.27919372e-07 -4.09146862e-07 -7.58615989e-08  6.43394649e-07\n",
      " -4.09146862e-07 -6.52984846e-08  6.08370338e-07 -4.09146862e-07\n",
      " -5.80166117e-08  3.90430911e-07 -4.09146862e-07 -3.86098166e-08\n",
      "  8.48403831e-07 -4.09146862e-07 -6.40073262e-08 -1.19127085e-06\n",
      " -4.09146862e-07  7.61571109e-08  5.99842211e-06 -1.20440059e-07\n",
      "  7.37772012e-08  3.24019557e-06  2.27443575e-09  7.13972915e-08\n",
      "  6.86668255e-07  1.90932563e-08  6.90173818e-08 -1.48465998e-07\n",
      "  8.98417324e-09  6.66374721e-08 -1.75024659e-07  1.53645579e-09\n",
      "  6.42575623e-08 -6.33022991e-08 -5.91109437e-10  6.18776526e-08\n",
      " -4.77978825e-09 -5.18059179e-10  5.94977429e-08  7.11739651e-09\n",
      " -1.64725588e-10  5.71178332e-08  4.18927841e-09 -3.08999835e-12\n",
      "  5.47379235e-08  9.83060449e-10  2.30858104e-11  5.23580138e-08\n",
      " -1.45434569e-10  1.17347969e-11  4.99781040e-08 -2.17797863e-10\n",
      "  2.28354341e-12  4.75981943e-08 -8.46422479e-11 -6.36974325e-13\n",
      "  4.52182846e-08 -8.81431927e-12 -6.52001963e-13  4.28383749e-08\n",
      "  8.33343528e-12 -2.23285594e-13  4.04584652e-08  5.38548894e-12\n",
      " -1.16878395e-14  3.80785555e-08  1.38563963e-12  2.76306684e-14\n",
      "  3.56986457e-08 -1.27446949e-13  1.52378783e-14  3.33187360e-08\n",
      " -2.69121904e-13  3.31559501e-15  3.09388263e-08 -1.12390734e-13\n",
      " -6.56049805e-16  2.85589166e-08 -1.47014711e-14 -8.15428829e-16\n",
      "  2.61790069e-08  9.60177147e-15 -3.00262216e-16  2.37990972e-08\n",
      "  6.88398920e-15 -2.48957018e-17  2.14191874e-08  1.92816834e-15\n",
      "  3.26551920e-17  1.90392777e-08 -8.61106678e-17  1.96446331e-17\n",
      "  1.66593680e-08 -3.29798144e-16  4.69844895e-18  1.42794583e-08\n",
      " -1.48050677e-16 -6.57619517e-19  1.18995486e-08 -2.29144416e-17\n",
      " -1.04153394e-18  9.51963887e-09  1.10582522e-17 -4.29405849e-19\n",
      "  7.13972915e-09  8.95891853e-18 -7.28091417e-20  4.75981943e-09\n",
      "  2.88124808e-18  8.61493037e-21  2.37990972e-09  1.53394183e-19\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "#########################################################\n",
      "Predicted displacements: tensor([-1.6950e-07, -2.9057e-06,  2.7907e-06,  1.6326e-06, -2.1765e-06,\n",
      "         1.4566e-06, -1.3188e-06, -4.5495e-07,  8.5309e-07, -1.9781e-06,\n",
      "        -1.1679e-06,  2.1091e-06, -1.0440e-06,  2.0713e-06, -3.3341e-07,\n",
      "        -2.1923e-06, -2.0182e-06, -6.6310e-07, -1.4080e-06,  1.7248e-06,\n",
      "         2.6114e-06, -2.5760e-06, -8.8476e-08,  1.4482e-07,  5.1374e-07,\n",
      "         9.9465e-07, -9.7137e-07,  8.5682e-07,  3.3285e-06,  1.5944e-06,\n",
      "         8.0094e-07,  3.2131e-07,  1.0103e-06,  7.9069e-07,  3.6834e-07,\n",
      "         2.8498e-07,  1.9129e-06, -4.6566e-09, -1.8217e-06, -5.3644e-07,\n",
      "        -1.2787e-06, -1.5283e-06, -2.5025e-06, -1.0645e-06,  9.2573e-07,\n",
      "        -1.6000e-06,  1.4529e-07, -2.5686e-06,  1.3132e-06,  1.4082e-06,\n",
      "        -1.2591e-06,  6.2957e-07, -1.7546e-06, -1.5032e-06,  1.2743e-06,\n",
      "        -2.1993e-06, -9.5737e-08,  3.9083e-06,  9.6485e-07,  2.1486e-06,\n",
      "         1.5348e-06,  2.2743e-06,  7.5996e-07,  1.0906e-06,  5.5879e-07,\n",
      "        -1.6652e-06,  2.0638e-06, -2.3004e-06, -1.0920e-07,  6.5169e-07,\n",
      "        -2.6925e-06, -1.9791e-06,  2.5295e-06, -1.6592e-06, -1.8505e-06,\n",
      "         1.5832e-07,  1.3616e-06,  9.4739e-07,  3.0352e-06, -1.0747e-06,\n",
      "         1.6997e-07, -1.2089e-06,  1.2349e-06, -7.9628e-08, -6.9849e-08,\n",
      "        -1.2480e-06,  4.0047e-07, -1.3411e-07,  9.1270e-07, -2.1278e-06,\n",
      "        -8.1398e-07, -6.9849e-08, -1.3970e-09, -2.7695e-07, -6.6217e-07,\n",
      "        -9.5135e-07,  1.8552e-06,  1.0943e-07,  8.5449e-07, -1.5479e-06,\n",
      "        -1.9204e-06, -1.4231e-06,  1.1912e-06, -2.7800e-07, -6.7148e-07,\n",
      "        -7.6741e-07, -8.5495e-07,  6.1002e-07,  1.3923e-06,  2.0649e-06,\n",
      "        -1.5926e-06,  1.7229e-06, -1.5995e-07,  1.2703e-06,  2.1867e-06,\n",
      "        -1.0350e-06,  1.8775e-06,  1.6368e-07,  8.3679e-07,  1.3262e-06,\n",
      "         6.9337e-07,  2.6841e-06,  1.8682e-06,  1.9372e-06, -6.0862e-07,\n",
      "         7.9162e-07,  3.0532e-05, -4.3568e-07, -1.0999e-06,  1.9390e-06,\n",
      "        -2.2259e-06, -1.6182e-07, -3.5856e-08,  2.0079e-06, -2.2686e-06,\n",
      "         1.4799e-06,  1.4054e-06, -2.9267e-07, -9.0711e-07,  1.7360e-06,\n",
      "        -8.0472e-07, -1.2355e-06,  2.3413e-06,  1.3076e-06,  1.0133e-06,\n",
      "        -1.7229e-07,  1.7993e-06,  1.4529e-07,  1.0382e-06, -1.8557e-06,\n",
      "         1.2275e-06, -2.2538e-06, -1.0966e-06, -9.5740e-07, -3.2596e-08,\n",
      "        -1.0878e-06, -1.0245e-07, -1.3690e-06, -9.4995e-07,  1.6168e-06,\n",
      "        -1.1404e-06,  2.2212e-06, -2.1490e-07, -6.0722e-07,  4.4517e-07,\n",
      "         9.5693e-07,  8.4378e-07,  1.1567e-06,  2.0526e-06,  1.2182e-06,\n",
      "         1.3467e-06,  2.0741e-06, -1.0896e-06, -1.3337e-06, -1.1614e-06,\n",
      "        -1.4016e-06,  1.6065e-06, -1.1305e-06,  2.7940e-08,  2.3795e-06,\n",
      "        -9.7230e-07, -1.4408e-06,  1.4789e-06,  2.3628e-06, -1.2189e-07,\n",
      "        -1.6270e-06,  1.1846e-06, -1.7229e-06,  1.6273e-06, -2.0619e-06,\n",
      "        -1.5665e-06, -6.0350e-07, -2.7474e-07, -1.5367e-06, -1.7714e-06,\n",
      "        -4.1080e-07, -8.1671e-07,  1.9185e-07, -6.4913e-07, -5.6473e-05,\n",
      "        -1.8179e-06, -4.6566e-07, -3.8696e-07, -8.8953e-07,  2.1122e-06,\n",
      "         1.5777e-06,  2.5865e-06, -1.2405e-06, -1.1269e-06, -3.5716e-07,\n",
      "        -5.7835e-07,  1.2042e-06, -4.3435e-07,  1.8444e-06,  7.3505e-07,\n",
      "         1.6438e-07,  1.8300e-06, -7.8324e-07, -1.4725e-06,  4.2468e-07,\n",
      "        -1.5181e-06, -8.7149e-07,  2.5108e-06,  9.5239e-07,  1.3076e-06,\n",
      "        -1.0505e-06, -9.1270e-08, -1.2666e-06, -2.8424e-06, -3.2582e-06,\n",
      "        -3.9881e-07, -1.3249e-06,  1.4761e-06, -7.7183e-07, -1.3104e-06,\n",
      "        -5.5507e-07, -1.6550e-06,  1.3318e-07,  2.7316e-06, -1.8124e-06,\n",
      "         2.2233e-06, -1.5416e-06, -1.7118e-06, -1.3532e-06, -2.5402e-06,\n",
      "        -2.2519e-06, -5.4180e-07,  1.4317e-06, -9.0897e-07, -5.1339e-07,\n",
      "         1.4901e-08, -3.9046e-07,  2.9476e-06,  2.0489e-07,  5.7751e-06,\n",
      "        -1.0169e-06, -3.1840e-07,  1.4405e-06,  2.0564e-06,  6.3516e-07,\n",
      "        -9.7230e-07,  2.1793e-06, -7.0781e-08, -7.5437e-07,  3.4525e-06,\n",
      "         1.6131e-06,  1.9139e-06,  3.1065e-07, -4.7870e-07, -2.0396e-07,\n",
      "        -1.2051e-06,  5.1223e-07,  1.4277e-06, -5.4017e-07, -1.2238e-06,\n",
      "         9.9652e-07, -7.8743e-07, -3.3155e-07, -5.3481e-07,  1.5981e-06,\n",
      "        -1.3919e-06,  1.0496e-06,  7.0781e-07,  1.0300e-06,  2.1979e-07,\n",
      "         1.6298e-06, -6.9756e-07,  1.7378e-06,  1.4771e-06,  2.0401e-06,\n",
      "         9.9652e-07], requires_grad=True)\n",
      "Inference time [s]: 0.0013523101806640625\n",
      "L2 error: 2.570443630218506\n",
      "Energy error: 0\n",
      "H1 error: 7.502703374484554e-05\n"
     ]
    }
   ],
   "source": [
    "# New geometry parameter\n",
    "I_new = 1e-4\n",
    "A_new = 1\n",
    "E_new = 110e7\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp, load = mesh.generate_portic_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Solve the problem using the VEM\n",
    "uh_vem, K, f, solving_time = solve_vem.solve_1d(nodes, elements, supp, E_new, A_new, I_new, load, q, t)\n",
    "\n",
    "# Testing the model with new parameters\n",
    "material_params = torch.tensor([E_new , A_new , I_new ], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "nodes, material_params = neural.normalize_inputs(nodes, material_params)\n",
    "predicted_displacements, l2_error, energy_error, h1_error, inference_time = neural.test_portic(\n",
    "    nodes=nodes,\n",
    "    material_params=material_params,\n",
    "    model=model,\n",
    "    uh_vem=uh_vem,\n",
    "    K=K,\n",
    "    f=f,\n",
    "    concatanate=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
