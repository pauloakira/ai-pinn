{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points:\n",
    "\n",
    "1. **Using VEM/FEM Solutions for Efficient Training**:\n",
    "   - By training the neural network on the displacement field computed using VEM/FEM, you're providing the model with a high-quality reference solution. This allows the model to learn the underlying physical relationships between the parameters (such as Young’s modulus \\(E\\), cross-sectional area \\(A\\), and moment of inertia \\(I\\)) and the displacement field.\n",
    "\n",
    "2. **Generalization with Fewer Data**:\n",
    "   - Since the model is grounded in physically informed solutions, you likely need **fewer training examples** to generalize to new material and geometrical configurations. Unlike traditional machine learning models that require vast amounts of labeled data, your approach can rely on solving a **few instances** of VEM/FEM solutions and using that information to generalize.\n",
    "\n",
    "3. **Parameter Sensitivity and Inference**:\n",
    "   - The network’s sensitivity to material and geometrical parameters (\\(E\\), \\(A\\), \\(I\\)) is key. Once trained, the model will allow for **rapid inference** with new combinations of these parameters without needing to solve the full VEM/FEM system again.\n",
    "   - In an engineering context, this is particularly advantageous, as engineers often need to explore various material or geometric configurations during design optimization. Having a trained neural network that provides **instant predictions** without solving a full VEM/FEM problem would significantly improve efficiency.\n",
    "\n",
    "4. **Efficiency Compared to Traditional VEM/FEM**:\n",
    "   - Solving a full VEM/FEM problem repeatedly for different parameter values can be computationally expensive, especially for large or complex systems. By training a neural network to approximate the displacement field based on these parameters, you essentially create a **surrogate model** that can make predictions more efficiently.\n",
    "\n",
    "### Challenges and Considerations:\n",
    "- **Accuracy vs. Efficiency**: While the neural network may provide fast predictions, the trade-off is the potential for reduced accuracy compared to solving the full VEM/FEM system. This can be mitigated by fine-tuning the network and introducing additional regularization techniques like Sobolev training.\n",
    "  \n",
    "- **Extrapolation Limits**: The network might struggle with extrapolating far beyond the range of material and geometrical parameters it was trained on. Ensuring that the training data includes a representative range of parameters will be crucial for reliable generalization.\n",
    "\n",
    "- **Hybrid Model Validation**: You could validate your hypothesis by comparing the **computational cost** (in terms of time) and **accuracy** between solving multiple VEM/FEM instances and using the trained neural network for inference over a variety of material/geometrical configurations.\n",
    "\n",
    "### Conclusion:\n",
    "The approach of training a neural network using VEM/FEM solutions to enable efficient inference of displacement fields for different material and geometric configurations is a practical and promising solution in engineering contexts. It leverages the strengths of both numerical methods and machine learning to balance accuracy and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import core.vem as vem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS backend is available!\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS backend is available!\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS backend is not available. Using CPU.\")\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_l2_error(uh_vem, uh_nn):\n",
    "    \"\"\"\n",
    "    Compute the L2 norm error between the FEM and NN displacement fields.\n",
    "\n",
    "    Parameters:\n",
    "    uh_fem (torch.Tensor): Displacement field from FEM (ndof x 1)\n",
    "    uh_nn (torch.Tensor): Displacement field from NN (ndof x 1)\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: L2 norm error as a scalar\n",
    "    \"\"\"\n",
    "    error = torch.norm(uh_nn - uh_vem) / torch.norm(uh_vem)\n",
    "    return error\n",
    "\n",
    "def compute_energy_error(K, uh_fem, uh_nn):\n",
    "    \"\"\"\n",
    "    Compute the energy error between the FEM and NN solutions.\n",
    "\n",
    "    Parameters:\n",
    "    K (torch.Tensor): Stiffness matrix (ndof x ndof)\n",
    "    uh_fem (torch.Tensor): Displacement field from FEM (ndof x 1)\n",
    "    uh_nn (torch.Tensor): Displacement field from NN (ndof x 1)\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: Energy error as a scalar\n",
    "    \"\"\"\n",
    "    # Ensure all tensors are of the same type (float32)\n",
    "    K = K.float()\n",
    "    uh_fem = uh_fem.float()\n",
    "    uh_nn = uh_nn.float()\n",
    "    \n",
    "    # Compute strain energy for FEM and NN solutions\n",
    "    U_fem = 0.5 * torch.matmul(uh_fem.T, torch.matmul(K, uh_fem))\n",
    "    U_nn = 0.5 * torch.matmul(uh_nn.T, torch.matmul(K, uh_nn))\n",
    "\n",
    "    # Compute energy error\n",
    "    energy_error = (U_nn - U_fem) / U_fem\n",
    "    return energy_error.abs()  # Return the absolute value of the error\n",
    "\n",
    "import torch\n",
    "\n",
    "def compute_h1_norm(K, uh_fem, uh_nn):\n",
    "    \"\"\"\n",
    "    Compute the H1 norm between the FEM and NN solutions.\n",
    "    \n",
    "    Parameters:\n",
    "    K (torch.Tensor): Stiffness matrix (ndof x ndof)\n",
    "    uh_fem (torch.Tensor): Displacement field from FEM (ndof x 1)\n",
    "    uh_nn (torch.Tensor): Displacement field from NN (ndof x 1)\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: H1 norm error as a scalar\n",
    "    \"\"\"\n",
    "    # Ensure all tensors are of the same type and have requires_grad=True\n",
    "    uh_fem = uh_fem.float().requires_grad_(True)\n",
    "    uh_nn = uh_nn.float().requires_grad_(True)\n",
    "\n",
    "    # Compute L2 norm of the displacement field\n",
    "    l2_error = torch.norm(uh_nn - uh_fem) ** 2\n",
    "\n",
    "    # Compute gradient (strain) of the displacement fields\n",
    "    grad_uh_fem = torch.autograd.grad(uh_fem.sum(), uh_fem, create_graph=True)[0]\n",
    "    grad_uh_nn = torch.autograd.grad(uh_nn.sum(), uh_nn, create_graph=True)[0]\n",
    "\n",
    "    # Compute L2 norm of the gradient (strain)\n",
    "    grad_error = torch.norm(grad_uh_nn - grad_uh_fem) ** 2\n",
    "\n",
    "    # Combine L2 norm of the displacement and gradient\n",
    "    h1_error = torch.sqrt(l2_error + grad_error)\n",
    "\n",
    "    return h1_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(K, uh, F):\n",
    "    \"\"\"\n",
    "    Compute the loss function as (K * uh - F)^2 using PyTorch\n",
    "\n",
    "    Parameters:\n",
    "    K (torch.Tensor): Stiffness matrix (ndof x ndof)\n",
    "    uh (torch.Tensor): Solution vector (ndof x 1)\n",
    "    F (torch.Tensor): Load vector (ndof x 1)\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The loss value\n",
    "    \"\"\"\n",
    "    # Compute the residual\n",
    "    R = torch.matmul(K, uh) - F\n",
    "    \n",
    "    # Compute the loss (squared residual)\n",
    "    loss = torch.sum(R**2)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def compute_loss_with_uh(uh_vem, uh):\n",
    "    \"\"\"\n",
    "    Compute the loss function as (uh - uh_vem)^2 using PyTorch.\n",
    "\n",
    "    Parameters:\n",
    "    uh_vem (torch.Tensor): Solution vector from VEM (ndof x 1)\n",
    "    uh (torch.Tensor): Solution vector (ndof x 1)\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The loss value\n",
    "    \"\"\"\n",
    "    \n",
    "    # Detach uh_vem if necessary to avoid tracking gradients\n",
    "    uh_vem = torch.tensor(uh_vem, requires_grad=True)\n",
    "\n",
    "    # Compute the loss (squared residual)\n",
    "    loss = torch.sum((uh - uh_vem)**2)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def compute_boundary_loss(uh, supp):\n",
    "    \"\"\"\n",
    "    Compute the loss function for enforcing the Dirichlet boundary conditions.\n",
    "\n",
    "    Parameters:\n",
    "    uh (torch.Tensor): Solution vector (ndof x 1)\n",
    "    supp (torch.Tensor): Support vector (ndof x N, where N is the number of nodes with boundary conditions)\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The loss value as a PyTorch tensor\n",
    "    \"\"\"\n",
    "    # Initialize the loss as a scalar tensor with zero\n",
    "    loss = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "    \n",
    "    for node in supp:\n",
    "        if node[1] == 1:  # x-direction fixed\n",
    "            k = 3 * int(node[0])\n",
    "            loss = loss + uh[k] ** 2  # Avoid in-place operation by using a new tensor\n",
    "        if node[2] == 1:  # y-direction fixed\n",
    "            k = 3 * int(node[0]) + 1\n",
    "            loss = loss + uh[k] ** 2  # Avoid in-place operation by using a new tensor\n",
    "        if node[3] == 1:  # z-direction fixed\n",
    "            k = 3 * int(node[0]) + 2\n",
    "            loss = loss + uh[k] ** 2  # Avoid in-place operation by using a new tensor\n",
    "\n",
    "    return loss\n",
    "\n",
    "def compute_material_penalty(model, nodes, material_params_1, material_params_2):\n",
    "    \"\"\"\n",
    "    Computes a penalty for the model if the material parameters don't affect the predictions sufficiently.\n",
    "\n",
    "    Parameters:\n",
    "    mode (str): Material penalty mode ('l1' or 'l2')\n",
    "    nodes (torch.Tensor): Node coordinates (nnodes x 3)\n",
    "    material_params_1 (torch.Tensor): Material parameters for material 1 (nnodes x 1)\n",
    "    material_params_2 (torch.Tensor): Material parameters for material 2 (nnodes x 1)\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: Material penalty term as a scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    input_1 = torch.cat((nodes, material_params_1))\n",
    "    input_2 = torch.cat((nodes, material_params_2))\n",
    "\n",
    "    uh_1 = model(input_1)\n",
    "    uh_2 = model(input_2)\n",
    "\n",
    "    penalty = torch.sum((uh_1 - uh_2) ** 2)\n",
    "    return penalty\n",
    "\n",
    "def normalize_loss_and_penalty(loss, material_penalty, beta=1e-4):\n",
    "    \"\"\"\n",
    "    Normalizes the loss and material penalty by computing the scaling factor alpha.\n",
    "\n",
    "    A factor beta is added to the loss and penalty to avoid division by zero.\n",
    "\n",
    "    Parameters:\n",
    "    loss (torch.Tensor): Loss term as a scalar\n",
    "    material_penalty (torch.Tensor): Material penalty term as a scalar\n",
    "    beta (float): Penalty factor (default: 1e-4)\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: Normalized loss term as a scalar\n",
    "    \"\"\"\n",
    "    loss_magnitude = loss.item() + beta\n",
    "    penalty_magnitude = material_penalty.item() + beta\n",
    "\n",
    "    alpha = loss_magnitude / penalty_magnitude\n",
    "    \n",
    "    return alpha\n",
    "\n",
    "\n",
    "def compute_sobolev_loss(model, nodes, material_params, uh_vem, displacement_loss):\n",
    "    \"\"\"\n",
    "    Computes the Sobolev loss, includging both displacements and derivatives losses.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): Neural network model\n",
    "    nodes (torch.Tensor): Node coordinates (nnodes x 3)\n",
    "    material_params (torch.Tensor): Material parameters (nnodes x 1)\n",
    "    uh_vem (torch.Tensor): Displacement field from VEM (ndof x 1)\n",
    "    displacements_loss (torch.Tensor): Displacement loss as a scalar between uh and uh_vem\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: Sobolev loss as a scalar\n",
    "    \"\"\"\n",
    "    # Concatanete the nodes and material parameters\n",
    "    input_vector = torch.cat((nodes, material_params))\n",
    "\n",
    "    # Compute the displacement field from the neural network\n",
    "    uh = model(input_vector)\n",
    "\n",
    "    # Compute the strain (first derivative)\n",
    "    strain = torch.autograd.grad(uh, nodes, grad_outputs=torch.ones_like(uh), create_graph=True)[0]\n",
    "\n",
    "    # Compute the curvature (second derivative)\n",
    "    curvature = torch.autograd.grad(strain, nodes, grad_outputs=torch.ones_like(strain), create_graph=True)[0]\n",
    "\n",
    "    # Compute the strain loss\n",
    "    strain_loss = torch.sum(strain ** 2)\n",
    "\n",
    "    # Compute the curvature loss\n",
    "    curvature_loss = torch.sum(curvature ** 2)\n",
    "\n",
    "    # Compute the total Sobolev loss\n",
    "    sobolev_loss = displacement_loss + strain_loss + curvature_loss\n",
    "\n",
    "    return sobolev_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_geometry(num_elements_per_edge, L):\n",
    "    \n",
    "    x_coords = np.linspace(0, L, num_elements_per_edge + 1)\n",
    "    y_coords = np.linspace(0, L, num_elements_per_edge + 1)\n",
    "\n",
    "    top_nodes = np.array([[x, L] for x in x_coords if x != 0])\n",
    "    left_nodes = np.array([[0, y] for y in y_coords])\n",
    "    right_nodes = np.array([[L, y] for y in reversed(y_coords) if y != L])\n",
    "\n",
    "    nodes = np.vstack([left_nodes, top_nodes, right_nodes])\n",
    "\n",
    "    elements = np.array([[i, i+1] for i in range(len(nodes)-1)])\n",
    "    flatten_elements = elements.flatten()\n",
    "\n",
    "    supp = np.array([[flatten_elements[0], 1, 1, 1], [flatten_elements[-1], 1, 1, 1]])\n",
    "\n",
    "    return nodes, elements, supp\n",
    "\n",
    "def plot_nodes(nodes, elements):\n",
    "    \"\"\"\n",
    "    Plot the nodes and elements of a 2D mesh.\n",
    "\n",
    "    Parameters:\n",
    "    nodes (np.ndarray): Node coordinates (n_nodes x 2)\n",
    "    elements (np.ndarray): Element connectivity (n_elements x n_nodes_per_element)\n",
    "    \"\"\"\n",
    "\n",
    "    _, ax = plt.subplots()\n",
    "    \n",
    "    # Plot nodes\n",
    "    ax.plot(nodes[:, 0], nodes[:, 1], 'ro', label='Nodes')\n",
    "\n",
    "    # Plot elements as lines connecting nodes\n",
    "    for element in elements:\n",
    "        element_coords = nodes[element]\n",
    "        ax.plot(element_coords[:, 0], element_coords[:, 1], 'b-')\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_title('Custom Geometry Plot')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network for the beam problem\n",
    "class BeamApproximator(nn.Module):\n",
    "    def __init__(self, input_dim, layers, ndof):\n",
    "        super(BeamApproximator, self).__init__()\n",
    "        # First layer from input to the first hidden layer\n",
    "        self.fin = nn.Linear(input_dim, layers[0])\n",
    "        \n",
    "        # Hidden layers\n",
    "        self.hidden = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # Final output layer from the last hidden layer to the output (ndof)\n",
    "        self.fout = nn.Linear(layers[-1], ndof)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through the first layer\n",
    "        z = torch.relu(self.fin(x))\n",
    "        \n",
    "        # Pass through the hidden layers\n",
    "        for layer in self.hidden:\n",
    "            z = torch.sigmoid(layer(z))\n",
    "            # z = torch.nn.functional.leaky_relu(layer(z), negative_slope=0.01)\n",
    "        \n",
    "        # Final output layer\n",
    "        z = self.fout(z)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "class ResidualBeamApproximator(nn.Module):\n",
    "    def __init__(self, input_dim, layers, ndof):\n",
    "        super(ResidualBeamApproximator, self).__init__()\n",
    "        # First layer from input to the first hidden layer\n",
    "        self.fin = nn.Linear(input_dim, layers[0])\n",
    "        \n",
    "        # Hidden layers\n",
    "        self.hidden = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # Final output layer from the last hidden layer to the output (ndof)\n",
    "        self.fout = nn.Linear(layers[-1], ndof)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through the first layer\n",
    "        z = torch.relu(self.fin(x))\n",
    "        \n",
    "        # Pass through the hidden layers\n",
    "        for layer in self.hidden:\n",
    "            z_res = z\n",
    "            z = torch.sigmoid(layer(z))\n",
    "\n",
    "            # Residual block\n",
    "            if z.shape == z_res.shape:\n",
    "                z = z + z_res\n",
    "        \n",
    "        # Final output layer\n",
    "        z = self.fout(z)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "class BeamApproximatorWithMaterials(nn.Module):\n",
    "    def __init__(self, input_dim_nodes, input_dim_materials, nodes_layers, material_layers, final_layers, ndof):\n",
    "        super(BeamApproximatorWithMaterials, self).__init__()\n",
    "        # Neural network for nodes\n",
    "        print(f\"input_dim_nodes =  {input_dim_nodes}\")\n",
    "        self.nodes_in = nn.Linear(input_dim_nodes, nodes_layers[0])\n",
    "        self.nodes_hidden = nn.ModuleList([nn.Linear(nodes_layers[i], nodes_layers[i+1]) for i in range(len(nodes_layers)-1)])\n",
    "        self.nodes_out = nn.Linear(nodes_layers[-1], ndof)\n",
    "\n",
    "        # Neural network for materials\n",
    "        self.materials_in = nn.Linear(input_dim_materials, material_layers[0])\n",
    "        self.materials_hidden = nn.ModuleList([nn.Linear(material_layers[i], material_layers[i+1]) for i in range(len(material_layers)-1)])\n",
    "        self.materials_out = nn.Linear(material_layers[-1], ndof)\n",
    "\n",
    "        # Final output layer\n",
    "        print(f\"ndof =  {ndof}\")\n",
    "        self.final_in = nn.Linear(ndof*2, final_layers[0])\n",
    "        self.final_hidden = nn.ModuleList([nn.Linear(final_layers[i], final_layers[i+1]) for i in range(len(final_layers)-1)])\n",
    "        self.final_out = nn.Linear(final_layers[-1], ndof)  # Output layer\n",
    "\n",
    "    def forward(self, x_nodes, x_materials):\n",
    "        # Pass through the first layer\n",
    "        print(f\"x_nodes.shape =  {x_nodes.shape}\")\n",
    "        print(f\"nodes_in.shape =  {self.nodes_in}\")\n",
    "        print(f\"x_materials.shape =  {x_materials.shape}\")\n",
    "        z_nodes = torch.relu(self.nodes_in(x_nodes))\n",
    "        z_materials = torch.relu(self.materials_in(x_materials))\n",
    "\n",
    "        # Pass through the hidden layers\n",
    "        for layer in self.nodes_hidden:\n",
    "            z_nodes = torch.relu(layer(z_nodes))\n",
    "        z_nodes = self.nodes_out(z_nodes)\n",
    "\n",
    "        for layer in self.materials_hidden:\n",
    "            z_materials = torch.relu(layer(z_materials))\n",
    "        z_materials = self.materials_out(z_materials)\n",
    "\n",
    "        # Concatenate the nodes and materials\n",
    "        z_combined = torch.cat([z_nodes, z_materials])\n",
    "        print(f\"z_combined.shape =  {z_combined.shape}\")\n",
    "\n",
    "        # Pass through the final layers\n",
    "        z_combined = torch.relu(self.final_in(z_combined))\n",
    "        for layer in self.final_hidden:\n",
    "            z_combined = torch.relu(layer(z_combined))\n",
    "        z_combined = self.final_out(z_combined)\n",
    "        \n",
    "        return z_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################### Beam ##########################\n",
      "[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.17339955e-08\n",
      " -2.14427330e-05  2.27723133e-07  1.12629721e-07 -4.28854659e-05\n",
      " -1.24878169e-06  2.62794616e-07 -5.91198655e-05  1.01313694e-07\n",
      " -2.80378315e-08 -6.49375985e-05  2.27919706e-06 -3.96031942e-10\n",
      " -6.55469981e-05 -2.44648029e-06 -9.34621382e-07 -6.61563978e-05\n",
      "  9.97413425e-06  4.01151099e-06 -6.67657974e-05 -4.94893421e-05\n",
      " -1.90264993e-05 -6.73751970e-05  2.33847275e-04 -1.89877264e-05\n",
      " -2.13883922e-05  1.34893551e-04 -1.89489536e-05 -3.95818289e-07\n",
      "  3.38934285e-05 -1.89101807e-05  3.21478705e-06 -4.16219740e-06\n",
      " -1.88714079e-05  1.64297824e-06 -7.56588465e-06 -1.88326351e-05\n",
      "  1.15968873e-07 -3.80380196e-06 -1.87938622e-05 -1.31417160e-07\n",
      "  2.67110206e-06 -1.87550894e-05 -1.49977127e-06 -1.27715466e-05\n",
      " -1.87163165e-05  4.87519701e-06  6.46176812e-05 -5.93255208e-06\n",
      "  4.26579739e-06  3.75985832e-05 -4.48395776e-08  3.65639776e-06\n",
      "  9.44926570e-06  9.87875854e-07  3.04699813e-06 -1.24139342e-06\n",
      "  5.53969497e-07  2.43759851e-06 -2.28370860e-06  1.44723226e-07\n",
      "  1.82819888e-06 -1.04411274e-06 -3.99003619e-09  1.21879925e-06\n",
      " -1.99444530e-07 -1.44603012e-08  6.09399627e-07  6.18312411e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "#########################################################\n"
     ]
    }
   ],
   "source": [
    "num_elements_per_edge = 8\n",
    "\n",
    "# geometry data\n",
    "L = 2.0\n",
    "I = 36e-4\n",
    "A = 0.12\n",
    "\n",
    "# material data\n",
    "E = 20e6\n",
    "\n",
    "# Generate the geometry\n",
    "nodes, elements, supp = generate_geometry(num_elements_per_edge, L)\n",
    "\n",
    "# Plot the nodes\n",
    "plot_nodes(nodes, elements)\n",
    "\n",
    "\n",
    "# loads\n",
    "load = np.array([[2,3],[3,4]])\n",
    "q = -400\n",
    "t = 0\n",
    "f_dist = vem.buildBeamDistributedLoad(load,t,q,nodes)\n",
    "\n",
    "# stiffness matrix\n",
    "K = vem.buildGlobaBeamK(nodes, elements, E, A, I, 1)\n",
    "\n",
    "# apply DBC\n",
    "K, f = vem.applyDBCBeam(K, f_dist, supp)\n",
    "\n",
    "# solve\n",
    "print()\n",
    "print(\"######################### Beam ##########################\")\n",
    "uh_vem = np.linalg.solve(K,f)\n",
    "print(uh_vem)\n",
    "print(\"#########################################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model refers to the disaplcement field and the loss function regards to the calculation of the residual taking in consideration the Virtual Element Method's stiffness matrix and load vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, nodes, K, f, E, A, I, verbose=True, use_residual=False):\n",
    "    ndof = 3 * len(nodes)\n",
    "    input_dim = 2*len(nodes) + 3\n",
    "\n",
    "    nodes = nodes.flatten()\n",
    "    nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "    material_params = torch.tensor([E, A, I], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "    input_vector = torch.cat([nodes, material_params])\n",
    "\n",
    "    lr = 1e-3\n",
    "\n",
    "    # Initialize the model and optimizer\n",
    "    layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024]\n",
    "    # layers = [128, 128, 256, 256, 512, 512, 512, 512]\n",
    "    # layers = [128, 256, 512]\n",
    "    if use_residual:\n",
    "        model = ResidualBeamApproximator(input_dim, layers, ndof)\n",
    "    else:\n",
    "        model = BeamApproximator(input_dim, layers, ndof)\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=0.0000000001, weight_decay=1e-4)\n",
    "    # optimizer = optim.RMSprop(model.parameters(), lr=0.0000000001)\n",
    "\n",
    "    K = torch.tensor(K, dtype=torch.float32, requires_grad=True)\n",
    "    f = torch.tensor(f, dtype=torch.float32, requires_grad=True)\n",
    "    # uh = torch.linalg.solve(K, f)\n",
    "\n",
    "    # epochs = 10000\n",
    "    loss_buffer = float('inf')  # Initialize with a large value\n",
    "    loss_values = []\n",
    "\n",
    "    # Scaling factor for loss\n",
    "    alpha = 1e-17\n",
    "\n",
    "    # Original material parameters\n",
    "    material_params_1 = torch.tensor([E, A, I], dtype=torch.float32)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        uh = model(input_vector)\n",
    "        \n",
    "        # Compute the loss\n",
    "        # loss = compute_loss_with_uh(uh_vem, uh)\n",
    "        loss = alpha * compute_loss(K, uh, f)\n",
    "        sobolev_loss = compute_sobolev_loss(model, nodes, material_params_1, uh_vem, loss)\n",
    "        total_loss = loss + sobolev_loss\n",
    "\n",
    "        # total_loss = loss + penalty_coefficient*loss_bc\n",
    "        \n",
    "        # Only update the model if the new loss is smaller than the loss_buffer\n",
    "        \n",
    "        total_loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        loss_buffer = total_loss.item()  # Update the loss buffer with the new smaller loss\n",
    "        if epoch > 0:\n",
    "            loss_values.append(total_loss.item())\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Epoch: {epoch + 1}, Total Loss: {total_loss.item()}')\n",
    "        \n",
    "        # Early stopping condition if the loss is not improving\n",
    "        # if total_loss.item() >= loss_buffer:\n",
    "        #     print(f'Early stopping at epoch {epoch + 1} as the loss is not improving.')\n",
    "        #     break\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Training complete.\")\n",
    "        plt.plot(loss_values)\n",
    "        plt.xlabel('Epochs (Sub-Epochs)')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss over Epochs')\n",
    "        plt.show()\n",
    "\n",
    "    return input_vector, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the reference displacement field calculated by the Virtual Element Method, a displacemente field is supposed to be calculated considering the material parameters contributions to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_material(epochs, nodes, K, f, E, A, I, verbose=True, network_type='material'):\n",
    "    ndof = 3 * len(nodes)\n",
    "    input_dim = 2*len(nodes) + 3\n",
    "\n",
    "    input_dim_nodes = 2*len(nodes)\n",
    "    input_dim_materials = 3\n",
    "\n",
    "    nodes = nodes.flatten()\n",
    "    nodes = torch.tensor(nodes, dtype=torch.float32, requires_grad=True)\n",
    "    print(f\"Nodes shape: {nodes.shape}\")\n",
    "\n",
    "    # Original material parameters\n",
    "    material_params_1 = torch.tensor([E, A, I], dtype=torch.float32)\n",
    "    print(f\"Material params shape: {material_params_1.shape}\")\n",
    "\n",
    "    # Perturbed material parameters (slightly changed)\n",
    "    material_params_2 = torch.tensor([E *2, A * 2.2, I * 0.35], dtype=torch.float32)\n",
    "\n",
    "    input_vector = torch.cat([nodes, material_params_1])\n",
    "\n",
    "    lr = 1e-3\n",
    "\n",
    "    # Initialize the model and optimizer\n",
    "    if network_type == 'residual':\n",
    "        layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024]\n",
    "        # layers = [128, 128, 256, 256, 512, 512, 512, 512]\n",
    "        # layers = [128, 256, 512]\n",
    "        model = ResidualBeamApproximator(input_dim, layers, ndof)\n",
    "    if network_type == 'material':\n",
    "        nodes_layers = [128, 256, 512]  # Layers for nodes sub-network\n",
    "        material_layers = [128, 256, 512]  # Layers for materials sub-network\n",
    "        final_layers = [1024, 1024, 1024, 1024]  # Layers for final combination network\n",
    "        print(f\"input_dim_nodes_in_pipeline =  {2*len(nodes)}\")\n",
    "        model = BeamApproximatorWithMaterials(\n",
    "            input_dim_nodes=input_dim_nodes, \n",
    "            input_dim_materials=input_dim_materials, \n",
    "            nodes_layers=nodes_layers, \n",
    "            material_layers=material_layers, \n",
    "            final_layers=final_layers, \n",
    "            ndof=ndof)\n",
    "    else:\n",
    "        layers = [128, 128, 256, 256, 512, 512, 512, 1024, 1024, 1024, 1024, 1024, 1024]\n",
    "        # layers = [128, 128, 256, 256, 512, 512, 512, 512]\n",
    "        # layers = [128, 256, 512]\n",
    "        model = BeamApproximator(input_dim, layers, ndof)\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=0.0000000001, weight_decay=1e-4)\n",
    "    # optimizer = optim.RMSprop(model.parameters(), lr=0.0000000001)\n",
    "\n",
    "    K = torch.tensor(K, dtype=torch.float32, requires_grad=True)\n",
    "    f = torch.tensor(f, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "    total_loss_values = []\n",
    "    loss_values = []\n",
    "    material_loss_values = []\n",
    "    sobolev_loss_values = []\n",
    "    alpha_values_values = []\n",
    "\n",
    "    # Scaling factor for loss\n",
    "    # alpha = 1e-17\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        # uh = model(input_vector)\n",
    "        uh = model(nodes, material_params_1)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = compute_loss_with_uh(uh_vem, uh)\n",
    "        # Compute the sobolev loss\n",
    "        sobolev_loss = compute_sobolev_loss(model, nodes, material_params_1, uh_vem, loss)\n",
    "        # Compute material penalty\n",
    "        material_penalty = compute_material_penalty(model, nodes, material_params_1, material_params_2)\n",
    "        # Normalize the loss and penalty\n",
    "        alpha = normalize_loss_and_penalty(loss, material_penalty)\n",
    "        total_loss = loss + alpha * material_penalty + sobolev_loss\n",
    "        \n",
    "        total_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        if epoch > 0:\n",
    "            total_loss_values.append(total_loss.item())\n",
    "            loss_values.append(loss.item())\n",
    "            material_loss_values.append(material_penalty.item())\n",
    "            sobolev_loss_values.append(sobolev_loss.item())\n",
    "            alpha_values_values.append(alpha)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Epoch: {epoch + 1}, Total Loss: {total_loss.item()}')\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Training complete.\")\n",
    "        plt.plot(total_loss_values)\n",
    "        plt.xlabel('Epochs (Sub-Epochs)')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss over Epochs')\n",
    "        plt.show()\n",
    "\n",
    "    return input_vector, model, total_loss_values, loss_values, material_loss_values, sobolev_loss_values, alpha_values_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes shape: torch.Size([50])\n",
      "Material params shape: torch.Size([3])\n",
      "input_dim_nodes_in_pipeline =  100\n",
      "input_dim_nodes =  50\n",
      "ndof =  75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_nodes.shape =  torch.Size([50])\n",
      "nodes_in.shape =  Linear(in_features=50, out_features=128, bias=True)\n",
      "x_materials.shape =  torch.Size([3])\n",
      "z_combined.shape =  torch.Size([150])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1024) must match the size of tensor b (75) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m input_vector, model, total_loss_values, loss_values, material_loss_values, sobolev_loss_values, alpha_values_values \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_material\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mI\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaterial\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# input_vector, model = train(epochs=3000, nodes=nodes, K=K, f=f, E=E, A=A, I=I, use_residual=False)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 69\u001b[0m, in \u001b[0;36mtrain_material\u001b[0;34m(epochs, nodes, K, f, E, A, I, verbose, network_type)\u001b[0m\n\u001b[1;32m     66\u001b[0m uh \u001b[38;5;241m=\u001b[39m model(nodes, material_params_1)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_loss_with_uh\u001b[49m\u001b[43m(\u001b[49m\u001b[43muh_vem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Compute the sobolev loss\u001b[39;00m\n\u001b[1;32m     71\u001b[0m sobolev_loss \u001b[38;5;241m=\u001b[39m compute_sobolev_loss(model, nodes, material_params_1, uh_vem, loss)\n",
      "Cell \u001b[0;32mIn[4], line 37\u001b[0m, in \u001b[0;36mcompute_loss_with_uh\u001b[0;34m(uh_vem, uh)\u001b[0m\n\u001b[1;32m     34\u001b[0m uh_vem \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(uh_vem, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Compute the loss (squared residual)\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum((\u001b[43muh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muh_vem\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1024) must match the size of tensor b (75) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "input_vector, model, total_loss_values, loss_values, material_loss_values, sobolev_loss_values, alpha_values_values = train_material(epochs=2000, nodes=nodes, K=K, f=f, E=E, A=A, I=I, network_type='material')\n",
    "# input_vector, model = train(epochs=3000, nodes=nodes, K=K, f=f, E=E, A=A, I=I, use_residual=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(input_vector, model, uh_vem, K, f):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    \n",
    "    K = torch.tensor(K, dtype=torch.float32, requires_grad=True)\n",
    "    f = torch.tensor(f, dtype=torch.float32, requires_grad=True)\n",
    "    uh_vem = torch.tensor(uh_vem, dtype=torch.float32)\n",
    "\n",
    "    # Ensure gradients are not tracked during prediction\n",
    "    with torch.no_grad():\n",
    "        # Use the trained model to make predictions\n",
    "        predicted_displacements = model(input_vector)\n",
    "\n",
    "    # Print or use the predicted displacements\n",
    "    print(\"Predicted displacements:\", predicted_displacements)\n",
    "\n",
    "    # Compute errors and ensure tensors are on the same device\n",
    "    l2_error = compute_l2_error(uh_vem, predicted_displacements).item()\n",
    "    energy_error = compute_energy_error(K, uh_vem, predicted_displacements).item()\n",
    "    h1_error = compute_h1_norm(K, uh_vem, predicted_displacements).item()\n",
    "\n",
    "    # print(f\"L2 error: {l2_error}\")\n",
    "    # print(f\"Energy error: {energy_error}\")\n",
    "    # print(f\"H1 error: {h1_error}\")\n",
    "\n",
    "    return predicted_displacements, l2_error, energy_error, h1_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_displacements, l2_error, energy_error, h1_error = test(input_vector, model, uh_vem, K, f)\n",
    "print(f\"L2 error: {l2_error}\")\n",
    "print(f\"Energy error: {energy_error}\")\n",
    "print(f\"H1 error: {h1_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbed material parameters (slightly changed)\n",
    "material_params = torch.tensor([E *100, A * 0.2, I * 0.35], dtype=torch.float32)\n",
    "nodes = torch.tensor(nodes.flatten(), dtype=torch.float32)\n",
    "input_vector = torch.cat([nodes, material_params])\n",
    "predicted_displacements, l2_error, energy_error, h1_error = test(input_vector, model, uh_vem, K, f)\n",
    "print(f\"L2 error: {l2_error}\")\n",
    "print(f\"Energy error: {energy_error}\")\n",
    "print(f\"H1 error: {h1_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
